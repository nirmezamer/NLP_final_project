{
    "How often should promotional posts be allowed?": {
        "title": "How often should promotional posts be allowed?",
        "score": 12,
        "url": "https://www.reddit.com/r/dataengineering/comments/1dnemu2/how_often_should_promotional_posts_be_allowed/",
        "content": "Context: We allow self promotion but limit the frequency to once every 2 weeks. This poll is on whether or not we should update the frequency it is allowed.\n\n[View Poll](https://www.reddit.com/poll/1dnemu2)",
        "num_comments": 14,
        "comments": [
            "I am fine with any frequency as long as they are upfront about it.\n\nMost of these fuckers act in a very shady way which has exactly the opposite outcome they are trying to achieve. \n\nI got sucked into getting on call with Firebolt marketing folks and it was giant waste of time.  Has to be one of the shadiest data companies out there.",
            "Given the complexities and level of astroturfing, I'd rather there was zero self promotion, market elsewhere.",
            "It may help to better define self promotion?  For example, if a person works for company X and a conversation has begun organically involving their product, it should be fine for them to pop in to clarify or provide information.  Everyone works for someone.",
            "Is every 4 weeks all that different to once a month?",
            "Zero please.",
            "As one of the people promoting  on here (dlt data load tool), i'd love more clarity on the rules. In their current form they are not applied (1:9 ratio) by any of the promoters. I try to keep my dlt-related answers useful, a healthy ratio of non dlt answers, and post rarely enough, but without explicit rules I can follow, it's anyone's call what is too much. I managed to trigger someone who spreads rumors about me now also on other platforms. If we had explicit rules, they wouldn't feel entitled to seek out and do harm on their own as they could refer to rules and have them enforced if the case, or be in the wrong.\n\nAlso could we differentiate posts from comments explicitly? or explicitly consider them the same? I don't know what's expected, the rule only talks about posts.\n\nAlso, not sure it makes sense for me as a founder to do a 9:1 ratio on posts to be able to communicate major updates, but if we are going to enforce this across the board then that would be fine too.\n\nAlso currently Limit self promo says nothing about frequency just ratio - so it would be good to actually make that rule explicit and clarify what you expect from promoters. Currently it looks like there is one rule (9:1) and nobody follows it. And while  most non-shills just try to be decent communicators and not waste anyone's time, there are many shills too. Would be nice if whatever was agreed between the mods is also communicated to the rest of us so we can know the rule and apply it. I mean here, idk if there are other rules elsewhere:  [https://www.reddit.com/r/dataengineering/about/rules](https://www.reddit.com/r/dataengineering/about/rules)\n\nThere are also companies that use many accounts (maybe their company employees) to get around rules - should they be considered as a single actor?\n\nWhat about marketers that only post content promoting their websites with high regularity? there's at least one that pushes heavily but because he is vendor agnostic it doesn't raise any flags.",
            "Can we force these posts to have a specific flair so we can know it\u2019s a self promotion?",
            "TY for the subtle reminder (for all of us) to go read rule #3 details again.  :)",
            "Force posts to have a self-promotion flair.",
            "Oncee a day"
        ]
    },
    "Quarterly Salary Discussion - Jun 2024": {
        "title": "Quarterly Salary Discussion - Jun 2024",
        "score": 19,
        "url": "https://www.reddit.com/r/dataengineering/comments/1d5q7db/quarterly_salary_discussion_jun_2024/",
        "content": "https://preview.redd.it/ia7kdykk8dlb1.png?width=500&format=png&auto=webp&s=5cbb667f30e089119bae1fcb2922ffac0700aecd\n\nThis is a recurring thread that happens quarterly and was created to help increase transparency around salary and compensation for Data Engineering.\n\n# [Submit your salary here](https://tally.so/r/nraYkN)\n\nYou can view and analyze all of the data on our [DE salary page](https://dataengineering.wiki/Community/Salaries) and get involved with this open-source project [here](https://github.com/data-engineering-community/data-engineering-salaries).\n\n&#x200B;\n\nIf you'd like to share publicly as well you can comment on this thread using the template below but it will not be reflected in the dataset:\n\n1. Current title\n2. Years of experience (YOE)\n3. Location\n4. Base salary & currency (dollars, euro, pesos, etc.)\n5. Bonuses/Equity (optional)\n6. Industry (optional)\n7. Tech stack (optional)",
        "num_comments": 23,
        "comments": [
            "\n1. SR BI Engineer.\n2. 2 YOE after officially pivoting to data only roles. This is after 6-7 years of more jack of all trades roles in IT which included business analysis and reporting duties, along with some implementation projects.\n3. Ohio (100% remote).\n4. 140k base.\n5. 10% of base. $75k in equity vested over 4 years.\n6. SaaS (but on the business side).\n7. Snowflake, DBT, Python, AWS.\n\nI started this role very recently. I'll be staying here as long as I can. It's a great company with room for growth. Previous role I was at 118k, no bonuses or equity, but still 100% remote.",
            "any value in sharing EU salaries?",
            "1. Data Engineer\n2. 2 YOE\n3. Ohio\n4. 98k Base (Will get another raise soon, which I am estimating to be 8%, which would put me at 105840)\n5. 10% - 15% of Base\n6. Aerospace/Aviation\n7. Snowflake, AWS, Python, SQL",
            "Forgot New Zealand in you countries list.",
            "[https://c.tenor.com/lx2WSGRk8bcAAAAC/tenor.gif](https://c.tenor.com/lx2WSGRk8bcAAAAC/tenor.gif)\n\nIs the job market so bad that people are now even ashamed to share their salary?",
            "Is the link to the DE salary page working for anyone else? I get an error any time I try to use it in any browser.",
            "1. Data Migration Specialist\n\n2. 2 YOE\n\n3. NY (Remote)\n\n4. 61k\n\n5. None\n\n6. Health\n\n7. Excel SQL Python",
            "1. Data Engineer\n2. 4 years\n3. New Jersey, USA\n4. $107k\n6. Healthcare\n7. Azure databricks, PySpark, ADF, SQL Server, Snowflake",
            "1. Data Engineer\n\n2. 4 YOE\n\n3. Florida\n\n4. $147K\n\n5. 15% bonus/year\n\n6. Defense Intelligence\n\n7. AWS, SQL, Python, Azure, PySpark, etc.",
            "1. Data Engineer II.\n\n2. Just shy of two years.\n\n3. Midwest.\n\n4. 105k, USD.\n\n5. 20%.\n\n6. Finance.\n\n7. Azure, Databricks, Synapse, DBT. Was: Snowflake, Azure, AWS, DBT, Airflow."
        ]
    },
    "Why does every data engineering job require 3-5+ years experience": {
        "title": "Why does every data engineering job require 3-5+ years experience",
        "score": 87,
        "url": "https://www.reddit.com/r/dataengineering/comments/1dquupe/why_does_every_data_engineering_job_require_35/",
        "content": "Questions:\n\nWhy do most of the data engineering jobs require 3-5 years experience? Is there something qualitative DE jobs are looking for nowadays that can\u2019t be gained through \u201chours in\u201d building data architecture?\n\nWhat is the current overview of the DE job market? Is it exceptionally dry right now? Are there recruiting cycles? Is there a surplus of data engineers?\n\nDo you have personal experience with applying for DE jobs just slightly under minimum required YOE (but you make up for it in other aspects such as side projects, unique perspective, etc)\n\nHere is some context to the questions above:\nI have recently been applying to data engineering jobs and have had miserably low success. I have 2 years traditional work experience but due to my personal projects and startup I\u2019m building I really am competitive for 3-5 year experience jobs. Just based on hours worked compared to 40 hour weeks x 3 years. I come from a top 20 US college & top 10 US asset manager. Ive got a ton of hands on experience in really \u201chot\u201d data engineering tools since I\u2019ve had to build most things from scratch, which I believe to be a significantly more valuable learning experience than maintaining a pre-built enterprise system. My current portfolio demonstrates experience in Kubernetes, Airflow, Azure, SQL&Mongo, DBT, and flask but I feel like I\u2019m missing something key which is why I\u2019m getting so many rejections. Please provide advice or resources on a young less-experienced data engineer. I really love this stuff but can\u2019t get anyone to give me an opportunity.",
        "num_comments": 76,
        "comments": [
            "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
            "Because then they regret hiring people like me with only 3 days of SQL experience before getting the job.",
            "Here\u2019s the argument companies make; don\u2019t kill the messenger \n\nData engineering isn\u2019t a discipline, it\u2019s a combination of disciplines. It combines business context, analytics insight, anticipating business needs, infrastructure, software engineering, SRE, and many other functions. While technical skills can be trained, data engineers benefit from years of experience of figuring out how to motivate software engineers, communicate with product managers, name columns for data scientists, organize data for BI engineers; so on and so forth. Data engineers know (from years of experience) that when the business says \u201cwe need it to refresh real time\u201d, they don\u2019t actually need it real time, SWE won\u2019t promise real time SLAs, dashboards won\u2019t refresh real time, predictive models won\u2019t run inference in real time, and we respond with \u201csounds good, it will refresh daily\u201d.\n\nThere are entries into data engineering all over the place. Most data engineers start in SQL-centric roles or engineering-centric roles. A junior data engineer is usually coming in with a few years of experience in an adjacent discipline.",
            "Junior positions are disappearing across all engineering spaces, not just DE.",
            "I once was recruiting for interns at a startup and I sat down with the Data Director asking about what he is looking for in interns.  Fully knowing that we were talking about interns, he said seriously, that he looked for 2 years of experience...",
            "Managers are too busy to train juniors which is BS. I make my seniors train the mids, and mids train the juniors. Having people below you gives you invaluable experience.",
            "This is BS. I worked in this field for almost 3 decades, and it's totally possible to train people for DE starting from junior. There are plenty of simple pipelines for them to get staryed, just don't throw them them most complex mess you have to load on day 1.\n\nI write it down to lazyness, greed and a mindset of everyone for themselves that will eventually lead to failure. If you have at least one senior person, you can hire a junior. If you lose them after you train6them, it's because you don't want to recognize their growth.",
            "Mostly it\u2019s because of mediocre HR practices and a general desire to not train new employees right now. \n\nBut I will say that there is some weight to the idea that data engineering isn\u2019t the most junior position. \n\nYou can definitely train a junior data engineer, but a good data engineer needs a fairly wide range of technical skills and a decent set of soft skills as well, because you need to be interfacing with your end users. And some industry domain knowledge is extremely helpful. \n\nA junior engineer is a big investment, and a somewhat risky one.",
            "My company stopped hiring juniors. They sometimes promote juniors from the support team, I would maybe try that as there can be a lot of data there. Very frustrating because I see their point in some ways but at other times you have a senior doing a very basic task because you don't have a single junior.\n\nYou also aren't even a true junior. You learn so much in those first 2 years",
            "Well my company, we just aren't hiring juniors or people with 3 years experience who claim to be \"sr eng\" right now.\n\nI can get 1 Staff engineer who will do the work of a mixed 3 person team of juniors and \"seniors\", for less money, less meeting overhead, less ramp time. Plus they are generally older and come with less drama, and aren't looking to jump after 2 years. \n\nI have a paid intern program each summer during which we can usually identify a handful of kids who can be rapidly leveled up to perform at sr. eng level and who dont waste people's time, thats our pipeline for younger talent.\n\nOther then that, true senior (10 year experience) or staff eng is all we are interested in.\n\nI'"
        ]
    },
    "Introducing Sidetrek - build an OSS modern data stack in minutes": {
        "title": "Introducing Sidetrek - build an OSS modern data stack in minutes",
        "score": 11,
        "url": "https://www.reddit.com/r/dataengineering/comments/1dr1eq8/introducing_sidetrek_build_an_oss_modern_data/",
        "content": "Hi everyone,\n\nI think it\u2019s still too difficult to start data engineering projects, so I built an open-source CLI tool called Sidetrek that lets you build an OSS modern data stack in minutes.\n\nWith just a couple of commands, you can set up and run an end-to-end data project built on Dagster, Meltano, DBT, Iceberg, Trino, and Superset. I\u2019ll be adding more tools for different use cases.\n\nI\u2019ve attached a quick demo video below.\n\nI'd love for you to try it out and share your feedback.\n\nThanks for checking this out, and I can\u2019t wait to hear what you think!\n\n(Please note that it currently only works on Mac and Linux!)\n\nWebsite: [https://sidetrek.com](https://sidetrek.com)\n\nDocumentation: [https://docs.sidetrek.com](https://docs.sidetrek.com)\n\nDemo video: [https://youtu.be/mSarAb60fMg](https://youtu.be/mSarAb60fMg)",
        "num_comments": 1,
        "comments": [
            "Thanks for sharing. Looks like it works in a very similar way to a project I started not long ago called insta-infra (https://github.com/data-catering/insta-infra). In the case of insta-infra, it is just a wrapper script around docker compose but I can see you use python instead. Could you do the same with scripts or are you using python for something extra?"
        ]
    },
    "How to start learning data engineering?": {
        "title": "How to start learning data engineering?",
        "score": 4,
        "url": "https://www.reddit.com/r/dataengineering/comments/1dr4isk/how_to_start_learning_data_engineering/",
        "content": "Hi! So first off some background. I\u2019m a data analyst, and everything I have learnt is self taught (I\u2019m actually a chemical engineer by degree). Now I\u2019m currently working at a start up and one of the things my CTO said was that we clone the database and then whatever query I write on Metabase is on the cloned database. However, the company is planning to grow and that means that many of the queries we have written will stop working (some have already started timing out). For this purpose the CTO has told me that you should think about data engineering and see how we can make multiple databases to get around this issue. \n\nMy first question is: how can I bypass the issue by cloning multiple databases? Or should I create multiple databases for different use cases? \n\nMy second question is: where should I start learning about all of this?\n\nThanks!",
        "num_comments": 5,
        "comments": [
            "You can find a list of community-submitted learning resources here: https://dataengineering.wiki/Learning+Resources\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/dataengineering) if you have any questions or concerns.*",
            "How many queries do you have coming to your database at once? \nHow big are your queries? Timeout means that either your query is too big or inefficient. \n\nDo the databases get updated much? New data coming in? - if there is, you may want to execute queries on your most recent dataset so the clones will all have to be synced up to eachother.\n\nDatabases can be clustered such that they are synced up and have backups for redundancy. \n\nI would read about the details of how querying sql databases work, why timeouts happen, and how to avoid them.",
            "Also, I frequently have conversations with ChatGPT when trying to further understand tech concepts like this. It might help copy pasting your post in there lol",
            "I have started using ChatGPT to write my more complex queries for sure! When learning a new concept though I feel like it's not very helpful!\n\nSo any query that takes more than 40 seconds is getting timed out from what I have seen. The majority of the queries that are getting timed out are the ones that deals with the chat event table - which basically has every single event that takes place for all our whatsapp customers, from incoming messages to system events such as tags etc. As far as I know, other than the queries written by the Analytics team, there are numerous cron jobs and queries by the tech team that are also going on. \n\nYeap! The databased DO get updated frequently as it's live data in terms of conversations and slot bookings etc.  I am a complete noob when it comes to databases and all, so I guess I need to start from the basics and understand what is going on to be able to understand what the CTO means when he says think about scaling up the database. Currently we have 100 core team members, and by the end of the year we are planning to make that 3x so the queries are likely to start breaking.",
            "Yeh here\u2019s a useful article for DB scaling options and how they work. Sometimes here I use chatgpt on the side asking it questions like what is a connection pool etc. little definitions\n\nhttps://www.freecodecamp.org/news/understanding-database-scaling-patterns/\n\nEdit: it seems ur database is fairly standard by means of scalability options"
        ]
    }
}