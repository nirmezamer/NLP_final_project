{
    "|Bi-Daily Thread| Ask for help here in the comments or anything you want to post": {
        "title": "|Bi-Daily Thread| Ask for help here in the comments or anything you want to post",
        "score": 0,
        "url": "https://www.reddit.com/r/docker/comments/1dqpzw0/bidaily_thread_ask_for_help_here_in_the_comments/",
        "content": "",
        "num_comments": 0,
        "comments": []
    },
    "Docker compose/build straight to interactive shell?": {
        "title": "Docker compose/build straight to interactive shell?",
        "score": 2,
        "url": "https://www.reddit.com/r/docker/comments/1dr4y00/docker_composebuild_straight_to_interactive_shell/",
        "content": "I'm using `FROM pytorch/pytorch:2.3.1-cuda11.8-cudnn8-devel`, among other build commands, in my Dockerfile, and I'm mounting a bunch of directories from my host to the container.\n\nI'm using `docker compose` (not `docker-compose`, if that makes any difference?)\n\nWhat I'd like is to build the container via my `docker-compose.yml` and to be dropped into an interactive shell inside the container. I've tried a few things like `ENTRYPOINT [\"/bin/bash\"]`, but everything I've tried seems to drop me back to my host shell instead of inside the container.\n\nThe only thing that sort-of works, but is very cumbersome, is to have an entrypoint in my Dockerfile that starts some long-running service, and then to `docker exec -it {container} /bin/bash` from another terminal.\n\nThere has to be a way?\n\nEdit: oh yeah, and in my `docker-compose.yml` I have `user: 1000:1000` so the files created on mounted volumes are owned by me as opposed to root, so it would be great if the shell was in that user also.",
        "num_comments": 4,
        "comments": [
            "Not sure if this fits your use case, but there's `docker compose run`, which spins up required services before running the specified command in the container. I assume it's very similar to `docker run` (don't have time to check rn), so passing `-ti` should give you what you want.",
            "Thanks!\n\nWith \\`tty: true\\` I can \\`docker compose up -d && docker exec -ti {container} /bin/bash\\` and it does exactly what I want! I don't even need to specify a \\`ENTRYPOINT\\` or \\`CMD\\` in the compose file!",
            "Yep.",
            "> I'm using docker compose (not docker-compose, if that makes any difference?)\n\nNot exactly. It used to be `docker-compose` but has been changed to be `docker compose` for quite a while now, so if someone is still using `docker-compose` its a indication that their installed Docker and Compose versions might be out of date. *(There are more details to the historic differences between the two command versions, they didnt just rename it, but thats not the topic here)*\n\nYou should try to seperate your build of the image more from what your compose does. Focus the image itself on whatever application it is providing. The compose should simply provide the settings to run that image with whatever options you want.\n\nYou can add `tty: true` to your compose.\n\nSee the [top answer here](https://stackoverflow.com/questions/66638731/why-do-i-need-tty-true-in-docker-compose-yml-and-other-images-do-not) for some explanation."
        ]
    },
    "postgres connects via docker run but not with docker compose": {
        "title": "postgres connects via docker run but not with docker compose",
        "score": 2,
        "url": "https://www.reddit.com/r/docker/comments/1dqzvi9/postgres_connects_via_docker_run_but_not_with/",
        "content": "What is the difference in running a (pre-built) image via `docker run` with options and `docker compose up`? \n\nUsing `docker run` my server can connect to the postgres server (on the same network) but using `docker compose up` the server throws `Datasource '<default>': Driver does not support the provided URL: jdbc:postgres://pgkeydb/keycloak` error...\n\nUsing same options, connecting to same database on the same network, same user etc...\n\nSome more info for those that didn't my response to first comment:\n\nI am using Dockerfile with compose to build optimized image (as per [Running Keycloak in a container](https://www.keycloak.org/server/containers)) for PRODUCTION purposes (otherwise I would not bother with the pre-built image...)\n\nThe Dockerfile file:\n```Dockerfile\nFROM quay.io/keycloak/keycloak:25.0.1 as builder\n\nVOLUME keycloak-data:/opt/keycloak/\n\nENV KC_HEALTH_ENABLED=true\nENV KC_METRICS_ENABLED=true\n\nENV KC_DB=postgres\n\nWORKDIR /opt/keycloak\nCOPY --chown=1000:0 certs/fullchain.pem /opt/keycloak/fullchain.pem\nCOPY --chown=1000:0 certs/privkey.pem /opt/keycloak/privkey.pem\n\nRUN /opt/keycloak/bin/kc.sh build\n\nFROM quay.io/keycloak/keycloak:25.0.1\nCOPY --from=builder /opt/keycloak/ /opt/keycloak/\n\nENV KC_FEATURES=hostname:v2\nENV KC_DB_URL=jdbc:postgresql://pgkeydb/keycloak\nENV KC_DB_USERNAME=postgres\nENV KC_DB_PASSWORD=some_strong_password\nENV KC_HOSTNAME=keycloak.tld.com\nENV KC_HOSTNAME_PORT=8443\nENV KC_HTTPS_CERTIFICATE_FILE=/opt/keycloak/fullchain.pem\nENV KC_HTTPS_CERTIFICATE_KEY_FILE=/opt/keycloak/privkey.pem\nENTRYPOINT [\"/opt/keycloak/bin/kc.sh\"]\n```\nMy docker-compose.yml (running via `docker compose up -d`)\n```yaml\nservices:\n  keycloak:\n    build: .\n    container_name: service-keycloak\n    command: start --optimized\n    restart: always\n    env_file: \"keycloak.env\"\n    depends_on:\n      - pgkeydb\n    ports:\n      - 8080:8080\n      - 8443:8443\n      - 9000:9000\n    volumes:\n      - keycloak-data:/opt/keycloak\n    networks:\n      - keycloak-network\n  pgkeydb:\n    image: postgres:16\n    container_name: keycloak-postgres\n    restart: always\n    env_file: \"pgres.env\"\n    volumes:\n      - pgkeydb-data:/var/lib/postgresql/data\n    networks:\n      - keycloak-network\nvolumes:\n  keycloak-data:\n  pgkeydb-data:\nnetworks:\n  keycloak-network:\n    name: keycloak-network\n```\nRunning the above with `docker compose up -d` results in error:\n`Datasource '<default>': Driver does not support the provided URL: jdbc:postgres://pgkeydb/keycloak`\n\nRunning with the same options, from the BUILT image (and with the postgres container running, the same container that the yaml refers to, as it built it...) using just:\n\n `docker run -d --name service-keycloak --net keycloak-network -p 58080:8080 -p 58443:8443 -p 59000:9000 -e KEYCLOAK_ADMIN=keyadmin -e KEYCLOAK_ADMIN_PASSWORD=some_strong_password -v keycloak-data service-keycloak start --optimized --verbose`\n\nConnects and runs just fine! ONLY the `docker-compose.yaml` executtion fails! (Provided URL error, but is the EXACT SAME url, to the EXACT SAME Postgres instance and network!!)\nHave tried many multiple variations with the same result...",
        "num_comments": 40,
        "comments": [
            "Is postgres part of the compose file as well?\n\nAlso, when asking for help with a specific configuration, it's generally advisable to share said configuration (both the docker run command and the compose file), else we're all just guessing based on incomplete information.",
            "How do you run your postgres container via docker run? Do you specify the name pgkeydb or keycloak-postgres?",
            "There's really minimal difference.  Compose is basically just a task runner.  A way to declarative define/create docker stuff (networks, volumes, containers).  You can do all the same stuff with either.",
            "I mean can you share how you run the pg container via docker run? docker run\u2026? What name parameter do you use?",
            "So from my understanding the issue is coming from the keycloak image then? But they are the same image. Probably might have to ask on r/keycloak?",
            "Well it's part of the `docker-compose` file (both the keycloak and the postgres services are run from there) so it starts fine. I just leave the postgres instance running for further `compose` tests and then also when I run the `docker run...` command... \n\nIf I shut the postgres instance down then it does not connect, obviously.",
            "I will rebuild the image with `KC_URL` of `jdbc:postgresql://keycloak-postgres/keycloak` then and get back to you. I cannot see how this will make a difference as the `docker run` command is using the same ENV but succeeeding... (if it was incorect then `docker run` would also error...",
            "Not sure.  There's probably some difference between the two.  Try running each and grabbing the docker inspect output then comparing",
            "Have you tried removing the container name (for pg) from the compose file?",
            "> and get back to you. \n\nDont bother."
        ]
    },
    "Docker is awesome, I want more! How do I administer my setup better?!": {
        "title": "Docker is awesome, I want more! How do I administer my setup better?!",
        "score": 17,
        "url": "https://www.reddit.com/r/docker/comments/1dqjmnc/docker_is_awesome_i_want_more_how_do_i_administer/",
        "content": "I am learning docker and containers. I have a better grasp of it now but I wanted to go over a few things to make sure I'm handling this the best way.\n\nIf anyone can point me in the right direction, I'd really appreciate it!\n\nMy setup:\n\nAlmaLinux 9  \nDocker using docker compose files  \nNginx Proxy Manager  \n(all of these containers fall under the same network as NPM)  \n- MariaDB  \n- RocketChat  \n- Mongo  \n- few others\n\nMy file structure:\n\n/home/local/docker/containername/  \n/home/local/docker/containername/docker-compose.yml  \n/home/local/docker/containername/data\n\nExample for MariaDB:\n\n/home/local/docker/mariadb/  \n/home/local/docker/mariadb/docker-compose.yml  \n/home/local/docker/mariadb/data\n\nEverything I've done has been from the command line. Whereas, I do like the command line, it's becoming tedious. Is there any way that I can handle my current containers, that are running on docker compose, without losing my data and be able to administer these containers in a much easier way?\n\nAlso, since I keep my \"data\" in the data folder under each container, what is my best option for backing up docker? Just backup each of these \"data\" directories? Zip them up and send them elsewhere?\n\nOne last thing, if you see anything that could be setup in a better way, please let me know!\n\nThanks all!\n\n",
        "num_comments": 18,
        "comments": [
            "As others have said, Portainer makes container management so much easier. I've got a couple docker host VMs and Portainer makes managing all of them quite easy. To use the corporate term, its a nice \"single pane of glass\" to work with for container management. \n\nI saw someone suggest Dockge as well, never used it so I can't say much for it.",
            "Are you deploying something app centric? If yes, I recommend looking at Kamal which will nicely handle some of the deploy concerns (zero downtime, assets bridging). This weekend I'll finish a first update for Kamal Handbook for latest Kamal 1.7.3 if you would like a starter guide.",
            "I would add portainer and use stacks you can easily convert docker yml file to a portainer stack... you would get some easier monitoring tools and you can install watch tower which will keep your dockers upto date... after that I think next option would be os like proxmox which allows containers basically and VMs .... you can even install portainer or docker on it... with lxc and VM you get more things you can do and run beyond just dockers...",
            "Apparently I have two different accounts. One on my phone and another on my computer. Never noticed lolol",
            "Yup. I have Portainer BE and it has been great. I tied Traefik and Authentik into my system and I love it. All three apps make life way easier.",
            "Absolutely, give me a yell. I'll be futzing with it all weekend. \ud83d\ude01",
            "Great. More stuff to play with. \ud83d\ude01",
            "I'vebeen using NPM but\u00a0I've been having issues with it. I will check\u00a0thoseout. TY!",
            "I do like this idea! Ty!",
            "Portainer for management. Just put it into a compose file like you normally do and run it normally. Boom. Nice GUI for all your docker needs.\n\nAs to backups. Just run a cron rsync job for your compose files and the persistent data folders to a NAS. Or the host if you don't have any type of network storage available. But please sort that out or at least have an external HDD for backups.\n\nI just run a backup once a week and it has been good enough. I'm sure there are more advanced backup methods, but a simple cron job goes a long way."
        ]
    },
    "Docker API under windows with docker in WSL?": {
        "title": "Docker API under windows with docker in WSL?",
        "score": 0,
        "url": "https://www.reddit.com/r/docker/comments/1dqulhn/docker_api_under_windows_with_docker_in_wsl/",
        "content": "I have docker installed as WSL2 images. How can I use docker API, from windows?",
        "num_comments": 7,
        "comments": [
            "If you're using a TCP socket, you can access the same port under Windows.\n\nIf you're using the default Unix socket, I'm not sure if you can access that from Windows.",
            "How do I connect over tcp instead of unix socket? I don't see any mention in the API manual. I'm testing with curl, but want to use python ultimately.\n\n```\nimport docker\nclient = docker.from_env()\n\nresults in CreateFile The system cannot find the file specified. It's using a named pipe.",
            "rtfm ffs",
            "Thank you!",
            "curl --unix-socket /var/run/docker.sock http://localhost/v1.46/containers/json\n\nPrints \"failed to connect to port 80...\"",
            "Exactly how you would use it from anywhere else.\n\nEnable the (TCP) API and then connect to it.\n\n[Read the documentation for details.](https://docs.docker.com/config/daemon/remote-access/)",
            "https://gist.github.com/styblope/dc55e0ad2a9848f2cc3307d4819d819f"
        ]
    }
}