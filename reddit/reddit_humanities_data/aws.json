{
    "Calling all new AWS users: read this first!": {
        "title": "Calling all new AWS users: read this first!",
        "score": 98,
        "url": "https://www.reddit.com/r/aws/comments/16ep32j/calling_all_new_aws_users_read_this_first/",
        "content": "Hello and welcome to the `/r/AWS` subreddit! We are here to support those that are new to Amazon Web Services (`AWS`) along with those that continue to maintain and deploy on the *AWS Cloud*! An important consideration of utilizing the *AWS Cloud* is controlling operational expense (costs) when maintaining your AWS resources and services utilized.\n\nWe've curated a set of documentation, articles and posts that help to understand costs along with controlling them accordingly. See below for recommended reading based on your `AWS` journey:\n\n## If you're new to AWS and want to ensure you're utilizing the free tier..\n\n* [What is the AWS Free Tier, and how do I use it?](https://aws.amazon.com/premiumsupport/knowledge-center/what-is-free-tier/)\n* [How do I make sure I don't incur charges when I'm using the AWS Free Tier?](https://aws.amazon.com/premiumsupport/knowledge-center/free-tier-charges/)\n* [A Beginner\u2019s Guide to AWS Cost Management](https://aws.amazon.com/blogs/aws-cloud-financial-management/beginners-guide-to-aws-cost-management/)\n* [Using the AWS Free Tier](https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/billing-free-tier.html)\n\n## If you're a regular user (think: developer / engineer / architect) and want to ensure costs are controlled and reduce/eliminate operational expense surprises..\n\n* [AWS Well-Architected Framework: Cost Optimization Pillar](https://docs.aws.amazon.com/wellarchitected/latest/cost-optimization-pillar/welcome.html)\n* [AWS Cost Optimization Best Practices](https://aws.amazon.com/aws-cost-management/aws-cost-optimization/)\n* [How to manage cost overruns in your AWS multi-account environment pt1](https://aws.amazon.com/blogs/mt/manage-cost-overruns-part-1/)\n* [How to manage cost overruns in your AWS multi-account environment pt2](https://aws.amazon.com/blogs/mt/manage-cost-overruns-part-2/)\n\n## Enable multi-factor authentication whenever possible!\n\n* [Enabling a virtual multi-factor authentication (MFA) device (console)](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_credentials_mfa_enable_virtual.html)\n* [Different forms of MFA](https://aws.amazon.com/iam/features/mfa/)\n* [Guided tour on how to add MFA to your AWS IAM users](https://pages.awscloud.com/how-to-enable-multi-factor-authentication-for-aws-account.html?nc1=f_ls)\n* [Adding multiple MFA devices to IAM users](https://aws.amazon.com/blogs/security/you-can-now-assign-multiple-mfa-devices-in-iam/)\n\n## [Continued reading material, straight from the /r/AWS community..](https://www.reddit.com/r/aws/search/?q=free%20tier%20AND%20bill%20AND%20costs%20AND%20cost%20AND%20billing&restrict_sr=1&sr_nsfw=&sort=relevance&t=all)\n\nPlease note, this is a living thread and we'll do our best to continue to update it with new resources/blog posts/material to help support the community.\n\nThank you!\n\n**Your** `/r/AWS` **Moderation Team**\n\n    changelog\n    09.09.2023_v1.3 - Readded post\n    12.31.2022_v1.2 - Added MFA entry and bumped back to the top.\n    07.12.2022_v1.1 - Revision includes post about MFA, thanks to a /u/fjleon for the reminder!\n    06.28.2022_v1.0 - Initial draft and stickied post",
        "num_comments": 0,
        "comments": []
    },
    "AWS News at FinOpsX 2024": {
        "title": "AWS News at FinOpsX 2024",
        "score": 2,
        "url": "https://www.reddit.com/r/aws/comments/1dr8oof/aws_news_at_finopsx_2024/",
        "content": "James Greenfield, VP of AWS Commerce Platform, highlighted AWS\u2019s commitment to FinOps practices at the 2024 FinOps X conference. AWS showcased new product capabilities designed to enhance FinOps goals, emphasizing the need for trust, flexibility, and user-friendliness in their Cloud Financial Management (CFM) tools.\n\nCost Optimization Hub\n\nAWS has introduced Data Exports for Cost Optimization Hub, allowing users to receive consolidated cost optimization recommendations in CSV or parquet format directly to Amazon S3.\n\nThis feature simplifies the process of reviewing cost-saving opportunities, such as EC2 instance rightsizing and AWS Graviton migration. Users can customize their data export using SQL queries or filters and integrate these datasets into their data pipelines.\n\nThe service aims to streamline cost optimization by providing easy-to-ingest data files, replacing the need for paginated APIs. With this update, AWS continues to enhance tools for efficient cloud financial management.\n\nRDS Optimizations\n\nAWS has introduced new recommendations for Amazon RDS MySQL and PostgreSQL databases, aiming to improve cost efficiency and performance. The service now detects idle RDS instances and suggests optimal configurations for instance types and provisioned IOPS.\n\nThis update simplifies the process of optimizing database resources, potentially leading to significant cost savings and performance boosts.\n\nCustomers like Wabtec and Here Technologies have already benefited from these insights, streamlining their RDS optimization efforts and confidently adopting AWS Graviton instances based on the provided data.\n\nThe Compute Optimizer analyzes various metrics to provide tailored recommendations, which are now also integrated into the Cost Optimization Hub for a comprehensive view of savings opportunities across an organization.\n\nFOCUS Project support at AWS Billing\n\nAWS introduces Data Exports for FOCUS 1.0 (Preview), a feature allowing users to export AWS cost and usage data with the FOCUS 1.0 schema.\n\nFOCUS, an open-source billing data specification, simplifies cloud cost reporting and analysis. The export aligns with the AWS Cost and Usage Report (CUR), ensuring billed costs match invoiced amounts.\n\nIt offers hourly granularity, and resource-level data, and is available for Consolidated Billing in AWS Organizations. The FOCUS export includes 48 columns, with 43 following the FOCUS standard and 5 AWS-specific.",
        "num_comments": 0,
        "comments": []
    },
    "Issue with IAM Identity Center": {
        "title": "Issue with IAM Identity Center",
        "score": 2,
        "url": "https://www.reddit.com/r/aws/comments/1dransd/issue_with_iam_identity_center/",
        "content": "Hello,\n\n  \nBlindly after creating my free tier account, I\\`ve enabled IAM Identity Center.\n\n  \nNow, after taking some steps into learning AWS, I want to connect from my ubuntu server to the AWS CLI. After surfing the web, I\\`ve found out that I need to go to this IAM Identity Center to retrieve the user\\`s credentials and keys in order to connect.\n\n  \nNow when I\\`m accessing the IAM Identity Center I\\`m faced with the ENABLE button. When pressing it I\\`m getting \"You have already registered another region\".\n\nhttps://preview.redd.it/plgd523ndi9d1.png?width=1799&format=png&auto=webp&s=979910a0e73b19e38352a40b9b9055f55a9166f9\n\n  \nI have went through all regions, and none have this enabled. How can I find out where is this service enabled and how to access/disable it.\n\n  \nThank you!",
        "num_comments": 3,
        "comments": [
            "Wont that be charged as I am a free tier user?",
            "raise support ticket with AWS.",
            "Hi there,\n\nThis doc shows how to enable or disable a [Region ](https://go.aws/3xEzUMU) \n\nIf you're still encountering issues, please create a case to our [Support](https://go.aws/support-center) team for further guidance.\n\n\\- Elle G."
        ]
    },
    "Auto Confirm Email, but not Verify - Amplify": {
        "title": "Auto Confirm Email, but not Verify - Amplify",
        "score": 2,
        "url": "https://www.reddit.com/r/aws/comments/1dragix/auto_confirm_email_but_not_verify_amplify/",
        "content": "Hi all,\n\nI'm working in a Gen 2 Amplify stack and wanting to get the Auth flow working as I want. \n\nA user should be able to login to their account imminently after sign up. I've done this using the auto confirm pre sign up lambda function. I've tried to include a send verification email in the trigger, but haven't been successful.\n\nProblem is, there are some things on the site I want the user to have a Verified email for. I've been unable to figure out how to get this working. It seems like confirmation and verification are very closely tired together and almost interchangeable?\n\nAm I approaching this correctly, or is there a better way of doing this?",
        "num_comments": 0,
        "comments": []
    },
    "How to assess computing cost before purchasing a large dataset?": {
        "title": "How to assess computing cost before purchasing a large dataset?",
        "score": 7,
        "url": "https://www.reddit.com/r/aws/comments/1dr0hgz/how_to_assess_computing_cost_before_purchasing_a/",
        "content": "I've read all the manuals for a few weeks and also familiar with the estimator tool but am still stuck. I will be purchasing a dataset with several tables totaling around 50TB. Each table has around 200 columns/attributes, some of which have billions of observations. It is hosted through a company through AWS, and I want to know a method to be able to estimate my computation costs.\n\nThe dataset will be for academic research purposes. Hence, I will be working a lot with data using SQL through EC2 when I purchase it: taking percentiles of columns, running regressions, and merging with other datasets that I'll upload. I will probably be working three hours a day for three years on it. What is a ballpark I can expect? or knowing what method I should use to get a range.",
        "num_comments": 7,
        "comments": [
            "Is there a reason it has to be on AWS? Dont fall for the belief that cloud equals so much faster than my local environment.  Its just not always true. My M3 Pro MacBook is faster than most affordable cloud instances. For 50GB of data being regularly worked on Id go local before cloud unless I had a compelling reason to do otherwise(sharing, public access, etc.)",
            "In what format will the data be delivered? Will it be parquet files sitting on s3 ultimately?",
            "Ive worked on data of this size. Assuming this is 50TB of compressed Parquet files, storage cost will be $1000/mo if you put it all in S3. A super expensive operation like CTAS select distinct of the entire thing will cost ~$1000 to run using a data lake architecture (Spark in EMR). You can avoid idle compute costs by turning off your EMR cluster when its not being used. Partitioning the data to match your typical query patterns will reduce how much of it is scanned if you are not working with all the data all the time.",
            "Unfortunately, they are hosting it on AWS, and I don't have any say in that. Also, mine is TB, not GB.",
            "If they are hosting it then they can give you an estimate",
            "Ah, gotcha. I misread that. My bad. In that case, yeah, you're in the cloud.",
            "So there's 2 halves to db costs (assuming your using RDS), storage and compute. [https://aws.amazon.com/rds/postgresql/pricing/?pg=pr&loc=3](https://aws.amazon.com/rds/postgresql/pricing/?pg=pr&loc=3) is an example for postgres\n\nStorage depends on how much data you store, at 50TB you're looking in the range of 6k/month (0.01 to 0.0115$ per GB, depending on the exact db type)\n\nCompute depends on how big you make your server, how long you leave it on.\n\nThe smallest of the small for normal mysql/postgres is just $0.016 / hour, which is like, 12$ a month.\n\nThe biggest is like 18$ / hour, which is like 13k/month.\n\nYou can cut this down by turning off the server when you don't use it, but it'll turn itself back on after a day or so.\n\nThe more complicated your queries, the bigger an instance you'll want so you don't sit waiting, but that's impossible for us to say.\n\nOr you can spend about 4.5k$ to download it all once, and just buy a buncha harddrives to put it on. Probably a lot cheaper if you don't mind handling the data yourself. AWS isn't known for being cheap"
        ]
    }
}