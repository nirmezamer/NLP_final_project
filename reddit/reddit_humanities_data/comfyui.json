{
    "PSA: If you've used the ComfyUI_LLMVISION node from u/AppleBotzz, you've been hacked": {
        "title": "PSA: If you've used the ComfyUI_LLMVISION node from u/AppleBotzz, you've been hacked",
        "score": 1018,
        "url": "https://www.reddit.com/r/comfyui/comments/1dbls5n/psa_if_youve_used_the_comfyui_llmvision_node_from/",
        "content": "I've blocked the user so they can't see this post to give you time to address this if you've been compromised. \n\nLong story short, if you've installed and used that node, your browser passwords, credit card info, and browsing history have been sent to a Discord server via webhook. \n\nI've been personally affected by this. About a week after I installed this package, I got a ton of malicious login notifications on a bunch of services, so I'm absolutely sure that they're actively using this data. \n\nHere's how to verify:\n\nThe custom node has custom wheels for the OpenAI and Anthropic libraries in [requirements.txt](https://github.com/AppleBotzz/ComfyUI_LLMVISION/blob/main/requirements.txt).  Inside those wheels are malicious code. You can download the wheels and unzip to see what's inside. \n\n**If you have the wheel labeled 1.16.2 installed:**\n\n* it's actually installing 1.16.3, which doesn't exist. There is no 1.16.3 \u2014 the release history goes from 1.16.2 to 1.17. [https://pypi.org/project/openai/#history](https://pypi.org/project/openai/#history)\n* Inside that package, you'll find /lib/browser/admin.py. This file reads your browser data and stores it in your temp directory in a subdirectory with the format pre\\_XXXXX\\_suf. Inside, you'll find C.txt and F.txt, corresponding to Chrome or Firefox data. \n* The file contains an encrypted string. When you decrypt, it points to a Discord webhook: [https://discord.com/api/webhooks/1226397926067273850/8DRvc59pUs0E0SuVGJXJUJSwD\\_iEjQUhq-G1iFoe6DjDv6Y3WiQJMQONetAokJD2nwym](https://discord.com/api/webhooks/1226397926067273850/8DRvc59pUs0E0SuVGJXJUJSwD_iEjQUhq-G1iFoe6DjDv6Y3WiQJMQONetAokJD2nwym)\n* This file is sending your data to that webhook. \n\n**If you have 1.30.2 installed:**\n\n* Again, it's compromised. You'll find openai/\\_OAI.py. Inside are two encrypted strings that are Pastebin links. I won't paste them here so you don't accidentally download the files... \n* The first Pastebin link contains another encrypted string that, when decrypted, points to another Discord webhook: [https://discord.com/api/webhooks/1243343909526962247/zmZbH3D5iMWsfDlbBIauVHc2u8bjMUSlYe4cosNfnV5XIP2ql-Q37hHBCI8eeteib2aB](https://discord.com/api/webhooks/1243343909526962247/zmZbH3D5iMWsfDlbBIauVHc2u8bjMUSlYe4cosNfnV5XIP2ql-Q37hHBCI8eeteib2aB)\n* The second contains the URL for a presumably malicious file, VISION-D.exe. The script downloads and runs that file. \n* From looking at the rest of the code, it looks like the code is creating a registry entry, as well as stealing API keys and sending them to the Discord webhook. \n\n**Here's how to tell if you've been affected:**\n\n1. Check C:\\\\Users\\\\YourUser\\\\AppData\\\\Local\\\\Temp. Look for directories with the format pre\\_XXXX\\_suf. Inside, check for a C.txt and F.txt. If so, your data has been compromised. \n2. Check python\\_embedded\\\\site-packages for the following packages. If you have any installed, your data has been compromised. Note that the latter two look like legitimate distributions. Check for the files I referenced above. \n   1. openai-1.16.3.dist-info\n   2. anthropic-0.21.4.dist-info\n   3. openai-1.30.2.dist-info\n   4. anthropic-0.26.1.dist-info\n3. Check your Windows registry under HKEY\\_CURRENT\\_USER\\\\Software\\\\OpenAICLI. You're looking for FunctionRun with a value of 1. If it's set, you've been compromised. \n\n**Here's how to clean it up:** \n\nAt least, from what I can tell... There may be more going on. \n\n1. Remove the packages listed above. \n2. Search your filesystem for any references to the following files and remove them:\n   1. lib/browser/admin.py\n   2. Cadmino. py\n   3. Fadmino. py\n   4. VISION-D.exe\n3. Check your Windows registry for the key listed above and remove it. \n4. Run a malware scanner. Mine didn't catch this. \n5. Change all of your passwords, everywhere. \n6. **F\\*\\*\\* that guy.** \n\nBefore you assume that this was an innocent mistake, u/applebotzz updated this code *twice,* making the code harder to spot the second time. This was deliberate. \n\nFrom now on, I'll be carefully checking all of the custom nodes and extensions I install. I had kind of assumed that this community wasn't going to be like that, but apparently some people are like that. \n\nF\\*\\*\\* that guy. ",
        "num_comments": 443,
        "comments": [
            "I think this post needs to get pinned",
            "This needs to be reported to the FBI.",
            "To help people figure out whether OP is fear-mongering or legit, I verified the existance of _OAI.py in the current custom 1.30.2 OpenAI wheel in the linked git hub repository; I didn't reverse engineer it to decrypt the apparent payload strings but it looks for all the world like code designed to be hard to understand but look like machine-compressed js (but it's obviously not to me), and therefore SCREAMS \"suspicious\".\n\nI'd take this one seriously.\n\nVery weirdly, I personally hard a creeped out feeling about LLMVISION when I saw that package, and speculated that anyone trying this kind of thing (I think I was thinking about gathering OpenAI keys) would be quickly found out, but didn't install the package. No idea why I would have felt suspicious though.",
            "this is why we can't have nice things.",
            "the question now is... what other nodes are compromised?",
            "Relaying from the ComfyUI Matrix chat: Manager has been notified and has updated to now contain a check that will detect and warn you immediately if you were affected by this malware\n\nhttps://preview.redd.it/vtxhv4tmyh5d1.png?width=984&format=png&auto=webp&s=94b134ef6fff10c17c660d302eca684e1bd9eece",
            "The asshats have retaliated against me by leaking all of the passwords they stole from me. If anyone has a heart and wants to help me clean up here and fight back, shoot me a DM?",
            "While it isnt going to fully protect you i recommend learning how to install comfyui in a docker container, it isnt necessarily easy but there will be a lot more of stuff like this",
            "OP, did you report it to GitHub?",
            "Thank you for this and I'm sorry you got compromised. F\\*\\*\\* that guy."
        ]
    },
    "reverse image search to find workflows with similar outputs": {
        "title": "reverse image search to find workflows with similar outputs",
        "score": 68,
        "url": "https://v.redd.it/e4lc9rh67d9d1",
        "content": "",
        "num_comments": 7,
        "comments": [
            "hey guys, i always love seeing a cool image online and trying to reproduce it, but trying to find the original method or workflow is troublesome since google\u2018s image search just shows similar looking images. So, i added reverse image search that queries a workflow catalog to find workflows that produce similar looking results.  \n  \nyou can try it out here:\u00a0[https://comfyui-cloud.com/workflows/image-search](https://comfyui-cloud.com/workflows/image-search?utm_source=reddit)  \n  \ni really appreciated the feedback from last time, and would love to hear your thoughts again!",
            "That's a really neat idea. Which websites does it draw the workflows from?",
            "Wowwwwww can\u2019t wait to try this THANK YOU!",
            "it draws from [openart.ai](http://openart.ai) and comfyworkflows right now, am open to suggestions for adding more too",
            "Add civit ai website too",
            "civit ai seems to have a ton, will definitely look into adding them",
            "Cool"
        ]
    },
    "Best all in one workflows": {
        "title": "Best all in one workflows",
        "score": 11,
        "url": "https://www.reddit.com/r/comfyui/comments/1dqz20h/best_all_in_one_workflows/",
        "content": "Hello, I'm a beginner looking for a somewhat simple all in one workflow that would work on my 4070 Ti super with 16gb vram.",
        "num_comments": 6,
        "comments": [
            "Check out my two-pass SDXL pipeline here: [https://github.com/roblaughter/comfyui-workflows](https://github.com/roblaughter/comfyui-workflows)  \nAlso check out the upscale workflow for cranking the resolution and detail on select images.",
            "Probably [this](https://perilli.com/ai/comfyui/). But I agree with the other commenter - make smaller task specific workflows yourself",
            "What do you mean by all in one? What should it include exactly?  \nActually I prefer using smaller specific workflows instead of bigger all in one ones. Specific workflows allow for more flexibility and are wayyy less messy",
            "somethink like this i think [https://openart.ai/workflows/skb/lazy-xl-v2---all-in-one/s1FxAiFzsMWqQnay8Lc3](https://openart.ai/workflows/skb/lazy-xl-v2---all-in-one/s1FxAiFzsMWqQnay8Lc3)",
            "you can try my new workflow, it's ready to go with sdxl, Pixart, sd3 and you can switch off what you don't use. https://civitai.com/models/541962",
            "Text to image with upscaling"
        ]
    },
    "V1.4 | Unlock Powerful New Features in Photoshop with AI Plugin": {
        "title": "V1.4 | Unlock Powerful New Features in Photoshop with AI Plugin",
        "score": 2,
        "url": "https://www.youtube.com/watch?v=dChOlGzeiMs",
        "content": "\nThe latest version of the ComfyUI plugin for Photoshop, V1.4.3, has just been released!\ud83d\udd25\n\n## What's New:\n- \ud83d\udccc **Embedded ComfyUI**\n- \ud83c\udf10 **Remote Rendering**\n- \u2699\ufe0f **Settings Page**\n- \ud83d\udc41\ufe0f **Preview Mode Options**\n- \ud83c\udfa8 **Photopea Integration**\n- \ud83d\udcf7 **Dynamic Previews**\n- \ud83d\udd04 **Load Workflow Button**\n- \u2728 **Simplified Operations**\n- \ud83d\ude80 **Boosted Performance**\n\n## Fixes:\n- Non-English PS fixed\n- Added UTF-8 support\n- Support for all macOS versions\n- Node freeze issue fixed\n- Access issues resolved\n\nIf you have any questions, feel free to ask! \n\n[Subscribe on YouTube to stay updated](https://youtube.com/@nimanzrii?si=bWO4TR-oz-1-SRdu)\n",
        "num_comments": 0,
        "comments": []
    },
    "SD3 now supports ControlNet on Comfy UI!": {
        "title": "SD3 now supports ControlNet on Comfy UI!",
        "score": 50,
        "url": "https://www.reddit.com/r/comfyui/comments/1dqidz2/sd3_now_supports_controlnet_on_comfy_ui/",
        "content": "Hi everyone, ControlNet for SD3 is available on Comfy UI! Please read the instructions below:\n\n1- In order to use the native 'ControlNetApplySD3' node, you need to have the latest Comfy UI, so update your Comfy UI.\n\n2- Right now, there are 3 known ControlNet models, created by Instant-X team: Canny, Pose and Tile. This example is for Canny, but you can use the others as well.\n\nCanny: \u00a0[https://huggingface.co/InstantX/SD3-Controlnet-Canny/blob/main/diffusion\\_pytorch\\_model.safetensors](https://huggingface.co/InstantX/SD3-Controlnet-Canny/blob/main/diffusion_pytorch_model.safetensors)\n\nPose: \u00a0[https://huggingface.co/InstantX/SD3-Controlnet-Pose/blob/main/diffusion\\_pytorch\\_model.safetensors](https://huggingface.co/InstantX/SD3-Controlnet-Pose/blob/main/diffusion_pytorch_model.safetensors)\n\nTile: \u00a0[https://huggingface.co/InstantX/SD3-Controlnet-Tile/blob/main/diffusion\\_pytorch\\_model.safetensors](https://huggingface.co/InstantX/SD3-Controlnet-Tile/blob/main/diffusion_pytorch_model.safetensors)\n\nExample workflow: [https://openart.ai/workflows/sg2IeIOwngVOqZ6Rc5is](https://openart.ai/workflows/sg2IeIOwngVOqZ6Rc5is)\n\nThanks to the ComfyOrg & Instant-X teams!\n\n(Please let me know if anything is missing or inaccurate)\n\nP.s: you might need to adjust your 'strength' and 'threshold' parameters for getting the best results.",
        "num_comments": 28,
        "comments": [
            "In the SD3-based transformer model, the controlnet is deeply integrated into the main diffusion process. It processes the input through parallel sets of 'joint_blocks' and 'controlnet_blocks', applying controlling transformations at each step of the diffusion process. The control signal (hint) is embedded early and influences the entire forward pass. The model produces a list of outputs at different stages, suggesting multi-scale control.\n\nIn contrast, traditional controlnet architectures for convolutional models like SDXL typically:\n\n1. Process the control signal (e.g., edge map, depth map) through a separate network\n2. Inject the processed control information at specific points in the main UNet\n3. Use zero convolutions to allow easy balancing of the control strength\n4. Often have a more rigid structure with predefined injection points\n\nThe SD3 approach seems more fluid, with the control mechanism more tightly woven into the core diffusion process. This could potentially allow for more nuanced and effective control, but may also be more complex to tune or adjust.\n\nThe transformer-based architecture of SD3 also means that the controlnet is operating on a different type of representation compared to the spatial feature maps in convolutional models, which could lead to different strengths and limitations in terms of the types of control that can be effectively applied.\n\nNaively, SD3 should be far more controllable than SDXL. I look forward to seeing more control nets emerge as time goes on. Hoping of course that the license is also fixed\u2026",
            "Canny works but it seems to lose any sd3 quality when it produces an image",
            "Has anybody tested img2img woman lying on the grass, using a decent source image? I'm thinking a reliable creative model to establish the composition, then to SD3.",
            "Many thanks, I will test it later.",
            "Is IPAdapter available yet?",
            "So people are actually training SD3?\n\nI thought it was on pause until the license gets fixed",
            "As long as both canny and openpose work reliably well, it could be possible to have better anatomy. But I have doubts. Although Cascade had both, I could only get canny to work with it. I fear that developers are so reluctant to work with SD3 2B that this is all that artists will have to work with. Same story as Cascade.",
            "Tile? Does this mean upscale and enhance is now possible with SD3?",
            "I'm having trouble running the example workflow. I use a remote GPU version of Comfy UI, so I'm not sure if I have the latest version. I run Comfy UI on Vast.ai. I've tried downloading missing nodes, but one of the nodes I simply cannot find. I get a message \"When loading the graph the following node types were not found, ControlNetApplySD3\"",
            "Is it going to be possible to use InstantID face and ipAdapter with SD3? My current instantID workflow fails when I use SD3"
        ]
    }
}