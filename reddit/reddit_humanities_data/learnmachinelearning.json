{
    "Machine-Learning-Related Resume Review Post": {
        "title": "Machine-Learning-Related Resume Review Post",
        "score": 5,
        "url": "https://www.reddit.com/r/learnmachinelearning/comments/1d8odje/machinelearningrelated_resume_review_post/",
        "content": "Please politely redirect any post that is about resume review to here\n\n  \nFor those who are looking for resume reviews, please post them in [imgur.com](http://imgur.com) first and then post the link as a comment, or even post on /r/resumes or r/EngineeringResumes first and then crosspost it here. ",
        "num_comments": 5,
        "comments": [
            "There's really nothing wrong with your resume, it looks good. You could replace \"Undergraduate teaching assistant\" with \"Course name teaching assistant\", but it probably doesn't matter much.\n\nInternships are sort of a crapshoot, ML/AI ones especially, and it's pretty late in the year to be looking for them. The \"best\" (i.e. most prestigious) ones usually start soliciting candidates in the fall of the year before the summer in which the internship would occur. I think some companies have cut back on internships this year too, as part of a broader trend of cost cutting and layoffs.",
            "I would say move the Positions of Responsibilty section to the last and keep Projects & Tech Skills above it. Your project section is more impressive compared to other section and should be able to grab the recruiter's attention first. It demonstrates your abilities well. Either move it to the bottom or merge it with the Experience section.  \nAreas of Interest section is a bit incoherent.  \nI would drop C Language. Its a thing everyone does in their bachelors and doesnt work as a differentiator.  \nIf you know any proprietary tool or are learning right now, add them too. Industry uses a lot of proprietary tools and expects new hires to at least be familiar with those when they bring you on board (even if they are going to teach you that anyway). I have seen candidates getting rejected purely based on this in my company. Just the fact that you are already exposed to xyz tool or not.",
            "1. I have different versions of structuring resume, so it makes sense to have the project section above POR\n\n\n2. I'll drop the C language. Makes sense, not a differentiator.\n\n\n3. I'll include the proprietary tools I am familiar with. Totally makes sense.\n\n\nThanks !",
            "Hi everyone ! I'm applying for MLE/RE roles (whatever are available at the current moment), and want some resume review. I feel I can do better, so any pointers would be appreciated. Here's the resume : [https://imgur.com/a/FF1zH07](https://imgur.com/a/FF1zH07)",
            "Hey everyone! I'm looking for a resume review. I have been applying to a lot of ML-based internships and have had no luck so far. I have a feeling that my resume is lacking something but I can't really determine what it is. I would appreciate any help that I can get! Thank You!\n\nResume link:  \n[QmMDBea.jpeg (791\u00d71024) (imgur.com)](https://i.imgur.com/QmMDBea.jpeg)"
        ]
    },
    "TIL I have AI chat in WhatsApp ": {
        "title": "TIL I have AI chat in WhatsApp ",
        "score": 33,
        "url": "https://i.redd.it/olgstjq0vh9d1.jpeg",
        "content": "",
        "num_comments": 25,
        "comments": [
            "I dont understand the point of AI on whatsapp, nobody goes to whatsapp to say code or search something.",
            "Is it still exclusive to the US ?",
            "It was added for everyone few days ago , before that beta testers had it",
            "i have had this for last 3 some months & have not used since the day it launched as beta to some users in india , i actually use a lot of other ai tools i, \n\nworst is it uses bing search engine,",
            "Yk WhatsApp has a huge user base here in my place... People who may not be able to browse the internet rely on WhatsApp for almost everything from messaging to content consumption so it makes sense that Meta is trying to tap into the user base they already have.",
            "The point is they want to start training that behavior. It\u2019s why MetaAI is also now on Facebook and Instagram. It\u2019s a way for meta to now capitalize on search data (which they\u2019ve been hungry for since googles creation) and psychometric data which they excel in.",
            "Umm actually I noticed this new icon, I clicked and there was this chatbot apparently powered by llama 3",
            "Nope I live in India",
            "Now I really feel like I was living under  a rock.\n It's a cool thing. I don't really use much ai tools, just ChatGPT and openai APIs. But now I really wanna dig deep it llama 3, kinda excited to as I'm about to start learning RAG.",
            "I never understood that, are there no ISPs in India? Or do they only offer access to Facebook and WhatsApp?"
        ]
    },
    "Let's execute a full-scale GPT-2 pre-training run in TinyGrad": {
        "title": "Let's execute a full-scale GPT-2 pre-training run in TinyGrad",
        "score": 7,
        "url": "https://www.reddit.com/r/learnmachinelearning/comments/1drb5l7/lets_execute_a_fullscale_gpt2_pretraining_run_in/",
        "content": "Hey everyone,\n\nTLDR: I'm reproducing the results of Andrej Karpathy's GPT-2 pre-training in TinyGrad. Join this discord if you want to do this and eventually create an entire LLM with your bare hands. Once this is done, I have plenty of other ideas for models to train, but this is a good starting point for executing larger training runs. Interested? [Join the discord](https://discord.gg/rbm66fnA) and let's get it done.\n\n  \nFor those who aren't familiar, TinyGrad is a tensor automatic-differentiation library being developed with a particular focus on conciseness(\\~8000 LOC) and cleaner abstractions than existing frameworks. This makes it really easy to add new accelerators, debug errors, and just understand what's really going on. It has lots of unique features (i.e. native kernel fusion) and in general feels so much more pure than PyTorch. As for speed, it is generally slower than PyTorch on Nvidia but beats it in most other settings, and will likely eclipse it on every accelerator the coming years.  \n  \nIn the words of their genius founder George Hotz, \"we will beat pytorch at speed, API simplicity, and having less bugs. if we do that, we win.\" I really do believe in this, and I think you will be compelled to believe the same after using it. To start, I recommend checking out beautiful\\_mnist.py in the examples folder of their repo. The outward facing API is very similar to PyTorch (although even cleaner to use), so if you're good with Torch there will be a very minimal learning curve.  \n  \nBack to the subject of the psot, I was inspired by Andrej Karpathy\u2019s \u201cLet\u2019s Reproduce GPT-2\u201d video and wanted to replicate the results in TinyGrad. In particular, there are two things to match: training tokens/s and model performance (val loss and HellaSwag). It only took a couple hours of work to complete the unoptimized version (training + support for loading pre-trained weights), but the real challenge is in optimization. While I've already fleshed out a lot of the basic infrastructure, there is still a good amount of bug-fixing/features to be added, as well as evaluation. Once those are done, there will be some TinyGrad-specific optimizations like BEAM search that should hopefully bring the performance closer to the Torch implementation, but that\u2019s pretty much it.  \n  \nI have access to some A100s through my university, and am also willing to cover the cost of the final training run because the university GPUs may not be enough (probably want 8xA100). I've created a [discord server](https://discord.gg/rbm66fnA) and pushed everything I have to a public GitHub repo. Send me a DM if you have any questions.",
        "num_comments": 0,
        "comments": []
    },
    "why did andrej karpathy say this about learning cuda now? ": {
        "title": "why did andrej karpathy say this about learning cuda now? ",
        "score": 2,
        "url": "https://www.reddit.com/r/learnmachinelearning/comments/1dre3y9/why_did_andrej_karpathy_say_this_about_learning/",
        "content": "https://preview.redd.it/vxs8xq6k7j9d1.png?width=1260&format=png&auto=webp&s=4a71c7357e0e8520a194d9a3b29135b3fc3968ff\n\n",
        "num_comments": 0,
        "comments": []
    },
    "Is there a good deep learning course without math prerequisite that teaches necessary math along the course ?": {
        "title": "Is there a good deep learning course without math prerequisite that teaches necessary math along the course ?",
        "score": 28,
        "url": "https://www.reddit.com/r/learnmachinelearning/comments/1dqx4mr/is_there_a_good_deep_learning_course_without_math/",
        "content": "I think learning math in parallel with deep learning maybe more interesting than learning math first and after deep learning. Is there a good deep learning course without math prerequisite that teaches necessary math along the course ?",
        "num_comments": 17,
        "comments": [
            "That would be like trying to pick up algebra inside the diff eq course. Grab some books with titles like \u201ccalculus for machine learning\u201d and, more importantly, \u201clinear algebra for machine learning\u201d. If you want to learn to do it correctly though then also grab a book on probability theory. After that you\u2019ll be set to dip your toe in. Without a deep background in stat though, your experience in machine learning will always be somewhat limited",
            "I don't think so, just because the math prerequisites are quite large. If you already have a stats and calculus foundation though you might be able to find this. But if you are starting from 0 it is going to just be a math course",
            "If you were to start along the typical undergrad math track, you wouldn't have the prerequisites completed until sometime in year 2 or 3.",
            "Check out the fast.ai course, it's known for being beginner-friendly and teaching the math as you go.",
            "Yes, it is called a CS degree.",
            "Not really. Courses either assume a reasonable knowledge of math, and cover deep learning using math. Or they just skip the math and explain it mostly using diagrams and other tools.",
            "Depends on how much math we are talking about? Do you have problems with basic arithmetic, have no idea what a function is? Then no, I don't think so.",
            "you'd be doing a lot of stuff without understanding why you doing these things. It's like doing everything a Stoic would without even understanding why they do those actions at all. They'd make a not very good Stoic.",
            "What's this one called? Thx",
            "Unlike all these gatekeepers, I don\u2019t have a strong math background during high school. I took Machine Learning course on Coursera and later on it become a deepleaening.ai course by Andrew Ng.\n\nThe man is inspiring and doesn\u2019t discourage learner from \u201coh you need to know stats to study my course\u201d kind of Bull sht . His course alone inspire me to study linear algebra and calculus alongside machine learning.\n\nTry deeplearning.ai by Coursera. Should encourage you enough to side study math and machine learning."
        ]
    }
}