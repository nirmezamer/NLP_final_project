{
    "[D] Simple Questions Thread": {
        "title": "[D] Simple Questions Thread",
        "score": 17,
        "url": "https://www.reddit.com/r/MachineLearning/comments/1dh9f6b/d_simple_questions_thread/",
        "content": "Please post your questions here instead of creating a new thread. Encourage others who create new posts for questions to post here instead!\n\nThread will stay alive until next one so keep posting after the date in the title.\n\nThanks to everyone for answering questions in the previous thread!",
        "num_comments": 101,
        "comments": [
            "Hi everyone, I have a question about decoders. For LMs, the text generation stops when some special token, e.g., <EOS>, is generated. How does the generation stop for transformer decoders that don't generate discrete tokens via softmax? One of the approaches I know is to set a predefined length, but is there a more dynamic way of doing so? Thanks!",
            "To all people in this sub who are Machine Learning Engineer's, what are you doing daily as part of your job, projects that you're working on and skills that you have/need to learn to complete the said project. Will be super helpful if answered cuz I just started learning ML and lost figuring out what to learn and from where to learn.",
            "is it possible for an llm to adjust its own weights on the fly based on my replies? afaik there are several RL techniques but can they adjust weights *on the fly* based *only on replies*, like trying to act more like when i praise it and less like when i scold it? do it work with rnn-like models like mamba, rwkv and based or it will probably ruin the current state?",
            "I'm working on my first computer vision project, which involves annotating charts for their underlying data-table. I'd like to fine-tune an existing model I've found, but all resources for doing so primarily share code, without logic or details about dataset generation, required dataset size, best practices for dealing with common failure cases, learning rate (this is covered a bit though), epochs, etc. What are good resources for learning about all of these very specific decisions, or any other good in depth nitty-gritty resources for similar topics in deep learning in general?",
            "Hi, so I'm working on a project in which I want to calculate the cosine similarity between a query vector and corresponding document vectors ( around a billion of them ) and then threshold them to get the most relevant documents.  The number of relevant documents isn't bounded so kNN isn't very relevant other than for initial pruning. Here, the speed is of the essence so the scale is a problem. I initially looked into FAISS but is there any other thing that I can look at that would be faster than FAISS? Also, should I instead turn to some other programming language altogether to get the additional boost in performance? Note that finally I'm supposed to deploy it on gcp.",
            "**When authors use the term \"ill conditioned\" for machine learning problems what do they mean?**\n\nI have read some papers about optimization techniques for machine learning and sometimes people just use the term \"ill conditioned\" but don't say what they mean by it. I know conditioning for matrices but those authors talk about \"ill conditioned objectives\" or optimization techniques that \"deal with ill conditioning\". What do they mean by that?",
            "Is anyone here trying to get Austrian Visa for ICML? I'm applying from NYC and can try for group door-step appointment if there are few. Otherwise its inordinately expensive.",
            "other things being equal, what will have better performance: a model like based (an rnn-like model + small sliding window attention), or like mamba2-hybrid (an rnn-like model + full context attention) + TOVA with the same size as based-like's window?",
            "Looking for an advance Machine Learning book.\n\nHi everyone, recently i had finish Bishop Deep Learning book and i found it interested. I want to read more about advance topic in machine learning (especially multimodal field). Can anyone suggest me some books to read ? (like same type Bishop book, i really love it).",
            "Hello Everyone\n\nCan someone tell me if I can use EncoderDecoder Model such as T5 for pretraining using Causal Language Model? I want to pretrain it for Next word prediction"
        ]
    },
    "[D] \"Grok\" means way too many different things": {
        "title": "[D] \"Grok\" means way too many different things",
        "score": 132,
        "url": "https://www.reddit.com/r/MachineLearning/comments/1dqpyb3/d_grok_means_way_too_many_different_things/",
        "content": "I am tired of seeing this word everywhere and it has a different meaning in the same field everytime. First for me was when Elon Musk was introducing and hyping up Twitter's new (not new now but was then) \"Grok AI\", then I read more papers and I found a pretty big bombshell discovery that apparently everyone on Earth had known about besides me for awhile which was that after a certain point overfit models begin to be able to generalize, which destroys so many preconceived notions I had and things I learned in school and beyond. But this phenomenon is also known as \"Grok\", and then there was this big new \"GrokFast\" paper which was based on this definition of Grok, and there's \"Groq\" not to be confused with these other two \"Grok\" and not to even mention Elon Musk makes his AI outfit named \"xAI\" which mechanistic interpretability people were already using that term as a shortening of \"explainable AI\", it's too much for me",
        "num_comments": 85,
        "comments": [
            "The act of grokking was introduced in Heinlein's Stranger in a Strange Land. All other uses are categorical errors.",
            "Just go read stranger in a strange land and you'll understand why they chose \"grok\" in those papers.",
            "To be fair the problem seems to be Musk (the grokking paper came before Twitter's Grok and xai for explainable AI came before his xAI)",
            "(no one tell OP how overloaded the term \"bias\" is)",
            "As far as I know the only meaning of grok is \"understand.\" Product names don't matter",
            "you will be pleased to meet its friends Kernel and Normal",
            "STEM people in general (and CS people in particular, and AI/ML people in ssuper particular) love to show off how \"clever\" they are with acronyms or overloading already well-defined terms (especially from other fields). It's frankly annoying and causes unnecessary confusion.",
            "It comes from a sci-fi novel and was intentionally an uwu/vague/philosophical notion. Then it was picked up by hacker culture, where we were just having fun and didn't really need to give a damn about exact definitions. It's not supposed to be a powerfully technical term.",
            "grok means to grasp intuitively, and has so for decades",
            "It's a stupid term that doesn't add to our understanding"
        ]
    },
    "[D] Why do DINO models use augmentations for the teacher encoder?": {
        "title": "[D] Why do DINO models use augmentations for the teacher encoder?",
        "score": 7,
        "url": "https://www.reddit.com/r/MachineLearning/comments/1dr6aad/d_why_do_dino_models_use_augmentations_for_the/",
        "content": "As in title - DINO and DINOv2 use augmentations for inputs that go into the teacher networks. Why is this? Doesn't it make more sense to generate teacher representations from the \"cleanest\" possible version of the data? Would really appreciate getting to hear what the intuition is behind what they did.",
        "num_comments": 5,
        "comments": [
            "You don't wanna get a hidden representation of certain aspects of the training data, such as orientation, size, whathaveyou. That means that your decoder should produce the correct output, no matter if your input is flipped, rotated, zoomed in, whatever. That is why  you augment, to get rotation, mirroring, etc. represented in the hidden state.\n\nDisclaimer: This is to the best of my knowledge.",
            "sure that makes sense for what the student gets but why the teacher?",
            "As far as I understand it, DINO (as well as SimCLR, BYOL, SimSiam...) learn augmentation-invariance through contrastive learning / self distillation etc. \nThe idea is that the network encodes the features of the data unaffected by augmentations. So, even if you augment the images passed to the teacher model, the properties you want to encode are still there.\n\nOn the other hand, augmenting the teacher images makes for more diverse \"target\" encodings for the student model.",
            "Could you clarify what you mean by \"augmentation for inputs into the teacher network\"? From what I recall, the student and teach models both receive the same inputs (a quick glance at the official implementation confirms).  \nIs the question: why doesn't the teacher receive inputs without augmentation while the student receives augmented inputs?    \nIf so, it's to align the prediction task, since augmentation can lead to token misalignment (due to scale and rotation) and could obscure the classes (with color shifts - e.g. the \"firetruck\" embedding may be weaker with a hue shift toward green). Since DINO uses patch-based self-supervision, the embeddings have a direct spatial relationship in the loss function (flipped images would make that impossible).  \nIn general, the teacher model will be more capable of predicting the outputs (since it's bigger), which would mean giving the student a much harder task than the teacher originally had during training (this is why the teacher output have a temperature too). The goal is not to produce the best possible model with distillation, but is to produce a model similar to the teacher. \n\nAlso, augmentation is mainly used to \"artificially\" increase the dataset size and remove biases in the collection process (e.g. perfectly horizontally aligned subjects with good color correction). Ideally the model would only see each image once during training, and the images would be varied enough so that augmentation would not be necessary."
        ]
    },
    "[D] Anyone see any real usage of Kolmogorov-Arnold Networks in the wild?": {
        "title": "[D] Anyone see any real usage of Kolmogorov-Arnold Networks in the wild?",
        "score": 47,
        "url": "https://www.reddit.com/r/MachineLearning/comments/1dqr9gh/d_anyone_see_any_real_usage_of_kolmogorovarnold/",
        "content": "KANs were all the hype everywhere (including Reddit), and so many people had so much to say about it, although not all good. It's been around 3 months now. Has anyone seen anything to either corroborate or contradict the \"believers\"? Personally, I have not seen the adoption of KANs anywhere noteworthy. Would like to hear from the community.",
        "num_comments": 22,
        "comments": [
            "No, I think the problem with Kolmogorov Arnold its not locally smooth like NN",
            "Can someone ELI20 KANs? I just haven't a chance to read up on it at all.",
            "The KAN hype is really bizarre because the main point seems to be that they are supposedly better than MLPs, but MLPs never \"worked\" for regression. There is a reason why MLPs were seldomly used in the early 2000s, they just don't work. Then doing better than MLPs is not really that impressive.",
            "People have unrealistic expectations where they expect AI to bootstrap itself to the moon by next Tuesday because its all moving so fast!\n\nIn reality it takes time for ideas to spread and be adopted, even if they work. And KANs havent even been proven to work yet.",
            "and the concept is not a entirely new one, with similar approaches in the 80s. It is worth revisiting, but its not like we will get a better architecture overnight",
            "You can think about it as development of trainable ReLU. Replace ReLU with spline - nonlinear approximator with a lot of parameters. Because spline have built-in multiplications we don't need matrix multiplication after spline layer. Instead it's simple row sum. Effectively matrix merged into nonlinear layer. Relation to Kolmogorov-Arnold representation is tangential. Kolmogorov-Arnold theorem saying about representing any continious function  as composition and sum of single variable functions. But composing functions in theorem are *very* bad. Like Banach-Tarski bad (not literally but you get the idea). Not like nice, smooth splines at all.",
            "Huh? MLPs are widely used and are sort of the default neural network. Transformers are just MLPs + attention layers.",
            "They are used in there not because they are good at regression, but they are easy to use as a module that provides non-linearity in end-to-end deep learning stuff. A lot of papers in the 2000s benchmarked various models for regression, and MLPs were  never really particularly good at it.",
            "Pretty much all neural architecture are small variations on MLPs. I would even call attention as basically 3 MLPS except even less than that.",
            "Can you elaborate on what for regression means?"
        ]
    },
    "[D] When using embedding models \u2026.": {
        "title": "[D] When using embedding models \u2026.",
        "score": 2,
        "url": "https://www.reddit.com/r/MachineLearning/comments/1dr86u3/d_when_using_embedding_models/",
        "content": "When using embedding models to incorporate new, extensive data into LLMs like GPT-4, is manual data preparation (cleaning, classification, etc.) necessary, or do these models handle it automatically?\n",
        "num_comments": 1,
        "comments": [
            "It's really hard to tell nowadays with these large and powerful models being close-sourced.\n\nPersonally, it seems like the trend is thinking how can we include instructions or few-shot demonstrations better rather than how can we pre-process the input data itself.\n\nI guess you could call the former pre-processing as well though."
        ]
    }
}