{
    "Sunday Daily Thread: What's everyone working on this week?": {
        "title": "Sunday Daily Thread: What's everyone working on this week?",
        "score": 10,
        "url": "https://www.reddit.com/r/Python/comments/1cke7cp/sunday_daily_thread_whats_everyone_working_on/",
        "content": "# Weekly Thread: What's Everyone Working On This Week? \ud83d\udee0\ufe0f\n\nHello /r/Python! It's time to share what you've been working on! Whether it's a work-in-progress, a completed masterpiece, or just a rough idea, let us know what you're up to!\n\n## How it Works:\n\n1. **Show & Tell**: Share your current projects, completed works, or future ideas.\n2. **Discuss**: Get feedback, find collaborators, or just chat about your project.\n3. **Inspire**: Your project might inspire someone else, just as you might get inspired here.\n\n## Guidelines:\n\n* Feel free to include as many details as you'd like. Code snippets, screenshots, and links are all welcome.\n* Whether it's your job, your hobby, or your passion project, all Python-related work is welcome here.\n\n## Example Shares:\n\n1. **Machine Learning Model**: Working on a ML model to predict stock prices. Just cracked a 90% accuracy rate!\n2. **Web Scraping**: Built a script to scrape and analyze news articles. It's helped me understand media bias better.\n3. **Automation**: Automated my home lighting with Python and Raspberry Pi. My life has never been easier!\n\nLet's build and grow together! Share your journey and learn from others. Happy coding! \ud83c\udf1f",
        "num_comments": 37,
        "comments": [
            "Not sure if it counts, and I'm a newbie to this subreddit, but ... starting to slowly read the Fluent Python book and work though the examples.\n\nI'm just an amateur coding in Python to build smallish (3-20kloc) programs to support my main hobby, and I'm tired of the feeling that I could be much more effective if I learned the language systematically instead of one Google search at a time.",
            "Working on kicking out tutorials for the coding challenges I have gotten as a principal/senior engineer so that others can benefit from my terrible interview experiences.",
            "Working on a evolution sim, where each creature is an independent small neural network, sized 3/16/4. Mutation by random modding selected weights.\nDisplaying the movements in a 3d world. Creatures are low poly 3d models.  Thusly also working on a 3d projection engine.\nPredictable,  at more than 80 creatures my modest desktop grinds to about 1 fps \nSo sone optimisation to do (numba?)\nAnyway its just my hobby, huge fun.",
            "I just released [qtile-bonsai](https://github.com/aravinda0/qtile-bonsai) yesterday!\n\nIt's sort of an extension for the python-scriptable [qtile](https://github.com/qtile/qtile/) tiling window manager , that lets you arrange your windows as splits, tabs and even sub-tabs.",
            "Hi everyone,\n\nI just coded a chat application tailored for family use. Motivated by the high costs associated with the team version of ChatGPT, I sought an alternative that uses the cost-effective OpenRouter API and OpenAI's API services.\n\nThe app features:\n\n* **Conversational Memory:**\u00a0For more natural discussions.\n* **PDFChat:**\u00a0To easily talk about content in PDF documents.\n* **Image Generation:**\u00a0For creating images from text prompts.\n\nIt was a personal project to better connect with my family, but I thought it might be helpful to others seeking similar solutions.\n\nIf you\u2019re interested, you can check it out here:\u00a0[Family Chat on GitHub](https://github.com/DrDavidL/family-chat/blob/main/README.md)\n\nI\u2019m really hoping it can be useful to someone else, and I\u2019m open to any feedback or suggestions.\n\nThanks for checking it out!",
            "Built an AI weather forecasting tooling [repo](https://github.com/secondlaw-ai/skyrim) on top of large weather models. They are like LLMs in the sense that it has been really painful to run & experiment with them. Any feedback welcome!",
            "heyo, recently made a personal budget tracker in python using oop it calculates the total saving,total expenses and annual income of a person. However im snot able to calculate the or truly depict the result of annual income rest all are working fine.",
            "Currently working on a Terminal User Interface (TUI) build with the great [Textual](https://textual.textualize.io) package for [Rye](https://rye-up.com) the relatively new project/package manager.   \nIf you want to try it out already you can find more infos [here (github)](https://github.com/Zaloog/rye-tui).",
            "2 things, the first is only Python related, a set of [Just Files](https://github.com/casey/just) to manage my Python projects\n\n[https://github.com/sffjunkie/justfiles/](https://github.com/sffjunkie/justfiles/)\n\nand the second a command line tool to manage \\`.gitignore\\` files",
            "I have created a command line tool that tries to put together the find command with the tree command by generating a **tree** with the search results.\n\nThis is a screenshot to get an idea how it works:\n\n[vifind](https://www.reddit.com/media?url=https%3A%2F%2Fpreview.redd.it%2Fvisual-version-of-gnu-find-v0-3g6n4rc97evc1.jpg%3Fwidth%3D1918%26format%3Dpjpg%26auto%3Dwebp%26s%3D9eeec96b67fc0161cabaa52d24de2917327c3388)\n\nIt is written completely in **python** (with the standard libraries) under the GPL licence, any advice/contribution is appreciated.\n\nThe repository with the documentation can be found [here](https://codeberg.org/notanamber/nerd_tree)",
            "Working on a PDF library: [https://github.com/desgeeko/pdfsyntax](https://github.com/desgeeko/pdfsyntax)",
            "I'm working on a novel class of GA. When I say novel  I mean it. no one has anything like this. Im still refining it and building up the frame work for easy testing and deployment. Right now its capable of transfer learning and incremental learning between runs. The framework is designed to work with discrete genes. just define the fitness class and the gene set and go. still refining things and fully understanding how the innerworkings play together. Working on getting everything set for a patent application.",
            "Not sure if it counts but I'm working on using visualization llibraries in python to create an interactive visual of the the globe where each country can be clicked on to see FIfa20 players who are in the game and from that country.",
            "A memecoin sniper bot (on Solana); hopefully I can buy a lambo soon /s",
            "I'm trying to make a program with a timer, stopwatch and date calculator",
            "trying to roll out some platform improvements: logging, upgrading python versions across different projects, adding type hinting to all our systems and improving the database access layer/code - lots of generic type hinting (everything is a dict)",
            "I am still trying to figure things out because i am new to programming,",
            "In an ideal world, I would have an automatic web-form filling tool that could do the job in 0-2 seconds to get very highly coveted / very hard to get tickets... From researching a possible bot to do this today, it seems Python might be the right language to do that. the issue is that I know absolutely jack-shit about Python... Anyone here knowledgeable about something like this? PM me if so",
            "I'm working on a new GUI framework that lets you create modern web apps in just a few lines of Python. Our goal is to simplify web and app development, so you can focus on the things you care about.\n\nWe do this by following the core principles of Python that we all know and love. Python is supposed to be simple and compact - and so is [Rio](https://rio.dev/). There is no need to learn any additional languages such as HTML, CSS or JavaScript, because all of the UI, Logic, Components and even layouting is done entirely in Python.\n\n```\nclass MyComponent(rio.Component):\n    clicks: int = 0\n\n    def _on_press(self) -> None:\n        self.clicks += 1\n\n    def build(self) -> rio.Component:\n        return rio.Column(\n            rio.Button('Click me', on_press=self._on_press),\n            rio.Text(f'You clicked the button {self.clicks} time(s)'),\n        )\n\napp = rio.App(build=MyComponent)\napp.run_in_browser()\n```\n\nGive Rio a star on [GitHub](https://github.com/rio-labs/rio) to help us grow. :)",
            "I recently finished a small self-project for my work with creating a small script. I Am a supervisor of 40 employees and we started a new rotating day off schedule. I noticed with the schedule there is 4 groups and within those groups of people are employees who would like to be called in if  we need their help and offer them overtime. I created a list of each 4 groups and use the random import to ask me the question of which group I am looking into, then it will randomly pick an employee with their name and number from that group and ask me if they wanted to cover a shift. yes or no. If I answer no it will repeat the random process until there is no one else to select and if I say yes it would end the program. I created it to be more fair and show no favoritism towards another.",
            "I can't code, but I've utilized Chat GPT 4 to create a pretty cool website that I host on my Nas server. My NBA team is in the playoffs and I love monitoring the Reddit live game threads and seeing the different comments from my team, the opposing team, and the /nba live stream that's more neutral. I have code that can pull comments from all 3 threads at the same time, and then display the comments in 3 columns side by side as they come in.\n\nI'm learning very quickly that AI is a great helper, but isn't capable of doing everything I'd like, but I'm getting addicted and am starting to learn to code a bit because of this.\n\nFunniest part about it, is the current major roadblock is OpenAi integration. Trying to do sentiment analysis of each thread, and a happiness meter. ChatGPT can't figure out how to fix calling out to its own system",
            "Building my first program. It\u2019s a blackjack game that helps users learn basic strategy.",
            "Hello there,  \n  \nI am working on a dictionary, named it [D5L](https://github.com/storlak/PythonMiniProjects/tree/main/003%20-%20D5L%20Dictionary). I am a newbie with Python, learning it as a hobby and published very recently the .exe [release](https://github.com/storlak/PythonMiniProjects/releases) of this Dictionary project. I'll appreciate a lot suggestions for the app and comments about the code.",
            "I've been working on releasing a new version of my in-python DSL for Web API clients - [https://github.com/python-lapidary/lapidary](https://github.com/python-lapidary/lapidary)",
            "Today I learned by accident you can stick an `else` behind loops.\n  \nExample:\n\n    for i in range(1, 4): \n        print(i) \n    else:  # Executed because no break in for \n        print(\"No Break\")\n\n[Source](https://www.geeksforgeeks.org/using-else-conditional-statement-with-for-loop-in-python/)\n\nI was aware of the `try/except/else/finally` construct, but in 10 years of writing Python I never realized you could stick it at the end of `for/while` too.",
            "Just wanted to throw this out there.\n\nBeen listening to audiobooks lately and found this website that's very similar to Audible (even has some Audible exclusives) and a plan to sign up... But they let you listen to free. They break up the books into sections (it says chapters but... The breaks are never at chapters lol) to insert ads.\n\nWell... Turns out they don't do a great job at protecting the audio files themselves. It's pretty easy to inspect the page, go to the player, and figure out where the source audio is coming from. And besides that, they don't bother to scramble anything (So the urls look like https://www.fakewebsite.com/klsjfdhtlk/973485973/BookNameAuthorNameChapter001.mp3 , then you just change it to chapter002.mp3 for the next section).\n\nYup... About 5 minutes spent for a 30 line python script that goes through and keeps downloading until it gets a bad gateway. Just gotta input the base URL and tell it what folder to save it in and it works perfectly.\n\nI know this is super simple and Python wasn't even needed but... Just wanted to throw out a real-world use-case scenario where knowing how to do it with Python saved me a good hour :)",
            "i don't actually want to say...im scared the idea is worth something",
            "Question, as someone else who's making a Linux based tool, how do you best distribute your package? I see you have listed pip install, but most modern versions of pip aren't letting users install a package without being in a virtual environment (for good reason). Then you have to explain what a virtual environment is and how to set it up. Oftentimes (for venv at least) then you have to make sure you've got the environment active and that all seems like a mess from a user perspective. \n\nI feel like the best way would be to get it into each ditro's repository but I'm barely familiar with packaging for Python and pip, let alone every Linux distro in existence.",
            "I added retrieval of similarity chunks for the citations making RAG much more helpful and verifiable for users! I also added web search chat. You\u2019ll  need another api key for that part (rapid-api).",
            "Knowing almost nothing about weather models this looks really cool at first glance. \n\nQuestion related to your kiting example, is this more aimed at \u201cmacro\u201d forecasts or are the underlying models/your project applicable to granular forecasts? For example instead of asking is there enough breeze to kite tomorrow would this make sense to forecast wind speed/direction in different parts of a bay every 15 or so minutes across the next 9 hours?",
            "Every idea is worth *something.*\n\nIt's the ability to sell it what's worth money :)",
            "For a tool (like a CLI/GUI application), I reckon the fairly standard way of doing it nowadays is to install it via [pipx](https://github.com/pypa/pipx), which automatically installs things into venvs behind the scenes. But it's made available in your shell and desktop-env just like any other application.\n\neg. I have tools like `httpie`, `ipython`, etc installed this way.\n\nAs a developer, you just have to make your package available in the usual way in PyPI.\n\nFor my library here, it's a little tricky since it's not a tool, rather a library. And it's kind of an extension to a tool - `qtile`. (btw, I'd install qtile via \\`pipx\\` if it wasn't available in my linux package manager).\n\nRight now, I actually have to do `pip install qtile-bonsai --break-system-packages` so that the system level qtile package can see my library package (I should add this to the README). I have a TODO to publish it on other channels where qtile is available.\n\nI think \\`pipx\\` should have a way to have 2 packages share the same venv so they can see each other, but I haven't looked into it.\n\nEdit: Just saw that `pipx` has a [pipx inject](https://github.com/pypa/pipx?tab=readme-ov-file#inject-a-package) feature that allows the above :)",
            "oh please",
            "Yeah I'll probably have to give pipx a look because I haven't really used it but it does seem like the answer to my distribution problem. \n\nThanks for the advice!"
        ]
    },
    "Saturday Daily Thread: Resource Request and Sharing! Daily Thread": {
        "title": "Saturday Daily Thread: Resource Request and Sharing! Daily Thread",
        "score": 3,
        "url": "https://www.reddit.com/r/Python/comments/1cjmysm/saturday_daily_thread_resource_request_and/",
        "content": "# Weekly Thread: Resource Request and Sharing \ud83d\udcda\n\nStumbled upon a useful Python resource? Or are you looking for a guide on a specific topic? Welcome to the Resource Request and Sharing thread!\n\n## How it Works:\n\n1. **Request**: Can't find a resource on a particular topic? Ask here!\n2. **Share**: Found something useful? Share it with the community.\n3. **Review**: Give or get opinions on Python resources you've used.\n\n## Guidelines:\n\n* Please include the type of resource (e.g., book, video, article) and the topic.\n* Always be respectful when reviewing someone else's shared resource.\n\n## Example Shares:\n\n1. **Book**: [\"Fluent Python\"](https://www.amazon.com/Fluent-Python-Concise-Effective-Programming/dp/1491946008) \\- Great for understanding Pythonic idioms.\n2. **Video**: [Python Data Structures](https://www.youtube.com/watch?v=pkYVOmU3MgA) \\- Excellent overview of Python's built-in data structures.\n3. **Article**: [Understanding Python Decorators](https://realpython.com/primer-on-python-decorators/) \\- A deep dive into decorators.\n\n## Example Requests:\n\n1. **Looking for**: Video tutorials on web scraping with Python.\n2. **Need**: Book recommendations for Python machine learning.\n\nShare the knowledge, enrich the community. Happy learning! \ud83c\udf1f",
        "num_comments": 0,
        "comments": []
    },
    "I made a little Python quiz for interns and new Python developers at my company": {
        "title": "I made a little Python quiz for interns and new Python developers at my company",
        "score": 308,
        "url": "https://www.reddit.com/r/Python/comments/1dkz4gv/i_made_a_little_python_quiz_for_interns_and_new/",
        "content": "I put this quiz together to help create conversation for interns and new python developers at my company. Its based on the content from one of my favourite books ([Fluent Python](https://www.oreilly.com/library/view/fluent-python-2nd/9781492056348/)). I hope you enjoy it!\n\n[Quiz](https://us.idyllic.app/quiz/hpea2jl39w-how-well-do-you-understand-python)",
        "num_comments": 107,
        "comments": [
            "I mean, strictly speaking, \"self\" is a convention, not a feature of the language. There's nothing stopping you from defining\n\n```\nclass Foo:\n   \n    def __init__(this_shit, value):\n        this_shit.value = value\n```",
            "Nice quiz! 18/20, the question about the ABC language was quite puzzling :)",
            "18/20.\n\nI'm not going to kick myself about the ABC history question.\n\nThe \"Duck typing\" one - Is duck typing a language feature? I answered on the basis duck typing is more like a pattern you can use because the language is dynamically typed (which *is* a language feature).",
            "I'm going to argue that all possible answers to question 6 (What does the 'yield' keyword do in Python?) are wrong.\n\nFrom [the docs](https://docs.python.org/3/reference/expressions.html#yield-expressions) (emphasis added)\n> Using a yield expression in a function\u2019s body causes that function **to be a generator** function[...]When a generator function is called, it returns an iterator known as a generator. That generator then controls the execution of the generator function. The execution starts when one of the generator\u2019s methods is called. At that time, the execution proceeds to the first yield expression, where it is suspended again, returning the value of expression_list to the generator\u2019s caller[...]\n\nSo IMO the correct answer would be something like \"it causes the function to become a generator, which in turn will run until the first yield statement before being suspended, returning the yielded argument\", which is quite long.\n\nThe supposedly correct answer \"Causes the function to return a generator\" is just plain wrong. The following function `foo` returns a generator:\n\n    def foo():\n        def bar():\n            yield 42\n        return bar()\n\nEdit: thinking more about it, \"causes the function to return a generator object\" would still not be ideal, but technically correct. Because in the example above, calling bar() will return a generator object, because bar is a generator.",
            "Some of the questions I found to be quite ambiguous. For example, #12 is asking about `self` in a class method. Is \"class method\" referring to a method of a class annotated with @classmethod decorator or a member function?\nAlso, the first parameter of a member function doesn't have to be called \"self.\" Self is just a convention.\n\nHighly recommended for beginners, but it can be confusing for someone with more experience.",
            "> 11 What is the primary function of the `__init__` method in a class?\n\n`__init__` initializes the instance object, not the class object. If you wanted to custom-initialize the class object, you'd need a metaclass (or `__init_subclass__` if you're using a class hierarchy)",
            "If you're going to quiz interns and new hires, you better get the details right.\n\n* Q1: garbage collection is a feature of an [implementation](https://docs.python.org/3.12/reference/introduction.html#alternate-implementations), not a language. In the case of Python, the garbage collector differs between different versions and different interpreters, e.g.\n\n  - Python 1 had only reference counting;\n  - Python 2 and 3 has both reference counting and a cyclic garbage collector;\n  - PyPy can be configured for many different garbage collectors;\n  - Jython uses whatever the JVM uses (which is *not* reference counting); \n  - IronPython uses whatever the .Net CLR uses (again, not reference counting);\n  - I have no idea what RustPython and Nuitika use;\n  - and *in principle* somebody could make a Python interpreter with no garbage collection at all. (It would be a pretty awful Python implementation, but it would be a Python implementation).\n\n* Q2: While I personally am fascinated by the history of and evolution of programming languages, I think that expecting your Python devs to memorise which features came from ABC and which didn't is going a bit far.\n\n* Q4: `try...except` is *two* statements, not one. You can have a `try` without an `except`, e.g. `try...finally`.\n\n* Q6: technically all the answers are wrong. `yield` is an *expression* which at compile-time (yes, the Python interpreter has a compile-time -- what do you think the `compile` function does?) causes the function containing a `yield` to be treated as a generator function. At run-time, a `yield` does three thing: pauses execution of the generator, returns a value, and then when the generator resumes, [accepts a value to be passed back into the generator](http://www.dabeaz.com/coroutines/). Few people know about that last step, even though it has been in the language for at least 14 years.\n\n* Q7: The answer depends on where in the function definition the `*` is. But given that you specify it as an operator, the only correct answer is *multiplication*.\n\n  - In the *body* of a function, `*` is an operator that can be used for multiplication, or sequence unpacking: `spam, eggs, aardvark, *the_rest = mysequence*4`\n  - in the *header* of the function, `*` in the default value of a parameter is multiplication, just like in the body: `def spam(arg=42*'eggs'): ...`\n  - still in the header, a leading `*` before a parameter name is **not an operator** it is a syntactic form for a special identifier which collects any extra positional arguments: `def spam(arg, *extras): ...`\n  - still in the header, a `*` *without a parameter name* acts to separate positional-or-keyword parameters from keyword-only parameters; \n  - this is not a complete list! The star symbol `*` is one of the most heavily overloaded symbols in Python.\n\n* Q11: the `__init__` method does not initialise the class object. The class object is initialised when the `class` statement runs. (Classes are objects too.) The `__init__` method is called, not when the class object is created, but when an instance of that the class is created.\n\n* Q12: `self` is a convention, so it doesn't actually have any special meaning at all. And by convention, it doesn't get used in class- and static-methods.\n\n* Q20: the *primary* purpose of the `with` statement, in the sense of the most common and most useful, is to handle files. I've probably written a hundred `with fp in open(...)` statements for every other context manager. Compared to dealing with files, all other context managers are *secondary*. (YMMV.)\n\nEdit: `with open(...) as fp` of course. Why am I still up at 4am?",
            "16/20 there were some things I honestly saw for the first time.",
            "Re: 2. Which feature is NOT inherited by Python from the ABC language?\n\nBut Python is very OOP, everything in Python is an object, even functions. Is it even possible to tell why Python is OOP and where it got it from?",
            "17/20, I don't really see the point of this and would laugh if someone legit thought they could use it to evaluate an intern/jr.\n\n\\#2 -- absolutely no idea what ABC is or it's relationship to Python. Why would anyone know this? \n\n\\#6 -- I don't think the functions `returns` a generator, I think it becomes a generator?\n\n\\#7 -- * doesn't unpack. It collects listed args into a var.\n\n\\#13 -- might be fair. Idk tbh. I don't remember all those things off the top of my head. My answer would've been \"My IDE tells me\" lol\n\nThe rest are whatever, but I don't think it's a good way to evaluate devs on their Python abilities. Some of these questions are just kinda obscure.\n\nWould much rather ask them to build a Flask backend or a simple script or something to evaluate their skills.",
            "You don't actually screen people for employment with these obscure questions do you?",
            "Oops, got one wrong. This is for beginners (like me). \n\nI started reading that book. It starts fast, maybe a little too fast for the current version of me. Hopefully a future version will do better with it.\n\nP.S. Nice work on the quiz!",
            "Man I got the what is self in a class method cause I thought you are talking about a class method. Maybe that can be called a \u201cmethod inside a class\u201d",
            "Awful. \n\nIt's become a cliche at this point that to get jobs with a language, you just learn \"about the language\". \n\nThis is like hiring as athlete based their knowledge of Olympic trivia.",
            "Nice quiz",
            "Question 13 is wrong\n\n13. Which Python feature allows a quick check if an object supports a protocol via try/except without using `isinstance` or `hasattr`?\n\nIf anything this is dynamic typing but it's a very weird question overall. Duck typing requires that an object meets ALL of the criteria of the protocol to be considered a duck",
            "Got a solid \"Good\", nice",
            "Oof, only 15 - but I know why I got some wrong. \n\nThe ones about with and * seemed like there were two correct answers",
            "19/20. Gonna go over the book though. Looks like it could have some gems",
            "I\u2019m sorry dog but this quiz stinks.",
            "For me the advantage of a deque over list is it\u2019s thread safe.",
            "I'll say the same as some people here about \\#7, the usage of `*` in a function definition. I'd assume what you meant was actually \"pack\" (or collect) instead of \"unpack\", non strictly speaking. It would be unpack if you used it when calling the function.",
            "16/20 and I haven\u2019t touched Python in nearly 3 years so I\u2019m alright with that.",
            "I got 17/20",
            "20/20, can somebody hire me please",
            "Wow, I just program from time to time for simple scripts but still got 19/20.",
            "Wow, Idyllic really has branched out from their original purpose\n\n> Everything You Need for Effortless Image Creation and Design",
            "16... Not bad",
            "Neat, 100%! I'm finally getting the basics after 14 years!",
            "12/20. Eep",
            "11/20 feels pretty good for a beginner with no idea what they are doing. I will try and read a little more \ud83d\ude02",
            "19 out of 20. Fucking ABC programming... I don't know it.",
            "17/20. Knew I should have taken DSA seriously.",
            "Question 4's answer is in Question 4. I didn't check if I could edit Q4 retrospectively.",
            "15/20 I'm washed",
            "Q7 is inaccurate. \n\nThe \\* operator unpacks values **outside** a function definition, whereas **inside** a function definition, it does the opposite by packing multiple arguments into a single parameter.",
            "I thought Q19 was a trick question, since the string class is str :/",
            "I mean i just got 10/20 can u guys suggest me any resources like some youtube videos to watch and learn more about python cause i really want to become a python developer",
            "Fluent python is a nice book and the random trivia might be somewhat interesting for some mid level devs. However, if you evaluate (or let them self evaluate) beginners based on a factually incorrect and slightly unpragmatic quiz, you're doing everyone involved a disfavour imo. While it might teach someone a fun fact or two, it will definitely also confuse or discourage others specially since there's a few mistakes and other trivia that doesn't help in being a better programmer. So not necessarily a good quiz to evaluate whether someone is a good python dev, if that's what you'll use it for. Cheers for sharing though, keep iterating :)",
            "Note: class method and class object are quite different from an instance method and instance itself:\n```\nclass C:\n  @classmethod\n  def this_is_class_method(cls):\n         \"cls is a class object\"\n  def instance_method(self):\n      \"self is the instance\"\n```\n\nC is a class object, C() is an instance.\n`C().__class__ is C`.\n\nAlso `*` (star/asterisk) on a function *definition* does the opposite of unpack: it accepts/combines multiple (arbitrary number of) positional arguments into a single tuple, and forces further  args to be accepted by name only (as keyword args):\n\n```\n>>> def f(*args, byname):\n...     print(f\"{args=}, {byname=}\")\n...     \n>>> f(1,2,3, byname=True)\nargs=(1, 2, 3), byname=True\n\n>>> def g(*, byname): pass\n```\n\n`*` star does unpack during a function *call*:\n\n```\n>>> r = range(2) \n>>> print(*r, 2, *r)\n0 1 2 0 1\n>>> *range(2),\n(0, 1)\n```\n\nhttps://stackoverflow.com/questions/36901/what-does-double-star-asterisk-and-star-asterisk-do-for-parameters\n\nThere is a similar behavior for assignments (extended iterable unpacking): `first, *middle, last = range(4)`  Here, the word unpacking makes sense: whatever is on the right is unpacked (parts of the object are bound to corresponding names).",
            "8. What does the `enumerate()` function do when applied to a list?\n\n\nThis is pretty wrong also. Enumerate takes an iterable creates an enumerator object, and returns a tuple of index and value when __next__ is called. It doesn\u2019t yield anything and it doesn\u2019t return an iterator.",
            "Good quiz, I got 16/20, I was expecting a lot less as I'm only a hobbyist.\n\n> What is 'Timsort' in Python?\n\nThis seems way too obvious considering it has \"sort\" in the name.",
            "I think you have some wrong, `__init__` does not instantiate the object, `__new__` is responsible for that. `__init__` is actually just for defining attributes, which is run after class instantiation.\n\nAlso on number 7, you have as the correct answer that the * operator unpacks the values when used in a function definition, but it kind of does the opposite, where it packs multiple arguments into a single one, conventionally named as `args`. If you pass multiple arguments and then inside your `def func(*args)` you print args, then you will see that it's just a tuple of the multiple arguments you passed when calling it.\n\nCool idea though, looks like a fun thing to make and use.",
            "19/20. Question 2 was quite bizarre, but maybe I\u2019m just salty over not getting a perfect score. Nice quiz.",
            "11/12. I will head back to r/learnpython where I normally hang out.",
            "Quizzes are pointless. They serve no purpose, especially the foo bar crap. If you want to help interns, give them a challenge directly related to the work they will be doing. Perhaps a task that you found challenging during your time working for the company.",
            "Could you explain question 13 please:\n\n\n13.\u00a0Which Python feature allows a quick check if an object supports a protocol via try/except without using `isinstance` or `hasattr`?\n\n\nHow does duck typing help you here?",
            "12/20, 60%... \ud83d\ude14",
            "`__shameless_plug__`\n\nI released [a similar app](https://play.google.com/store/apps/details?id=io.github.prahladyeri.pythonmcq) on the Android play store earlier this week.",
            "This one returned an error when I tried it with a past script I have from Python version 2, it says \"the value is getting too old for this_shit\"",
            "Also, a \"class method\" usually means a method that can be called either on an instance of a class or the class itself, so that first argument might actually be a type object.",
            "So there are still some older packages that use \n\n    def __init__(cls, value)\n       cls.value = value\n\nWhen I was starting out more than a decade ago this would really throw me.",
            "Yeah that's not a question about python, it's a question about ABC which is not a commonly used language. On top of that it is worded poorly.",
            "I've been programming in python for 10+ years and have never heard of the ABC language. Got that one wrong too.",
            "19/20 \ud83d\ude11 I would remove that one",
            "Yeah, that one was the only one I got wrong. Kind of out of place compared to the other questions IMO.",
            "Same results. I started studying python two months ago.",
            "> Is duck typing a language feature?\n\nIt was one of the main features touted when Python was young. 1.x days.\n\ncite: I was there.",
            "The [wiki page](https://en.m.wikipedia.org/wiki/Duck_typing) mentions a couple but mostly because you can tell it to do type checking at runtime rather than compile time\n\nAdditionally, while TypeScript can be fairly flexible in its statically-typed-ness (you could just say every variable is `any` type if you really wanted to I guess), when done rigourously, it is a statically (and strongly) typed language that allows duck typing technically speaking.",
            "Same result here.",
            "You could have a statically typed language with duck typing.\n\nInterfaces (or traits) are 99% of the way to duck typing, they allow you to work with type based on what functions it implements, not what it actually is.   \n\nThe one restriction is that you must explicitly annotate classes as implementing an interface. If someone was to make a static language which allowed you to use interfaces without explicit annotations (which could be done at compile time) then it would be duck typed. \n\n\nActually, now that I think about it: C++ templates are duck typed.",
            "I mean, there's no difference between generators and generator objects just like there isn't any between strings and string objects or ints and int objects. Using yield anywhere makes a function stay a function, but one that returns a generator (object), exactly what the correct answer offers.",
            "The quiz isn't exactly *wrong* here per se. The problem is that the term \"generator\" is ambiguous - it's used to refer to both a *generator function* and a *generator iterator* in different contexts. In some sense, it's correct to say that using \"yield\" makes the function a generate *and* causes it to a return a generator.\n\nThe glossary recommends specifying whether you're referring to a generator function or a generator iterator whenever it's ambiguous.",
            "There can be multiple correct answers to the question What does foo do?\n\nA correct answer != the most complete and correct answer.",
            "That one tripped me up too. Apart from the fact that `self` is just convention, a class method (as opposed to an instance method) in my definition gets called *without* an instance (but the type of the class), i.e. the equivalent of `static` methods in C++.",
            "It\u2019s not even needed to initialize an instance of a class. This works and prints out the statement:\n\nclass test_class:\n\n    def example(self):\n\n        print(\"no init needed\")\n        \nobj = test_class()\n\nobj.example()",
            "This.",
            "You should check out the book too! Really helps mature your understanding of Python!",
            "I got the same score!\u00a0",
            "Found this question annoying - why bother about ABC lang at all?",
            "Python is very object oriented, but the ABC programming language doesn't seem to be. At least to me, it does seem unlikely that Python would get its object orientation inspiration from a language that only has 5 data types (numbers, strings, compounds (unnamed product types), lists, and tables (dictionaries)) and no other object oriented facilities.\n\nIt seems to be inspired somewhat [by Modula-3 and C++](https://docs.python.org/3/tutorial/classes.html#classes), as the docs mention.\n\nHowever, this is admittedly a bit esoteric knowledge.",
            "I wouldn't say *everything* in Python is an object.  In Ruby you can extend the Integer class so that it's possible to write something like `5.days.ago which returns the date from 5 days in the past.`",
            "Its certainly a book for those who've been using Python for a while and grocked the basics. I view the book as more of a \"programming languages\" type book with examples of what makes Python so special. Keep up the good work! The language is well worth knowing well!",
            "> Duck typing requires that an object meets ALL of the criteria of the protocol to be considered a duck\n\nNah. If all you need is something that swims like a duck, a goose or a swan  is fine too even though they don't quack like a duck.\n\nI thought that question was awful.",
            "I was just going to comment on the '*' question, is there any right answer?\n\n> In Python, what does the '*' operator do when used in a function definition?  \n> * Unpacks a list or tuple  \n> * Creates a pointer  \n> * Raises an error  \n> * Multiplies values  \n\nThen look at this function definition:\n\n    def foo(a, b, *, c=1, d=2):\n        return a + b + c + d\n\nI know (I think?) the question is about `*args` (or `**kwargs`), but '*' by itself is valid to force anything after it to be provided only as keyword arguments\n\nAnd for anyone else interested, there's also '/' by itself to force arguments as positional only:\n\n    def foo(a, /, b, *, c=1):\n        return a + b + c\n\nthis requires `a` to be only positional:\n\n    ----> 1 foo(a=1, b=2, c=3)\n    TypeError: foo() got some positional-only arguments passed as keyword arguments: 'a'\n\nand forces c to be only a keyword argument:\n\n    ----> 1 foo(1, 2, 3)\n    TypeError: foo() takes 2 positional arguments but 3 were given\n\nmaking only `foo(1, 2, c=3)` or `foo(1, b=2, c=3)` as valid in this case\n\n---\n\nalso on that note.. the question feels a bit confusing, that it  'unpacks a list or tuple' isn't really correct, because, if you create a function like this:\n\n    def foo(*inp):\n        print(inp)\n\nthen call it with `foo([1, 2 ,3])`, it's not going to unpack the list I provided, `inp` will be a single item tuple with the list as the only element (`([1, 2, 3], )`).. This syntax is to dynamically capture the positional arguments not defined, but which answer captures that? \n\nIs this question referring to something else?",
            "The purpose was to help create conversation with interns and new developers in my company! Do you know why its called Timsort and the history of it?",
            "Actually, even if a class method is called on an instance, it still receives the class as its first argument. \n\n| A class method receives the class as an implicit first argument,\n\n[https://docs.python.org/3/library/functions.html#classmethod](https://docs.python.org/3/library/functions.html#classmethod)",
            "What is ABC language and why anyone should care about it? :D \n\n\nye there are few strange questions there.",
            "I began wondering if it was talking about Abstract Base Classes.",
            "same. 19/20, ABC is the only one I got wrong, and the \"correct\" answer seems to suggest that python is not an OOP language, which is ludicrous.",
            "\"generator object\" is unclear because both the function and the iterator it creates can be called generators, and they're also both objects. \"Generator iterator\" and \"generator function\" are the unambiguous terms.",
            "Will do!",
            "Ahh, that way around!\n\n>However, this is admittedly a bit esoteric knowledge.\n\nYes. And then the question is phrased very counterintuitively.",
            "The `int` type is immutable, but you can inherit from it. (This isn't a good idea, but it is possible.)\n\n    >>> class MyInt(int):\n    ...     def foo(self, a):\n    ...         return self+a\n    ... \n    >>> x = MyInt(45)\n    >>> x.foo(34)\n    79\n    \nIt also has some methods, though the syntax doesn't seem to support directly calling methods on literals, so you have to surround them with parentheses:\n    \n    >>> (4553).bit_count()\n    6\n\nAdditionally, the CPython implementation has interned integer objects from -5 to 256 for performance. (Don't rely on this for any sort of behaviour in your code though!)\n\n    >>> a = 2\n    >>> a is 2\n    True\n    >>> b = 123456\n    >>> b is 123456\n    False",
            "just because python isn't ruby doesn't mean the statement \"everything in python is an object\" is wrong.",
            "> I wouldn't say everything in Python is an object\n\nIn Python, every thing, every value, is an object. There are no values which are not objects, like in C or Java. If you've used Java, there is a distinction between boxed and unboxed values. Python does not have this distinction -- everything is boxed.\n\nThere are meta-things which are part of the language itself but exist only in the code itself, like \"for loops\", and these are not values and aren't objects.",
            "In Python you can create a subclass of the integer class, which has a .days.ago property and does exactly what you mention. You just can't change the existing integer class itself.",
            "Admittedly, I said that a bit carelessly, but the general point still stands :)",
            "I agree it is such a wonderful language. I will still work my way through the book. It's certainly not the first book above my head. I'll learn what I can from it and then come back to it at a later date.",
            "If all the protocol says is \"can swim and has feathers\" then correct a duck a goose and a swan match. but if the protocol says \"can swim and has fins\" then a duck is no longer \"duck typed\" to that protocol",
            "My guess is that OP meant for the question to say \"in a function call\"? The correct answer makes more sense then, as a * in a function call unpacks the list/tuple to use as arguments.",
            "I honestly don\u2019t know. I also thought \u201cdefinition\u201d of a function was ambiguous, if it had said the argument and something about keyword args it might\u2019ve been clearer.  Like is\n\ndef f(a,b):\n\n    return a*b\n\nNot a function definition?",
            "I'd never heard of it, but I knew that it must be a sorting algorithm because it had sort in its name and followed the \\[X\\]sort naming convention of sorting algorithms.",
            "oh shit I thought it was talking about \"Abstract Base Classes\" and was worded really poorly. Had no idea \"ABC\" is an actual language.",
            "> What is ABC language and why anyone should care about it? :D\n\nIt was the primary inspiration for Python. Not the only one: Guido was inspired by features and syntax from a bunch of languages, but mostly ABC. If you google for his blog(s) he discusses it a bit.",
            "> why anyone should care about it?\n\nhistorical curiosity? Topic to bring up at really nerdy parties?",
            "I inferred OOP because it\u2019s the one feature of the four that was so huge, it couldn\u2019t have come from a language as obscure as ABC.\u00a0\n\nWeird phrasing on the part of the question; I believe it intends to mean that although python supports OOP, it didn\u2019t get OOP from ABC.\u00a0",
            "Same, 19/20, who cares about some abc",
            "> the syntax doesn't seem to support directly calling methods on literals\n\nOf course it does: `\"Hello world\".upper() works fine.\n\nInt literals are a bit trickier because the dot causes the parser to interpret it as a float: `123.bit_count()` is a syntax error, but this works: `123 .bit_count()` (note the sneaky little space).",
            "Oh yeah, that would make sense!",
            "Yeah that's true as well, the question is too vague",
            "Yeah, it's one of Python's main inspirations (at least a bunch of the features). \n\nIt isn't really where the \"object oriented\"ness comes from though. The docs point to [Modula-3 and C++](https://docs.python.org/3/tutorial/classes.html#classes) as being the primary inspirations for the OOP features",
            "ye but who cares :D",
            "ye I am not such a perv ;)",
            "Not to complain as I thought it was good - but the with keyword is used to manage context, yes, but the overwhelming majority of cases I see it used for is in opening files / managing exceptions which is why I answered that.",
            "Yeah, I see where you're coming from, but \"to open files and handle exceptions\" is just examples of context managers being used. It might still be the most common cases for most people as you mention, but the primary purpose of `with` is to handle context management in general.\n\nWith that in mind, I would probably not have that as an answer option to the question, because of this exact reason, it can be confusing.",
            "Agree with both"
        ]
    },
    "Running Python in Web Browsers": {
        "title": "Running Python in Web Browsers",
        "score": 32,
        "url": "https://www.reddit.com/r/Python/comments/1dl8stp/running_python_in_web_browsers/",
        "content": "Python is one of the world's most popular programming languages and the web is the most ubiquitous application platform. There are several projects which aim to enable Python to run in web browsers.\n\n* [Brython](https://www.brython.info/) is an implementation of Python 3 written in JavaScript.\n* [Skulpt](https://skulpt.org/) is an implementation of Python 2/3 written in JavaScript.\n* [PyScript](https://pyscript.net/) is an implementation of Python 3 written in WebAssembly.\n* [Transcrypt](https://www.reddit.com/r/VistaPython/) is a Python to JavaScript compiler - unfortunately, the project seems to have been abandoned.\n* [Batavia](https://github.com/beeware/batavia) is a Python virtual machine written in JavaScript - unfortunately, the project seems to have been abandoned.\n\nFinally, I have created [VistaPython](https://www.reddit.com/r/VistaPython/) which is also intended to run Python 3 in web browsers but by using a bytecode interpreter written in JavaScript.\n\nEach design has strengths and weaknesses:\n\nBoth Brython and Skulpt use hand-written Python parsers which are difficult to maintain. VistaPython uses a parser generator, [Antlr](https://www.antlr.org/), to automatically generate the JavaScript code for the parser. The parser can be updated to match the latest Python version by simply running a script.\n\nAlso, both Brython and Skulpt generate JavaScript code which is then evaluated. In VistaPython, the compiler produces a \"code object\" which is then executed using the bytecode interpreter. The first approach will result in faster code whereas the second approach can be more flexible for code stepping, etc.\n\nPyScript is based on [Pyodide](https://pyodide.org/en/stable/) which is a port of CPython to WebAssembly.\n\nPyScript can be upgraded the latest Python release by recompiling the latest CPython sources. Its main disadvantage is that it is very heavy to load and seems to run poorly on mobile devices.\n\nIn VistaPython, the load profiles are:\n\n* vm.js (Python virtual machine) 761kb\n* Python parser 368 kb\n* Mobile client GUI 2.4 Mb\n* Desktop client GUI 2.9 Mb\n\nCompiled applications can be run using only the Python virtual machine (761kb).\n\nThe design goal of VistaPython is to be able to load compiled applications from a database and run them quickly on any web device.\n\n",
        "num_comments": 6,
        "comments": [
            "Are you sure you\u2019re obeying the Python license?  And trademark rules?",
            "How is pyscript these days? Seemed promising when I first heard about it but was pretty slow.\n\n Always like the idea of eliminating barriers to run python applications, thanks for this rundown",
            "Check out anvil.",
            "The thing is for frontend you also need frameworks/libraries. JavaScript has a lot of tools, SPA frameworks and more. Python browsers variants still are \"experimental\" on their own and don't have good ecosystem around them. And then a frontend/fullstack developer would have to use it. Backend dev without getting to know frontend won't be able to use it efficiently or at all.",
            "They move to MicroPython as the default backend, that rather helped with issues.",
            "+1 for anvil, the team manages skulpt heavily as they rely on it for the python-to-JS"
        ]
    },
    "Open source Python projects with good software design that is worth studying": {
        "title": "Open source Python projects with good software design that is worth studying",
        "score": 204,
        "url": "https://www.reddit.com/r/Python/comments/1dkrfgh/open_source_python_projects_with_good_software/",
        "content": "What are some software projects written in python that are well-structured and use good code design practices that are worth spending time to study?   \n\n\n",
        "num_comments": 38,
        "comments": [
            "I've had similar thoughts during my career - wanting to read others code so I can get a good idea of how they work and how I can learn to replicate. Its not a bad thought, and I'd highly encourage doing it even if the mature projects you know about are very well established and hard to follow/understand.\n\n  \nOne thing I'd encourage is for you to also look back in history of the commits and code bases. It can be hard sometimes to understand how code evolves over time, but its very important. For example, I just started using this new open source python project for my home security camera setup (https://github.com/blakeblackshear/frigate) and I was hugely impressed with how many features there are given its made by a hobbyist! I decided to look back in the commit history and saw the very first, humble, and honest commit \"was just\" a script to detect objects: https://github.com/blakeblackshear/frigate/blob/72393be6d66e7642343476f5adb4b8e99d613c79/detect\\_objects.py\n\nI hope this little bit of advice is useful and good luck with learning! The hard work will pay off!",
            "You should go look through Mozilla\u2019s GitHub. There are a lot of Python projects from some really great engineers",
            "I always liked the get_or_create and filter methods in Django so I studied those at one point to make a lightweight ORM interface for different backing datastores. \n\nHaven\u2019t compared to other codebases to say if it\u2019s \u201cgood\u201d or not but the source code was readable and not buried in tiers of abstractions",
            "I like both mypy and pylint codebases. Both are readable enough I\u2019ve occasionally made small bug fixes and both have pretty high quality test suites.\n\nTensorflow is less good codebase to learn from but still has ok structure and it is massive and more complicated than many codebases I interact with at work.",
            "On this note, is there any website/youtube channel that explains these high level & low level decisions in open source projects. I really think it takes a trained eye can spot & explain good SW design to beginners.",
            "Sebastian Ramirez (https://tiangolo.com). He created FastAPI and Typer. I really like both of these libraries. I think the docs are well laid out, and I think his programming idioms are both innovative and effective.\n\nTyper I especially like because it\u2019s mostly just click - but what it does on top creates a much more intuitive programming interface (at least for me).",
            "Sqlalchemy",
            "Taiga is a excellent Django app written by pros if you wanna check out a web backend",
            "The source code for the packages that are part of the Python standard library were considered so good they were included in the standard library.  They should be good examples of excellent Python code.",
            "we already had this discussion -- with you as the OP -- a few days ago. 83 points and 33 comments. Do we really need to do this again so soon?\n\nhttps://www.reddit.com/r/learnpython/comments/1dicifq/open_source_python_projects_with_good_software/",
            "I think a good choice is apache superset. The domain is interesting and easy to understand so you can focus studying the design and implementation. The documentation is quite good.\n\n[https://github.com/apache/superset](https://github.com/apache/superset)",
            "- Sqlalchemy\n- Pyramid web framework\n- psycopg\n- pyqt/qt c++\n- litestar (api/web framework)\n- bottle\n- sortedcontainers\n- more-itertools (not related to software design but good material)\n- xlsxwriter (on how to keep and maintain a spec, very functional (fp))",
            "Maybe a bit conceited, but I'll plug my own data library [PyBARE](https://git.sr.ht/~chiefnoah/pybare). It's small, fairly well tested, and uses pretty much every advanced metaprogramming technique available in Python short of `eval`.",
            "I am admittedly not a python expert but will give you the one that helped me the most.  My initial foray into python was studying how map-a-droid runs. Then I learned how to mod it to suit my purposes.  Ran it over 4 years, so got to see a fair amount of evolution. It touches on many subjects that have helped me in my current projects: asyncio, multiprocessing, mariadb, caching, redis, inter process communication and so on.",
            "Probably the big ones like PyTorch, numpy, pandas, scipy, scikit-learn etc.",
            "[Facebook Business SDK](https://github.com/facebook/facebook-python-business-sdk)",
            "Sentry, Sentry\\_sdk\n\nIt's a Django monolith.  \n\n\nU're welcome",
            "Thank for sharing!",
            "Thank you this is helpful \n\nDid you study any books/resources on code design that you think helped you practically afterwards?",
            "I think this is an important point. Well-designed projects probably have years of iteration to get to that point. It's okay to make mistakes and change it later. That's just the nature of software development.",
            "I found this guy that walks through the code of open source projects\n\nhttps://www.youtube.com/@ants_are_everywhere/videos",
            "Sadly fastapi is the worst , similar to turbogears.\nTry litestar, read it and you\u2019ll understand my point.",
            "You nailed this. I would check out polyfactory as well while you're at it. Can be useful at times for mocking if you're into that kind of thing",
            "Excellent example of how to grow an API.\n\nI would also point to Django as something to strive for.",
            "What would you consider good about their design?",
            "The best of the best",
            "Yes I asked here because this sub has more people with senior lvl experience so it would add value and another perspective to the discussion on code design, and it shows in the answers",
            "lol wtf op. Also this has been asked many times before",
            "I just remembered others:\n\n- bokeh\n- twisted\n- pygal\n- diskcache",
            "There were a few books I did enjoy studying that helped frame my thinking. That said, take everything you read with a grain of salt and try think about how they relate to your problem at hand. Try different paradigms and patterns in your own time and write as much code as possible along with studying generic resources.\n\n- Fluent Python  \n- Philosophy of Software Design  \n- Designing Data Intensive Applications",
            "Good find!",
            "Can you explain what you mean?  \nI just spent half an hour to get a cursory overview of both project's structures and I am probably too junior to spot some obvious issues :)",
            "I had the idea OP has a few weeks ago. I took a peek a Django. It probably doesn't help that I haven't used it, but a bunch of what I looked at left me thinking 'WTF is this for?'. I did find some bits easier to follow, and I still want to take a deeper look when I have more time. \n\nIt did make me wish there was some kind of high level overview documentation from a code architecture perspective to help me orientate around the project. Maybe it exists and I missed it. There's tons of documentation on using, and contributing that was very easy to find and beautiful to see.",
            "Yes Django is a good choice too.",
            "Don't spam subs with the same question. You got some answers so take them and make use of them. Don't waste our time.",
            "Is this like what you're seeking? https://docs.djangoproject.com/en/5.0/py-modindex/\n\nIt's definitely one of those app frameworks that at first seems daunting and confusing, but once you start to understand the concepts it kinda has an epiphany moment where you're like, \"WHOA, ok, *now* I get it!\"",
            "It makes sense to ask in different subs if they have different communities/people. Seeking another perspective from people with more advanced level is not a waste of time and the answers may benefit others not just me. If it\u2019s a waste of your time you could skip the post altogether",
            "It doesn\u2019t. You\u2019re getting the same answers here as you did in the other sub. Go look at some big popular libraries. That\u2019s the answer."
        ]
    },
    "Log Monitoring with Kafka ETL using Python via Docker and Pathway": {
        "title": "Log Monitoring with Kafka ETL using Python via Docker and Pathway",
        "score": 5,
        "url": "https://www.reddit.com/r/Python/comments/1dl7c60/log_monitoring_with_kafka_etl_using_python_via/",
        "content": "Hi r/Python,\n\nThis project is for a Streaming ETL problem statement for Fraud-detection/Log Monitoring use-case.\n\n* Here's a link to the blog explainer: [https://pathway.com/developers/templates/kafka-etl](https://pathway.com/developers/templates/kafka-etl)\n* GitHub Repo link:\u00a0[https://github.com/pathwaycom/pathway/tree/main/examples/projects/kafka-ETL](https://github.com/pathwaycom/pathway/tree/main/examples/projects/kafka-ETL)\n\n# What the Project Does\n\nLet's say we're monitoring logs from servers in New York and Paris. The logs have different time zones so you need to unify these different time zones into a single format to maintain data integrity. Now, Kafka is a popular ETL tool but it's usable only in Java/Scala.\n\n# Target Audience\n\nThis is mostly for Python developers/data scientists/ML engineers and people who work on Fraud Detection or ETL.\n\n# Comparison\n\nThis project leverages Pathway, a Python ETL framework powered by an underlying Rust engine that surpasses Flink/Kafka in benchmarks. With this Pythonic framework we:\n\n* Extract data streams from Kafka using built-in Kafka input connectors.\n* Convert times with varying time zones into unified timestamps the datetime module.\n* Load the final data stream back into Kafka.\n\nThe entire script is available as an app template on the repo, which can be run via Docker in minutes. Open to your feedback/questions!",
        "num_comments": 0,
        "comments": []
    },
    "A simple website scraper script": {
        "title": "A simple website scraper script",
        "score": 2,
        "url": "https://www.reddit.com/r/Python/comments/1dlfge9/a_simple_website_scraper_script/",
        "content": "# Web Scraper Script\n\n## What My Project Does\n\nThis project scrapes websites to extract and display titles and links of articles. It processes multiple websites in parallel, fetching and parsing content to provide a consolidated list of articles with their full URLs.\n\n## Target Audience\n\nHome users, researchers, and web enthusiasts who need to gather information from multiple websites quickly and efficiently.\n\n## Features\n\n- **Parallel Processing**: Uses `ThreadPoolExecutor` to fetch multiple websites concurrently, speeding up the scraping process.\n- **Error Handling and Logging**: Provides detailed logging for debugging and retry mechanisms for robustness.\n- **Full URL Extraction**: Ensures that all extracted links are complete URLs, enhancing usability.\n- **Customizable Headers**: Allows customization of HTTP headers to mimic different browsers.\n\n## Script Overview\n\nThe script consists of several key components:\n\n### Fetching URLs\n\nThe script fetches content from the given URLs using the `requests` library. It includes retry logic with exponential backoff to handle transient errors.\n\n### Parsing Content\n\nThe script uses `BeautifulSoup` to parse the fetched HTML content and extract article titles and links. It ensures that the links are converted to full URLs using `urljoin`.\n\n### Concurrent Execution\n\nThe script employs `ThreadPoolExecutor` to fetch and parse content from multiple websites in parallel, improving efficiency.\n\n## Access the Script\n\nYou can access the script on GitHub here: [Web Scraper Script on GitHub](https://github.com/slyfox1186/script-repo/blob/main/Python3/Networking/web-scraper.py)\n\n## How to Use\n\n1. **Install Dependencies**:\n   Ensure you have `requests` and `beautifulsoup4` installed:\n   ```sh\n   pip install requests beautifulsoup4\n   ```\n\n2. **Run the Script**:\n   Provide the URLs of the websites you want to scrape as arguments:\n   ```sh\n   python3 web-scraper.py https://yahoo.com https://sports.yahoo.com\n   ```\n\n## Conclusion\n\nThis web scraper script is designed to be robust, efficient, and easy to use. It handles multiple websites in parallel, provides detailed logging, and ensures full URL extraction for all links. Ideal for users who need to quickly gather and consolidate information from various sources.",
        "num_comments": 0,
        "comments": []
    },
    "localslackirc - bridge slack and IRC": {
        "title": "localslackirc - bridge slack and IRC",
        "score": 8,
        "url": "https://www.reddit.com/r/Python/comments/1dl064e/localslackirc_bridge_slack_and_irc/",
        "content": "I made a minor bugfix release of localslackirc\n\nhttps://codeberg.org/ltworf/localslackirc\n\nIt can be installed via apt or ran from sources. No pypi package, sorry.\n\nWhat My Project Does\n===========\n\nAfter configuring it with a token from slack, it creates a local IRC server that bridges with slack.\n\nIt supports threads, sending files. It doesn't support reactions.\n\nIt supports muting @here notifications from certain users or certain channels.\n\nIt allows to silently leave a channel, but rejoins it if the user is personally mentioned there.\n\n\nTarget Audience\n=========\n\nMostly people who have to use slack for work and would prefer IRC.\n\nComparison\n=======\n\nI am not aware of a project doing the same thing. I know weechat has a slack plugin, but that's slightly different. I don't use weechat and I wanted to keep using my IRC client.\n\n\nout of date link to avoid the post from being removed: https://github.com/ltworf/localslackirc",
        "num_comments": 1,
        "comments": [
            "[Relevant XKCD](https://xkcd.com/1782/)"
        ]
    },
    "Python community in Amsterdam, The Netherlands": {
        "title": "Python community in Amsterdam, The Netherlands",
        "score": 4,
        "url": "https://www.reddit.com/r/Python/comments/1dl0f8b/python_community_in_amsterdam_the_netherlands/",
        "content": "Hi, I'm trying to find a Python community in Amsterdam in The Netherlands.  There used to be an active [MeetUp group](https://www.meetup.com/pyamsterdam/) and [Slack](https://pyamsterdam.slack.com/), but there has been little to no activity on either in a long, long time.\n\nPythonistas in my city, what social / networking events or activities are there around here?\n\nAdditionally, would anyone be interested in reviving the Python MeetUps in Amsterdam?  ",
        "num_comments": 2,
        "comments": [
            "I'm also in the area (Almere)!",
            "And Arnhem"
        ]
    },
    "Eventum: Flexible event generator": {
        "title": "Eventum: Flexible event generator",
        "score": 11,
        "url": "https://www.reddit.com/r/Python/comments/1dkvsmy/eventum_flexible_event_generator/",
        "content": "Hi, recently I created event generator in Python called **Eventum**.\n\nHere is a link to website: [https://eventum-generatives.github.io/Website/](https://eventum-generatives.github.io/Website/)\n\nAnd the main repo: [https://github.com/Eventum-Generatives/EventumCore](https://github.com/Eventum-Generatives/EventumCore)\n\n# What My Project Does\n\nIt can be used in task like:\n\n* Generation of datasets\n* Simulation of processes in real time\n* Filling different systems with demo data\n* Testing on arbitrary data and stress testing\n\n# Target Audience\n\nThis generating tool is mostly for developers and people who work with data. It is also very near to **ELK** stack, **OpenSearch** and SIEM systems like **Splunk**. But you can use it as you want :)\n\n# Comparison\n\nThere is a project **Eventgen** developed by Splunk, but Eventum has next advantages over it:\n\n* More rich events scheduling\n* Extended functionality in event templates\n* More parametrizable configurations\n* Has content developing tools (UI for visualization time distributions and rendering templates)",
        "num_comments": 2,
        "comments": [
            "Very nice documentation! This looks very useful for benchmark and fuzz testing, thanks for sharing!",
            "Interesting project, saved. Good work!"
        ]
    },
    "Basic based turtle drawing language.": {
        "title": "Basic based turtle drawing language.",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1dld1uv/basic_based_turtle_drawing_language/",
        "content": "I'm currently working on  basic based turtle drawing programming language.\n\nIt just for fun and i want to ask you what about this project. I should leave or continue it and if you can you can give some features to add.\n\nthe programming language is simple and basic like his inspired language.",
        "num_comments": 1,
        "comments": [
            "Do you have a link to it? And do you know about the turtle module in the standard library?"
        ]
    },
    "Robogram - Minimal Wrapper for Telegram Bot API in Python": {
        "title": "Robogram - Minimal Wrapper for Telegram Bot API in Python",
        "score": 1,
        "url": "https://www.reddit.com/r/Python/comments/1dkvoja/robogram_minimal_wrapper_for_telegram_bot_api_in/",
        "content": "Guys, I recently released my first (in a while) open-source project wrapper on [Telegram Bot API](https://core.telegram.org/bots/api).\n\nI call it `robogram` and when I was developing in Python, I had a use case to send notifications from Raspberry Pi to my iPhone via [Telegram](https://telegram.org/). After searching online, I found no minimalist wrapper in Python 3+ to send messages via Bot API.\n\nSo, I decided to create one :-)\n\n# What My Project Does\n\nMinimal Wrapper around the Telegram Bot API. It's only dependency is `requests`  in Python which is ubiquitous. It allows to retrieve info on Bot, or to send messages to users via personal chat, channel, or group.\n\n# Target Audience\u00a0\n\nToy project I just came up with, after realizing no solution out there was best fit for me. But I have deployed this on production for personal project, and it's for sure production-ready.\n\nTarget audience here would be other developers who are on Telegram and looking to leverage Bot API to facilitate the sending of messages or notifications to an audience on Telegram.\n\n# Comparison\n\nSome packages out there are only async support, or only work on Python 2 (actually I found one with some popularity that doesn't work in Python 3+ at all), or are dependency- or code- heavy and can introduce code bloat, especially to small, personal projects.\n\nAs someone working on a personal project myself, I wanted a lightweight solution that only used minimal dependencies such as `requests` for making API requests. So, since I could not find one out there in wild, I decided to create my own!\n\n--\n\nI want to get your thoughts, if anyone likes it I will be glad to feedback.\n\n[https://github.com/rnag/robogram](https://github.com/rnag/robogram)",
        "num_comments": 1,
        "comments": []
    },
    "What are your opinions on mutation testing code using AI?": {
        "title": "What are your opinions on mutation testing code using AI?",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1dlemi8/what_are_your_opinions_on_mutation_testing_code/",
        "content": "I came across this open source [project](https://github.com/codeintegrity-ai/mutahunter)\u00a0that talks about using LLM agents to do language agnostic mutation testing of code. Looks really cool! Do you guys think LLMs are going to enhance mutation testing?",
        "num_comments": 4,
        "comments": [
            "Sure! Why not!\n\nAre you sure this question belongs in the Python sub\u2026?",
            "> I came across \n\nDid you really come across? Or is the real purpose of this post to advertise your own project?\n\nEdit: it's really your project. The discord invitation link said \"Ominopsguy (raghura.) has invited you to join...\". Your reddit name is ominiopsFounder. Both have \"omniops\".",
            "I think it's a cool idea too! Wanted to know how python devs feel about this",
            "I'd say Python devs are the ones working on the language itself.\n\nOtherwise people shouldn't pigeonhole themselves."
        ]
    },
    "Introducing Lambda Forge: Simplifying AWS Lambda Deployment and Development!": {
        "title": "Introducing Lambda Forge: Simplifying AWS Lambda Deployment and Development!",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1dlfj8o/introducing_lambda_forge_simplifying_aws_lambda/",
        "content": "Hey everyone,\n\nI just wanted to share a project I've been working on called **Lambda Forge**. It's a tool designed to simplify the deployment and management of AWS Lambda functions. If you're like me and spend a lot of time working with serverless architecture, you might find it pretty useful.\n\n# What My Project Does\n\nLambda Forge helps you deploy and manage AWS Lambda functions with ease. One of its standout features is the WebSocket connection for hot reloading of local code. It uses MQTT over Websockets to proxy requests to a local server, making development seamless. No more redeploying code just to see if your changes work!\n\n# Target Audience\n\nThis project is meant for developers who work with AWS Lambda in both production and development environments. Whether you're a seasoned backend engineer or just getting started with serverless, Lambda Forge can help streamline your workflow.\n\n# Comparison\n\nCompared to other deployment tools, Lambda Forge focuses on enhancing the development experience with hot reloading capabilities. Many existing tools require a full redeployment for changes to take effect, which can be time-consuming. Lambda Forge's WebSocket integration saves time by allowing you to see changes in real-time without redeployment.\n\nIf you're interested, you can check out the documentation here: [Lambda Forge Docs](https://docs.lambda-forge.com/)\n\nAnd if you want to dive into the code or contribute, here's the GitHub repo: [Lambda Forge on GitHub](https://github.com/GuiPimenta-Dev/lambda-forge)\n\nI\u2019d love to hear your thoughts and feedback.",
        "num_comments": 1,
        "comments": [
            "This is all extremely vague except it seems that you wrote a dev server that proxies http over mqtt over web sockets and hosts a single Python lambda function?  Is that good or bad?\n\nYou have a section called \u201ccomparison\u201d that doesn\u2019t mention any other options, so is not really a comparison and is just a lot of adjectives without many nouns.  I am pretty sure there\u2019s lots of other ways to run AWS lambda Python functions on my computer?  How is this better than those?  How is it worse?\n\nNot that you should post this again, but if you ever do another thing and want to write one post about it, I would encourage you to think about framing it as:\n\n- here\u2019s a *specific problem* I had (eg \u201cthere were no other AWS lambda function local hosting things\u201d or \u201cthey all required some buggy C extension\u201d)\n- here\u2019s what I did\n- here\u2019s specifically how it solves that problem \n- not ever using words like \u201chelp\u201d and \u201cdeploy\u201d and \u201cmanage\u201d\n- if the goal is to show something is simple to use then say so just before you show or link to the exact steps someone needs to follow.  Your README doesn\u2019t provide any information at all about using it."
        ]
    },
    "Object Oriented Programming Simplified": {
        "title": "Object Oriented Programming Simplified",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1dlhdyq/object_oriented_programming_simplified/",
        "content": "I created a 1 minute animated video to simplify OOP if you're interested it can be found on my yt channel called brendonmehdi \n\n  \ni made this because i struggled to grasp this concept and was intimidated by it i hope it helps someone who's in the same shoes i once was in (could also be used as refresher if youre returning to programming) ",
        "num_comments": 1,
        "comments": [
            "[https://www.youtube.com/watch?v=M0oAQ5VEbMs](https://www.youtube.com/watch?v=M0oAQ5VEbMs)"
        ]
    },
    "Friday Daily Thread: r/Python Meta and Free-Talk Fridays": {
        "title": "Friday Daily Thread: r/Python Meta and Free-Talk Fridays",
        "score": 1,
        "url": "https://www.reddit.com/r/Python/comments/1ciuske/friday_daily_thread_rpython_meta_and_freetalk/",
        "content": "# Weekly Thread: Meta Discussions and Free Talk Friday \ud83c\udf99\ufe0f\n\nWelcome to Free Talk Friday on /r/Python! This is the place to discuss the r/Python community (meta discussions), Python news, projects, or anything else Python-related!\n\n## How it Works:\n\n1. **Open Mic**: Share your thoughts, questions, or anything you'd like related to Python or the community.\n2. **Community Pulse**: Discuss what you feel is working well or what could be improved in the /r/python community.\n3. **News & Updates**: Keep up-to-date with the latest in Python and share any news you find interesting.\n\n## Guidelines:\n\n* All topics should be related to Python or the /r/python community.\n* Be respectful and follow Reddit's [Code of Conduct](https://www.redditinc.com/policies/content-policy).\n\n## Example Topics:\n\n1. **New Python Release**: What do you think about the new features in Python 3.11?\n2. **Community Events**: Any Python meetups or webinars coming up?\n3. **Learning Resources**: Found a great Python tutorial? Share it here!\n4. **Job Market**: How has Python impacted your career?\n5. **Hot Takes**: Got a controversial Python opinion? Let's hear it!\n6. **Community Ideas**: Something you'd like to see us do? tell us.\n\nLet's keep the conversation going. Happy discussing! \ud83c\udf1f",
        "num_comments": 0,
        "comments": []
    },
    "Mirascope-Python's Alternative To Langchain\n": {
        "title": "Mirascope-Python's Alternative To Langchain\n",
        "score": 1,
        "url": "https://www.reddit.com/r/Python/comments/1dkhmpa/mirascopepythons_alternative_to_langchain/",
        "content": "Mirascope is a Python library that lets you access a range of Large Language Models, but in a more straightforward and Pythonic way.\n\n[https://www.i-programmer.info/news/90-tools/17275-mirascope-pythons-alternative-to-langchain.html](https://www.i-programmer.info/news/90-tools/17275-mirascope-pythons-alternative-to-langchain.html)",
        "num_comments": 0,
        "comments": []
    },
    "Web scraper for protein prices ": {
        "title": "Web scraper for protein prices ",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1dkmwzy/web_scraper_for_protein_prices/",
        "content": "Hey everyone, looking for some input.\n\nFor work I\u2019ve worked on web scraping for prices to see if my components are adequately priced on the internet compared to competitors.\n\nI can use this for protein prices as a personal project. I have experience now with Beautiful Soup, Selenium, and Excel Power BI.\n\nWhat route should I go?\n\nShould I only pull pricing from Amazon? Or should I do Amazon and the manufacturer site to see which is better pricing? Ideas would be great. Should be a fun project.\n\nIf I go with beautiful soup, there\u2019s no UI and I can print all to terminal \n\nIf I use selenium, I can use UC to pass anti-bot measures and also print to terminal, but it will open a browser window for each price scrape.\n\nIf I use excel power BI, I\u2019ll just load data to a worksheet and pricing will update at the price of a button.",
        "num_comments": 7,
        "comments": [
            "Scraping should be an absolute last resort. \u00a0[Amazon has an API](https://developer-docs.amazon.com/sp-api/docs/product-pricing-api-v0-reference).\n\n\nIf you do need to scrape, Selenium should also be last resort, but you can use headless mode if you don't want the window to open.",
            "Also in future you might have better luck asking in r/learnpython",
            "What this guy said. Also if you scrape, remember to check the `robots.txt` file before doing so.",
            "Thank you! This is very useful to me",
            "Thanks I\u2019ll start there!",
            "Check for what?",
            "The rules to follow, the pages to exclude.\n\nhttps://www.cloudflare.com/learning/bots/what-is-robots-txt/"
        ]
    },
    "Python on Cloud GPUs": {
        "title": "Python on Cloud GPUs",
        "score": 1,
        "url": "https://www.reddit.com/r/Python/comments/1dketsw/python_on_cloud_gpus/",
        "content": "Hi All,\n\nI wanted to try to speed up some Python code with a GPU recently and was pretty shocked at how difficult it is to properly set up and configure things. I have lots of experience in the PyData space, but am definitely not a cloud devops expert.\n\nSo some colleagues and I wrote a decorator that automatically sets up a cloud VM, runs the decorated function, and returns the function\u2019s result back locally to my laptop. [Here\u2019s an example](https://docs.coiled.io/user_guide/pytorch.html) that trains a PyTorch model on an NVIDIA A10 GPU on AWS.\n\nThe Coiled Function API is nice because I didn\u2019t have to build any Docker images, muck around in the AWS console, or do anything special to set up a cloud GPU. That said, there are definitely tradeoffs here. We optimized for privacy and no standing costs, so it takes \\~1-2 minutes to fully spin up VMs (no warm pool of VMs waiting). We also only run on AWS/GCP/Azure so this doesn\u2019t help with on-prem workloads.\n\nI\u2019m definitely biased as I work at Coiled, but think this is a simple way to run Python on cloud hardware (especially for folks without a lot of cloud experience).\u00a0\n\nI\u2019m curious to hear from folks here. Do you have a favorite way to run Python code on the cloud? What do you like about your current setup? For example, ergonomics, performance, something else?",
        "num_comments": 5,
        "comments": [
            "I build a similar internal library for my company. Do you support AzureML?",
            "Is it possible to run coil on my own hardware",
            "We use Azure VM Scale Sets (VMSS) to manage cloud VMs. We don't integrate with Azure ML directly, but do see lots of users with ML use cases (for example, [PyTorch training](https://docs.coiled.io/user_guide/pytorch.html), [experiment tracking](https://docs.coiled.io/user_guide/mlops-with-mlflow.html)). Are there specific AzureML services that you\u2019re interested in?",
            "Today we only run on AWS/GCP/Azure (so not on-prem). Everything runs inside your own cloud account, but still on cloud hardware."
        ]
    },
    "Textual Serve - Serve TUIs in the browser": {
        "title": "Textual Serve - Serve TUIs in the browser",
        "score": 88,
        "url": "https://www.reddit.com/r/Python/comments/1djk6u8/textual_serve_serve_tuis_in_the_browser/",
        "content": "Textual Serve (https://github.com/Textualize/textual-serve) is a project which serves TUIs (built with Textual) in the browser.\n\nThis is self-hosted, so you don't need to rely on any external service.",
        "num_comments": 11,
        "comments": [
            "This looks awesome! Didn't know I wanted this!",
            "So very cool.",
            "holy shit, I was looking for this last week and couldnt figure out what was ganglion.",
            "This is dope. Made my [first TUI](https://github.com/ben-n93/tab-pal/tree/main) with Textual just a couple of months ago so keen to check this out.",
            "This is beautiful. Everyone I know always asks me how I make such beautiful APIs and interfaces and I show them Rich. Never got very far with textual, but this might convince me to come back to it",
            "How's its mobile performance? That's where I see the main opportunities for it!",
            "Ganglion is the code name of the server that powers textual-web. It's not something you need to download.",
            "Not much, what's ganglion with you?",
            "Varies from phone to phone. Still more work to do there.",
            "I understood that part, I was just trying to hack textual-web somehow to host in an ASGI context. Didn't get too far.",
            "I don\u2019t think that would work with textual-web, but it might with textual-serve!"
        ]
    },
    "Python Project Management Primer": {
        "title": "Python Project Management Primer",
        "score": 30,
        "url": "https://www.reddit.com/r/Python/comments/1djp1gw/python_project_management_primer/",
        "content": "[This article](https://open.substack.com/pub/martynassubonis/p/python-project-management-primer?utm_source=share&utm_medium=android&r=3c7yz7) explores how to manage Python project environments and dependencies, as well as how to structure projects effectively.",
        "num_comments": 6,
        "comments": [
            "Great write up. For me, it sort of ties together all the little bits of info I learned through the years.",
            "Thanks for sharing it!",
            "nice article",
            "Is this suggesting working without venvs?",
            "Did you read the article? It goes into specific detail in the use of venvs...",
            "No, it's quite long. I skimmed through and looked at the workflow examples. Just checked it again and apparently poetry does that implicitly."
        ]
    },
    "Python on ARM laptops": {
        "title": "Python on ARM laptops",
        "score": 17,
        "url": "https://www.reddit.com/r/Python/comments/1djtma4/python_on_arm_laptops/",
        "content": "Hi there !\n\nI'm thinking about buying an ARM windows laptop with the new Qualcomm chips. They will replace the x86 so I was wondering : Will There be a massive risk of non-compatibility of Python packages ? I guess they are made for x86 but I don't know if it's possible to work with them with an ARM based CPU.\n\n  \nEdit : Had a great deal on the ideapad pro 5 gen 9 so I went for it. Glad to have these incredible specs and decided to rely on x86 chip for the moment, because I wanted to avoid all the early-adoption problems ",
        "num_comments": 44,
        "comments": [
            "Probably you will need to use the Windows Subsystem For Linux (WSL) as your development environment in order to install compiled packages of arm distributions of Linux.  There are probably lots of libraries that aren\u2019t yet providing prebuilt wheels for native Arm Windows.",
            "Most Python packages are distributed as \"wheels\". They may or may not be platform-specific. Most Python packages are pure-Python and have a single wheel that works everywhere.\n\nIf they are platform specific because of some native extension for CPython, it depends on the package authors which Python versions \u00d7 operating systems \u00d7 CPU architectures are supported. The particular combination `win+arm64` is effectively nonexistent, though. That may change in the future.\n\nBut this doesn't mean that you can't install those packages \u2013 it means `pip` may have to download the source code and compile the packages on your system. That is a lot slower, and requires that you have a suitable compiler toolchain installed. Because this is quite challenging on Windows, some people prefer tools like Conda that may offer pre-compiled packages even if the original package authors didn't create a wheel.\n\nOther platforms like linux+arm64 or macos+arm64 are decently common. ARM support itself is not an issue, the Windows ecosystem for ARM is just very small.\n\n> I'm thinking about buying an ARM windows laptop \n\nThat's early adopter stuff. I probably wouldn't do that unless you value battery life more than compatibility.\n\nIf this platform includes an emulation layer (like Apple's Rosetta), it may be possible to run x86_64 programs, including Python. This would remove many compatibility concerns, at a performance penalty. But I haven't read up on Microsoft's approach here. Similarly, you can sidestep the problem by using Linux (possibly via the WSL virtual machine).",
            "I have been using a Thinkpad x13 for 6 months or so and have had no issues in this regard.\u00a0\n\n\nAs another comment mentioned, WSL is there:\nLinux tpadx13s 5.15.153.1-microsoft-standard-WSL2 #1 SMP Fri Mar 29 23:16:34 UTC 2024 aarch64 aarch64 aarch64 GNU/Linux\n\n\nHere's some info about emulation:\u00a0\nhttps://learn.microsoft.com/en-us/windows/arm/apps-on-arm-x86-emulation\n\n\n\nThere is a Windows ARM Python release.\u00a0\n\n\nI use Python and powershell primarily through vscode and haven't had to do anything differently.\u00a0\n\n\nI also play with micropython and use thonny most of the time for it, using the x64 version for that and I've had no issues. Honestly even forgot until writing this comment. Same for the Arduino IDE.\u00a0\n\n\nReally the only issue I have had at all is the emulation doesn't get you drivers, so if you have a device you want to connect and there isn't a native driver, your probably not going to find one.\u00a0\n\n\nFor the why on my side, I wanted the battery life and the slim size, but even more than those I wanted something fanless. It has worked out great for me. Most of the time have no idea when I last charged it. I picked mine up as a refurb from eBay, but it was really an open box. I got it only about 6 weeks after it was originally purchased. 16GB with an unlocked 5G modem in it and 3 yr warranty was 525 shipped.\u00a0",
            "You can write any program in any language for any operating system. \n\nThat said,  you sure you want to use windows? If your goal is python development, and performance is of any importancs (even if it's last on priority list, it is important enough to make the priority list) then removing the spyware/bloatware of windows and going with <insert any distro> Linux will be your best option.\n\nI saw a 30% improvement in performance just by changing operating system. And the only compatibility issues I've had have been using the wrong version of Wine.",
            "Main issue with python libraries I had were with numpy and pandas.\n\nAs others have mentioned wsl works fine, discounting the occasional freeze.",
            "Note that there are some problems with dev tools on those chips, yesterday one of the reviewers did a live stream and Windows was blocking some of the apps from even installing. It's still a very early platform (and it would be good to have Linux and not just Windows as Linux on ARM is way more mature not to mention better for development).",
            "I had some issues with a package when running python on my M1 Max, but the package was built by Intel so that was expected. Except for this one, everything I used on ML/Webdev worked fine.",
            "If you want to do any data processing using packages like numpy, pytorch, pandas you could use the wheels from https://github.com/cgohlke/win_arm64-wheels/\nBut as others have said, this is all early adopter stage stuff",
            "I would not risk buying windows arm now. Better wait at least a year and see, how apps will be adopted. For now x64 win and arm64 mac os are far more preferable and time-tested",
            "It was kinda a mess on Apple Silicon when it first came out too, but it get better over time. As usual: Don't buy it when it first come out if you worry.",
            "You\u2019re going to be pulling out your hair because of python dependencies and that\u2019s _with_ using x86. Just use the most popular stack with python and focus on your core competency. Don\u2019t make it harder than it already is.",
            "At this point you shouldn\u2019t encounter many incompatibilities caused by ARM vs x86",
            "ARM should be fine. I daily drive an M1 MacBook. And our servers are all on ARM too running Linux. No issues",
            "Thanks for your answer !!\n\n  \nYEah, I will check how the situation evolves but it would be very dumb to buy a laptop and not be able to work because of these issues. I will probably go for an x86",
            "THanks for your answer ! \n\nIndeed, they included an emulation layer called Microsoft Prism. But indeed, I have an M1 Macbook air right now but I would like to switch to windows. There is one thing I want to avoid and it's compatibility problems or performance penalties due to the emulation.\n\nI just need a laptop with enough battery for a class day in uni. I'm going to retrieve some info but it will be better to be careful and go for an x86 laptop.",
            "Oh mate thanks for your answer ! \n\nThat's really great news, I will check this and your link. The worst thing for me would be to pay for a new laptop and have these issues. And you made a great deal for your x13 haha.\n\nOn my side, if I buy an ARM version I would go for the new snapdragon plus or elite computers to make it futureproof with good battery life. But I will check everything before buying.\n\nIf I see a great deal on an x86 I will probably save some bucks and go for this one",
            "What kind of packages do you use? Have you found it impossible to install some through the regular pip procedure?",
            "Thanks for your reply ! \n\nI just bought a laptop with R7 8845hs. I had a very very good deal so I just went for it.",
            "Thanks for your message ! \n\nThere was an incredible deal so I went for the Ideapad pro 5 with an R7, 32gb of RAM. I saved some bucks and decided to rely on x86 chip.",
            "Thanks for your answer.\n\n  \nThat's great news ! If you have some time to explain, will the packages need to be updated for ARM or not ? I guess not and that's why you said there should not be many incompabilities but it would be great to know more",
            "But M-series chips are out since 2020 so they had time to adapt. It's maybe too recent for windows laptops, I don't want to risk not being able bc of these issues.\n\n  \nThx for your answer !!",
            "Just to clarify, windows computers now have a way to run a Linux  virtual machine natively without additional emulation software.   It lets you run programs in a Linux environment instead of windows.  This is especially helpful when the underlying CPU is ARM based because Python libraries with compiled extensions are way more likely to make Linux ARM versions and release them on pypi than native windows binaries.   For example, Numpy just released a 2.0 version, but by the looks of it you can only get x86 versions for native Windows.  But if you use the WSL2 on an ARM windows machine you will be installing the ARM Linux versions without any issues. \n\nIf you are coming from Mac, the Linux environment will also feel more familiar.   \n\nLinux ARM versions are becoming more common both because people on MacOs are running Linux via Docker, and because there now many cloud computing environments that offer Linux runtimes on ARM cpus.  That incentivizes library maintainers to support them sooner than windows ARM environments.",
            "Python compatibility with ARM is great\u2026 on Macs :D I use it daily and didn\u2019t have any issue with any Python package on M1.",
            "For me, the MS Surface Pro 7 does this job and much more. I am very happy with the battery life and performance. I code in VSCode and Python daily and it doesn\u2019t let me down. On more intense loads I just use cloud providers and spin up a VM. It\u2019s lightweight, cheap and not locked in to Apples elitist ecosystem and I love it!",
            ">But indeed, I have an M1 Macbook air right now but I would like to switch to windows.\n\nMight I ask why? Honestly curious, I've rarely seen anyone want to switch to a non \\*nix system once they've used one.",
            "Just curious, why do you want to switch? Your Python experience will likely degrade in several ways.",
            "I meant to say 'x13s' in my comment. Prior to getting it, I had an x13 which is a super nice machine with good battery life as well. My brother had his laptop stolen so I gave him the x13 and got the x13s.\n\nperformance-wise, I've had no problems with this. it has surprised me because I expected a low power device to come with some compromises in that regard. \n\nfunny thing, i have a samsung s24 ultra phone, and it has the same(or very close to) cpu.",
            "i've not had any issues installing stuff with pip. most of the stuff I do from this machine is either work stuff with redfish, various ip tools, etc or playing around with circuitpython. though, in the case of the latter I think most of the packages I am installing are simple scripts. i suppose it's possible there could be package problems, but i'm not a developer or software engineer so i'm probably not doing deep enough stuff to find them.",
            "Most of the original issues when the M1s came out were that there wasn\u2019t a great Fortran compiler for ARM and a lot of linear algebra libraries were not able to work because of that (anything with BLAS). This has been resolved",
            "C api packages will need to be updated. Docker images also. Not everyone puts out arm binaries. \n\nIt\u2019s still an issue. On Mac people use Rosetta, not sure about windows",
            "Win10 was available on ARM. admittedly, there weren\u2019t many devices, and it didn\u2019t have great support from MS, but it was available. It could emulate x86 to a certain point. \n\nFWIW, I develop on an M-series device, and deploy to AWS on x86 and ARM. Have run into very few compatibility issues.",
            "ARM is ARM, mostly. IMO, in terms of compatibility, It\u2019s like comparing an Intel Core 4th gen vs 8th gen. I think the big question mark is from windows on arm instead of arm itself",
            "also if wheels aren't available you can just try compiling yourself. however it will take longer and can fail for things like pandas which are notoriously quirky to compile",
            "- Screen size : I would like to get a 15 or 16 inch instead of my current 13 inch   \n- It's so weird but I don't feel good with MacOS. I preferred my W10 experience but I know W11 is worse on this side. Windows 10 was so good...  \n- Price : I don't want to put that much money again in a computer... I just can have better specs for cheaper on windows \n\nThe only thing keeping me on mac now is battery life. it's crazy how it's bad on x86 laptops.",
            "Just bought a R7 8845HS,32Gb laptop on x86 chip. ( the lenovo idepadpro 5 gen 9)\n\nI wanted :  \n- a bigger screen size (and god knows how expensive it is with Apple)  \n- I'm in finance so I also use a lot of excel/vba and it is crap on macOS  \n- Probably the most important point : I don't like macOS. I feel better and more pleased with Windows. I will miss battery life and data privacy but that's ok for me",
            "I just got a very very good deal on the Ideapad pro 5 with R7, 32gb of RAM and 1tb of storage. I saved some bucks and looking forward to receive it !!",
            "Ok thanks. I\u2019m not a developer either. I mostly make scripts as well, but more data analytics oriented.",
            "Out of curiosity, what libraries do you have issues with? \u00a0I haven\u2019t had to use Rosetta on my Mac in well over a year and Docker works fine for my heavy use at work",
            "Okay I see. Microsoft released Prism which is an equivalent of Rosetta. However, the performance drop seems quite big at the moment.\n\nI'm going to wait a month to see how the situation evolves but for now, it seems better to go for an x86 laptop even though their battery life is worse",
            "Overall, it seems that it should be okay then but I will check before buying. I'm ready and just waiting for a good deal to pay !!",
            "I'm probably less tech-savvy than you, thanks for the clarification ! \n\nYes indeed, It's still too recent but I think Microsoft Prism ( the emulation layer) is doing a decent job. But I still have to wait for some independent reviews",
            "It may be fine but warrants more research. I use arm Mac for work and it\u2019s still an issue. Mostly with docker containers",
            "The performance isn\u2019t much different, here\u2019s a [video](https://youtu.be/uY-tMBk9Vx4) about it.",
            "I currently have mac M1 but I need windows, and I also struggle with MacOS. I prefer Windows even though it's more buggy.\n\nI could emulate windows with UTM but I only have 8gb of RAM so it's quite difficult as you can imagine."
        ]
    },
    "Video Quality Ranker": {
        "title": "Video Quality Ranker",
        "score": 1,
        "url": "https://www.reddit.com/r/Python/comments/1dk0ru7/video_quality_ranker/",
        "content": "## What my project does\nRanks videos based on overall quality. Takes into account multiple metrics to determine what quality is the best.\n\n## Target audience\nHome users / Video enthusiasts\n\n## Comparison\n\nThis project uses the following metrics to rank videos:\n\n- **Resolution**: Higher resolution videos are preferred.\n- **Frame Rate**: Videos with higher frame rates are ranked higher.\n- **Bitrate**: Higher bitrate often indicates better quality.\n- **Codec**: Some codecs provide better quality than others at the same bitrate.\n\nThe script extracts these metrics using `ffprobe` from the FFmpeg suite and sorts the videos accordingly. Here's how the metrics are used:\n\n1. **Resolution**: The script first compares the resolution (width x height) of the videos. Higher resolutions are ranked higher.\n2. **Frame Rate**: If two videos have the same resolution, the one with the higher frame rate is ranked higher.\n3. **Bitrate**: For videos with the same resolution and frame rate, the bitrate is used to determine the quality.\n4. **Codec**: In case of a tie in all other metrics, the codec is considered to break the tie.\n\n## Access the Script\nYou can access the script on GitHub [here](https://github.com/slyfox1186/script-repo/blob/115b8d2f038c22ec5b5ea9b85ae87287106e90b8/Bash/Installer%20Scripts/FFmpeg/run-scripts/video-quality-ranker.py)",
        "num_comments": 3,
        "comments": [
            "PSNR, SSIM and friends are important tools to include in video quality ranking.",
            "what kind of command line would you implement using these tools?",
            "I don't really understand your question.  I mean, your script evaluates the quality of video files, right?  It's up to you to determine a balance between the output of these psychometric algorthims and objective facts like resolution, etc."
        ]
    },
    "A JIT compiler for CPython": {
        "title": "A JIT compiler for CPython",
        "score": 20,
        "url": "https://www.reddit.com/r/Python/comments/1djdy0z/a_jit_compiler_for_cpython/",
        "content": "Brandt Bucher talks on JIT compiler for Python at CPython Core Developer Sprint. Brandt is  a member of the [Faster CPython project](https://github.com/faster-cpython), which is working on making the reference implementation of the language faster via a variety of techniques.\n\n[https://www.youtube.com/watch?v=HxSHIpEQRjs](https://www.youtube.com/watch?v=HxSHIpEQRjs)\n\n",
        "num_comments": 4,
        "comments": [
            "FYI the youtube link OP posted is from PyCon 2023, but the lwn link that /u/mechanickle is about the talks given at PyCon 2024. I think we're still waiting for the PyCon 2024 talks to start being published.",
            "There's an article on lwn.net, but it's paywalled.",
            "Here you go: https://lwn.net/SubscriberLink/977855/066153bb25e9adb1/",
            "Thank you\ud83d\udc4d\ud83c\udffc"
        ]
    },
    "Conway's game of life. can you find an optimization?": {
        "title": "Conway's game of life. can you find an optimization?",
        "score": 3,
        "url": "https://www.reddit.com/r/Python/comments/1djta0v/conways_game_of_life_can_you_find_an_optimization/",
        "content": "little challenge for you, how fast can this be pushed in python?\n\nThis function takes a numpy.ndarray / 2d numpy array, and returns the updated array. iv updated this function several times, this i the fastiest so far.\n\nnumba jit dosn't like the double roll, and its faster than for loops in jit.\n\n    def conways_game_of_life(board:numpy.ndarray):\n      n_neighbour = sum(numpy.roll(numpy.roll(board, i, 0), j, 1) for i in (-1, 0, 1) for j in (-1, 0, 1) if (i != 0 or j != 0))\n      board[(n_neighbour<2) | (n_neighbour>3)] = 0\n      board[(n_neighbour==3)] = 1\n      return board",
        "num_comments": 6,
        "comments": [
            "Can't keep myself from plugging my favourite optimization trick: you can achieve exponential speedup using the Hashlife algorithm, see [https://en.wikipedia.org/wiki/Hashlife](https://en.wikipedia.org/wiki/Hashlife)",
            "    \u00a0 \u00a0 import numpy as np\n    \u00a0 \u00a0 import scipy.ndimage as nd\n    \n    \n    \u00a0 \u00a0 KERNEL = np.array([[1, 1, 1], [1, 0, 1], [1, 1, 1]], dtype=np.uint8)\n    \n    \n    \u00a0 \u00a0 def next_state(universe):\n    \u00a0 \u00a0 \u00a0 \u00a0 neighbor_count = nd.convolve(universe, KERNEL, mode=\"constant\")\n    \u00a0 \u00a0 \u00a0 \u00a0 still_alive = universe & np.isin(neighbor_count, (2, 3))\n    \u00a0 \u00a0 \u00a0 \u00a0 births = ~universe & (neighbor_count == 3)\n    \u00a0 \u00a0 \u00a0 \u00a0 return still_alive | births\n\nif you allow yourself another library that has 2d convolutions, you may be able to get a speed up",
            "    speed results:\n    \n    #1st test, 10x10:\n    #sum(double_roll) = 232 \u00b5s \u00b1 57.6 \u00b5s per loop 1,000 loops each\n    #ndimage.convolve = 109 \u00b5s \u00b1 8.9 \u00b5s per loop 10,000 loops each < winner\n    \n    #2nd test 100x100\n    #sum(double_roll) = 313 \u00b5s \u00b1 113 \u00b5s per loop 1,000 loops each\n    #ndimage.convolve = 228 \u00b5s \u00b1 12.4 \u00b5s per loop 1,000 loops each < winner\n    \n    #3rd test 1000x1000\n    #sum(double_roll) = 5.41 ms \u00b1 773 \u00b5s per loop 100 loops each < winner\n    #ndimage.convolve = 15.9 ms \u00b1 891 \u00b5s per loop 100 loops each\n    \n    #4th test 10_000x10_000\n    #sum(double_roll) = 1.8 s \u00b1 173 ms per loop 1 loop each < winnner\n    #ndimage.convolve = 3.51 s \u00b1 474 ms per loop 1 loop each\n    \n    # - this test was run on my potato btw.",
            "Try it with scipy.signal.convolve2d? It might be faster for the larger arrays\n\nEdit: I misread the original as np.convolve, I\u2019m not sure this would actually be faster then",
            "    # scipy.signal.convolve2d.\n    # 1st, 10x10\n    # 21.9 \u00b5s \u00b1 4.93 \u00b5s per loop - 10,000 loops each\n    # 2nd, 100x100\n    # 557 \u00b5s \u00b1 87.1 \u00b5s per loop - 1,000 loops each\n    # 3rd, 1000x1000\n    # 58.1 ms \u00b1 11.2 ms per loop - 10 loops each\n    # 4th, 10_000x10_000\n    # 6.15 s \u00b1 290 ms per loop - 1 loop each\n    \n    # after 6 seconds my potato was ready for harvest. my downloaded rams not working.",
            "Huh, so it\u2019s actually worse for larger values but better for the minimal case, weird"
        ]
    },
    "json3pdf : Batch OCR for high quality document archiving.": {
        "title": "json3pdf : Batch OCR for high quality document archiving.",
        "score": 4,
        "url": "https://www.reddit.com/r/Python/comments/1djlr6e/json3pdf_batch_ocr_for_high_quality_document/",
        "content": "## What my project does \nPerforms OCR on scanned Books using Microsoft Azure Document Intelligence read\n\n## Target audience\nPeople who are unsatisfied with traditional OCR\nPeople who want to add clear text to the original PDF and not just extract the text.\nPeople who want to archive documents at best quality.\n\n##Comparasion\nIn my use case traditional OCR was near to useless.\nTesseract was meh, Google API didn't process large files.\nDocument Intelligence takes up to 500MB (although in practice a little less), and is possible to OCR 400-600 pages over books in batch by dividing and merging the source and results locally by only a few chunks.\nIt doesn't provide the text in PDF form so that was my reason to start this project.\n\nStill in alpha and in separate modules and a lot of rigid coding, but it is working fine for my original task so thought maybe I'd showcase it.\n\n\nhttps://github.com/DesertDoggy/json3pdf\n\n\n",
        "num_comments": 0,
        "comments": []
    },
    "Thursday Daily Thread: Python Careers, Courses, and Furthering Education!": {
        "title": "Thursday Daily Thread: Python Careers, Courses, and Furthering Education!",
        "score": 7,
        "url": "https://www.reddit.com/r/Python/comments/1ci1f9v/thursday_daily_thread_python_careers_courses_and/",
        "content": "# Weekly Thread: Professional Use, Jobs, and Education \ud83c\udfe2\n\nWelcome to this week's discussion on Python in the professional world! This is your spot to talk about job hunting, career growth, and educational resources in Python. Please note, this thread is **not for recruitment**.\n\n---\n\n## How it Works:\n\n1. **Career Talk**: Discuss using Python in your job, or the job market for Python roles.\n2. **Education Q&A**: Ask or answer questions about Python courses, certifications, and educational resources.\n3. **Workplace Chat**: Share your experiences, challenges, or success stories about using Python professionally.\n\n---\n\n## Guidelines:\n\n- This thread is **not for recruitment**. For job postings, please see r/PythonJobs or the recruitment thread in the sidebar.\n- Keep discussions relevant to Python in the professional and educational context.\n  \n---\n\n## Example Topics:\n\n1. **Career Paths**: What kinds of roles are out there for Python developers?\n2. **Certifications**: Are Python certifications worth it?\n3. **Course Recommendations**: Any good advanced Python courses to recommend?\n4. **Workplace Tools**: What Python libraries are indispensable in your professional work?\n5. **Interview Tips**: What types of Python questions are commonly asked in interviews?\n\n---\n\nLet's help each other grow in our careers and education. Happy discussing! \ud83c\udf1f",
        "num_comments": 2,
        "comments": [
            "What would be a good starter recommendation when it comes to getting into Python? I work in Metrology Polyworks, and slowly stumbling into macros and commands, I know it's not 1 to 1, but learning some basic python could help me better understand the programming within Polyworks from my understanding and maybe future things from there. \n\n  \nSo just curious what you would recommend in your free time to get an overall grasps of the basics. TIA.",
            "Do we have any certifications available free?"
        ]
    },
    "Experimental Python Wheels for Windows on ARM64": {
        "title": "Experimental Python Wheels for Windows on ARM64",
        "score": 2,
        "url": "https://www.reddit.com/r/Python/comments/1djpj8t/experimental_python_wheels_for_windows_on_arm64/",
        "content": "For anyone on a (new) Windows on Arm system, I found this great repo with Arm64 Windows wheels:\n\n* [https://github.com/cgohlke/win\\_arm64-wheels](https://github.com/cgohlke/win_arm64-wheels)\n\n*Highlights*\n\n* 256 packages for Python 3.12\n* Built with numpy 2 if possible\n* Scipy stack: numpy with OpenBLAS, scipy, matplotlib, Pandas, scikit-learn, scikit-image, numba, etc.\n* GIS stack: GDAL, netCDF4, pyproj, Shapely, rasterio, basemap, Fiona, etc.\n* Image IO: Imagecodecs, Pillow, OpenImageIO, OpenEXR, pylibCZIrw, etc.\n* Noteworthy: Pytorch, Kivy, opencv\\_python\\_headless, pymol-open-source, pywin32",
        "num_comments": 0,
        "comments": []
    },
    "Parsing Python ASTs 20x faster with Rust": {
        "title": "Parsing Python ASTs 20x faster with Rust",
        "score": 34,
        "url": "https://www.reddit.com/r/Python/comments/1div2e8/parsing_python_asts_20x_faster_with_rust/",
        "content": "[https://www.gauge.sh/blog/parsing-python-asts-20x-faster-with-rust](https://www.gauge.sh/blog/parsing-python-asts-20x-faster-with-rust)\n\n",
        "num_comments": 14,
        "comments": [
            "I see these sorts of things all the time and wonder: is it the language that is faster or the implementation. Nearly speed gain like this comes with a drawback somewhere -- some corner cases that stop working or something. If they didn't, then rewriting to obtain this speed should be possible in other lower level languages (C, Fortran, etc.)",
            "Hi I'm the author of the blog post! I think in this case it would definitely be possible to get the same performance in another low-level language. Any compiled extension which avoids building the AST representation out of PyObjects should show better performance than the naive implementation, even if the logic of the parser is identical to the one found in CPython. Like the other comment said, I used the custom parser that ruff uses because it was built for a very similar use case and the best alternative (the RustPython parser) was not as reliable in my tests.",
            "Python uses a standard PEG grammar now so there shouldn\u2019t be any corner cases.",
            "It's of course (in large parts) the implementation - but coming up with a given implementation and implementing it (in a maintainable way) is very much language dependent. There's no difference in theory but there is one in pratice.\n\nRust allows you to be somewhat faster for some things than C or whatever (honestly mentioning Fortran for a text processing thing is wild) *in pratice* because it allows you to be very conservative with copies etc. It also helps that it has very good implementations of many standard data structures and algorithms you might want to use (as opposed to C++ where they're bad and third party code can be annoying to integrate, or C where they don't exist), and that it's so much easier to parallelize.\n\nSo could you write C that mirrors this in terms of speed? Yes, of course. But no ones going to do it",
            "Cpython is basically all C anyways - the article talks a bit about why Python was still so slow as compared to rust. The code is open source too, so you can take a peek! [https://github.com/gauge-sh/tach](https://github.com/gauge-sh/tach)",
            "It's how implementations of languages allocate memory. In order to have the flexibility you know and love Python objects are fairly heavy weight and they always use the heap and thus need garbage collection. In this case rust structures are much more efficient, and we don't need intermediate data structures to be flexible.",
            "Excellent work, btw. \n\nEven if it never gets integrated anywhere, but can be waived around as a benchmark to improve things, you'll have succeeded :)",
            "What does this mean?",
            "> honestly mentioning Fortran for a text processing thing is wild\n\nSelecting from low level languages that I can grok. I could have selected any other low level language and the point would still apply. A low level language should (after being compiled) be as close to machine level as possible, without having to write in ASM. So any implementation that is low level enough, and assuming optimized compilers, should achieve nearly the same performance when using the same algorithms. \n\nYou're absolutely correct that writing the above in Fortran would suck donkey balls.",
            "OP is asking about comparing Rust and C vs the implementation. The project in the post is made in C and then rewritten in Rust. That means, Python memory management and garbage collection is not involved in this.",
            "It means that the python code is no longer parsed by a bunch of custom code which is much more likely to have odd corner cases.\n\nThey\u2019ve switched to defining a grammar, parsed by a standard parser, which can also parse any other PEG grammar so it\u2019s much, much more likely to be the same parser-to-parser.",
            "Someone answered this [above](https://www.reddit.com/r/Python/s/3xUKh5PvEd), I think in summary it is a matter of C being so low level makes it still hard to come up with higher level solutions and then make sure there\u2019s nothing wrong. Probably by using the Rust implementation one could make a C counter part, but it probably won\u2019t be as easy to maintain anyway.",
            "CPython has always had a well defined grammer and a generated parser instead of having a bunch of custom code. The PEG parser just means that it can now parser much more complex forms instead of being a mostly LL(1) Grammer. That's why all the soft keywords are showing up and working well now vs like when async was hacked into the language as a soft keyword.\n\n\n\nOf course that doesn't mean using the generated parser is the only way to do this. And indeed it seems the parser the author used is Ruffs parser which is a hand written recursive decent parser. So there may indeed be edge cases but luckily parsers are pretty easy things to throw tests at.",
            "[PEP 617](https://peps.python.org/pep-0617/)\n\n> This new parser would allow the elimination of multiple \u201chacks\u201d that exist in the current grammar to circumvent the LL(1)-limitation"
        ]
    },
    "Trying to find this package": {
        "title": "Trying to find this package",
        "score": 5,
        "url": "https://www.reddit.com/r/Python/comments/1dj6q3w/trying_to_find_this_package/",
        "content": "I should have saved the post but maybe 4-6 months ago I was reading a post (I am pretty sure it was in r/Python) where someone created a package that creates a visual for data contained within a list. For example, let\u2019s say I have a data frame where one of the columns is named \u201ccolors\u201d and each record contains a list of colors. One record might be [black,blue,yellow] another record might have [blue,yellow,black]. The visual had two parts where the top was a column chart to show the frequency of the list combinations and below the column chart was more of a table that showed each \u201ccolor\u201d as one column and then across the row for each color and under the columns from the chart above was an indicator of sorts that would be greyed out of the color for that row was not in the corresponding columns list and highlighted another color of it was. Anyways this is probably a long shot but either the package or the name of this visual would be super helpful. Thanks python community!  ",
        "num_comments": 2,
        "comments": [
            "The holoviz community should be able to help you out \n\nhttps://panel.holoviz.org/",
            "Microsoft Lida"
        ]
    },
    "Wednesday Daily Thread: Beginner questions": {
        "title": "Wednesday Daily Thread: Beginner questions",
        "score": 2,
        "url": "https://www.reddit.com/r/Python/comments/1cmqqgn/wednesday_daily_thread_beginner_questions/",
        "content": "# Weekly Thread: Beginner Questions \ud83d\udc0d\n\nWelcome to our Beginner Questions thread! Whether you're new to Python or just looking to clarify some basics, this is the thread for you.\n\n## How it Works:\n\n1. **Ask Anything**: Feel free to ask any Python-related question. There are no bad questions here!\n2. **Community Support**: Get answers and advice from the community.\n3. **Resource Sharing**: Discover tutorials, articles, and beginner-friendly resources.\n\n## Guidelines:\n\n* This thread is specifically for **beginner questions**. For more advanced queries, check out our [Advanced Questions Thread](#advanced-questions-thread-link).\n\n## Recommended Resources:\n\n* If you don't receive a response, consider exploring r/LearnPython or join the [Python Discord Server](https://discord.gg/python) for quicker assistance.\n\n## Example Questions:\n\n1. **What is the difference between a list and a tuple?**\n2. **How do I read a CSV file in Python?**\n3. **What are Python decorators and how do I use them?**\n4. **How do I install a Python package using pip?**\n5. **What is a virtual environment and why should I use one?**\n\nLet's help each other learn Python! \ud83c\udf1f",
        "num_comments": 5,
        "comments": [
            "I want to relearn Python because I have been searching for an opportunity for a while now but am not getting any. This has jolted the pillars of my confidence because I am not a beginner. I have around 20 years of work experience, I have worked with a Big 4 for 10 years some of which were as a Manager of a DataViz team. I have been learning coding since the time of MS Dos and have been a Teaching Assistant for a Deep Learning course.\r  \n\r  \nI understand that r/Python won't be able to help me gain my confidence, that's not the purpose of this sub. However, I personally feel that if I relearn Python I would be able to gain back some of the lost confidence. So I am asking for your feedback and help.\r  \n\r  \n\\- If I were to relearn Python, will CS50 be a good idea?\r\n\n\\- Is this the correct URL for CS50? [https://cs50.harvard.edu/x/2024/](https://cs50.harvard.edu/x/2024/)\r\n\n\\- I see that CS50 has other topics like C, SQL etc other than Python. However, I do not see pointers which is making me rethink about CS50. Will CS50 cover majority of the important topics for Python, or will it omit important topics like pointers for C in Python too?\r\n\n\\- Can somebody suggest a note taking method why I can apply to keep notes from this course which will not only help me in future but others too since I plan to make my progress etc open-source.\r  \n\r  \nAny help would be highly appreciated. Thanks in advance.",
            "\nHello Python enthusiasts!\n\nI'm excited to join this community and dive deeper into the world of programming!\n\nA bit about my journey: I started tinkering with BASIC at the age of 12. Later running multiple BBSs on an Amiga. My adventure continued as I explored HTML, JAVA, PHP, and CSS. Lately, I've been fascinated by AI and ChatGPT. However, I realize that using builders alone won't suffice for integrating advanced features into my websites securely.\n\nMy aim is to create tools that assist individuals with disabilities, an endeavor close to my heart. To achieve this, I need to master the environment in which these tools operate. Although I've experimented with creating a series of agents to practice on, I'm still figuring out how to effectively deploy them on websites.\n\nI've always learned differently\u2014school tests were never my thing, so I carved my own path as an entrepreneur, learning from deconstructing top-rated sites and engaging with knowledgeable peers who were generous with their insights.\n\nAs I continue my learning journey in this community, could you help me understand where I should focus my efforts? What specific technologies or frameworks should I prioritize to better control and integrate AI functionalities into my web projects? Any advice or resources you could share would be incredibly appreciated!",
            "Why not [https://cs50.harvard.edu/python/2022/](https://cs50.harvard.edu/python/2022/) ? You can also use [https://programming-24.mooc.fi/](https://programming-24.mooc.fi/) - whatever course fits you best. You should choose a note taking app which works for you since it is far from guaranteed other people are interested in your notes, even if they are open source.",
            "You want to \"add AI\" to do what exactly?",
            "\nI'm developing a website designed for children with Autism and their parents. The core function of the AI on this site is to assist them in discovering both local and national resources for ASD. For the children, the website will feature an engaging area where they can play games and access coloring pages, among other activities. The AI will not only support interactive elements but will also ensure security and privacy, particularly important as the site caters to underage users. The integration of sophisticated AI capabilities will enable the website to respond to inquiries and securely retain information specific to each user, without my direct access to the data. This ensures a safe, interactive, and educational environment where privacy is paramount.\" I  also want it to work some of the behind the scenes stuff. I am having so much fun learning bit find I get information over load."
        ]
    },
    "I am Nominating Myself for PSF Board of Directors": {
        "title": "I am Nominating Myself for PSF Board of Directors",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1djunb5/i_am_nominating_myself_for_psf_board_of_directors/",
        "content": "I am nominating myself for the PSF Board of Directors! \ud83c\udf1f Check out my latest blog post to learn more about my journey, my commitment to the Python community, and my application for an OFAC license to expand educational activities in restricted areas.\n\nRead more at [my blog](https://blog.techbend.io/i-am-nominating-myself-for-psf-board-of-directors)",
        "num_comments": 9,
        "comments": [
            "Why\u2019s your account 19 minutes old?",
            "Cool, it's good to have a wide range of people putting themselves forward for the board.\n\nI will say that, while I am not a PSF member and am not familiar with their voting criteria, I wouldn't say your nomination stands out as well as many from previous years (https://www.python.org/nominations/elections/2023-python-software-foundation-board/nominees/).\n\nMore specifically, I'd say that your section on your experience seems quite vague and lacking, and it's not clear how you go above and beyond to contribute to the Python community.\n\nI also think you need to link your goals with the aims and abilities of the PSF. You mention internet access in other countries being an issue, but not what the PSF can do about it.\n\nYour nomination feels low quality enough that I'd guess you have almost no chance of getting on the board with it.",
            "i am also nominating myself",
            "It could also be that they wanted to separate their previous \"do anything\" account from one that will be used in a professional capacity.\n\n(Legitimate question though)",
            "Maybe because they didn't have a Reddit account before? \n\nThis is a valid post for the sub. As bad as the nomination is, I think it's completely unfair to use that as a point against them, and feels pretty gatekeepy.",
            "thanks I will edit it to clarify it. Also, I know that I don't have any chance, I use this opportunity to tell the problem and what I think can be a solutions.",
            "awsome!   \nif you elected please consider my concerns.",
            "Sorry, guess I just expected to see more of a presence on Reddit if they decided to share their nomination on Reddit. I was a bit surprised to see what looks like a throwaway account, and a bit suspicious because this OP has a hyperlink to \u201cmy blog.\u201d I went there anyway, and I like how he talks about wanting to bring more diversity to the topic. I guess I just wanted an explanation for *why Reddit*? Not necessarily *why r/Python*?\n\nHe is welcome though. Anyone willing to participate in making things better is welcome. I am in no position to gatekeep and don\u2019t want to.",
            "I have another Reddit account, but I made this new one with my real last name for professional reasons. I nominated myself for the PSF Board, and after I finished, I thought it would be good to write about it and introduce myself. Hashnode suggested I share it on Reddit.\n\nUnfortunately, my submitted nomination is not publicly available yet.\n\nBecause of the current situation in Iran, only a few of my friends and I can vote. So, I am sharing it with the wider community."
        ]
    },
    "Scrapegraph AI Tutorial; Scrape Websites Easily With LLaMA AI": {
        "title": "Scrapegraph AI Tutorial; Scrape Websites Easily With LLaMA AI",
        "score": 6,
        "url": "https://www.reddit.com/r/Python/comments/1dip146/scrapegraph_ai_tutorial_scrape_websites_easily/",
        "content": "I'm going to show you how to get Scrapegraph AI up and running, how to set up a language model, how to process JSON, scrape websites, use different AI models, and even turning your data into audio. Sounds like a lot, but it's easier than you think, and I'll walk you through it step by step.\n\n[https://www.scrapingbee.com/blog/scrapegraph-ai-tutorial-scrape-websites-easily-with-llama-ai/](https://www.scrapingbee.com/blog/scrapegraph-ai-tutorial-scrape-websites-easily-with-llama-ai/)",
        "num_comments": 1,
        "comments": [
            "Cool, I will try this thanks. Do you have a youtube channel for this?"
        ]
    },
    "What are the hardware requirements in a laptop to run Python + Future AI based projects?": {
        "title": "What are the hardware requirements in a laptop to run Python + Future AI based projects?",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1djfqwx/what_are_the_hardware_requirements_in_a_laptop_to/",
        "content": "I will buy a laptop for coding purposes but just started learning and practising Python using Pyecharm. What are the software requirements that lead to hardware specs a general Python coder must look into?\n\nPlease suggest the hardware setup within a pocket friendly budget. ",
        "num_comments": 20,
        "comments": [
            "Honestly, almost any laptop will let you run Python and Pycharm.  Ideally get at least 16Gb of RAM, and 32GB if possible.   Any modern CPU will do.\n\nFor advanced data science or AI, you'll want an NVIDIA dedicated GPU with at least ~~12GB~~ 8GB of vram as a bare minimum.   But if you actually want to do real hardcore DS and AI development, you won't be doing it on a laptop, you'll be doing it on hefty cloud resources.   But the laptop GPU I mentioned above would be fine for learning projects.\n\nEdit: As was pointed out in comments, 8GB is probably plenty for a laptop GPU for most things.",
            "Just start.. as you level up, you can go off CPU or find a way to write efficient code",
            "Don\u2019t worry about Python. It will run fine on just about anything you\u2019d consider fine for the AI dev side. Focus on that requirement instead.",
            "I got my degree using an old laptop with an i3 and no dedicated graphics card.\n\nI did resort to using Google Collab for some of the heavy lifting though.",
            "Depends on which kind of workloads you want to run and whether you want to run workloads locally or in cloud and need to run them on the go.\n\nI like to run some workloads locally and for budget reasons like to buy refurbished workstation/business notebooks (Lenovo Thinkpad, Dell Precision, ..., another option are gaming laptops). I usually want XEON or I7 CPUs, >16GB RAM and Thunderbolt for adding an eGPU if necessary. Since I want to run light \"AI\"-workloads on the go, I also look for a dedicated GPU with at least 6GB of VRAM (Quadro P3200, GTX 1060 6GB). This is enough to run a quantized LLM alongside a smaller STT and TTS model or basic image generation. Each GB of VRAM will make a difference, but only if you really need to run workloads locally and on the go.\n\nIf you don't need to run workloads on the go, you can use a much cheaper laptop just for development and run the workloads via cloud services (Google Colab, Runpod, LambdaLabs, ...) or run them on a solid PC if you prefer local, which you can upgrade for much longer and cheaper.\n\nI had some bad experiences with consumer grade notebooks, especially newer ones, so I would still focus on refurbished workstation/business notebooks, just without a dedicated GPU.\n\nCurrently, I am happy with using a refurbished Dell Precision 7530, XEON E-2176M, 64GB RAM,  Quadro P3200 and optionally an RTX 3060 as eGPU. However, a PC from refurbished/second-hand parts with a few Tesla P40/P100 GPUs would get you much more capability and performance for not that much more budget and maybe could be extended with RTX A5000/A6000 GPUs in a few years.",
            "This isn't as easy to answer as some suggest here.    The number one problem is that you are just learning python so getting deep into AI could be a year off (more or less).\n\nYou can learn PYthon on anything including a Raspberry PI.   This means for this end of the task any laptop will do.   Now when you start to talk about AI it really depends upon what you intend to do AI wise.  However going off the rails supported by most posts I'm going to suggest getting one of Apples laptops with Neural Engine.   Either that or wait for AMD's chip set that will be out soon with its own AI acceleration engine.   This way you will have dedicated AI acceleration hardware which may or may not be important depending upon what you intend to do.   For a desktop that would be Ryzen 8000G Phoenix and Ryzen 8040 AI APU's for mobile (coming).   The third alternative is to take a gamble on Snapdragon X.\n\nWhat I'm saying is that long term AI/ML acceleration hardware is the future.   Unfortunately at this moment in time the hardware is really new outside of Apple.    It might even be worthwhile to get a cheap laptop for Python now and in a year or two upgrade as the market shakes out.   Microsoft is all in with respect to the so called Neural acceleration hardware so again it makes sense to have such hardware as the support matures.",
            "Maybe a controversial opinion, but...\n\nCan be even a potato computer if you have the right skills. I used between 2066-2019\u00b1 a Dell latitude d620 (2005, 32 bits hardware) notebook for data science, and before a LGA775 2010 computer. \n\nToday... I use slightly better computers, but I think it's not the main point here. A modern Lenovo Thinkpad with i5/i7 and 16gb RAM, optionally with any extra GPU, it's more than enough. Most of the heavy stuff today you use cloud infrastructure anyway.\n\nHonestly, for frontend and mobile development we need much more high end computers than data science.\n\nPS.: I work with data science and ml engineering for basically ten years.",
            "You can code and run Python on anything that runs Windows 10 or higher.\nFor deep learning even the best laptop will be barely acceptable. Get a good desktop gpu or pay for expensive cloud resources.\u00a0",
            "Shoot, it'll run on damn near anything.",
            "You can use just about any laptop with the difference being how fast it will run.  So, low end = generic laptop with no GPU, middle = laptop with GPU, high = gaming laptop with high end CPUs and high end GPUs, higher=non-laptop with high end CPUs and GPUs with a UPS, better=cloud\n\nWith larger AI models it can run out of memory, making them unusable. Ran into that a few times.\n\nWith a GPU you may have to install a special driver for AI. And get one of those USB mouse gigglers to keep it from going into power save mode when doing a long AI run.\n\nMy setup (marked spoiler because it's bragging a bit):\n\n>!Processor\t11th Gen Intel(R) Core(TM) i9-11980HK @ 2.60GHz   3.30 GHz, 8 cores, 16 logical!<\n\n>!Installed RAM\t64.0 GB (63.7 GB usable), 3200 MHz!<\n\n>!NVIDIA GeForce RTX 3080 Laptop GPU, 48GB memory, 16GB dedicated!<",
            "I bought asus zyphyrus gtx 1080 16gb ram laptop exactly for this purpose 3yrs ago, not sure if the device can keep up,",
            "I love ![img](emote|t5_2qh0y|601)",
            "An Internet Connection.",
            "I agree with this comment, but OP could save a few bucks with an 8GB GPU. I work pretty heavily with AI assisted photogrammetry and my 4070 does a decent job. Once you go up to a 4080/4090 most laptops cannot cool them well enough for them to perform much better than a 4070. In a desktop I would absolutely go up to the 80/90 level though.",
            "If you do get to do GPU stuff probably better to use a cloud service.",
            "Great response. Looking for notebook to start coding as begginer.",
            "You're absolutely right.  I was overstating that.  I'll edit it.",
            "That's literally what I said?\n\nBut a decent laptop GPU is find for learning DS.",
            "Thanks. \nCoding is not hardware intensive, doesn\u2018t matter if as an beginner or advanced programmer. An older Thinkpad with 16GB of RAM will be plenty. \n\nHowever, if you want to run the software and you code something that utilizes machine learning, you want to take a closer look and can either benefit or absolutely need GPU compute. And the current state of available libraries absolutely allows beginners, to build machine learning projects. At this point, we get back to the decision, where to run it on (local, local&mobile, cloud).\n\nA potentially important point, that I forgot before is, that you will still want power to be available, when running ML workloads locally on the go. Using a dedicated GPU will drain a laptop battery pretty quickly.",
            "Oh ok I see. I meant to say don't bother with buying a GPU for DS purpose, always use a cloud service. I bought a GPU couple of years back Nvidia but current cuda doesn't support it anymore."
        ]
    },
    "Looking for a good WYZIWIG/visual editor to go with with Jinja + Weasyprint": {
        "title": "Looking for a good WYZIWIG/visual editor to go with with Jinja + Weasyprint",
        "score": 5,
        "url": "https://www.reddit.com/r/Python/comments/1diqpcb/looking_for_a_good_wyziwigvisual_editor_to_go/",
        "content": "End goal is to produce PDF using external data and a template. Needs to support Jinja tags, conditionals and loops.\n\nUsing [https://github.com/Kozea/WeasyPrint](https://github.com/Kozea/WeasyPrint) and [https://github.com/pallets/jinja](https://github.com/pallets/jinja) as base stack (Open to other suggestions)\n\nI was thinking of building some base HTML templates but would be awesome if I could find a visual HTML editor that could produce code 100% compatible with Weasyprint so that end users can build templates by themselves or modify existing ones.\n\nCould be Wysiwyg based using [https://editorjs.io](https://editorjs.io) or [https://github.com/slab/quill](https://github.com/slab/quill)  \nor more advanced web builders like [https://github.com/GrapesJS/grapesjs](https://github.com/GrapesJS/grapesjs)\n\nAnybody built something similar?",
        "num_comments": 2,
        "comments": [
            "Wyziwig (??) or Wysiwyg (What You See Is What You Get) ?",
            "yep or in my case it has to be \"What You See Is What I Get\" :)"
        ]
    },
    "NumPy 2.0.0 is the first major release since 2006.": {
        "title": "NumPy 2.0.0 is the first major release since 2006.",
        "score": 560,
        "url": "https://www.reddit.com/r/Python/comments/1dhtifv/numpy_200_is_the_first_major_release_since_2006/",
        "content": "NumPy 2.0.0 is the first major release since 2006.\n\n- https://github.com/numpy/numpy/releases/tag/v2.0.0\n- https://numpy.org/devdocs/release/2.0.0-notes.html\n- https://numpy.org/devdocs/numpy_2_0_migration_guide.html",
        "num_comments": 59,
        "comments": [
            "Some highlights:\n\n- np.quantile now supports a 'weights' param\n- np.unique_counts / np.unique_values, which I assume one of them is equivalent to pandas.Series.value_counts(), which will be totally awesome since I find I frequently convert to Series just to use value_counts.\n- weirdly, np.device and np.to_device were added, with only device='cpu' supported. Perhaps numpy is planning to become a Pytorch alternative?\n- StringDtype was added. If you had an array of strings its dtype was usually like \"U58\", indicating it was a varchar up to 58 characters. Now with StringDType it looks like it will be easier to add variable length strings to np arrays.\n- sort and argsort are going to be faster with better implementations.",
            "This is an example of a good governing model for open source libraries. Design your public APIs in such a way that there should be no breaking API changes in a short span of time and there should be minimum LTS branches to maintain. It allows industrial projects to catch up with most of your features and documentation. Then years later you finally revisit your legacy APIs, redesign them and move to version 2 while also maintaining backward compatibility. SQLAlchemy is another library that is built right.\n\nI discourage packages which goes from version 1 to version 6+ in a matter of 2 years. It creates too much fragmentation and users are not able to keep up to date with new APIs. High version number should not be seen as an indicator of rapid development.",
            "Wake up babe! Math 2 just dropped",
            "A bunch of CI pipelines are going to break",
            "Time to fix your requirements.txt",
            "Broke my spacy installation today. Seems spacy didn\u2019t expect it.",
            "I don't understand the deprecation of np.NaN but I guess I'm force to migrate to np 2.0 !",
            "Yes and I broke my packages lol",
            "Broke my opencv installation today \ud83d\ude43",
            "This update is wrecking havoc everywhere, many packages did not fix numpy version and are automatically updating to 2.0.0 and breaking. So you're exposed to it even if you don't depend on numpy directly.\n\nAnd most that I saw was just because of stylistic reasons: NaN - > nan",
            "developers it's time to fix depreciation bugs!",
            "Oh boy",
            "Seemed to break chromadb, although maybe that's a older issue?",
            "It broke Librosa too.",
            "Still can't do argmax, argmin over multiple axes \ud83d\ude15",
            "Insert wake up babe, new package just dropped meme",
            "python2->python3 vibes",
            "Hi, I'm new here, how do i install NumPy? Thanks.",
            "I believe the device thing is just to be standardized with pytorch and jax and what not. In my use case I have code where I pass a numpy-like module as a parameter, so this lets me keep the device line in that code rather than remove it if the module is numpy.\n\nBut I hope I\u2019m wrong. GPU support built into numpy would be awesome",
            "Oh my god they finally added weights to quantile? I've been following that thread forever. I stopped paying attention to it though because no progress was seeming to be made. I'm glad it finally landed.",
            "Value county uses numpy.unique, no?",
            "It\u2019s also a good example of what happens when an open source project is properly funded through Tidelift and other sources. Many important projects are run or led by a single harried developer who can\u2019t keep up and cuts backward compatibility somewhat abruptly to maintain their sanity \u2014 with consequences for the community. \n\nIf support matters pay for it or get your employer to.",
            "Oh, we've had plenty of API-breaking changes in the 1.x series. Much like Python itself, we don't follow SemVer. But they tended to be small and only a few with each 1.x release, each with reasonable deprecation periods. This is just the first release where we batched up a bunch all at once.",
            "Basically every 1.x.0 release of numpy had at least some things that a strict interpretation would consider 'breaking changes'. If numpy followed semver, their major version would probably be ~20ish by now.\n\nDon't get me wrong, I agree numpy has a pretty good policy here, but this comment makes it sound way stricter than it actually is",
            "Yes, a better title would've been \"NumPy 2.0.0 is the first breaking change since 2006.\" There's been plenty of major changes to NumPy since 2006, but fortunately not many breaking changes!",
            "Sure, but you can see that they missed tons of stuff early on that's remained bad its whole life (eg missing nullable number types).\n\nPolars moved fast and broke stuff for a while, and has now hit a very stable point with lots of incremental improvements from early on, which is awesome!",
            "We had a major outage last night :) `pandas` not pinning did us dirty.",
            "Lol yup happened to me last night",
            "I wonder how many packages out there have a naieve \"anything newer than X\" spec for numpy that are in for a pile of new issues >.<",
            "Had a scheduled deployment fail last night because of this lol",
            "Ahh fuck, gonna need to check up on that as well then",
            "I think they just wanted it all lower case, that's all.",
            "NaN however seemed to me some sort of MatLab legacy. I guess renaming to np.nan is more pythonic, but I might be wrong.",
            "Did you understand the difference between np.nan and np.NaN? It seems silly to focus on something like NaN when there is a trivial way to make it compatible with both.\n\nI\u2019m rolling the dice on the internal API for now, so could be worse.",
            "They have been warning for months and months and months",
            "Yes it's probably just for compatibility with [array API](https://data-apis.org/array-api/2022.12/).",
            "Aren't there NSF grants funding numpy development too?",
            "\"major\" here is a term of art. That version numbers system is called semantic versioning. The positions in the version id have names, `major.minor.patch`. https://semver.org/\n\nIt's like how in statistics a \"significant\" difference doesn't mean the difference is large, just statistically measurable. It's a technical term that has a very specific meaning in the context.",
            "Hah called it",
            "We caught it in CI thankfully",
            "What has two thumbs and spent Father\u2019s Day fixing broken workflows?",
            "A lot. A whole lot.",
            "I am so not a fan of backwards-incompatible changes for purely stylistic reasons. Think about the number of hours wasted by people finding this out and having to update all their references from NaN to nan...probably thousands",
            "Same with removing np.infty to np.inf! I remember infty is the way you write it in Latex.",
            "I\u2019m not going to get mad at Numpy, from the sounds of it they\u2019ve been doing the right thing. \n\nHOWEVER, I don\u2019t think we use numpy directly anywhere, it\u2019s a dependency buried 1, 2, 3+ layers deep in our requirements. There\u2019s no way I\u2019m reading the release notes for some package 2 layers down. \n\nOn a positive note, this may be the impetus we need to get serious about pinning dependencies everywhere.",
            "TIL about the array API",
            "Yes, this is correct.",
            "Just reading through the reasoning for the API reminds me why Python and the ecosystem are so well thought out and well executed. Such respect for performance, developer experience, and weaving together community projects rather than consuming them.",
            "[Not at present.](https://numpy.org/about/#sponsors)",
            "An IDE will do that with a simple single command, find all references, change all references, run tests to make sure everything is still passing. If you're set up correctly that can be done in under two minutes.",
            "Given there are tools for automatically fixing your code (https://docs.astral.sh/ruff/rules/#numpy-specific-rules-npy), the number of hours should be close to zero.",
            "Just don\u2019t look for awkward arrays ;)",
            "Imagine all the codebases that parse np.nan as a string!",
            "I am well aware of the mechanics of making the textual change. If you're able to go from detecting this issue in your CI/CD pipelines with multiple affected packages and having the builds resolved in under 2 minutes with no other work interrupted or affected for yourself or others, then congrats, you still had 2 minutes of your time unnecessarily wasted.",
            "Please time yourself setting those tools up, using them, pushing the fixes, and verifying they worked, and get back to me with how long it took.",
            "Imagine those codebases having to support np.nan, np.NaN and np.NAN. Oh, and also the hundreds of aliases for different dtypes. I'm glad they clean this mess up.",
            "If you are not already using ruff in your CI you are living under a rock.",
            "I use ruff, black, pylint, and mypy and I still experienced breaking changes from Numpy 2.0 that took several hours of my time yesterday to fully resolve."
        ]
    },
    "Load Tests Python Task Queues": {
        "title": "Load Tests Python Task Queues",
        "score": 15,
        "url": "https://www.reddit.com/r/Python/comments/1digyfg/load_tests_python_task_queues/",
        "content": "**What My Project Does**\n\nWhile looking for task queues, I found that there are many options available in the Python ecosystem, making it really hard to choose the right one. To get a sense of how each library performs and to help make an informed decision, I conducted a load test on some of the most popular ones: Python-RQ, ARQ, Celery, Huey, and Dramatiq.\n\n**Target Audience**\n\nI hope my findings can help those who are also looking for a task queue solution in Python.\n\n**Comparison**\n\nMost articles out there seem to focus on comparing the features of these libraries but rarely discuss performance. While there could be a lot of improvements on my tests, I think it still provide some different insights into how each library handles heavy loads and concurrency.\n\n**Links:**\n\nYou can read  my findings\u00a0[on my blog](https://stevenyue.com/blogs/exploring-python-task-queue-libraries-with-load-test)\n\nCheck out the source code:\u00a0[on Github](https://github.com/steventen/python_queue_benchmark)\n\n  \nThanks",
        "num_comments": 2,
        "comments": [
            "Interesting, great project and write up. I\u2019ve been looking for something like this. Saved for later.",
            "You should use something like Locust to benchmark. Like in pgmq https://github.com/tembo-io/pgmq/blob/main/tembo-pgmq-python/benches/locustfile.py"
        ]
    },
    " Aurora: An extensible Python static site generator ": {
        "title": " Aurora: An extensible Python static site generator ",
        "score": 53,
        "url": "https://www.reddit.com/r/Python/comments/1di1v8c/aurora_an_extensible_python_static_site_generator/",
        "content": "**What My Project Does**\n\n[Aurora](https://github.com/capjamesg/aurora) is a fast, extensible Python static site generator. With Aurora, I can generate my personal website (\\~1,700 files, with multiple layers of jinja2 templates for each page) in < 4 seconds. Aurora generated 292,884 pages from a Hacker News post dataset in 2m:20s.\n\nAurora supports incremental static regeneration, where pages can be regenerated in under 400ms, with hot reloading. I documented how this works [on my blog](https://jamesg.blog/2024/06/16/aurora-isr/).\n\n**Target Audience** \n\nI'm building Aurora to help me run my website, but it is built to be general so you can use it for your own projects. I would love feedback!\n\nI want this to be a tool for running static sites in production, at scale.\n\n**Comparison**\n\nAurora is inspired by the folder structure of Jekyll, but is written in Python. It has a hooks API that lets you define custom Python functions that manipulate the state of a page. This allows you to implement custom behaviours in isolation of the engine itself. I use this to open link previews from a cache that I plan to use on my website, among other things.",
        "num_comments": 9,
        "comments": [
            "Definitely gonna check out. Hoping creating a new template is easy.",
            "This looks really cool! \n\nJust a heads up, your badges are still markdown at [https://capjamesg.github.io/aurora/](https://capjamesg.github.io/aurora/)",
            "This seems fucking crazy, i have to try it. GG OP",
            "I like it, I started a project like that 3x in the last 10 years, cool to see something very close to what I wanted.  \nThe 2 main missing things for me out of the box  \n\\* Cache breaking static files with hash  \n\\* Image resize \n\nThis could probably be implemented with a generic way to process files that would allow to take a file on disk as an input and save a processed file with a name in a processed folder with some smarts around caching and incremental building based on the source file hash",
            "Cool cool. One of the things I want in my generator though is stuff like either Tailwind, or compiling bootstrap with custom theming, and I guess for that I'd need node or some other JavaScript shenanigans, right?",
            "This is cool! Nice work.",
            "Awesome idea, for someone lazy like me.",
            "Thank you! I plan to make a more comprehensive documentation site (built with Aurora :D), but I need time to think through the design."
        ]
    },
    "Suggestion: make ray.io a part of Python's std lib": {
        "title": "Suggestion: make ray.io a part of Python's std lib",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1djdl3q/suggestion_make_rayio_a_part_of_pythons_std_lib/",
        "content": "Imagine having the option to write code once and run on multiple cores or on the cluster as part of the std lib. I know there's a company (currently) behind it - Anyscale, also not sure what the license is but other than that, what's holding the Py community back?",
        "num_comments": 12,
        "comments": [
            "Very bad idea, especially if you like ray.io. Once it's in std, a library fossilize. It must retain backward-compatibility and each evolution is much harder to land in the code. It's not a critic of the language governance, it's the inherent dynamic of a standard library, whatever language.",
            "You'd have to make all the 3'rd party libraries Ray uses part of the stdlib as well, and even if that wasn't the case, there's absolutely no reason or benefit to make such a specific/esoteric library (that's also tightly coupled with some company) part of the stdlib. That's not what the stdlib is for.\n\nThere are far more popular and useful libraries than Ray, and even they shouldn't be part of the stdlib.",
            "What? No",
            "I think I want less executing code in the standard library rather than more. And possibly more standard interfaces.\n\nIs ray.io overwhelmingly popular in its area of use?",
            "I really want ray.io dependencies on my underpowered arm machine running small python script. It will power up the whole system, eat away battery in just 2 weeks (instead of normal 5 months) and use all space on my small flash device.\n\nSuprise, surprise, Python as language has different niches, and bringing stuff for one niche into others is not always good.\n\nLook at Rust. They actually, split their std into two parts, the supper essential (core) and std (which has niceness like memory allocation) to allow to use language in places where you can't afford memory allocations.",
            "Lol did the 11 year olds discover Reddit already?",
            "You would need to make its dependencies a part of the standard library as well, which includes fastapi, numpy, pandas, and a bunch of others.",
            "Tnx for the feedback. Didn't think of that. I assume that, in contrast to c++, Py is able to make breaking changes (and don't see a probl with adding \\`#requires\\_py>3.10,<3.12\\` at the beginning of the script. Or the way Rust solved this - having a global file for dependencies including Rust version itself. We could have \\`python.toml\\` with all the dependencies and python version required.",
            "> it's the inherent dynamic of a standard library, whatever language.\n\nNo its not something that is inherent and unavoidable. It is specific to how python chooses to govern the language. Plenty of languages have regular breaking changes in library API that ship with the language.\n\nThe obsession that python has with trying to keep CPython from experiencing breaking changes doesn't make much sense to me. Very few programs exclusively use CPython and the standard library, and developers who use those programs are constantly having to make adjustments to deal with breaking changes in non-standard packages.\n\nThey know how to handle it. They have the tooling to lock their package versions. They have the deprecation warnings to test their code with.",
            "I think it solves the parallel (and distributed) programming problem that Python has in a very nice way.",
            "We already have pyproject.toml for that ([PEP 621](https://peps.python.org/pep-0621/)). But it's optional and many tools still don't support it - python project and dependency management is generally quite the mess.",
            "This is already a thing. Python projects specify dependencies in `pyproject.toml`"
        ]
    },
    "Advise on choosing UI technology with Python": {
        "title": "Advise on choosing UI technology with Python",
        "score": 22,
        "url": "https://www.reddit.com/r/Python/comments/1dhyr23/advise_on_choosing_ui_technology_with_python/",
        "content": "I am new to python and currently working on simple 3 layer web application -\n\n* frontend - ?\n* backend API to fetch data from DB - python\n* DB - cloud\n\nThis application has main intention to fetch data from DB, display graphs , table format data etc.  also perform some combination analysis of data and show on UI.\n\nWhich less complex and stable technology I should prefer for frontend ? python flask, Bulma, Mesop by google or any other ? Thank you.",
        "num_comments": 16,
        "comments": [
            "You are mixing up various projects there. If it doesn't have to be a full dashboard for end users you can try Gradio/Streamlit and alike.\n\nIf you want a better UX / end-user dashboard then you will have to build something good. Flask or any other Python framework to make REST API to then make a SPA JS dashboard with vue, ember or alike JS framework using one of popular dashboard templates like Metronic. If you don't want the extra complexity of JS SPA app then you can make classical web app with views in Django or other framework.",
            "No recommendations on frontend. There are many many quality products for the backend. I would probably choose flask. For the db I would choose sqlalchemy on top of postgres. There's nothing that beats sqlalchemy in terms of ORMs.",
            "[Streamlit](https://docs.cloud.ploomber.io/en/latest/apps/streamlit.html) is the best for these types of projects.",
            "Reflex, the all Python God Framework\ud83d\udd25\ud83d\udd25\ud83d\udd25. It is easy to learn.  \nIf you want mature and more complex apps, you can prefer to choose Django (Batteries-Included).\n\n[reflex.dev](http://reflex.dev)\n\nUse Chakra UI (from React)  \n[https://v2.chakra-ui.com/](https://v2.chakra-ui.com/)",
            "I like Vue for front end SPAs.",
            "If you're new to web dev in general, try Flask or Django for the backend and go with React.js or Vue.js for the frontend. All of them are very common for all types of small and big projects. I don't recommend diving into some fancy stuff at this point. After you've got a good understanding of how to work with those, you can play with something else.",
            "For the frontend consider using HTML + Jinja2 and Vanilla JS",
            "I love svelte for FE!",
            "u/riklaunim  thanks.",
            "I mean I\u2019m trying to learn reflex but without any frontend knowledger it is so difficult \ud83d\ude2d",
            "For front end no choice but to use JS. I went through the same path. The beginning is tough but it is worth it. Cause for pretty much anything with front end u want to do, there is already ppl did it and put their code on github for front end and you can just clone it. So in the long term it is worth the effort to learn",
            "Only HTML knowledge is all you need for basic requirements. If you want more customization, learn CSS it's not that hard. Even the Docs are well-written and AI guidance using Inkeep. You can join their Discord. The community is always ready to help. No Toxicity At All.",
            "Okay I\u2019ll just learn html/css every frontend requires it anyway",
            "You can learn both in 2 HOURS for understanding. One Hour Each.",
            "Oh no shit? Nice"
        ]
    },
    "Tuesday Daily Thread: Advanced questions": {
        "title": "Tuesday Daily Thread: Advanced questions",
        "score": 1,
        "url": "https://www.reddit.com/r/Python/comments/1cly3uc/tuesday_daily_thread_advanced_questions/",
        "content": "# Weekly Wednesday Thread: Advanced Questions \ud83d\udc0d\n\nDive deep into Python with our Advanced Questions thread! This space is reserved for questions about more advanced Python topics, frameworks, and best practices.\n\n## How it Works:\n\n1. **Ask Away**: Post your advanced Python questions here.\n2. **Expert Insights**: Get answers from experienced developers.\n3. **Resource Pool**: Share or discover tutorials, articles, and tips.\n\n## Guidelines:\n\n* This thread is for **advanced questions only**. Beginner questions are welcome in our [Daily Beginner Thread](#daily-beginner-thread-link) every Thursday.\n* Questions that are not advanced may be removed and redirected to the appropriate thread.\n\n## Recommended Resources:\n\n* If you don't receive a response, consider exploring r/LearnPython or join the [Python Discord Server](https://discord.gg/python) for quicker assistance.\n\n## Example Questions:\n\n1. **How can you implement a custom memory allocator in Python?**\n2. **What are the best practices for optimizing Cython code for heavy numerical computations?**\n3. **How do you set up a multi-threaded architecture using Python's Global Interpreter Lock (GIL)?**\n4. **Can you explain the intricacies of metaclasses and how they influence object-oriented design in Python?**\n5. **How would you go about implementing a distributed task queue using Celery and RabbitMQ?**\n6. **What are some advanced use-cases for Python's decorators?**\n7. **How can you achieve real-time data streaming in Python with WebSockets?**\n8. **What are the performance implications of using native Python data structures vs NumPy arrays for large-scale data?**\n9. **Best practices for securing a Flask (or similar) REST API with OAuth 2.0?**\n10. **What are the best practices for using Python in a microservices architecture? (..and more generally, should I even use microservices?)**\n\nLet's deepen our Python knowledge together. Happy coding! \ud83c\udf1f",
        "num_comments": 0,
        "comments": []
    },
    "Ruff: A Modern Python Linter for Error-Free and Maintainable Code": {
        "title": "Ruff: A Modern Python Linter for Error-Free and Maintainable Code",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1disz53/ruff_a_modern_python_linter_for_errorfree_and/",
        "content": "Linting is essential to writing clean and readable code to share with others. A linter, like Ruff, is a tool that analyzes your code and looks for errors, stylistic issues, and suspicious constructs. Linting allows you to address issues and improve your code quality before you commit your code and share it with others.\n\nRuff is a modern linter that\u2019s extremely fast and has a simple interface, making it straightforward to use. It also aims to be a drop-in replacement for many other linting and formatting tools, such as Flake8, isort, and Black. It\u2019s quickly becoming one of the most popular Python linters.\n    \n    \n## Installing Ruff\nNow that you know why linting your code is important and how Ruff is a powerful tool for the job, it\u2019s time to install it. Thankfully, Ruff works out of the box, so no complicated installation instructions or configurations are needed to start using it.\n    \nAssuming your project is already set up with a virtual environment, you can install Ruff in the following ways:\n    \n    ```bash\n    $ python -m pip install ruff\n    ```\n    \n    You can check that Ruff installed correctly by using the ruff version command:\n    \n    ```bash\n    $ ruff version\n    ruff 0.4.7\n    ```\n    \n## Linting Your Python Code\nWhile linting helps keep your code consistent and error-free, it doesn\u2019t guarantee that your code will be bug-free. Finding the bugs in your code is best handled with a debugger and adequate testing, which won\u2019t be covered in this tutorial. Coming up in the next sections, you\u2019ll learn how to use Ruff to check for errors and speed up your workflow.\n    \n### Checking for Errors\n    \n    ```bash\n    $ ruff check\n    one_ring.py:1:8: F401 [*] `os` imported but unused\n    one_ring.py:10:12: F821 Undefined name `name`\n    Found 2 errors.\n    [*] 1 fixable with the `--fix` option.\n    ```\n    \nSuccess! Ruff found two errors. Not only does it show the file and line numbers of the errors, but it also gives you error codes and messages. In addition, it lets you know that one of the two errors is fixable. Great!\n    \nYou can tell Ruff to fix errors by applying the --fix flag. Here\u2019s what happens when you follow its suggestion:\n    \n    ```bash\n    $ ruff check --fix\n    one_ring.py:9:12: F821 Undefined name `name`\n    Found 2 errors (1 fixed, 1 remaining).\n    ```\n    \nYou can find the rest of this Free tutorial [here](https://realpython.com/ruff-python/)",
        "num_comments": 26,
        "comments": [
            "My big problem with \\`ruff\\`is that \\`ruff format\\` will sometimes reformat a .py file in a way that \\`ruff check\\` considers invalid. This is a known problem that the devs don't plan to fix.  This problem occurs because sometimes \\`ruff format\\` will output a line of code that contains more characters than it was told to limit any line to.  When this happens then \\`ruff check\\` considers the file to be invalidly formatted and \\`ruff check --fix\\` will fix it but then the next time you run \\`ruff format\\` on that file, it will unfix it again.",
            "I\u2019ve been using Ruff for about a year now. I\u2019ve been having problems with it ignoring my ruff.toml occasionally inside CI/CD. No idea why.",
            "How does it compare to black? I've been using a combo of black and flake8 for years and it gets the job done. Gotten very used to it.",
            "We know. You don\u2019t need to keep trying to sell us on this.",
            "Line length tends to be a contentious issue.\n\nWhere does Ruff fall in this debate?",
            "I have tried Ruff, but it makes me uncomfortable using it. It's very existence makes me uncomfortable.\n\nFirst I don't like anything that is overly opinionated. It's a tool to assist me, not to force someone's opinion, no matter how popular, on me.\n\nSecond, it is not written in Python! Something something eating your own dog food. I cannot access and understand the source (easily). So I cannot make changes so I cannot contribute to it. It may be open source, but it is effectively closed to me.",
            "We fixed the issue by disabling the linter rule knowing the formatter will handle it. We already did that with Black and other linters before. But Ruff replaced them all. Only one configuration and it's fast! I would never go back.",
            "Yes, I deal with this as well. I\u2019m going to try turning off the line length check and do a separate \u201cmake sure format doesn\u2019t do anything\u201d check.",
            "lol that right there sold me on never using it",
            "Same, but you can pass the config file as an optional parameter to fix that",
            "It advertises drop-in parity for both, so replacing them should simply speed up your formatting/linting by a huge factor. I also really like the simplicity of the single ruff binary.",
            "It\u2019s configurable.",
            "1, you must be fun to work with on a project\n\n2, skill issue",
            "It\u2019s orders of magnitude faster than other python linters in large part due to it not being written in python. That difference can be extremely noticeable in mid to large size code bases, so it seems pretty silly to insist on a philosophical property over a practical one. \n\nAlso, I don\u2019t really find the defaults all that opinionated. If anything I\u2019d probably prefer some stricter lints activated by default (notably the B family).",
            "Don't like overly opinionated yet talking about programming in one of the most opinionated languages that exists?\n\nNot written in python? Damn, better not tell you how the python language gets interpreted then because the language itself doesn't even eat it's own dog food.",
            "Thanks, helpful",
            "1. I've been the boss, or my own boss, most of my career, and am now retired, I can play by my own rules, but usually I adopt common coding styles.\n\n2. See 1. I get to choose which skills I'm going to develop, and which I won't. In my own very personal opinion, rust is a butt ugly language. It's syntax is neither easy to read nor easy to understand, even with a highly developed skill level. While it is very expressive, and removed some of the foot guns, it is not maintainable. Any thing beyond a minor typo fix needs a rewrite. This is something you can only learn from years of maintaining code in many different languages, and almost never from just writing code in one or two languages.",
            "Who hurt you?",
            "> so it seems pretty silly to insist on a philosophical property over a practical on\n\nwhy?  \n\nIf you work in a codebase(s) that is large enough that the slowness of other python linters matters... then use a tool that addresses that concern.\n\nIf you don't, then of course you would prioritize that factor less.  \n\nthe way I write code the difference in time between a linting suggestion being available in 0.2 seconds vs 2 seconds is negligible.  that performance gain offers me now value.  \n\nNow if it was the difference between 2 and 20s, nevermind 20 vs 200, then it would be different.  why does everyone insist that every has to need and like the same stuff they need and like?",
            "> I've been the boss, or my own boss, most of my career, and am now retired, I can play by my own rules.\n\nSo you haven\u2019t had to work as part of a team? That\u2019s the biggest benefit of tools like this. Standardize the formatting for an entire project, make PRs easier to review, be more productive.",
            "To be honest its better to know few languages into the depth than scratching the surface of multiple languages\u2026\n\nSpeaking of Rust - yeah it looks different and is harder to read than Python, but its possible to get used to it. \n\nRust (+Ruff) is here to stay, your mindset (avoiding new techs) wont help you in the long term",
            "It feels like you're responding to something I didn't say. The OC said he had a problem with the *very existence* of this tool, and gave two reasons. I felt that both of the given reasons were bad or flawed and explained why I thought that. I didn't say everyone who didn't immediately drop everything to switch to ruff was an idiot.",
            "For the record, there is value in extremely fast linting. It means you can run Ruff as part of your editor and get feedback about as fast as you type. You can also have it as a commit hook that runs across an entire codebase without interrupting your workflow. Is it impossible to do that with other linters? No. But you get much more lag.",
            "> > I've been the boss, or my own boss, **most** of my career, and am now retired, I can play by my own rules.\n\n\"most\" <> \"all\"",
            ">your mindset (avoiding new techs) wont help you in the long term\n\nI'm sure that's devastating to hear as a retired person.",
            "I know several retired engineers who are still in the event loop. Once you get out, its hard to get back to it :/"
        ]
    },
    "Advice for creating 3D modelling program": {
        "title": "Advice for creating 3D modelling program",
        "score": 7,
        "url": "https://www.reddit.com/r/Python/comments/1dhudt2/advice_for_creating_3d_modelling_program/",
        "content": "I am creating a Python program which models 3D shapes so that they can be saved and or interacted with (i.e. rotated). The process currently takes a while to render shapes consisting of multiple materials. The libraries being implemented are currently matplotlib and numpy. What would you advise for improving the rendering process (library choice etc)?",
        "num_comments": 9,
        "comments": [
            "I question whether matplotlib is the right library for this\u2026 I don\u2019t know the proper one, but i doubt it\u2019s matplotlib",
            "PyOpenGL is what I use for procedurally generating 3D models.  A bit of a learning curve, but it\u2019s fast.",
            "Ever try ChimeraX?",
            "I use Vtk. It\u2019s orders of magnitude faster than matplotlib for 3d rendering, has a numpy api, and is pretty with a fringe map. It\u2019s used in Paraview (same group as Vtk and cmake), Ansys Mechanical and many other commercial tools.",
            "I would say this video and the channel itself is the best place to start:\nhttps://youtu.be/M_Hx0g5vFko?si=jS2h_IR1MzkmU2Q5",
            "Pyvista works pretty good for creating and rendering 3D shapes",
            "If you are trying to create Blender but in Python (Which it technically has bindings with its scripting api), you are going have to use a graphics spec like OpenGL, Vulkan, or something like VTK. PyOpenGL is a good start. Now if you are just trying to look at it and nothing else, there are many libraries you are ok with.",
            "FreeCAD is Python based, but I never looked at the details of what libraries it makes use of."
        ]
    },
    "pieshell: python for shell scripting and as an interactive shell": {
        "title": "pieshell: python for shell scripting and as an interactive shell",
        "score": 22,
        "url": "https://www.reddit.com/r/Python/comments/1dhhohd/pieshell_python_for_shell_scripting_and_as_an/",
        "content": "Pieshell is a Python shell environment that combines the expressiveness of shell pipelines with the power of python iterators.\n\nIt can be used in two major ways:\n\n* As an interactive shell replacing e.g. bash\n* As an ordinary python module replacing e.g. subprocess.Popen\n\nObligatory example:\n\n    140:/home/oven/pieshell >>> for x in ls(-a) | tr(\"s\", \"S\"):\n    ...   if x.endswith('.py'):\n    ...      print x\n    ... \n    Setup.py\n\nSource code: [https://github.com/redhog/pieshell](https://github.com/redhog/pieshell)\n\n# What the project does\n\nIt's a replacement for the subprocess module, and for bash as an interactive shell, and makes interacting with shell pipelines easier.\n\n# Target Audience\n\nSystem administrators, system software developers, data scientists\n\n# Comparison\n\nWhile os.system is very limited but easy to use, subprocess.Popen offers a lot of flexibility, but the interface is very low level. Any actual pipelining of multiple programs is pretty much required to be done by e.g. a bash process, constructing the pipeline as a shell script string. Further, interacting with standard in and standard out requires careful IO handling.\n\nPieshell on the other hand lets you construct pipelines as python objects. Standard io from a pipeline can be handled using iterators or async iterators. Pieshell has full asyncio integration.",
        "num_comments": 15,
        "comments": [
            "Alternate shells are always a cool project, but what are the advantages over [xonsh](https://xon.sh/)?",
            "I usually reach for https://github.com/tomerfiliba/plumbum when I need to interact with a process/non python supported binary. I feel ipython + plumbum come close to replacing a shell, at least for me, who codes in Python all day. \nI tried Xonsh a few times and unfortunately found bugs pretty quickly. Maybe it's better now.",
            "I've often thought having python as a command interpreter might be cool, but how would one deal with Python versioning through tools like `venv`, `pyenv`, `rye`, etc.?",
            "Xonsh introduces new syntax, and as such, can not just be imported as a python module with \"import modulename\" from a normal Python. Nor can their shell pipelines be introspected or subclasesed or assigned to variables.  \n  \nPieshell on the other hand consists of just ordinary python classes that trickily overloads the right operators to get a nice syntax *within* the standard python syntax. That is, it only provides new semantics.\n\nYou can use pieshell as a normal python module in any python project, without changing the interpreter used (/usr/bin/python3.11 or the like), just by importing it.",
            "This seems really nice, thanks for showing it.",
            "You can install pieshell either globally, or in a virtualenv.  \n  \nPieshell supports running the `env/bin/activate` bash script(!) directly to activate a virtualenv (use `bashsource(\"env/bin/activate\")`). Note that this activates the virtualenv for any python program started from pieshell (just like any program started from bash after running the same script).\n\nThis is different from importing / execing `env/bin/activate_this.py`which makes modules in the virtualenv available to the python or pieshell process itself. This obviously only work if they share python version, just like when run from a normal python.",
            "It would be more fair to compare it to plumbum, it has a similar architecture, but a more complete syntax and support for asyncio.",
            "Crazy, yeah I went to the repo and looked over the syntax, and I think the \"issue\" of having to wrap all the flags in parentheses would turn a lot of people off, since using it regularly would require more typing, but it's still pretty neat.\n\nI am guessing wide-spread adoption would require finding some way to mitigate wrapping flags, and getting a distro or two to use it as the default command line interpreter.  Or start a new distro aimed at data scientists, with `pieshell` one of its key selling points.",
            "Sorry,  which one has the more complete syntax?",
            "If comparing to plumbum, I would suggest [sh \u2014 sh 2.0.6 documentation](https://sh.readthedocs.io/en/latest/index.html)",
            "Funny you mention data scientists. That's my day job, and I wanted to be able to run external stuff and git commands and the like w/o leaving my nice python environment with pandas dataframes, that's kinda how this happened :P",
            "Hehe, tab completion helps a lot for having to type more, although the parenthesis you do have to type. Pieshell supports `jedi` and autocompletes command names and any long options that `bash` would autocomplete (yep, I run bash in the background and get it to do the completion).\n\nA new distro sounds like a lot of work. But as an alternative shell in a normal one, that's aimed ad data scientists and others who do most of their work inside python anyway maybe?",
            "sh seems to be more similar than any of the others, but with a clumsier syntax, esp. for pipes. Pieshell tries to \"misuse\" operators to provide a nice syntax that's similar to bash syntax and python function invocation. In particular, python kwargs are converted to long options (`git commit --message=\"Hello world\"` becomes `git.commit(message=\"Hello world\")`).\n\n  \nPieshell features I can't immediately find in sh docs that pieshell has:  \n\\* redirecting a iterator as input to a pipeline  \n\\* support for process substitutions (like `<(command)` in bash)  \n\\* sourcing a bash script to set internal environment variables  \n\\* special globals so you don't have to write `sh.COMMAND` but just `COMMAND` (pieshell has this when run interactively, and in modules named `*.pysh`)",
            "Not knocking anything. I found sh about a year ago and have really enjoyed it over plumbum. It feels very pythonic. As far as pipes go, this is from the creator(s).\n\n[FAQ \u2014 sh 2.0.6 documentation](https://sh.readthedocs.io/en/latest/sections/faq.html#why-not-use-to-pipe-commands)",
            "Right. That means that there is no (simple) syntax for process substitutions though? Those /do/ look like function calls in pieshell?\n\nHad I found sh before I wrote pieshell (I started many years ago, so might not have existed, but anyway), I might have worked on extending that instead of writing something from scratch..."
        ]
    },
    " PyPI Scout - Searching for Python packages on PyPI using vector embeddings ": {
        "title": " PyPI Scout - Searching for Python packages on PyPI using vector embeddings ",
        "score": 1,
        "url": "https://www.reddit.com/r/Python/comments/1dhylia/pypi_scout_searching_for_python_packages_on_pypi/",
        "content": "# What My Project Does\n\nFinding the right Python package on PyPI can be a bit difficult, since it isn't really designed for discovering packages easily. For example, you can [search for the word \"plot\"](https://pypi.org/search/?q=plot) and get a list of over a 1,000 packages that contain the word \"plot\" in seemingly random order.\n\nInspired by [a blog post](https://koaning.io/posts/search-boxes/) about finding arXiv articles using vector embeddings and Sentence Transformers, I decided to build a small application that helps you find Python packages with a similar approach. For example, you can ask it \"I want to make nice plots and visualizations\", and it will provide you with a short list of packages that can help you with that.\n\nYou can find the project on Github: **[\ud83d\udd0d PyPI Scout](https://github.com/fpgmaas/pypi-scout)**\n\n# Target Audience\n\nPython developers who want to discover relevant Python packages more efficiently and those interested in learning about working with vector embeddings.\n\n# Comparison\n\nUnlike the standard PyPI search, which often returns a large number of results without clear relevance, PyPI Scout uses vector embeddings and Sentence Transformers to provide more accurate and relevant package suggestions.",
        "num_comments": 1,
        "comments": []
    },
    "How does Python earn money? What would have been their business model?": {
        "title": "How does Python earn money? What would have been their business model?",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1dimpim/how_does_python_earn_money_what_would_have_been/",
        "content": "I was wondering recently about any startup and any coding language that how does they make money. So I was curious to know about Python which is widely used \n",
        "num_comments": 29,
        "comments": [
            "You\u2019ve misunderstood the world.\n\nThe Python project itself is almost entirely volunteers (with a small number of people paid by a charity), some of whom are paid by their employer to volunteer.\n\nTrying to sell a language/compiler/runtime/etc has almost entirely ceased to exist as a business model.",
            "Python is backed by a lot of groups, plus community support. The largest sponsors are listed at https://www.python.org/psf/sponsors/.",
            "From the [FAQ](https://psf-docs.readthedocs.io/en/latest/_docs/faq.html#how-does-the-psf-get-funding):\n\n>The Foundation has three primary sources of income:\n\n>The recently-introduced Associate Memberships (see the\u00a0[Associate Membership Page](http://psfmember.org/)\u00a0for more details)\n\n>Donations from individuals and organizations with an interest in the language\n\n>Profits from running the North American PyCon, a volunteer-run conference",
            "Just like how any other programming language, they don't.",
            "Python doesn't make money, it's open-source. The Py Foundation relies on donations and sponsorships.",
            "Programming languages and open source software development are one of the best arguments against capitalism asking ''but how does it earn money?'' for everything.",
            "You might want to watch [The Economics of Programming Languages](https://youtu.be/XZ3w_jec1v8?si=wK3jyaEsqd4ZdDKT).",
            "Python is not a company, and so therefore it does not have a business model.\n\nThe way most languages come about is that some programmer decides to fiddle with one, and so they create a language. This is done as a hobby on their free time. They work on it for a long time, then perhaps end up making it public, and maybe other language nerds also start using and working on it, again in their free time. Eventually, if it is very lucky and these folks stay dedicated to it for enough years, it becomes established enough that companies start using it, etc.\n\nSometimes people are paid to create languages, either by a university (research) or a company (to solve a need they have). This generally jump starts the language because they can work on it more full-time, but otherwise almost certainly stays the same in terms of being open-source.\n\nVery rarely are languages proprietary and considered a part of a company's product (example in the past, .NET). Even more rarely are they the _primary_ thing sold by the company. Because it has to be incredibly compelling for other companies to choose it over open-source alternatives.",
            "How does a hammer make money? Someone builds some furniture with it.",
            "SAS is the only language I can think of that is a paid business model. Most of the other languages are free but hardware manufacturers sold compilers\u00a0",
            "Thanks for posting about the associate membership. Python helps me earn a living, so I was happy to join.",
            "> The Foundation has three primary sources of income:\n\nAnd the comfy chair.",
            "Capitalists invest a ton into the open source community with the expectation of making money.  They just make it in the uses of open source, not the direct creation and sale of the open source product.",
            "People may complain that those evolves slowly, some projects even seem stuck in time, but then at least they never get to the enshitification phase.",
            "Not really, no.",
            "Excellent presentation; thank you for posting it and tuning me into that account.",
            "MATLAB is still a big player in some industries.",
            "Matlab, Mathematica, and Maple still require paid licenses.",
            "KDB+/q is another big one, but yes big market for hardware specific compilers, especially in FPGA land.\n\nI guess the other aspect was the Oracle model of incentivising adoption aggressively (which is largely credited as the reason for Java's ubiquity)",
            "Compilers can be for $$ though, and some times it makes sense to pay for them. Intel has a C++ compiler which can speed up certain simulations and other numerical calculations. I'm sure there's other examples.",
            "It has inertia, but like all proprietary systems, its days are ultimately limited.",
            "Stata is big as well",
            "Correct me if I\u2019m wrong here, but the thing you\u2019re buying isn\u2019t the language.\n\nYou\u2019re buying a comprehensive IDE and useful but difficult to implement packages. Packages which have paid equivalents in other languages, too.\n\nIt\u2019s like saying that people buy Unity for UnityScript - no, you buy it for the IDE and all of the paid packages.",
            "I don\u2019t agree, the cost isn\u2019t prohibitive to orgs who simply want the best tool for the job. MATLAB is pretty easy to use, comes with great support and documentation, and most importantly it has Simulink which has no real competitors in the control systems engineering space. It\u2019s doing a reasonable job at keeping up in the data science and ML space, although it will never unseat Python.",
            "Octave is already pushing down the pedal",
            "It will be usurped in time. It just takes one motivated programmer who is sick of dealing with license nonsense.",
            "If you're talking about hacking the program to use it for free, then yes.\n\nIf you're talking about eliminating it from the market, no.\n\nThe whole sales pitch for industry is that MATLAB and SAS have vetted algorithms that are created by professionals and maintained securely.\n\nYou're not just paying for a secure software that is significantly less vulnerable to hacking. You're paying for the expertise of the algorithm so that you don't have to hire professional statisticians and data scientists in house. \n\nEven for programs that require less expertise, such as office suites, MS Office still maintains dominance and gets people to pay for subscriptions. Why? Google has its own suite and LibreOffice is totally free.\n\nYet the same reasoning applies. The features of MSOffice aren't duplicated. You have data security, off-line functionality and a fixed price that Google doesn't really offer. You also have a feature-rich ecosystem that works well together. To convert decades of work to a new system for specious benefit makes no sense.",
            "> To convert decades of work to a new system for specious benefit makes no sense.\n\nYet someone will do it.\n\nI don't know what you are talking about with \"security\". These closed source systems have little security guarantees beyond \"trust me\". They are well developed because they are funded. It is their featurefulness, inertia, and marketing that keep users engaged. In contrast open source systems can be audited for vulnerabilities. \n\nThe information age is still very very new. People exploited compilers and operating systems in the beginning, and now those are starting to fade. \n\nOver time open systems will be featureful enough to overtake any proprietary system. This might be a long time period, but it is the trend.\n\nI am a software professional with rich expertise in computer science and mathematics. I produce code and systems that I could charge for, but I don't. I'm motivated by more than money. There are many others like me.\n\nIn time - perhaps decades - there will be a writing tool that replaces MS Office. I wouldn't bet on it being LibreOffice, but who knows.",
            "I don't know where you get the idea that closed systems aren't regularly audited for vulnerabilities. Or even open to the general public to\n\nAs a memorable example, Apple extended a job offer to a teenager that was able to jailbreak a new iPhone OS within days.\n\nThis is not about what motives you specifically. Yes, there are people and programmers specifically who are not motivated by money and produce excellent open source and/or hacked work. \n\nBut the reality is that funding matters, and programmers need to pay their bills too. \n\nI gave the example of LibreOffice precisely because as an open source alternative to MSOffice, it has comparatively few features. Most people, particularly private consumers, do not in fact need a feature-rich office suite anyway. Yet they don't use LibreOffice because there is little incentive for the developers of LibreOffice to invest their efforts into making it more attractive for people to use, i.e. make the GUI look pretty."
        ]
    },
    " I created a script to automatically patch revanced": {
        "title": " I created a script to automatically patch revanced",
        "score": 16,
        "url": "https://www.reddit.com/r/Python/comments/1dhfnl6/i_created_a_script_to_automatically_patch_revanced/",
        "content": "**What My Project Does**\n\nAutoReVanced is a Python script that automates downloading and patching APKs using ReVanced patches from ApkPure. It's perfect for anyone wanting to patch their revanced app.\n\n**Target Audience**\n\nSuitable for a fun side project or hobbyists, AutoReVanced is designed for anyone wanting to customize Android apps with ReVanced patches.\n\n**Comparison**\n\nUnlike alternatives, AutoReVanced is automatic.\n\nGitHub: [autorevanced](https://github.com/anishomsy/autorevanced)",
        "num_comments": 4,
        "comments": [
            "This is really interesting. Usually I only update my revanced apps when they break, so not sure what the benefit is. But I will have a look nonetheless. Thank you",
            "Ok cool but what is Revanced?",
            "No problem! Any feedback would be appreciated!",
            "oh boy I have news for you. r/revancedapp"
        ]
    },
    "Monday Daily Thread: Project ideas!": {
        "title": "Monday Daily Thread: Project ideas!",
        "score": 7,
        "url": "https://www.reddit.com/r/Python/comments/1cl5cl2/monday_daily_thread_project_ideas/",
        "content": "# Weekly Thread: Project Ideas \ud83d\udca1\n\nWelcome to our weekly Project Ideas thread! Whether you're a newbie looking for a first project or an expert seeking a new challenge, this is the place for you.\n\n## How it Works:\n\n1. **Suggest a Project**: Comment your project idea\u2014be it beginner-friendly or advanced.\n2. **Build & Share**: If you complete a project, reply to the original comment, share your experience, and attach your source code.\n3. **Explore**: Looking for ideas? Check out Al Sweigart's [\"The Big Book of Small Python Projects\"](https://www.amazon.com/Big-Book-Small-Python-Programming/dp/1718501242) for inspiration.\n\n## Guidelines:\n\n* Clearly state the difficulty level.\n* Provide a brief description and, if possible, outline the tech stack.\n* Feel free to link to tutorials or resources that might help.\n\n# Example Submissions:\n\n## Project Idea: Chatbot\n\n**Difficulty**: Intermediate\n\n**Tech Stack**: Python, NLP, Flask/FastAPI/Litestar \n\n**Description**: Create a chatbot that can answer FAQs for a website.\n\n**Resources**: [Building a Chatbot with Python](https://www.youtube.com/watch?v=a37BL0stIuM)\n\n# Project Idea: Weather Dashboard\n\n**Difficulty**: Beginner\n\n**Tech Stack**: HTML, CSS, JavaScript, API\n\n**Description**: Build a dashboard that displays real-time weather information using a weather API.\n\n**Resources**: [Weather API Tutorial](https://www.youtube.com/watch?v=9P5MY_2i7K8)\n\n## Project Idea: File Organizer\n\n**Difficulty**: Beginner\n\n**Tech Stack**: Python, File I/O\n\n**Description**: Create a script that organizes files in a directory into sub-folders based on file type.\n\n**Resources**: [Automate the Boring Stuff: Organizing Files](https://automatetheboringstuff.com/2e/chapter9/)\n\nLet's help each other grow. Happy coding! \ud83c\udf1f",
        "num_comments": 1,
        "comments": [
            "Ok here's one.\n\n# Project Idea: YouTube RSS\n\n**Difficulty:** Beginner / Intermediate\n\n**Tech Stack:** Python, File RW\n\n**Description:** Enter your favorite YouTube channels' URLs in a CSV file. Create a script that reads that CSV file, fetches the latest uploaded video titles, and saves them in a separate CSV file. And run a function every 5 minutes to check if any of those channels have a new video uploaded by comparing the latest uploaded video title to the saved titles in the CSV file. Make it run in the background, and show a messagebox on the screen saying \"X channel uploaded Y video.\" when a new video is uploaded.\n\n**Resources:** [Pytube](https://pytube.io/en/latest/)"
        ]
    },
    "abstract-factories - a simple framework for content creation pipelines": {
        "title": "abstract-factories - a simple framework for content creation pipelines",
        "score": 12,
        "url": "https://www.reddit.com/r/Python/comments/1dhcdre/abstractfactories_a_simple_framework_for_content/",
        "content": "Hey all, my project [abstract_factories](https://github.com/ldunham1/abstract_factories) is up to gauge interest and primarily feedback.  \n\nThe design goal is to make it easier to iterate on typical Content Creation pipeline tools (tool dev, rigging, validation, asset management etc) with a flexible framework to provide convenience, open and simple design and no dependencies (currently).\nIt's an approach I've used a lot over the years and found it pretty versatile in production across numerous projects.\n\n\n## Key features \n- Auto-registration of matching items (types or instances) from any given path or python module.\n- Simple or conditional item identifiers.\n- Versioning.\n- Recursive path searching (recursive module search in review).\n- Dynamic resolving and importing modules in packaged (supports relative importing).\n\n\n## Usage Examples\nThere are a couple of [simple examples](https://github.com/ldunham1/abstract_factories/tree/main/examples) given along with tests to cover all of the current features.\n\n\n## What the project does\nIt's a convenience package for creating scalable tools and frameworks using [Abstract Factory](https://refactoring.guru/design-patterns/abstract-factory) design pattern.\n\n\n## Target Audience \nDue to the solutions it's built for, it's aimed primarily at Technical Artists, Technical Animators, Pipeline and Tool Developers, but I'm interested in hearing about other possible applications.\n\n\n## Comparison \nCompared to other Factory and Abstract Factory convenience packages, mine is based on the work from [this GDC talk](https://youtu.be/3l5tgk8hRn4?si=c_jOZXq8WQqfE_C9). The direct \n`abstract-factories` currently comes with a few more conveniences I've found useful during production. \nThe idea stems from boiling down [Pyblish](https://pyblish.com/) to something that became a little more reusable when writing frameworks as opposed to being the framework.\n\n\nSuggestions, questions, comments etc welcome.",
        "num_comments": 5,
        "comments": [
            "VFX community go brrrr.\nDoes this also support validator dependencies? Like in pyblish i can only configure the order of validators.",
            "This is much less of a complete validation framework like Pyblish and more a large cog that can make such a thing easier to implement yourself.\n\nValidator order can be implemented however you'd want. The current simple validation example just uses the Validators from the registration order. You could have a method to derive order in the validator abstract or from your validation class as simple or as complex as you want. \n\nPersonally, I prefer explicit anyway, so the Validators would be given as a list to be run. This would be validation order wouldn't have to be tied to any internally functionalities.",
            "Sounds really cool! Could i also implement dependencies on an \\`Extractor\\` for instance?  \nI image something where i could write an \\`Extractor\\` that has dependencies on several \\`Validators\\` and maybe \\`Collectors\\`.",
            "Kinda like a preset or playlist of collectors and validators and actions?\nIt's not really the purpose of the lib but for sure you could. Again though, this library doesn't provide this for you, it just adds a lot of convenience for each of these parts, the beauty will come from what you can do with it.\n\nFor example, your main class that implements a factory for the collectors, validators and actions could have a simple serialise and deserialise method. \nThe factories rebuild and what you need given the names (and versions) of what you want (the main purpose of a factory design).",
            "Yeah basically like a preset that bundles together different factories. much like in \\`rez\\` where one could specify dependent apckages that would also get resolved.\n\nI think i'll need to read up on the main purpose of factory designs. but then i'll definitely try to tinker with this a bit :)"
        ]
    },
    "Showcase: pdf-to-podcast.com -- Convert PDF's to podcast episodes. Free and open-source :)\n": {
        "title": "Showcase: pdf-to-podcast.com -- Convert PDF's to podcast episodes. Free and open-source :)\n",
        "score": 4,
        "url": "https://www.reddit.com/r/Python/comments/1dhii88/showcase_pdftopodcastcom_convert_pdfs_to_podcast/",
        "content": "## What My Project Does\n\nUpload any PDF and have it converted into a podcast episode with two or more speakers discussing its contents.\n\nhttps://github.com/knowsuchagency/pdf-to-podcast\n\n## Target Audience\n\nAnyone, but other developers in-particular. The code is open-source on GitHub and there's a link to the source on https://pdf-to-podcast.com. I want the project to serve as an illustrative example of how to build useful things on top of LLMs with relatively little code.\n\n## Comparison\n\nI just made this for fun. It's possible there are other similar projects",
        "num_comments": 1,
        "comments": [
            "Nice! I love that the code is very simple yet powerful. Any future plans for the project?"
        ]
    },
    "Have anyone tried google/mesop": {
        "title": "Have anyone tried google/mesop",
        "score": 42,
        "url": "https://www.reddit.com/r/Python/comments/1dh1uu1/have_anyone_tried_googlemesop/",
        "content": "Google Open sourced Mesop. Mesop is a Python-based UI framework that allows you to rapidly build web apps. Used at Google for rapid internal app development similar to Streamlit.\n\nfind more [here](https://google.github.io/mesop/) ",
        "num_comments": 12,
        "comments": [
            "PyWebIO & Nicegui are my go-tos",
            "I've made some prototypes with it. Gonna stick with Holoviz Panel, though. Looks better, codes better, has a bigger set of batteries included.",
            "A few colleagues and me had a look, and ended up checking Shiny for python instead. They had experience with streamlit, I haven't used neither, but a quick play with Shiny was pretty alright. Easy to use I'd say. \n\nP.S.: sorry to not answer directly to your question, but from the same question we ended up trying Shiny.",
            "Following... curious about this project",
            "Interesting. I haven't played in this space for a couple of years, but when I was, I was using Anvil (https://anvil.works ) - it's got both front and back end, drag-and-drop design, and is just a joy to use.",
            "idk, they promise typing,\nbut i prefer just react and django instead.",
            "Thanks for the tip! I didn't know about this, and it looks great. I'll give it a go soon.",
            "Our team has been using Plotlys Dash framework for this for a long time. We tend to prefer it over Gradio, Shiny, and Streamlit as it feels a little less black box. \n\nHowever, these components look super nice. Might have to try this out.",
            "Hey - creator of Mesop here - saw this post a bit late! Happy to answer any questions.",
            "Wow. Looks amazing. Can you run it on your own server though?",
            "I haven't tried, but https://anvil.works/open-source & https://github.com/anvil-works/anvil-runtime",
            "Looks so cool! Thx"
        ]
    },
    "I created Yu-Gi-Oh! Power of Chaos save handler": {
        "title": "I created Yu-Gi-Oh! Power of Chaos save handler",
        "score": 6,
        "url": "https://www.reddit.com/r/Python/comments/1dh62bk/i_created_yugioh_power_of_chaos_save_handler/",
        "content": "Quick backstory:\n\nUpper floor of my house is sort of a man-cave until we decorate it, so during this time I have two PCs which I use to play games with a friend when we have extra time to waste. The other day I remembered the game mentioned in the title and we had lots of fun playing it (there's 3 different games in this series). I decided I'd transfer the save file to my main PC so I can play when he's not visiting and I quickly learned it's an extremely annoying process to transfer save files across different PCs. Long story short, you need to find a proper registry key (which isn't always located at same spot for some reason) and you need to locate a system.dat file also located in a folder that isn't always in the same place. This process gets tedious pretty quick, so I decided to use the power of Python to make my life easier.\n\nWhat the project does:\n\nIt's essentially a CLI save handler for the game mentioned in the title. It has 5 slots where you can backup your current save or load the backup to the computer. It can also fix minor registry issues if needed.\n\nTarget audience:\n\nGiven that I'm about 20 years too late... I'd say mostly people with very slow PCs or people who like to inhale nostalgia.\n\n  \nI learned a lot about using winreg and msvcrt and getch, so while I will likely get bored of the game in the coming weeks, I'm happy I learned something new in the meantime, plus maybe someone finds it useful!\n\nSource code: [markomavrinac/yugioh\\_poc\\_save\\_handler: Yu-Gi-Oh! Power of Chaos save handler - A script to manage your save games across multiple computers (github.com)](https://github.com/markomavrinac/yugioh_poc_save_handler)",
        "num_comments": 0,
        "comments": []
    },
    "Tutorial: A Timely Python Multi-page Streamlit Application on Olympic Medal Winning Countries": {
        "title": "Tutorial: A Timely Python Multi-page Streamlit Application on Olympic Medal Winning Countries",
        "score": 8,
        "url": "https://www.reddit.com/r/Python/comments/1dh2o89/tutorial_a_timely_python_multipage_streamlit/",
        "content": "***Streamlit***\u00a0is an open-source app framework that allows data scientists and analysts to create interactive web applications with ease.\n\nUsing just a few lines of Python, you can turn data scripts into shareable web apps.\n\nAnd combined with a data visualization library like\u00a0***Plotly,***\u00a0you can create beautiful charts and maps with only a few lines of code.\n\nIn this article, let me step you through how to use\u00a0***Streamlit***\u00a0to create a multi-page interactive application that visualizes Olympic medal data.\n\nThe application will have three pages:\n\n1. an overview of medal counts,\n2. a country-specific analysis, and\n3. a choropleth map displaying global medal distributions.\n\nLet\u2019s get to it!\n\nLink to free article [HERE](https://johnloewen.substack.com/p/a-beautiful-and-timely-python-multi)\n\nGithub repo [HERE](https://github.com/loewenj700/streamlit_multipage_olympics)",
        "num_comments": 1,
        "comments": [
            "Wish there were better ones of these. I want to see more examples of pages with lots of interaction."
        ]
    },
    "Learning Python coming from a JVM background ": {
        "title": "Learning Python coming from a JVM background ",
        "score": 17,
        "url": "https://www.reddit.com/r/Python/comments/1dgye28/learning_python_coming_from_a_jvm_background/",
        "content": "I have 4 years worth JVM languages (Java, Kotlin) and have a need to learn some Python.  What's a good resource to get up to speed quickly with idiomatic Python?  ",
        "num_comments": 27,
        "comments": [
            "Videos from Raymond Hattinger, especially the one where he shows how Java people tend to write python and then he transforms it into idiomatic python\n\nEdit : unintuitive title, beyond pep8: https://youtu.be/wf-BqAjZb8M?si=97IXZo0JhHz0TlLp",
            "The [official Python tutorial](https://docs.python.org/3/tutorial/index.html).",
            "As a resource, I like the book Fluent Python. Not something I'd sit down and read front-to-back, but it's good to skim the concepts and refer back to em.",
            "Use the official Python specification and tutorial.\n\nIt is a pretty logical, easy and straightforward language, with its power coming from its extensive libraries.\n\nJust one tip - Python's dynamic nature, loose typing and lack of private and protected types drove me nuts and led to many bugs before I got used to it. That is compensated by you spending most of your thinking on your problem, rather than on the language syntax. Your mileage may vary.",
            "https://speedsheet.io/s/python",
            "Rackerhank",
            "https://github.com/satwikkansal/wtfpython",
            "I have the reverse question for you. I spent 10 years in Python and now looking to branch out to java. any recommendations?",
            "Get an overview of syntax here: https://learnxinyminutes.com/docs/python/\n\nRead fluent python (2nd edition) if you want to go in depth.\n\nMost importantly: browse open source python projects (like flask, requests) to get a feel for \"pythonic\" code. The biggest mistake java developers make when they come to write Python code is they try to write java code in python",
            "Definitely look up bro code tutorial, he explains things so well and simply and you can dip In And out of that YouTube as much as you want",
            "If you already have experience with programming languages, I assume you also have experience with documentation. Therefore, I would propose you start with the python docs and not watch videos or read long articles because that is very time-consuming",
            "Similar background...\n\nPick a build/environment/packaging tool, a combination as simple as possible while you explore and stick with it. It's very easy to go down the tooling rabbit hole, that was my lesson.",
            "r/learnpython has some good resources",
            ">\u00a0especially the one where he shows how Java people tend to write python and then he transforms it into idiomatic python\n\n\nWould love to know which one you are talking about.",
            "Seconding that, except that I\u2019m actually in the process of reading it front to back. I also use Exercism to go through some exercises and the community solutions and mentoring helps a lot with learning idiomatic Python (and standard library features I wasn\u2019t aware of yet \ud83d\ude43).",
            "Working with data that has bit me in the ass so many times. You have chunks that are well formed and then all of a sudden you get 100k rows where a column is null all through and then blows up trying to get inserted to the db because Pandas/library of choice inferred a different type.\n\nSo then you have to go through the whole typing thing any way (which you should have earlier but hey it worked on my machine).\n\nSo yeah, be careful.\n\n(not knocking the language just some issues in my particular field)",
            "highly recommend using static type checking. Its not really enforcing anything, but it would warn you if you access methods or data members which start with a `_` and also all kinds of type errors (especially for types which are optional/can be null).\n\n\nI would never go back to a non-typed codebase today. It just saves so much time",
            "Added link",
            "Bingo.\n\nThe Python specification says this loose typing is an intentional design choice because they expect the language to be used in symbiosis with IDEs and linting tools. The downside is that the developer is left to the mercy of a properly and uniformly configured tool chain.",
            "Just two days ago, I had a bug in Dango. I statically typed a variable to a class but accidentally assigned a dict to it. No warning issued, except my code depended on there being no implicit conversion.\n\nThe Python static types are only hints and not enforced. Makes debugging of complicated code really hard.",
            "I don't disagree with it on principle but it rears it's ugly head now and then. Throw in some conversions to parquet/arrow and other typed formats just for extra funsies and deep stack traces.\n\nSo sometimes I end up thinking that sheeit I wouldn't have these issues in GO/JVM/C++. And then I look at the ecosystem where everything just exists and is reasonably pluggable. \n\nSo for non academic production data from the wild there are issues.",
            "Did you use mypy or pyright?",
            "I have not heard of either of those tools but will check them out.",
            "Type hints in Python usually have no effect. mypy and pyright are tools you can use to check for the warnings that you expected and it's possible to manually check annotations in the code.",
            "So I looked up the tools and they are linters.\n\nI use VSCode and had Pylannce and Black setup and switched to Ruff, which provides formatting and linting.\n\nAs far as I can tell, mypy and pyright fall in the same space.",
            "Thanks. That helps."
        ]
    },
    "I made a cool calendar app with PyQt6": {
        "title": "I made a cool calendar app with PyQt6",
        "score": 52,
        "url": "https://www.reddit.com/r/Python/comments/1dgpg4g/i_made_a_cool_calendar_app_with_pyqt6/",
        "content": "Tempus is a calendar with horoscopes, reminders, etc made with PyQt6 \n\n# What my Project does?\n\nTempus is a desktop-based calendar management application built with PyQt6, allowing users to manage their todos, reminders, and special dates efficiently. It offers features like adding, editing, and deleting tasks and reminders, as well as marking dates as special. Tempus ensures users stay organized and never miss important events. Plus, it shows you how many days are remaining until a special day in the dashboard.\n\n# Target Audience\n\nWell, anyone who uses a desktop calendar app I guess?\n\n# Comparison\n\nI did some research and couldn't find good calendar apps made with PyQt6.  If you guys knows any, please mention it below and I'm sorry in advance.\n\n# GitHub\n\n[https://github.com/rohankishore/Tempus](https://github.com/rohankishore/Tempus)",
        "num_comments": 18,
        "comments": [
            "Looks cool and polished.\n\nSide note:\n\nYou made it MIT license, but pyqt6 uses GPLv3. There might be a conflict. It's much safer to just use GPLv3 if you just want to share it.",
            "Awesome project. I loved the simplicity of the UI. Any consideration about integrating your app with third party calendars like google calendar or Microsoft? Probably other apps already do that, but still a cool think to learn and add.\nBesides that congratulations.",
            "Can you describe why you used PyQT6 rather than PySide?",
            "Thanks for sharing - this is really cool. I'm learning a lot reading through your code.",
            "What would be the advantage of using this over other planners?",
            "Also, please star my project if you like it :) \n\n  \n(wait is this against the repo rules?)",
            "Noted! Thanks a lot \ud83d\ude0a",
            "Yep! I'm planning to add Google Calendar first. Then Microsoft.\n\nAnd thanks a lot!!",
            "No particular reason tbh. I'm just more used to PyQt6. And also, the qfluentwidgets library works better with qt6",
            "Thanks a lot \ud83d\ude0a",
            "Well for one, you get daily horoscopes (haven't seen that in other PC calendars or maybe I'm wrong?) + its open source?",
            "Not against the rules as far as I can see, but [this little survey](https://new.reddit.com/r/github/comments/qf4p31/is_it_normal_to_ask_people_to_star_repository_or/) suggests that a lot of people (35%) disapprove of the practice.\n\nDownvoting without commenting a reason for doing so, goes against rule 9.",
            "I don\u2019t get why this is downvoted it\u2019s legit the feature OP is excited about",
            "I think a lot of planners also have pseudo-science in them.",
            "Yep, I would appreciate one like this, would be great to have one like this",
            "Thanks a lot bro \u263a\ufe0f also any feature recommendations?",
            "I want a calendar that lets me know when there is a mercury retrograde coming up because I want to play a very elaborate prank but that is awfully specific and I\u2019ve solved the problem by just adding reminders in my google calendar",
            "Well, I can implement it"
        ]
    },
    "Better-OrderedMultiDict - a fast pure-pyton implementation of an ordered multi-valued dictionary.": {
        "title": "Better-OrderedMultiDict - a fast pure-pyton implementation of an ordered multi-valued dictionary.",
        "score": 35,
        "url": "https://www.reddit.com/r/Python/comments/1dgmtbx/betterorderedmultidict_a_fast_purepyton/",
        "content": "# What my project does\n\nIt provides a fast pure-python implementation of an ordered, multi-valued dictionary.\n\n# Target audience\n\nPython developers that need this kind of specialized functionality.\n\nThis can be used in production. It has no dependencies. The code is unit-tested (almost fully, I'm working on it) It requires Python 3.12+\n\n# Comparison\n\n# Comparison to dict and OrderedDict\n\n`dict` and `OederedDict` are already ordered, but they only allow one value per key. You could use a defaultdict of lists, but then you have these disadvantages:\n\n* you can end up with empty lists within the dict if you aren't careful\n* you lose the order of individual items within the dict:\n\n&#8203;\n\n    items = [(1, '1'), (2, '2'), (2, '22'), (1, '11')]\n    normal_dict = defaultdict(list)\n    for key, value in items:\n        normal_dict [key].append(value)\n    om_dict = OrderedMultiDict(items)\n    print(list(normal_dict .items)) # prints [(1, ['1', '11']), (2, ['2', '22'])] \n    print(list(om\\_dict.items))     # prints [(1, '1'), (2, '2'), (2, '22'), (1, '11')]\n\n* iterating over all key/value pairs can be cumbersome as you need nested loops\n\n# Comparison to [omdict](https://pypi.org/project/orderedmultidict/).\n\n`OederedDict` provides a (in my opinion) nicer interface with less surprising behavior or pitfalls. My implementation is also faster. e.g iterating over all items is \\~5x faster.\n\n# More info\n\nThis started as a toy project, that later became useful to me, so I decided to cleanup the code, add tests, and publish it.\n\n    from better_orderedmultidict import OrderedMultiDict\n    omd: OrderedMultiDict[int, int] = OrderedMultiDict([(1,1), (2,2), (1,11), (2,22)])\n    \n    for key in reversed(omd.unique_keys()):\n        print(f\"{key}: {omd.getall(key)}\")\n    # prints:\n    # 2: [2, 22]\n    # 1: [1, 11]\n    \n    print(omd.popfirstitem())  # prints: (1, 1)\n    print(omd.poplast(2))  # prints: 22\n    \n    for key in reversed(omd.unique_keys()):\n        print(f\"{key}: {omd.getall(key)}\")\n    # prints:\n    # 2: [2]\n    # 1: [11]\n\n# Installation\n\nYou can install Better-OrderedMultiDict using pip:\n\n    pip install better-orderedmultidict\n\n# Contributing\n\nIf you have any suggestions or improvements for Better-OrderedMultiDict, feel free to submit a pull request or open an issue on the [GitHub repository](https://github.com/JoachimCoenen/Better-OrderedMultiDict/issues). I appreciate any feedback or contributions!   \n  \n\n# Links\n\nHere's the link to the GitHub repository: [https://github.com/JoachimCoenen/Better-OrderedMultiDict](https://github.com/JoachimCoenen/Better-OrderedMultiDict)\n\nHere's the link to PyPi: [https://pypi.org/project/better-orderedmultidict](https://pypi.org/project/better-orderedmultidict)",
        "num_comments": 2,
        "comments": [
            "package you might find interesting:   \n- https://grantjenks.com/docs/sortedcontainers/",
            "That sounds interesting. But they keep their containers sorted by the natural ordering of its contents (like a real world dictionary), whereas OrderedMultiDict keeps the original insertion order."
        ]
    },
    "Cant decide between flask, django ninja or fastAPI for sideproject": {
        "title": "Cant decide between flask, django ninja or fastAPI for sideproject",
        "score": 106,
        "url": "https://www.reddit.com/r/Python/comments/1dgbq1e/cant_decide_between_flask_django_ninja_or_fastapi/",
        "content": "As the title says, I cant decide what to use for rest api for mye summer project. I am uni student, so this project will only be very small scale project. I have made simpel rest apis in sll of them, but still cant decide which one to actuslly use for my project. Do anyone have any tips for which might be right one? A thing to consider for me answel is how easy it is to host.",
        "num_comments": 130,
        "comments": [
            "If you've tried all of them and haven't found any reason why one would be better or worse for your project, just pick one. No-one here knows your needs better than you. They're all perfectly good frameworks for a small project, they're all similarly straightforward to host, and they're all widely used.",
            "I had a similar issue for my projects.\n\nDjango is the full-fledged framework and it's sometimes too much. But the support, documentation, and infrastructure is awesome. \n\nMaybe my insight is limited or flawed, but I have the impression Django needs more work to have a REST API. Maybe with Django Ninja it's easier.\n\nFlask and FastAPI are probably easier to use. Have you considered Litestar? Check it out, it might be the solution you are looking for. It's a completely async framework whereas Flask and Django are not. \n\nNot sure if it helps.",
            "If you want to create a front-end and don't want to spend time learning JS, then use Django.\n\nIf you don't want to create a front-end (or it is being created by someone else), then use FastAPI.\n\nIf you have to implement login and authentication, Django is more beginner friendly for that. If login is not required, FastAPI is simpler to work with.",
            "FastAPI is the future. Get in now",
            "FastAPI FTW",
            "Having worked with a lot of python at this point, FastAPI seems like the way to go. Better structure, better async support and things like [Pydantic](https://docs.pydantic.dev/latest/concepts/models/) model support mean as your project grows you'll be able to keep a lot better handle on things.\n\nI'm using Flask + Restx in our project's SDK, but we're going to be swapping that over to FastAPI in a little bit for all the reasons I listed above.",
            "If flask is an option, why not Quart instead? It's flask but async.",
            "For small projects use Fastapi/Litestar + Sqlalchemy. For larger projects, use Django + Ninja. Leave Flask in the past.",
            "Small scale = Flask or Fast Api\n\nflask is declining, Fast Api is ascending. so it is quite logical to try with fast api first.",
            "I suggest FastAPI + SQLAlchemy + Alembic. Maybe Litestar as an alternative, if you want to experiment with newer stacks.\n\nDjango + DRF is great, when it comes to features you get out of the box, but the pitfalls, typing is still bad, the lack of proper async support (adrf is tiny), honestly, it feels too much of a pain to work with in the long run. Django Ninja feels alien to Django, I dropped my old endpoints and rewrote in plain DRF instead. Quart is dead, while Flask is not async.",
            "I used FastAPI and Beanie as ODM. Enjoyed coding it a lot",
            "One more vote for flask, because of the documentation n and the flexibility in complexity. You can start with a simple model, eg you can write simple SQL statements for database interaction - the official docu has a good example of that, etc. and you can integrate full blown html pages, including JavaScript frameworks, bootstrap and similar things.\n\nGo to Amazon and search for book for the named frameworks.",
            "Fastapi, if you want something that will give you experience on api frameworks used by major players. Take the time to learn it, all of the ways you can serve it up, container/lambda/etc.\n\nOr maybe you\u2019ll only appreciate it if you try Flask first haha.\n\nAnd if you want a quick front end for python apps, try out streamlit.\n\nIt\u2019s the only one I\u2019d consider at the moment. Happy learning :)",
            "I'm a big flask supporter. Django is pretty great but always overpowered for what I need and do.",
            "I choose fastapi with tortoise orm, the orm gives me similar feel of using Django with async",
            "Just pick one and go\n\nThen pick another one and try to mimic",
            "Hi Zango dev here, Try [Zango](https://github.com/Healthlane-Technologies/Zango), its an open source Django meta-framework that should significantly cut down the development effort. With Zango, you can directly get to developing your APIs using Django and Django Rest Framework only, without needing any setups. The additional batteries will significantly reduce overall effort. Also, leverage packages to support your use cases. Feedback welcome. Thanks :)",
            "If you need user management go for Django-Ninja. Also: Django ORM is so beautiful compared to sqlalchemy !",
            "fastAPI is fast and it is no joke. You can literally be up and running in minutes.......minutes. Very fast.",
            "Why don't you try something less conventional, but still very much production-ready?\n\n[https://litestar.dev/](https://litestar.dev/)",
            "I vote fastapi or litestar. I'd probably go with litestar if it were me. \n\nAnd pytest. Don't forget pytest.",
            "You might like [Sanic](https://sanic.dev/en/). It's flask-like, built to support async like FastAPI, and has a production level webserver built in, so hosting it is relatively easy (no need for things like wsgi).",
            "For small stuff I always just reach for flask, dead simple and most documented (besides django).\nIf I\u2019m not sure of the requirements that\u2019s usually my pick.\nIf I know I\u2019ll want a full app with a UI and statefulness then Django is a great choice, but not great if you\u2019re just starting with Pytho as it abstracts a lot away and is fairly opinionated about the way it handles everything.\nFastAPI is amazing if you\u2019re just building a REST API. Probably the least documented out of the three but you get async out of the box.",
            "If you're only using this for API purposes then I would go with FastAPI\n\nBoth flask and Django are full frameworks that will come with a ton of stuff you don't really need",
            "I would choose `Flask` in this situation, it is simple and minimalist, can be molded into whatever form you want. Use its basic routing directive (`@app.route`) to handle the REST API endpoints. Want to create a seamless frontend? Use the `jinja2` template system which is readable and efficient. Need a database abstraction layer? Use `sql-alchemy`.\n\nFastAPI is a specialized framework only for REST APIs and graphql. Learning this framework will only let you build those kind of apps, that's why I prefer Flask.\n\nDjango is the all-rounder framework, a good one at that but I somehow prefer flask to it. It comes with too many bells and whistles for my taste, things which you can easily implement yourself or better done using specialized python packages.\n\nIf you're familiar with PHP world, a comparison might be made between `Flask vs CodeIgniter` (minimalist, utilitarian) as well as `Django vs Laravel` (more features, larger community, etc.).",
            "I would only go the django route for bigfer projects. Django requires a database etc to run where most of the others just runs on nothing.\n\nFor the most part my rest api\u2019s already got a data source, so I end up with a seperate db just for the django stuff and that rubs me the wrong way.",
            "The only criteria provided was easy hosting. Where are you hosting? Which does it have the best documented support for? Otherwise, just go Django.",
            "Fastapi + plotly dash \n\nIf you want to whip up something fast",
            "Try falcon",
            "These are the best tools: https://testdriven.io/blog/fastapi-sqlmodel/\n\nHowever non async Django and DRF are very common too. So if you want to maximize learning, build your project in fastapi/etc first then build it again using Django+DRF.\n\nThe real expertise comes in when u can knowledgeably answer this question yourself and the only way is to use both tools. Enjoy",
            "do it. do it all",
            "Pyramid gang sound off!",
            "Used all three- fastapi is way easier if you need to deploy it as an installable package.  Django ninja is my preference if I want to use something that has migrations.  If you\u2019re deploying them as containers, Django ninja is my preference because you don\u2019t have to reinvent the wheel and can leverage built in Django functionality for things like permissions, plugins, middleware, etc. I LOVE the dependency injection of fastapi, so both are great but for different reasons.\n\nI would pick either of these over flask at this point - fastapi is more or less equivalent to flask and I\u2019d pick starlets over flask",
            "I have used both Django and flask and prefer flask as you can plug what you want in. Django has and answer for every situation though",
            "just pick one and run with it.  you will find things that are problematic, and then you'll figure out workarounds.\n\nthat process of problem solving and learning is the whole point.",
            "FastAPI. It\u2019s all you need for your use case.",
            "Pick one. Be happy",
            "Bottle+Gevent",
            "stick to django or fastapi",
            "If you are not already good with Django, then it's likely too complex for a starter project. The learning curve for it is much higher.\n\nFlask is pretty straightforward and quick. I haven't used the others.",
            "All my side projects are with LiteStar. At work I use FastAPI.\n\nIf you want a fancy UI, you can use jinja2, bulma and htmx on top. But it's your choice so pick your winner",
            "If you do not need authentication just post and get request for processing data client side or hell just a command line application go with fast API you won't need to write a lot for basic things and if you need a DB sqlite3 will do wonders.",
            "Just pick one. Doesn't really matter. If you want me to pick for you, FastAPI and HTMX. If you want jobs, Django + React",
            "I started the project with Flask, thinking that will switch to something else in future. Never did - works fine.",
            "I've been having fun with Dash on a side project, although it's a bit of a different category",
            "I work on a project using Flask, and we've generally agreed we would not use it again.  The Flask team has a very contrarian view on version numbers and it frequently breaks our builds.  You also don't get the automatic OpenAPI features that are built directly into FastAPI or Django.",
            "If I need a simple APIs => fastapi\nIf I need a big project => Django, ninja if I want to have some APIs \n\nI would for example use fast API for things like a slack hook, reverse proxies with super powers, and really simple APIs.\nI would use Django if I want to do a website or a CRM, i would use django-ninja if I expect to have an API with lots of endpoints, or if I listen to my intrusive thoughts and use react.\nIf I forget to take my pills for long enough and start working on a micro service architecture I would use fastapi.",
            "For an API, fastAPI is indeed extremely fast and convenient to use.",
            "I would check out Quart as awel - basically an asyncronous drop in replacement for Flask.",
            "Avoid django/drf at any cost. Given that you have tried all the three frameworks, you would be knowing why.",
            "Go with Typescript+Fastify",
            "I liked the experience with Django and Django Ninja more than with FastAPI. I came from node.js, so having all the pieces together already with great documentation was amazing. FastAPI may be \u201cfaster\u201d, but for side projects, maybe even all projects, this is only a concern when it\u2019s a concern, not before!",
            "Type annotations is too hard with Django. Don't recommend.",
            "FastAPI is meant for REST APIs I would use that if you are providing true API (i.e. you're not trying to also serve the html pages, css and other files)\n\nBTW: you might also check litestar: https://litestar.dev/ this project was created as some weren't happy with FastAPI direction. It's inspired by FastAPI and might solve some kinks FastAPI has. It also claims to be much faster. I haven't yet an opportunity to try it myself, and I don't want to rip FastAPI from existing projects if I don't have good reason as I'm happy with it too.",
            "I think litestar is pretty awesome for such cases, it feels lightweight and very structured to me",
            "Do Flask, FastAPI sucks.",
            "Use fast api and micro service architecture. It's simple and as it's side project this will force you to think what goes where.",
            "FastAPI if you are here for votes",
            "Django: DRF + darf-spectacular, nice orm, django admin. Even if you don't want an interface for users, you very likely need to know what is happening on your system. Django admin is awesome.\n\n\nOverall, after learning Django I never want to touch dh flask again.\u00a0\n\n\nHaven't used django ninja so far. Like interesting \ud83d\udc4d",
            "I\u2019ve only ever used flask and Django but here is my opinion. \n\nDjango is nice if you don\u2019t really want to mess with database management. It handles all that for you, but that is why I don\u2019t like it. Sometimes this can cause pain points in simple relational schemas. But you can define your models in code, and some people like that. \n\nFlask is nice if you want more control over things like the database. It is similar to other frameworks in that you can just connect and send your queries. \n\nFor both, creating the actual rest controllers is made to be simple, the routing is simple enough too.\n\nReally it\u2019s just a personal choice at the end of the day. All of these frameworks have pros and cons. But choosing one over another won\u2019t affect your application. It will only change the way it\u2019s written.\n\nAs far as hosting. I have only ever hosted a flask app and it was very easy using nginx. But I would assume Django and the rest would make it easy too.",
            "Don\u2019t make things complicated \n\nAsk yourself- \n\nDoes my project require database? Use django-ninja\n\nMy project only returns JSON? Use FastAPI",
            "Exactly.  OP, you may start down the road and find a reason to switch later, but premature optimization is one of the most common traps you can find yourself in.\n\nJust pick one and build your thing!",
            "Yeah this is the only answer",
            "FYI django-ninja basically clones FastAPI functionality into Django.",
            "I learned something new, async backend with python!",
            "Probably gonna get downvoted to hell but I didn\u2019t have a good time with Litestar. I get why it exists and why so many people prefer it, but I find the docs to be outdated in some places and overall not very clear, it\u2019s too much abstraction to the point where it just felt unnecessary and I\u2019ve had more bugs in Litestar than FastAPI.",
            ">Django needs more work to have a REST API.\n\nCheck out Django REST Framework.\n\nhttps://www.django-rest-framework.org/",
            "FastAPI already does anything Litestar does & more, and actual companies use FastAPI (1,600,000 downloads/day). Nobody except a couple people in this sub use or plug the Litestar project.\n\nThe focused pitch by Litestar was always \"We're a copycat of FastAPI, ***but*** we're working on it as a team and not primarily built by one person like FastAPI.\" Once FastAPI got more contributors involved including a couple impactful contributors who work full-time at Pydantic, that sole \"bus factor\" pitch died. Died a second time when the Litestar \"team\" had in-fighting holdups.",
            "full-fledged",
            "> Django needs more work to have a REST API\n\nMay I introduce you to our lord and savior [Django REST framework](https://www.django-rest-framework.org).",
            "I agree with django being too much, like on the project startup there is just so many things and what i think is that django is not for small projects as it will be very heavy . Also you cannot write shitty code in django cuz python is not so fast and does not tolerate it.",
            "I'm using FastAPI and NiceGUI as a frontend. No JS involved (unless I need a very specific thing), pure python, pure joy \ud83d\ude01\n\nAlso a project called Rio (I think?) seems to get a lot of traction.",
            "FastAPI and HTMX though",
            "With Django ninja you can create a backend pretty much the same way as with FastAPI. Main difference is:\n\nIf you need an admin page or user management, use Django.\n\nBoth can be implemented in FastAPI, but are a lot of work to get right and not worth the effort.",
            "I'm using fastapi and letting the front end get tokens with firebase. There's a sign up end point for creating users but it too requires a token",
            "My team builds on flask but we're planning on a quick migration to quart for async needs.  Looks painless.  I believe it's essentially a vast improvement on the flask framework, and a near 1:1 dev experience.",
            "Why? It\u2019s still a great and stable framework that is widely used",
            "This is my answer also.",
            "YouTube, Netflix,X using Flask",
            "Quart isn't dead, and Flask supports async route handlers and async event loops based on greenlets but not asyncio.",
            "Can you tell my why you go for mongo? Your models are most likely fixed (through pydantic) so why not sql?",
            "I wish I had read this one year ago when I started a FastAPI project.  \nI still struggle with user management and refresh tokens so the user don't have to login again once the JTW expires. To the date there's no built-in support or thirdparty libraries adding this functionality.",
            "I think there\u2019s also \u201cquart\u201d which is a flask async implementation",
            "Fastapi can also use Jinja2 templates.",
            "> micro service architecture\n\nIt's a trap!",
            "> Project only returns JSON? Use FastAPI.\n\n...what? FastAPI works great with databases and ORMs.\n\nFastAPI even maintain an example github repo of a full-stack application using a Postgres database, Alembic migrations, and SQLModel + SQLAlchemy for ORM.",
            "Glad you found my post useful. \ud83d\ude0a\n\nI think I've read somewhere that Django and Flask also go the async way too.\n\nBut it's a difference if the framework has it from the start or not.",
            "fyi \u2013 FastAPI has been async from the start and actual companies use FastAPI. Nobody except a couple people in this sub use or plug the Litestar project.",
            "Useful for front end too!",
            "I didn't downvote you (the opposite), but that's interesting. I actually started to use it in a project, but haven't come to a point of recognizing bugs.\n\nI see some issues with the documentation, but in most cases I came around. \n\nCould you give me some more insights where you find Litestar inappropriate? Thanks! \ud83d\udc4d",
            "Please do not use this - if you\u2019re just starting with Django the performance issues that serializers in Django rest framework can cause are a nightmare to untangle later on - stick with fastapi or Django ninja if you want api endpoints - they both force you to be thoughtful about your model relationships.\n\nDjango rest framework has a lot of gotchas, magic, and rope to hang yourself with.  It\u2019s not a BAD framework, it\u2019s just very easy to do wrong",
            "Thanks. I'm aware that Django has something like that.\ud83d\udc4d\n\nFor my taste, it's a bit too much and FastAPI and Litestar already have that integrated.",
            "Thanks for this insight! Didn't know it.",
            "What Litestar team split?",
            "Thanks, corrected. \ud83d\udc4d",
            "Yeah, that\u2019s the more work. Django Ninja is so much easier if you just need some endpoints with docs",
            "NiceGUI is excellent. I don't really know JS or web tech at all so it's been a little bit of a learning curve, but I'm very happy with what I've been able to make for my own use. I'm hosting my web app on a VPS and I use it every day for work and personal.",
            "For personal projects, these should be fine, yes. I keep forgetting.\n\nI actually have a couple of these bookmarked to check later, but I never get around to it.",
            "Check out Ludic",
            "And if you absolutely need interactivity, alpine js seems to fit perfectly into an ecosystem where you don't want to mess with a huge JS build pipeline",
            "The only issues I can think of are the fact that some APIs require awaiting, so you if you have some sync code, it seems you have to quart.ctx.copy\\_current\\_response\\_context to put the old sync stuff in a thread, and do the async stuff before and after.\n\nAnd I guess some people might have some bizarre design that is faster with threads than async?\n\nI haven't really had any issues, I'm definitely happy I decided to move from CherryPy to Quart.",
            "Flask always turns into an mess when it grews too large in my experience.",
            "Sure, it remains great and was the best simple web framework in its time. When you needed something to just get the job done without managing Django, Flask was the framework of choice.\n\nBut then Starlette came along and became widely adopted through FastAPI. It is hard to explain why, but having worked with both, I always have the feeling that Flask's design has been completely superseded by Starlette. I just don't see any reason to use it over a Starlette derived framework. Its day is done and that's ok.",
            "I bet on flask too, it's the framework I learned first, but data in hand it's still losing.",
            "How long have they been using it and would they given a choice today? \n\nThese are companies with hundreds and hundreds of engineers. Just saying they use a framework doesn\u2019t mean particularly much given the considerable effort and inertia to switch to something else.",
            "what is a greenlet?",
            "Since FastAPI with Mongo is a common stack in the office for internal tools. However, none of the tools actually implement Beanie as the ODM so wanted to do something new",
            "For big companies maybe. For a project that maybe does 3 things. We already do it if you have ever integrated Google authentication or a payment api.",
            "One simple case where I spent hours debugging was using Jinja2 with Litestar. More specifically I was trying to add the path for css files inside the template (like `src=\"{{ url_for(...) }}\"`. At the time, I couldn't find an example on how to do this in the docs, only very vague mentions on how it would be possible, but no code snippet of a working solution. After a lot of testing I found out I couldn't use quotes, otherwise it wouldn't work.\n\nFor instance, this would throw a 500 Internal Server Error: (I don't remember the method name, so I'l just use url\\_for)\n\n`src=\"{{ url_for('static', 'main.css') }}\"`\n\nBut this would work:\n\n`src={{ url_for('static', 'main.css') }}`\n\nOn FastAPI, both worked, and the docs had a very clear example of addind static files to templates. I had no clue why Litestar was so finnicky about this, even though I was using the same exact templating engine on both frameworks.\n\nAlso 500 errors don't give much information, so I had no direction whatsoever on what was going wrong.\n\nI'd say this was the biggest issue that threw me off.",
            "Thank you for that.",
            "Can you give examples?\u00a0",
            "Yeah, it depends on your use case.",
            "So with NiceGUI and FastAPI, html/css/JS can be bypassed? \n\nI want to convert one of my Tkinter apps to webapp but don\u2019t want to go through a big learning curve",
            "Note that I use it for work (I never do personal projects... Shame on me, but I work enough to not enjoy that on my free time).\n\nThe developer experience is great imo.",
            "You can have a lot of interactions with HTMX. I just dont want to deal with any JS \ud83d\ude05",
            "Same same. Almost always my Flask projects start to look like a Django knockoff with all the code, modules or libraries I add to handle an aspect of a web app that Django already does.",
            "Sounds like a you problem.\n\nPlus OP is asking for a small project.",
            "also Flask is maintained by a total jerkwad",
            "I'm not a fan of arguing based on feelings, are there any actual fact based arguments to use starlette over Flask?\u00a0",
            "It is very similar to an asyncio task, https://greenlet.readthedocs.io/en/latest/",
            "It only makes sense for big companies, to split up work. But it introduces a lot of red tape.\n\nFor small companies you have the red tape and the complication plus it's always the same people that have to handle everything :D",
            "Thank you very much! That was very insightful.\n\nLuckily my project just started so it would be probably easy to move it to FastAPI.",
            "The most consistent one is the use of Fields or mismatched queryset results vs serializer fields in serializers that return list endpoints starting to add exponentially more subqueries serially to return the data you asked for\n\nFor example, you have a Home model that has a name field and an address field - if your serializer is defined to have both but your queryset only returns name, the serializer will go fetch the address because it knows how.  Now instead of one query you have N+1.  Those kind of pitfalls are very easy to fall into as you\u2019re updating your models and serializers without recognizing it and your performance tanks",
            "It's present, but abstracted away for the most part. You don't need to write any HTML or JS, but you can if you want to extend what the library offers. I have had to figure out some CSS to make specific things look how I want, but it wasn't that big of a deal and it depends on what kind of app you're making. I was able to figure things out by reading the docs.",
            "That's good to know. I'll definitely try it out now.",
            "Fair enough, and modern CSS can also already do stuff that back in the day would have been JS.",
            "None that I know. I was going to say userbase size, but according to Github, 1.2m projects import Flask. Less than 600k import Starlette, FastAPI and Litestar combined.",
            "Seriously this. Don't start with a microservices architecture. Migrate to it only when you are hitting problems with a monolith.",
            "No probs. I wish Litestar can become mainstream soon because I really like its concepts, but for now it's not 100% battletested like FastAPI.\n\nGood luck on your project!",
            "Thanks for looking that up! I found out that if your application needs server sent events or websockets, then you should be better off with Starlette, but I think that these requirements come up often"
        ]
    },
    "Built a RAG ( Retrieval-Augmented Generation ) model using Gemini Api.": {
        "title": "Built a RAG ( Retrieval-Augmented Generation ) model using Gemini Api.",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1dh3jtj/built_a_rag_retrievalaugmented_generation_model/",
        "content": "#what my project does\nThis project is built to solve the issue of LLM unable to produce relevant answers for information in a particular context. uses the information  to train the model and stored it in a database and uses  this database to get relevant answers from the Model.\n\n#Target audiance \nThis project is for people who want to train a LLM on a particular piece of information.\n\n#comparison \nThis model only gives answers for information regarding the data you provided in the file. It will not answer any other questions including formal greetings.\n\nGitHub link :https://github.com/dharmateja2810/RAG-Retrieval-Augmented-Generation-Model",
        "num_comments": 4,
        "comments": [
            "I appreciate this very much, thank you for sharing!",
            "This is hello world stuff. \n\nWhy bother others with such bullshit?",
            "Either be constructive or stfu. If they\u2019re beginning with AI this is good practice for them. If you don\u2019t want to engage then don\u2019t.",
            "What this guy said.  If I can post my boobs on reddit and advertise an only fans where I sell my feet pics to bears then why on earth can\u2019t we post something actually accomplished and helpful to others at the same spot"
        ]
    },
    "What if we had a standard for relocating standardized configuration files?": {
        "title": "What if we had a standard for relocating standardized configuration files?",
        "score": 1,
        "url": "https://www.reddit.com/r/Python/comments/1dgrjsx/what_if_we_had_a_standard_for_relocating/",
        "content": "I can't be the only one who hates having 50 configuration files on my project's root directory, right?\n\nThere's .pylintrc, project.toml, Dockerfile, docker-compose.yml, Makefile, .gitignore, package.json, tsconfig.json, .eslintrc, .travis.yml and a whole lot more.\n\nAnyway, what if we had a standard way to put all these files **somewhere else**, while still being able to automatically detect them (therefore avoiding having to use some special \"--config-file\" flag in the CLI)?\n\nHere's my proposal, which I called the `translocate` standard (it's a homage to Unreal Tournament's Translocator, a personal teleporting device):\n\n1. Put a file called `.translocator` on your project's root.\n2. Inside the file, write as json where the desired files are.\n3. Whenever a program execute from the project's root, it includes the .translocator information in its standard lookup paths. And that's it!\n\nI have 2 proposals for the file's structure: a simple one, and a pseudo-namespaced one.\n\nSimple .translocator: flat json object where the key is the standard file name, and the value is the path to the file, wherever it may be. Here's an example:\n\n\n```json\n{\n    \".pylintrc\": \"C:/Users/myself/dev/.configs/.pylintrc\",\n    \"Dockerfile\": \".configs/docker/dockerfile\"\n}\n```\n\n\nPseudo-Namespaced: array of objects that includes both the file name and the CLI/executable/program name, in the eventual case that two different programs have configuration files with the same name. Here's an example:\n\n\n```json\n[\n    {\n        \"who\": \"pylint\",\n        \"what\": \".pylintc\",\n        \"where\": \"/home/foo/.templates/.pylintrc\"\n    },\n    {\n        \"who\": \"docker\",\n        \"what\": \"Dockerfile\",\n        \"where\": \".configs/docker/dockerfile\"\n    }\n]\n```\n\n\nAlso, all relative paths should be resolved in relation to the `.translocate` file, NOT the current working directory.\n\nThis standard allows developers to easily clean their project directories and reuse configuration files across different projects. It's honestly a great idea, so I'm sure someone has already thought of it, but I'm unaware of any programs or projects that employ a similar standard. \n\nThe biggest difficulty for sure would be getting programs/developers to adopt the standard, but then again, that's the story of every single standard that has ever existed.\n\nAnyway, that was my TEDxTalk.\n\nWhat do you guys think? Great idea? Too niche to get any traction? Just another case of [XKCD 927](https://xkcd.com/927/)? Am I having an OCD episode?",
        "num_comments": 1,
        "comments": []
    },
    "Python automation ideas": {
        "title": "Python automation ideas",
        "score": 51,
        "url": "https://www.reddit.com/r/Python/comments/1dg4cof/python_automation_ideas/",
        "content": "Hi I\u2019m looking for inspiration for some stupid python automation projects. If you have done something funny or stupid using python automation I would love to hear it.\n",
        "num_comments": 40,
        "comments": [
            "automate a bot to detect every time a similar question gets asked",
            "This kind of question is probably more suitable for /r/learnpython. Also, it\u2019s a very vague question. You should probably give some kind of specific about the type of automation you would be interested in doing.",
            "Xkcd made a comic about a script that searches eBay for something random about 10 bucks plus shipping, and orders it for you.\n\nPrep it up with a virtual credit card (to make sure it won't empty your bank account) and run it blind every week to get a random present.",
            "There is an entire book about this called \"Automate the boring stuff with python\" from No Starch Press.\nAt least it helped me increase my productivity and grow into the language.",
            "I have an idea.\n\nTrack popular protein prices and find the one with the LeastPrice per serving. Make it update with the click of a button so I don\u2019t have to manually search every few months.\n\n\nGold standard\nRecon1\nMuscle milk\nOrgain\nNutricost\nDymatize\n\nIf you don\u2019t build it then I will!",
            "Try selenium + chromedriver to scrap websites, LinkedIn is a favourite for it. Go to GitHub and you\u2019ll find a few projects there, very fun",
            "Not that follows or unfollows on social media, like TikTok.\n\nFind a web page that requires 2fa and try to automate log in process - I loved it.",
            "During college (CS major here), we were required to create a word document for all the practical work we did in the lab. This process was hella time consuming since there was a lot of formatting required. \n\nTo reduce the time, I created a program that had a Tkinter GUI to create these documents. \n\nhttps://github.com/themightywolfie/Word_Doc_Generator",
            "Few ideas:\n\n1. Bot which tracks flight prices and send alerts to you.\n\n2. Choose a board game you like and try to create a bot who is able to play with you.",
            "Find something that is applicable to your work, hobbies, or lifestyle. You\u2019ll likely lose interest quickly if you are not benefiting from the final product. Also, you learn way more by venturing off trail and making something new rather than following a premade example.",
            "I fucked up my Ubuntu installation trying to install Nvidia drivers for Verba, if that counts.",
            "The silliest, least useful, and most fun part of our business's Python code plays joyous music every time an order comes in from our website.\n\nOrders arrive via an email from Squarespace, the host for our company's website. This software wakes up every few minutes, then scans through our email inbox looking for new orders. When it finds a new order, it blasts joyous music and we celebrate.\n\nA recent useless joy-inspiring feature: when a payment comes in from Stripe, it plays the cha-ching cash register sound.",
            "I did automate naming letters i recieve. I scan them and would normally rename them by myself. Like date - sender - reason of the letter.\n\nI know only scan them and together with chatgpt it reads the first page and extracts all thr necessary infomations and renames the filename.",
            "A bot to automate email replies",
            "The recommendation for the same taste of songs.",
            "I wrote a code to notify me of crypto price every hour, sent via telegram..pretty basic for the people out here probably",
            "Prices of fast food restaurants and their standard meals.",
            "Just ask this question to ChatGPT and you will have plenty of idea:\n\n1. **Automated Meme Generator**:\n   - Create a bot that generates memes based on trending topics by scraping news headlines and matching them with relevant images.\n\n2. **Smart Home Controller**:\n   - Develop a script to control smart home devices like lights, thermostats, or security cameras based on your schedule or external data sources like weather.\n\n3. **Virtual Art Gallery**:\n   - Automate the creation of a virtual art gallery by scraping artworks from public APIs and presenting them in a daily rotating display on your desktop or a web page.\n\n4. **Financial Bot for Investments**:\n   - Build a bot that monitors stocks, cryptocurrencies, or other investments, sending alerts based on predefined conditions or unusual market movements.\n\n5. **Ebook Library Organizer**:\n   - Create a script that organizes your ebook library, automatically categorizing books by genre, author, or other metadata, and suggests which book to read next based on your mood or previous ratings.\n\n6. **Automated Bug Reporter**:\n   - Develop a tool that automatically reports bugs or issues found during routine software usage, capturing errors and submitting tickets to a tracking system.\n\n7. **AI-driven Content Curator**:\n   - Build an AI that curates content based on your past consumption, fetching articles, videos, and podcasts, and compiling them into a personalized newsletter.\n\n8. **Voice-Activated Assistant**:\n   - Create a more complex version of a voice-activated assistant that can perform tasks like setting reminders, controlling IoT devices, and answering questions with context understanding.\n\n9. **Game Stats Tracker**:\n   - Develop an automation that tracks your performance in video games, providing statistics and improvement tips based on gameplay analysis.",
            "and make it reply \"automate a bot to detect every time a similar question gets asked\"",
            "Do this on r/Linux r/Linuxquestions and r/Mint and it will eliminate 90% of the sub!\n\nIt's so bad I barely look at it now.",
            "is this something you would use NLP for? as in some NLP libraries? and/or Regular Expressions? Im very interested in learning web scraping with Python and wondering if this is something that a beginner programmer would possibly be able to get into and Im under the impression that learning NLP skills would be really helpful but swems quite daunting...",
            "Does the praw library still work after all the third party apps shut down?",
            "[deleted]",
            "Or use AliExpress and order a bunch of the one-cent specials :)",
            "I've been wanting to do this ever since the prices skyrocketed during covid. Just have to find the time for it. Please build it",
            "This would be very helpful to me. lol. I\u2019m still learning python. So far I can make it it ask me questions and tell me how many letters are in my responses",
            "how do you manually search ? on amazon ? asking to get a idea of where to get protein prices from",
            "Always when i read thinks like this I have the same question: do you do it using APIs or just web scraping using for example selenium?",
            "RemindMe! 6 months",
            "Why not a latex template?",
            "Lol that sounds amazing",
            "these all seem awesome but am I wrong that except for 1 and 3 and possibly 6 these would require a TON of learning and work? ...",
            "Automate asking these questions too.",
            "Do people even get something from such 'specials' as I've been scammed plenty of times in AliExpress",
            "Aight i'll try. I'm currently working on a Calendar project (I've posted it here few mins ago) so I'll try to find some time to do this.",
            "You can either pull pricing from Amazon or the manufacturer site using beautiful soup or selenium",
            "Web scraping. I\u2019m not smart enough for API\u2019s yet.",
            "I will be messaging you in 6 months on [**2024-12-15 00:45:03 UTC**](http://www.wolframalpha.com/input/?i=2024-12-15%2000:45:03%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/Python/comments/1dg4cof/python_automation_ideas/l8nw9s8/?context=3)\n\n[**CLICK THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FPython%2Fcomments%2F1dg4cof%2Fpython_automation_ideas%2Fl8nw9s8%2F%5D%0A%0ARemindMe%21%202024-12-15%2000%3A45%3A03%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201dg4cof)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
            "I hadn't learnt about latex templates back then\n\nEdit: Thanks for the idea, maybe I'll include a custom latex parser instead of a form. It should convert any latex template into a Word doc.",
            "It makes me smile."
        ]
    },
    "Lua-style code blocks for Python": {
        "title": "Lua-style code blocks for Python",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1dh6v9i/luastyle_code_blocks_for_python/",
        "content": "Python is a great programming language, but sometimes the indentation can be terrible for some people (especially people with visual impairments).\n\nSo i created `Lython`.\n\nWhat the project does:\n\nLython replacing the Python indentation to `lua-style` code blocks.\n\nthis is example lython code\n\n    def test(num)\n        for i in range(num) do\n            if i == 0 then\n                print(\"zero\")\n            elif i % 2 == 1 then\n                print(\"odd\")\n            else\n                print(\"even\")\n            end # if else\n        end # for\n    end # def\n    \n    test(10)\n\nfor more info, please visit lython repo.\n\nTarget audience:\n\nPeoples with visual impairments (especially) and Programmers who want to write python code with new experience (generally)\n\nRepo & Source code:\n\n[guangrei/lython](https://github.com/guangrei/lython)",
        "num_comments": 29,
        "comments": [
            "I can't see (heh) why having to read a bunch of ends and pairing them with the correct opening statement would be easier to read than an optical alignment that you don't even need to read in order to follow.",
            "I can see some value to this for visually impaired folks. Now that I think about it, I\u2019m kind of surprised that IDEs don\u2019t all have a mode like this.\n\nEdit: but some of this seems to just be a gratuitous addition to look more like Lua. The **then** keyword, for example, seems to have no value whatsoever wrt OP\u2019s stated aims.",
            "I applaud the effort to provide accessibility tools for people who might have difficulty coding. There\u2019s not nearly enough effort made to make these kinds of things more inclusive. That said, I would maybe reconsider whether this specific approach is wise. Creating a whole separate Python variant for this one thing will likely never get wide usage and will just make it so that people with accessibility issues are never really writing Python code that everyone else can run or contribute to. \n\nPerhaps a better approach could be something like a VSCode extension or CLI tool that adds/removes Python comments at these same locations/tabs. That way you still get the visual indicator for the end of a block of code but the code itself is still compliant python. You could even just make it a visual indicator in the IDE (not an actual comment) so when code gets committed or pulled, it doesn\u2019t actually need to add new content that other developers won\u2019t be familiar with and it would automatically add the indicator to code the person didn\u2019t actually write.\n\nI would recommend looking at something like \u201crainbow indent\u201d in the vscode third party extensions library. I often use that to make indentation easier to read and I think it strikes a good balance between modifying the visual appearance of the code without it being a permanent fixture in the saved file.",
            "The screen readers that the majority of blind people use have support for indented code. NVDA, the most popular free and opensource screen reader in the world, optionally represents indented levels with beeps (ascending as the indent increases) or speech queues (\"4 space  for i in range(num) do\"). It is primarily written (by blind/vi people) in Python (with lower level winapi interfaces etc in C++) without comments to represent the ends of blocks, BTW. I believe people have made like addons or something for VoiceOver on Mac as well. Perhaps there is some difficulty for visually impaired people using magnifiers rather than screen readers of which I'm unaware, or something.",
            "The forced indentation and lack of braces or begin/end is the single best feature of Python\n\nI'm also guilty of wanting to design a better language. Luckily I came down from my high before I published and made a fool of myself.",
            "Congrats, you butchered the language. The whole point of python is to have less boilerplate code.",
            "Feels bad for the next experienced python dev who has to take over this codebase",
            "Yuck.\n\nI\u2019ve used Luau a lot and the end statement is my least favorite part about Lua/Luau.\n\nI honestly have come to love Python\u2019s brace-less syntax since I don\u2019t have to worry about missing braces all the time.\n\nThis is even worse than braces.",
            "I find it hard to go back to Lua with all it's orphan end statements. Dirty stuff.",
            "I don't understand how this helps those who are visually impaired",
            "Look into the new match statements",
            "What is this witchcraft!? do/then is the tool of the devil!",
            "Couldn\u2019t this just be added by an editor?",
            "Might be useful, only time will tell.\n\nI use to think of a dialect with braces and semicolon (like Javascript) because it might be good to have JSON-like feature in Python.\n\nMeanwhile I found [Hy](https://hylang.org/), and think it might be able to do more and maybe will eventually can do meta-programming. So I don't pursue that JSON-like thing anymore.",
            "Just a quick tip, it can be worthwhile to spell out what the difference between this and ordinary python. I can imagine, especially with an visual impairment it would be really hard to see the difference just by looking at that codeblock.",
            "its will produce better error when an opened block not closed",
            "when you use % LYTHONOPTIMIZE=0 lython -c your_main.ly every python tools like flake8 etc should be working",
            "Lol thanks I hate it \ud83d\ude02",
            ">less boilerplate code\n\nI do really want some feature that auto include init params to  self.val like this\n\n    class My:\n        def __init__(self,@this,@that,@those,@thing):\n          pass\n\nand generate this automatically\n\n    class My:\n        def __init__(self,this,that,those,thing):\n            self.this = this\n            self.that = that\n            self.that = those\n            self.that = thing\n\nSomething similar to Haskell record extensions [RecordWildCards](https://ghc.gitlab.haskell.org/ghc/doc/users_guide/exts/record_wildcards.html#extension-RecordWildCards)  and [NamedFieldPuns](https://ghc.gitlab.haskell.org/ghc/doc/users_guide/exts/record_puns.html#extension-NamedFieldPuns)",
            "lython has special syntax checker that give better error than when you use native indentation",
            "you will know big difference when use screen reading",
            "here is match case example\u00a0https://github.com/guangrei/lython/blob/main/examples/match_case.ly",
            "the indentation in example is just to make code look pretty and not effects in parser, lython has special syntax checker that give better error than when you use native indentation",
            "Better than what? How is that better than the indentation error Python gives you?",
            "Have you checked the @dataclass feature? Python 3.7+",
            "I don\u2019t see how that\u2019s a better alternative though.",
            "Maybe it would make sense to someone with visual impairment. I don\u2019t see it too",
            "Thanks! That's cool! Now I can have smaller code ![gif](emote|free_emotes_pack|thumbs_up)\n\nNo idea how I miss this feature.",
            "yeah its hard to explain to people who never coding with screen reader"
        ]
    },
    "I made an MMORPG with Python & Telegram in 4 weeks": {
        "title": "I made an MMORPG with Python & Telegram in 4 weeks",
        "score": 81,
        "url": "https://www.reddit.com/r/Python/comments/1dftgrl/i_made_an_mmorpg_with_python_telegram_in_4_weeks/",
        "content": "well, kind of.\n\nI made Pilgram, an infinite idle RPG where your character goes on adventures and notifies you when stuff happens.\n\n# What my project does\n\nThe bot provides a text interface with wich you can \"play\" an MMO RPG, it's basically an online idle adventure game\n\n# Target audience\n\nIt's a toy project that i made out of boredom, also it sounded cool\n\n# Comparison\n\nI never heard of anything like this except for some really old browser games. Maybe i'm just not informed.\n\n# More info\n\nHow is it infinite? The secret is *AI*. Every quest and event in the game is generated by AI depending on the demand of the players, so in theory you can go on an infinite amount of quests.\n\nWhy did i call it an MMO? Because you can kind of play with your friends by creating & joining guilds and by sending gifts to eachother. There even is a guild leaderboard to see who gets the most points :)\n\nThe interface is exclusively text based, but the command interpreter i wrote is pretty easy to integrate in other places, even in GUIs if anyone wants to try.\n\nI tried out a lot of new things for this project, like using ORMs, writing unit tests (don't look at those, i kinda got bored after a short while), using AI & writing generic enough code that it can be swapped with any other implementation. I think most of the code i wrote is pretty ok, but you can tell me what to change & what to improve if you want.\n\n# Links\n\nhere's the link to the code: [https://github.com/SudoOmbro/pilgram](https://github.com/SudoOmbro/pilgram)\n\nif you wanna try out the version i'm running on my server start a conversation with `pilgram_bot` on Telegram, don't expect a balanced experience at first since that was kind of the last of my problems lol",
        "num_comments": 39,
        "comments": [
            "That title just blows you away until you start reading the details and realize it\u2019s basically a chat room. lol",
            "This is what, back in the mists of time, was called a MUD - Multi-User Dungeon - but with modern idle game mechanics. \n\nNot my jam, but I think the idea is neat.",
            "Interesting, you mind adding a license to your repo?",
            "no science based dragons? Pssssh",
            "Hmmm neat. If you add an interface for discord you could host it and run it via discord. \ud83d\ude01\n\nThen advertise the server as a free discord MUD",
            "I've seen worse tests. You left a print statement in one which makes me think you are a print debugger - if so try to turn those sessions into quick tests and leave yourself a comment about it (if you know its fragile or flaky remind future you so when it breaks on something stupid you can just delete it or repair it and move on). There may also be testing patterns in python that will make writing quick tests easier. Oh and on that topic I think you can get a lot of value just from checking invariants especially over a range of inputs, invariants being things like the returned value is always positive, or it is never the empty string, or even that a series or inputs always has an increasing/decreasing/changing output. What you have are correctness checks, which can be good but are also higher effort (and tend to be because you want to prove to yourself it works as expected). Testing invariants can be very fast because you typically just need to make a list or range of values that cover your inflection points (like for integer inputs a negative, zero, and positive value tends to cover the vast majority of cases) and then you can apply a uniform test to the function output.\n\n\nI don't know enough to comment fully on the bot and threading code, but it strikes me as odd that they are all using wait to synchronize. Why are they given a wait time at all? That is a timeout, the idea being that if a task gets too old to be relevant that you want to pick back up and do something about it.\n\nOh also in your is killed function get rid of the 'if boolean return true', just return the boolean.",
            "Is it a mud? Multi user dungeon?",
            "EVE Online is built on Python",
            "You should plug in some diffusers, for imagery.",
            ".",
            "Tbf, I think everyone kinda assumed that there wasn't gonna be much to the game if it's only been worked on for 4 weeks.",
            "It\u2019s a 4 week project built on top of Telegram. Idk what else you\u2019d expect.",
            "It's a bit more advanced than a simple chatroom but yeah the title is a bit clickbaity on purpose lol",
            "Ah yes was just about to post this https://en.m.wikipedia.org/wiki/Multi-user_dungeon , I had so much fun back in the day playing MUDs.",
            "Didn't know about the existence of those, thanks btw! :)",
            "Ah right, i forgot, thanks for reminding me, i'll do it as soon as i get home in a few hours :)\n\nedit: added license :)",
            "What does this mean?",
            "It could be done quite easily actually, the telegram code basically just calls my custom internal command handler wich doesn't care where messages come from. By making a couple small changes to the database structure i could even allow crossplay between any platform :)\n\nThansk for the idea ;)",
            "> print debugger \n\nAren\u2019t we all?",
            "Interesting review!",
            "Thanks for the tips on the tests, i'll try to apply them in the future!\n\nAbout the threads, i'm using sleep functions that wait for a kill signal to avoid running them all the time since it needs to run on very limited hardware along with other bots; And since the 2 threads that have that problem don't need to run all the time it works well enough.\n\nDidn't catch the is_killed, i wrote it while tired, thanks for noticing \ud83d\ude01\n\nedit: fixed is_killed :)",
            "So i've been told, but since i didn't know what those were before starting the project i'd describe it as an idle game where you occasionally interact with other people.",
            "Is it? Like the entirety of the game logic & client too? I never played it but if so that's very impressive",
            "It could easily be done, but since i'm trying to keep costs down i avoided it",
            "I made a 1000 mile range EV truck!\n\n::presents picture of wheelbarrow::",
            "Check some out for inspiration, some are still going.",
            "40 years ago.",
            "There are python frameworks for making them, too.",
            "How is this comment negative??",
            "A copyright license. By default all rights are reserved, so if you want other people to use your code you should provide a license saying so (the MIT license is common). And typically if you are sharing it like this then you don't mind someone forking or otherwise using it.",
            "No problem! Should be a fun thing to do while people chat",
            "Oh you know there is a reason I saw that and made an assumption",
            "The client is a mix of Python and C++ but the backend is Python: https://www.eveonline.com/news/view/stackless-python-2.7\n\nI also believe they are working on migrating to python 3, or they may have done it already. Havent played in a while.",
            "lol the whole attraction of diffusion is how cheap it makes imagery.",
            "I logged into one after no joke 25 years and the same person was still sitting in there and responsive.",
            "Got me I certainly didn\u2019t downvote him.",
            "I can't imagine everyone properly logging all the time...sometimes you just want a quick hello.",
            "I see, very interesting, thanks for sharing!"
        ]
    },
    "Introducing Temporal Adjusters: Simplify Time Series Adjustments in Python!": {
        "title": "Introducing Temporal Adjusters: Simplify Time Series Adjustments in Python!",
        "score": 11,
        "url": "https://www.reddit.com/r/Python/comments/1dg4fkv/introducing_temporal_adjusters_simplify_time/",
        "content": "Hey guys!\n\nI'm excited to introduce Temporal Adjusters, a new Python package designed to make time series adjustments easier and more efficient. If you work with time series data, you'll find this tool incredibly useful for various temporal adjustments.\n\n# What my project does\n\nAdjusters are a key tool for modifying temporal objects. They exist to externalize the process of adjustment, permitting different approaches, as per the strategy design pattern. Temporal Adjuster provides tools that help pinpoint very specific moments in time, without having to manually count days, weeks, or months. In essence, a Temporal Adjuster is a function that encapsulates a specific date/time manipulation rule. It operates on a temporal object (representing a date, time, or datetime) to produce a new temporal object adjusted according to the rule. Examples might be an adjuster that sets the date avoiding weekends, or one that sets the date to the last day of the month.\n\n## Installation\n\nYou can install Temporal Adjuster using pip:\n\n    pip install temporal-adjuster\n\n## Usage\n\nThis package provides a set of predefined temporal adjusters that can be used to adjust a temporal object in various ways. For example:\n\n    >>> from datetime import date, datetime\n    \n    >>> from temporal_adjuster import TemporalAdjuster\n    >>> from temporal_adjuster.common.enums import Weekday\n    \n    >>> TemporalAdjuster.first_day_of_next_week(date(2021, 1, 1))\n    datetime.date(2021, 1, 4)\n    \n    >>> TemporalAdjuster.last_day_of_last_month(datetime(2021, 1, 1))\n    datetime.datetime(2020, 12, 31)\n    \n    >>> TemporalAdjuster.first_of_year(Weekday.SATURDAY, date(2021, 1, 1))\n    datetime.date(2021, 1, 2)\n    \n    >>> TemporalAdjuster.nth_of_month(Weekday.SUNDAY, datetime(2021, 5, 1), 2)\n    datetime.datetime(2021, 5, 9)\n    \n    >>> TemporalAdjuster.next(Weekday.MONDAY, datetime(2021, 2, 11), 2)\n    datetime.datetime(2021, 2, 15)\n\n## Contributing\n\nIf you have any suggestions or improvements for pynimbar, feel free to submit a pull request or open an issue on the [GitHub repository](https://github.com/gtkacz/temporal_adjusters_py) as per the CONTRIBUTING document. We appreciate any feedback or contributions!\n\n# Target audience\nThis can be used in production. It has only one depedency, dateutils, which if you're manipulating temporal objects you probably already have. All the code is 100% unit-tested, as well as build tested for all supported Python versions.\n\n# Comparison\nThis is based on Java's native TemporalAdjuster interfaces, but I found no similar library/functionality for Python.",
        "num_comments": 9,
        "comments": [
            "It looks like your class isn't meant to produce instances, and instead serves as a namespace for static methods. That's necessary in Java (which you note this project is based on), but in Python you can just make everything a module-level function. In fact, since Python doesn't have this same restriction that Java has, it might be confusing to users that they are importing a class but not instantiating it.",
            "The operations it provides seem useful. But I see it as a major limitation that it can only operate on date/datetime objects, rather than numpy or pandas datetimes and arrays/series.",
            "FWIW here's the section of the Google Python style guide that covers staticmethods vs module-level functions\n\nhttps://google.github.io/styleguide/pyguide.html#217-function-and-method-decorators",
            "I've done this for a few reasons:\n\n1. I think the function names might be weird without the class/package name, for instance, next (which in the package's case is used to finding the instance of a weekday) and the built-in next function. This could be solved with more verbose names, but it is something I took into consideration alongside my other points below\n2. In this case, they can instance the class with no downside, so it hopefully won't confuse users\n3. I just don't like methods that aren't part of a class, I think it's not clean and expandable/maintainable code (this is really just a preference)\n4. I plan on adding future functionalities that would benefit from being part of a class, like method dispatching based on function signature \n\n\nEven so, I will take this into consideration, and maybe create a way to import the methods without needing to import the class.\n\nThanks for the feedback!;)",
            "Just an update: had a slow day at work and rolled out version 1.1.0 with full sequence support for all methods :)",
            "That is planned for the next version, which I should get to sometime next week. Thanks for the feedback!:)",
            "Thanks for your effort! It\u2019s not really a good solution though, because you\u2019re looping over the arrays/Series/\u2026, which is slow in Python. NumPy and pandas have vectorized datetime operations, IMHO those should be used.",
            "I thought about that, but that would require me to add numpy and pandas as dependencies. Do you think it's worth it to make numpy a dependency just to use vectorized functions?\n\nEDIT: Yeah, did some testing and numpy is ~100x faster, I think I'll convert everything to ndarrays, run the functions, and convert them back to original types",
            "You don\u2019t really need to have strict dependencies. You could make those dependencies optional and import the packages locally (not sure what\u2019s the best way for type hints, maybe provide them as strings or wrap try/except around imports and use a different path depending on the value of typing.TYPE_CHECKING). This is similar to what pandas does e.g. with openpyxl for handling Excel files or fastparquet/pyarrow for parquet files (or what Huggingface packages do for PyTorch and TensorFlow). You don\u2019t get these packages when you install pandas. You just need to have them when you call the respective methods, or you will get an error\u2026"
        ]
    },
    "Created an Api for APKpure": {
        "title": "Created an Api for APKpure",
        "score": 13,
        "url": "https://www.reddit.com/r/Python/comments/1dg2crg/created_an_api_for_apkpure/",
        "content": "Like the title said. I created an API fro [apkpure.com](http://apkpure.com) . I was creating a script to automate YouTube Revanced, but i couldn't find anyway to download the apk. You can try out the app here: [https://github.com/anishomsy/apkpure](https://github.com/anishomsy/apkpure)\n\n**What My Project Does**\n\nIt allows you to download apk from [apkpure](http://apkpure.com). Users can easily fetch specific versions of Android apps programmatically.\n\n**Target Audience**\n\nit is a hobby project, anyone can use it\n\n**Comparison**\n\nI did not find any existing alternatives. So I created my own. The only other way was to download it manually which is very tedious.\n\nPlease lmk how i can improve.\n\nThank you",
        "num_comments": 3,
        "comments": [
            "Oooh nice, i will try to use it",
            "Let's go \ud83d\ude09",
            "I opened an issue, you commit and did not answer, no interaction..."
        ]
    },
    "Making the most out of Python for specific data analysis tasks...": {
        "title": "Making the most out of Python for specific data analysis tasks...",
        "score": 1,
        "url": "https://www.reddit.com/r/Python/comments/1dgentt/making_the_most_out_of_python_for_specific_data/",
        "content": "Hi guys, I've been using Python seriously in a professional work environment for a few months now.\n\nI usually deal with lower level languages, so it is quite a new experience for me.\n\nThe most challenging adjustment for me is as most new Python programmers would say, concurrency & parallelism.\n\nSome of the main points I struggle with are IPC, limited threads, limited fork implementation forcing a spawn-first approach, and trying to work around these issues while still being able to play nice with whatever underlying low-level libraries in use at the moment. Numpy, Numba and being able to readily write C-extensions are absolute blessings, but sometimes we still end up wishing we could fully utilize the parallel capabilities of our container dataframe libraries without \\*any\\* interpreter oversight. I mainly use Polars these days, and the devs have been awesome - but the overhead of using `to_numpy()`, carefully crafted `numba.guvectorize` routines, or anything halting the Polars pipeline eventually adds up as datasets grow large. Not to mention, IPC via native Python containers like *Queues* or multiprocessing's *Manager* definitely take a cut of the performance if we wish to accomodate a wide range of data types on return.\n\nRecently, I came up with an ad-hoc way to make the most out of multiprocessing without straight dumping huge amounts of code to C, and I'd like to share it with you. So far, it has worked for me very well - and worked for me better than any other multiprocessing approaches I've tried from programming forums, books and Python documentation. I don't know if this type of 'routine' is well-known, has a name, or if it is riddled with potential risks and bad practices, but it would be great to receive some feedback on this.\n\nThe *problem area* is that of numerical data analysis - I'm using *Python Polars* `v0.20.31` as my data container/processing library (`python[3] -m pip install -U polars[\"all\"]`) - I'm guessing Pandas 2.0, DuckDB, etc of similar nature would work as well.\n\nA decent use case for this method would be if we have multiple large datasets (our dataframe objects) for which to perform some CPU intensive analysis/calculations. The best case would be if unit calculations are only based on row-wise data (row as in terms of a traditional column-row table structure) and there is no funny business like calculation of one step depending on values from previous rows/calculations, etc.\n\nThe '*trick*' I employ is to maintain a pair of global integer constants for the routine:\n\n* `OUTER_CORES`\n* `INNER_CORES`\n* `MAX_INNER_THREADS`\n\nIn a *separate non-main script*, I define a function to split each dataframe into several parts (let's say `N` parts such that `N % INNER_CORES == 0`) and run the intensive calculation routine on a multiprocessing `Pool` with `INNER_CORES` processes.\n\nIn our *main script*, we define *non-daemon* processes and start them; keeping them running on well-controlled rotation such that at most, `OUTER_CORES` *number of processes are running simultaneously at any given time*. Since we start these as *non-daemon* processes, `Pool` instances within the our *non-main script* are able to start uninterrupted and as usual. We can get result dataframes or return values via a multiprocessing helpers like `Queue`, `SharedMemory`, `Manager`, *pipes*, *pickling* or whatever works best for our use case.\n\n*A note regarding the separate script containing the Pool code*: This is a bit risky, since if the *OUTER* and *INNER* cores numbers are not configured in a reasonable manner, the system might crash. Moving on,\n\n* We limit the number of threads the underlying dataframe container library is able to create for parallel processing.      I find it works well for my case if it is <= OUTER\\_CORES. For Polars we'd use\n   * `import os ... os.environ['POLARS_MAX_THREADS'] = '4' # INT OF CHOICE...`\n\n* For *the function that each Pool instance's active session would execute*, we actually **separate each dataframe chunk further** (to say, `M` parts, such that `M % MAX_INNER_THREADS == 0`) and run them **as threads** - which initiate dataframe-heavy functions that perform the actual calculations. We could use `ThreadPoolExecutor` here as well as traditional loop controlled `Thread`s, but we must make sure that the number of simultaneous threads are reasonable (reasonable as in how many full on threads would we like for each process to run at one time). Otherwise a system crash would ensue in the form of a buffer overflow/lack of allocatable memory.\n* This way, even though the Python Global Interpreter Lock limits thread parallelism, it is unable to enforce such for the underlying low-level dataframe library and we're able to fully release the GIL at this point. Hence, if we set max '*simultaneous*' threads to an unreasonable number like 20 for each `INNER_CORES` simultaneous processes, memory requirements will rapidly exceed capacity resulting in either a crash, or incorrect/missing output data due to memory allocation failure.\n* The total cores used would then be `(OUTER_CORES * INNER_CORES) + OUTER_CORES` *and we must ensure it does not exceed that of our machine's total cores*. I usually like to keep about 2-4 cores free so as not to overwhelm the OS which actually improves the overall runtime performance (I'm guessing) due to the OS not being overburdened. Once in excess of the number of machine's cores however, the system will straight up doom crash to oblivion.\n* The processing of output values/output dataframe chunks from the Pool runs (and in turn, their thread runs) and eventual amalgamation of output dataframes thereof is handled in an appropriate way as deemed fit - at worst using global manual locked variables, although this would be a bad methodology in most cases.\n* Depending on *the nature* and *point in code* of executed dataframe '*splits*', one might need to pass actual **copies** of the split dataframe's chunks (for Polars I use \\`\\`\\`df.clone()\\`\\`\\`) so as not to mess up direct data reference locations. Polars uses a form of light copy, but I'm not too well aware of how they navigate the pointer overwrite issue without performing a full on *deepcopy*.\n\n# Positives\n\n* We are able to fine-tune according to hardware/data load oor experiment for optimum combination by carefully adjusting these parameters.\n   1. `OUTER_CORES`\n   2. `INNER_CORES`\n   3. `MAX_INNER_THREADS`\n\n* We are able to acheive 'full' GIL release than would otherwise be rarely possible no matter how many threads our backend libraries are using. Native Python is usually seen to cause massive stalling via internal thread locking & synchronizations. And native loops are just a maniacal chef's kiss.\n\n# Negatives\n\n* Overall this reeks of a terrible design pattern - which I'd personally never implement on a lower level language or any secure data handling routine.\n* This is just one of the many 'tape-overs' to circumvent the limitations of the Python GIL - With the rate at which Python is developing, so we might be free from such needs.\n* It has been working so far **for me** and I've been testing quite a bit for crashes, leaks, pointer-hysteria and other instabilities - but I am unable to guarantee any stability due to my limited knowledge in pretty much everything.\n* I'm pretty sure this has potential to leave the system vulnerable to massive abuse from malicious parties.\n* Doing something like this is probably a bad idea without low level access to parallel flow control mechanisms and some refined experience.\n\nThank you for your time & any forthcoming feedback, comments and advice.",
        "num_comments": 1,
        "comments": []
    },
    "My first Python package, D1py: A very simple library to interact with Cloudflare D1 Database API ": {
        "title": "My first Python package, D1py: A very simple library to interact with Cloudflare D1 Database API ",
        "score": 11,
        "url": "https://www.reddit.com/r/Python/comments/1dft2qf/my_first_python_package_d1py_a_very_simple/",
        "content": "## What My Project Does\n\nCloudflare offers a free SQLite based database D1. I needed it for some personal project so I thought of creating a very simple wrapper for it. D1py let's you connect to D1 database in your cloudflare account and run SQL queries(CRUD operations).\n\n## Target audience\n\nFor those who need a simple wrapper for Cloudflare D1 API for their projects.\n\n## Comparison\n\nRight now there are no Python wrappers or libraries for D1 yet.... that's why I thought of creating one. It's not perfect but it is my first attempt at writing a small library/package for doing a task.\n\n## Source\n\nRepository: https://github.com/Suleman-Elahi/D1py\n\nFeel free to drop any suggestions. Thanks.",
        "num_comments": 3,
        "comments": [
            "This is great! My first impression is very good. The readme is clear and detailed, which is a great starting point. You are already doing tests, which is also a great point.\n\n  \nThe biggest feedback I think is fairly obvious: it needs way more features. This is the foundation, but you need many more functionalities to make it worth it for people to use.\n\n  \nGood luck! \ud83d\ude0a\ud83d\ude0a",
            "Thank you.",
            "my pleasure \ud83d\ude09"
        ]
    },
    "Perpetual - a self-generalizing, hyperparameter-free gradient boosting machine": {
        "title": "Perpetual - a self-generalizing, hyperparameter-free gradient boosting machine",
        "score": 10,
        "url": "https://www.reddit.com/r/Python/comments/1dfrpzk/perpetual_a_selfgeneralizing_hyperparameterfree/",
        "content": "https://github.com/perpetual-ml/perpetual\n\n# What My Project Does\n\nPerpetualBooster is a gradient boosting machine (GBM) algorithm which doesn't have hyperparameters to be tuned so that you can use it without needing hyperparameter optimization packages unlike other GBM algorithms. Similar to AutoML libraries, it has a `budget` parameter which ranges between `(0, 1)`. Increasing the `budget` parameter increases predictive power of the algorithm and gives better results on unseen data. Start with a small budget and increase it once you are confident with your features. If you don't see any improvement with further increasing `budget`, it means that you are already extracting the most predictive power out of your data.\n\n# Target Audience\n\nThe project is meant for production. You can replace hyperparameter packages plus other gradient boosting algorithms with PerpetualBooster.\n\n# Comparison\n\nOther gradient boosting algorithms (XGBoost, LightGBM, Catboost) and most of the machine learning algorithms need hyperparameter optimization for the best performance on unseen data. But PerpetualBooster doesn't have hyperparameters so it doesn't need hyperparameter tuning. It has a built-in generalization algorithm and provides the best performance. \n\nThe following table summarizes the results for the [California Housing](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html) dataset:\n\n| Perpetual budget | LightGBM n_estimators | Perpetual mse | LightGBM mse | Perpetual cpu time | LightGBM cpu time | Speed-up |\n| ---------------- | --------------------- | ------------- | ------------ | ------------------ | ----------------- | -------- |\n| 0.33             | 100                   | 0.192         | 0.192        | 10.1               | 990               | 98x      |\n| 0.35             | 200                   | 0.190         | 0.191        | 11.0               | 2030              | 186x     |\n| 0.45             | 300                   | 0.187         | 0.188        | 18.7               | 3272              | 179x     |\n",
        "num_comments": 8,
        "comments": [
            "Show us a white paper and it is easier to analyze. But a quick look in trees.rs shows you are using hyperparameters. \n\nWhy is that?",
            "What do you think about the algorithm? I would like to get your feedback.",
            "They are not used during training. They exist due to legacy reasons and testing purposes. The paper will be released as soon as possible.",
            "We can't evaluate the algorithm until we read the paper. I want to know how it works before I invest time into testing it.",
            "What do you mean not used during training? Hopefully questions here can be addressed in your paper!",
            "Thanks for the feedback. The paper will be released as soon as possible. In the meantime, we didn't want to wait and released the algorithm. It is very easy to try.",
            "I mean that they are not used when growing trees and finding splits. Probably we should remove them to prevent confusion. Thanks for the feedback.",
            "Sounds good. Nice work on doing it in Rust!"
        ]
    },
    "Problem details for FastAPI applications (RFC9457)": {
        "title": "Problem details for FastAPI applications (RFC9457)",
        "score": 3,
        "url": "https://www.reddit.com/r/Python/comments/1dftrbu/problem_details_for_fastapi_applications_rfc9457/",
        "content": "Just released v0.8.0 of fastapi\\_problem to provide problem details for FastAPI applications. Hoping it can provide value to some other peoples projects.\n\nCode: [https://github.com/NRWLDev/fastapi-problem](https://github.com/NRWLDev/fastapi-problem) \n\nDocs: [https://nrwldev.github.io/fastapi-problem/](https://nrwldev.github.io/fastapi-problem/) \n\nPypi: [https://pypi.org/project/fastapi-problem/](https://pypi.org/project/fastapi-problem/)\n\n# What My Project Does\n\nProvides a simple exception handler and an underlying exception class heirarchy to remove the need to think about error management in your FastAPI project, just raise errors as appropriate and let the handler deal with responses.\n\n# Target Audience\n\nWeb developers\n\n# Comparison\n\nThere was a previous project that supported RFC7807 but that is no longer maintained, and is also made obsolete by RFC9457.\n\n# RFC9457\n\nFor anyone who does not make use of FastAPI, the underlying exception library has also been released, and can be used to implement handlers for any web framework you might be into.\n\n[https://github.com/NRWLDev/rfc9457](https://github.com/NRWLDev/rfc9457) \n\n[https://pypi.org/project/rfc9457/](https://pypi.org/project/rfc9457/)",
        "num_comments": 3,
        "comments": [
            "What about when you have multiple errors (think form submission)?\n\nWhat about when the field that errored is nested ? Like {field1: [{field2: wrong_value}]} ? \n\nDoes it support nested fields & multiple errors?",
            "That is generally handled by fastapi's RequestValidationError, but if you had some custom validation that happened outside of that flow, you can provide custom keyword arguments on raise (or a dict with nested information) that would be included in the response for that raised instance.\n\nMentioned in the docs, here:\n\nhttps://nrwldev.github.io/fastapi-problem/error/#custom-errors\n\nIn the case of RequestValidationErrors the messages information is returned as the additional field `errors`. \n\nTry out this example to see that one in action. `/validation-error`\n\nhttps://github.com/NRWLDev/fastapi-problem/blob/main/examples/builtin.py\n\nEdit: grammar",
            "Have fixed a bug in the examples, and added a \\`POST\\` example with nested errors to \\`builtin.py\\` as well."
        ]
    },
    "I tried to explain python imports": {
        "title": "I tried to explain python imports",
        "score": 1,
        "url": "https://www.reddit.com/r/Python/comments/1dfzuyr/i_tried_to_explain_python_imports/",
        "content": "When I was a beginner (or maybe still I am) I struggled a lot with pythons import function.\n\nOver the years I went over different approaches, how to handle imports and ended up using mostly exclusive poetry.\n\nI've met a lot of people struggling the same way, bit always could just explain very shortly my experience.\n\nI've now decided to write it down as a scenario, where I can show and explain my pitfalls:\n\nhttps://github.com/MaKaNu/pyimport-explained",
        "num_comments": 4,
        "comments": [
            "This is good, and I don't mean to detract from it, but honestly just use Poetry and [scripts](https://python-poetry.org/docs/pyproject/#scripts).\n\nI'd suggest extending this with Poetry.",
            "Test 06 Not written down until now, but the test exists already",
            "Ah excellent. There's several ways to structure a project with Poetry, and Poetry handles them pretty seamlessly with [packages](https://python-poetry.org/docs/pyproject/#packages) so there's probably a 'Test 7' and 'Test 8' there too."
        ]
    },
    "a new version of ultimateultimateguitar": {
        "title": "a new version of ultimateultimateguitar",
        "score": 39,
        "url": "https://www.reddit.com/r/Python/comments/1df7w7f/a_new_version_of_ultimateultimateguitar/",
        "content": "What My Project Does\n======\n\nIt is a CLI to get songs from ultimateguitar.\n\nHow it looks like: https://youtu.be/Spm1IIaYo8Q\n\nI've only tried it on linux.\n\nAvailable in debian and pypi.\n\n\n\nTarget audience\n=====\n\nFor musicians who also use the terminal and who don't especially like the ultimateguitar website.\n\n\n\nComparison\n=======\n\nI'm not aware of other projects doing the same thing.\n\nCompared to the website, it can transpose and it is much faster.\n\nSource\n=====\n\nProject website: https://codeberg.org/ltworf/ultimateultimateguitar\n\nOut of date website (just here to avoid the post to be auto-removed): https://github.com/ltworf/ultimateultimateguitar",
        "num_comments": 7,
        "comments": [
            "This is great. Takes me back to the old days of UG",
            "I love it!\n\nSmall suggestions for improvements, in case it's useful:\n\nThe readme is too sparse, it does not give a good overview. I would add 1 or 2 screenshots.\n\nThe \"Requirements\" section feels wrong, since it just redirects to the file. I would say either remvoe it entirely or flesh it out further.\n\nI am only saying that because it gives a subpar first impression to your great project! First impressions matter \ud83d\ude09\ud83d\ude09",
            "wicked! i\u2019m going to check this out later tonight",
            "awesome!! thank you",
            "Yeah this project is a bit old, but I released it for real just recently.\n\nI can probably improve the README :)",
            "It's nice, I'm glad you shared it!",
            "I made an improved readme now."
        ]
    },
    "how about one-line try-except statement ?": {
        "title": "how about one-line try-except statement ?",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1dfsjdu/how_about_oneline_tryexcept_statement/",
        "content": "is there a proposal for a shorter exception handling syntax for those very frequent cases where a library function doesn't return \"error value\" like `str.index` ?\n\nsomething like instead of :\n\n    try:\n        i = my_str.index(\"sub\", st, en)\n    except ValueError: # if \"sub\" has not been found\n        pass\n    else:\n        # do stuff with i (note that i usually want independent error handling here)\n\nsomething like this :\n\n    i = my_str.index(\"sub\", st, en) except ValueError -1 # or maybe even return here\n    if i == -1: # also can return right away if i want to avoid an indent next\n        # do stuff with i ...\n\ni suspect there might be something \"un-pythonic\" here in what i am imagining , but please forgive me if that's the case . i am a fan of Python for many years , but haven't really invested any time in learning the philosophy\n\nso i am interested in what the community thinks about this , how ok would such syntax be from the point of the \"Python way\" , and if there is such a proposal i would like to know if i can consider maybe voting on it somehow",
        "num_comments": 6,
        "comments": [
            "It fits a little awkwardly with \"there should be one, and ideally only one, obvious way to to it\". I know this was part of the reason they held off adding ternary operators on the early days (although of course they have them now).\n\n\nSpeaking for myself, I can't think of many times when I've worked with code that this would help with. And I know they don't like to add language syntax unless it solves quite a lot of people's problems well.\n\n\nFor something like your use case, where you're dealing with a common and expected case, it would be common to have an alternate method that returns a sentinel value. And indeed there is such a method, `str.find`.",
            "You could always build something like  this yourself:\n\n    def ordefault(fn, exc=Exception, default=None):\n        def wrapped(*args, **kwargs)\n            try:\n                return fn(*args, **kwargs)\n            except exc as e:\n                return default\n        wrapped.__name__ = fn.__name__ # Not necessary, just makes debugging easier\n        return wrapped\n\nYour\n\n    i = my_str.index(\"sub\", st, en) except ValueError -1 \n\ncould then be written as\n\n    i = ordefault(my_str.index, ValueError, -1)(\"sub\", st, en)\n\nwhich wouldn't be so bad. Python has enough flexibility that you often don't need new syntax to add new semantics...",
            "There was a PEP for a similar syntax:\u00a0https://legacy.python.org/dev/peps/pep-0463/#proposal\n\n\nGuido van Rossum discussed it in his PyCon 2014 keynote and noted that he didn't think saving a couple lines of code was worthwhile enough for the new syntax proposed.\u00a0",
            "`i = my_str.index(\"sub\", st, en) except ValueError -1  except TypeError -2 except Exception -3 expect -4`",
            "interesting , thanks"
        ]
    },
    "uv added experimental commands for `uv add/remove`": {
        "title": "uv added experimental commands for `uv add/remove`",
        "score": 138,
        "url": "https://www.reddit.com/r/Python/comments/1desxf4/uv_added_experimental_commands_for_uv_addremove/",
        "content": "uv is the \"pip but blazingly fast\u2122\ufe0f because it's written in rust\" and is developed by the same folks that did ruff. In 0.2.11 they released an experimental/preview command of \\`uv add/remove\\` that adds a library to pyproject.toml. It's the first step to become a fully-fledged package manager!\n\nI noticed you can also manage python installations with uv using \\`uv toolchain\\` command (i.e. be like pyenv) and run tools (like a smaller version of pipx) with \\`uv run\\`.\n\nI'm genuinely excited about this, Python packaging is going to become such a smooth experience \ud83d\ude0e\n\nCommands are in preview so expect missing stuff.\n\n(I bear no affiliation with astral)\n\n  \n[https://github.com/astral-sh/uv](https://github.com/astral-sh/uv)",
        "num_comments": 36,
        "comments": [
            "I only use \\`uv\\` now for virtual environments and package installation. It's so damn fast that returning to vanilla pip feels extremely cumbersome. \n\nLook forward to it becoming the full fledged thing they want it to be.",
            "They really need to [support](https://github.com/astral-sh/uv/issues/2679) multi-platform and multi-python support for much wider adoption. I would say after dependency resolution, this should be the most important feature any package manager should have.",
            "> Python packaging is going to become such a smooth experience \ud83d\ude0e\n\nAlready is with pdm in my book :)",
            "They also recently took over maintaining rye (which uses ruff and uv under the hood). I've been using rye  in a recent project and it is much more enjoyable than pyenv/poetry/pipenv/conda and very close to the cargo experience in rust.",
            "Can someone sell me on this?  How can this be such a 'smooth experience' compared to appending a package name to a .txt file and running one command to install them?\n\nIt's got built in commands to setup a virtual environment?  Don't care, I already set it up with a single command anyways.\n\nIt's faster?  Don't care, this only helps deployment times which are heavily gated by unit tests, not pip installs.\n\nThe only real troubles I run into with Python package management are packages that incorrectly define their compatibilities with other packages.  So just including one package may brick an entirely different package just by having it installed.  Or not being compatible with another package that just got updated and changed their interface.  AFAIK these aren't problems a new CLI can fix.\n\nIf it's better great, I guess I'll use it the next time I work on a project that already has it but otherwise, I don't see the point in adding in more complexity to solve problems I don't have.",
            "How long before we see rspython?",
            "joke attractive smell complete flowery observation toothbrush gullible meeting chief\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
            "How have I not heard about `uv` until now?? Looks amazing, thank you for sharing. Only issue I've noticed is there aren't wheels for arm64, but that's not necessarily a deal breaker",
            "Looks interesting",
            "Idk I like c more",
            "Isn't downloading packages the slowest part in both pip and uv? Also wonder if you know how uv compares to poetry (resolving may be a slow in poetry).",
            "Yeah I aliased pip to 'uv pip' because it's so much faster. Really looking forward to them building out this tool!",
            "You are absolutely right but they are at 0.2.11 and are adding many additional features. Supporting many platforms and version right now could hinder they development speed. so I would not prioritize that immediately but only after developing the most relevant features",
            "Agree. I think they are waiting for a Python standard to be agreed upon [https://discuss.python.org/t/lock-files-again-but-this-time-w-sdists/46593](https://discuss.python.org/t/lock-files-again-but-this-time-w-sdists/46593)",
            "if working with conda and pypi, checkout [pixi by prefix](https://pixi.sh) they follow the platform support cargo does and use their own solver for conda and uv for pip + they all get solved together",
            "I was a huuuuge PDM user/advocate. But then I stopped because I tried uv/rye and it was just so much faster. A friend had huge problems in CI and switched back to poetry\u2026 do you use PDM in containers too? Did they add UV as installer?\u00a0",
            "Agreed! There are some edges which are a little ruff, but it's my main package manager. It's not super updated though. I was made aware that uv will eventually be the \"cargo for python\" and \"supersede\" rye.",
            "> Can someone sell me on this? How can this be such a 'smooth experience' compared to appending a package name to a .txt file and running one command to install them?\n\nif you \"just write\" microservices code that's totally viable!\n\nI mostly deal with libraries/packages which happen to have a bunch of group dependencies, so a package manager helps a lot. When you have 2/3/4 optional + dev dependencies you have to have that many requirements files + write your setup.py. and good luck updating the versions or getting the dependency constraints right writing all by hand. IIRC if you need to uninstall a library you don't get the transitive dependencies removed - you have to do that by hand.\n\nplus you have to have all files for plugins (ruff/flake8/black/pytest/whatever) or maybe just a pyproject.toml but at that point you can write dependencies there (even by hand!).\n\n> It's faster? Don't care, this only helps deployment times which are heavily gated by unit tests, not pip installs.\n\nactually been deploying minimal APIs powered by small and large ML models and pip installs were the gate. but I totally see your point \ud83d\ude0a  For me it's about the devx more than the speed.",
            "> How can this be such a 'smooth experience' compared to appending a package name to a .txt file and running one command to install them?\n\nJust want to point out that uv can do this as well.",
            "[https://rustpython.github.io/](https://rustpython.github.io/) it's been a couple of years I think eheh",
            "They have support for ordering repositories and when to stop searching, but I think it's not as much as you/we want. but it's on their roadmap.",
            "uh I did not notice. I have an ARM Mac never realised that.",
            "Why are you even here",
            "Definitely not, package downloading is not a big bottleneck if your connect speed is decent. But the installation and resolving, in uv is almost instant, whereas it's quite slow in pip.\n\nHaven't used poetry much tbh .",
            "Same!",
            "I do use pdm in containers without any issue. Clearly, pdm is slower than uv. I don't know where the plan lies in regards to integrating uv.",
            "Fair enough, thanks for the insight!",
            "Looking into it further, I now see there are ARM64 wheels on PyPI. When I first commented, I had tested on Termux (Android) and noticed it was compiling the source tarball.",
            "pigeon holes",
            "pigeon holes",
            "I've been working on pip performance for the last few years, and I've been reporting lots of issues to uv as I find them, and I would like to add a big \"it depends what you're doing\".\n\nResolution *can* be the reason pip comparatively slow, but uv does a few things which speed it up far more significantly than resolution usually contributes to:\n\n 1. It optimistically prefetches metadata\n 2. It's carefully avoids downloading full packages when it only needs metadata\n 3. It does multiple downloads concurrently\n 4. It builds packages while it's downloading other packages\n 5. It installs packages in parallel\n 6. It caches resolution, metadata, and prepared installs, not packages.\n\nPip could implement 2, 3, and 5.\n\nIn fact there is a PR that's very likely to land to download in parallel for 24.2+, there is another PR to only use metadata when it needs but it's very complex and I don't know the chances of it landing, pip maintainers are very conservative on complex changes.\n\nI posted an issue to consider making parallel installs, but first it would be good if there's any obvious speed ups that can be made to installs before trying to run things in parallel, one of the maintainers is doing that.\n\nAs for resolution, there are two categories of improvements that can be made, the first is speeding up and removing bottlenecks, quite a few of these landed for 24.1 (beta 2 is out now!) and more will make it for 24.2.\n\nAnd the second is improving the algorithm. uv's resolution is based on pubgrub-rs and is usually very good but has some known weaknesses. Where as pip's is based on resolvelib, which is a DFS approach which some specific optimizations split between the resolvelib and the pip codebase, it's two main weakness is it has multiple parts which are O( n^2 ) and the implementation in pip can make them O( n^3 ) or worse, and other other weakness it is doesn't always best implement CDCL (conflict-driven clause learning). I hope both situations improve significantly in the near future, but even if pip resolved faster than uv in most situations it would still be slower than uv because of the other issues I posted.",
            "Thanks! Should try uv on some project, using poetry so far",
            "Thank you for detailed explanation. We often take for granted all things a package manager does.",
            "Consider hatch which uses uv and ruff under the hood.",
            "Yeah, packages are hard, especially in an environment that didn't start with a formal spec but rather a bunch of stuff people put together organically over time, as is the case with the Python package ecosystem.\n\nIMO pip's great unsung sucess is being able to install packages from that ecosystem and install them and \"just work\", and slowly move over to all the standards that have been defined over the last decade.\n\nI really beleive this process has allowed other tools like uv to come in and largely follow the standards, giving them an easier time to work with the Python packaging ecosystem.",
            "The main reason poetry doesn't use uv is that the generates platform specific requirements and poetry's lock is platform independent:\n\nhttps://github.com/astral-sh/uv?tab=readme-ov-file#limitations\n\nAs I understand Poetry doesn't use PIP either.",
            "Poetry uses it's own dependency resolver, which shares the same roots as the uv resolver (pubgrub) but implemented in Python.\n\nPoetry does implictly depend on pip to build packages, which means build time resolutions are still done by pip.\n\nuv has now built a universal lock resolver, which is similiar to Poetry's, but there may be different design choices and other reasons why Poetry might not want to depend on uv."
        ]
    },
    "Pathway - Build Mission Critical ETL and RAG in Python (used by NATO, F1)": {
        "title": "Pathway - Build Mission Critical ETL and RAG in Python (used by NATO, F1)",
        "score": 34,
        "url": "https://www.reddit.com/r/Python/comments/1dezxa3/pathway_build_mission_critical_etl_and_rag_in/",
        "content": "Hi Python data folks,\n\nI am excited to share Pathway, a Python data processing framework we built for ETL and RAG pipelines.\n\n[https://github.com/pathwaycom/pathway](https://github.com/pathwaycom/pathway)\n\n**What My Project Does**\n\nWe started Pathway to solve event processing for IoT and geospatial indexing. Think freight train operations in unmapped depots bringing key merchandise from China to Europe. This was not something we could use Flink or Elastic for.\n\nThen we added more connectors for streaming ETL (Kafka, Postgres CDC\u2026), data indexing (yay vectors!), and LLM wrappers for RAG. Today Pathway provides a data indexing layer for live data updates, stateless and stateful data transformations over streams, and retrieval of structured and unstructured data.\n\nPathway ships with a Python API and a Rust runtime based on Differential Dataflow to perform incremental computation. All the pipeline is kept in memory and can be easily deployed with Docker and Kubernetes (pipelines-as-code).\n\nWe built Pathway to support enterprises like F1 teams and processors of highly sensitive information to build mission-critical data pipelines. We do this by putting security and performance first. For example, you can build and deploy self-hosted RAG pipelines with local LLM models and Pathway\u2019s in-memory vector index, so no data ever leaves your infrastructure. Pathway connectors and transformations work with live data by default, so you can avoid expensive reprocessing and rely on fresh data.\n\nYou can install Pathway with pip and Docker, and get started with templates and notebooks:\n\n[https://pathway.com/developers/showcases](https://pathway.com/developers/showcases)\n\nWe also host demo RAG pipelines implemented 100% in Pathway, feel free to interact with their API endpoints:\n\n[https://pathway.com/solutions/rag-pipelines#try-it-out](https://pathway.com/solutions/rag-pipelines#try-it-out)\n\nWe'd love to hear what you think of Pathway!",
        "num_comments": 15,
        "comments": [
            "What is RAG?",
            "Do you store data in memoey or read it from a type of file. Of so which backend file are you using?",
            "Is this actually used by Nato and F1 teams or did you just \"design\" it to potentially do so?",
            "This is cool! Will try to use it in one of my portfolio projects!",
            "> mission critical RAG\n\nlmao",
            "Retrieval Augmented Generation. Here it is about indexing your unstructured data for natural language queries. Sorry I cannot change the title in OP now...",
            "Data is stored in memory operationally, but persistence/cache goes on file backends. The persistence backend is configurable, S3 or local filesystem are currently the supported options. [https://pathway.com/developers/user-guide/deployment/persistence](https://pathway.com/developers/user-guide/deployment/persistence)",
            "Please see [pathway.com](http://pathway.com) for user/client \"success stories\" etc. We only list some of the use we know about or have contractualized.",
            "\\[Pathway CTO here\\] By all means please do and let us know how it worked for you!",
            "Mostly in the document processing vertical. We are not talking chatbots here.",
            "Sure but the file format, what is it? Parquet/sqlite/csv etc?",
            "Yeah this complete non-response is the sort of thing you want to avoid in the future. This obvious lie has entirely wrecked any interest i might have had in your project.",
            "For now it's some homebrewed file structure that also allows for easy KV accesses if needed. The roadmap goal is to converge to a sequential Parquet file format, possibly with full Delta Lake compatibility.",
            "The OP title is very clear. The website contains most of the information you asked about - DM me if you really want specific pointers.",
            "Cool, thx, I'll check it out for sure, since performance is something important in data engineering. Congrats!"
        ]
    },
    "Polars 1.0 will be out in a few weeks, but you can already install the pre-release!": {
        "title": "Polars 1.0 will be out in a few weeks, but you can already install the pre-release!",
        "score": 200,
        "url": "https://www.reddit.com/r/Python/comments/1decdu5/polars_10_will_be_out_in_a_few_weeks_but_you_can/",
        "content": "In a few weeks, Polars 1.0 will be out. How exciting!\n\nYou can already try out the pre-release by running:\n\n\\`\\`\\`\n\npip install -U --pre polars  \n\\`\\`\\`\n\nIf you encounter any bugs, you can report them to [https://github.com/pola-rs/polars/issues](https://github.com/pola-rs/polars/issues), so they can be fixed before 1.0 comes out.\n\nRelease notes: [https://github.com/pola-rs/polars/releases/tag/py-1.0.0-alpha.1](https://github.com/pola-rs/polars/releases/tag/py-1.0.0-alpha.1)",
        "num_comments": 58,
        "comments": [
            "I'm really bummed that their `value_counts` method doesn't have a `normalize` option.\n\nAlso, pandas is faster at loading large parquet file for me, although polars takes way less memory.",
            "Ran into a bug with polars the other day where transformations on larger than ram data were unreliable\u2026considering this is why I would use polars over pandas, it was quite disappointing",
            "prefer duckdb here\n\nhaving everything standardized to SQL (and in a file we can ship around) is amazing. \n\ntrying to get non-engineers to read/learn/understand business logic in polars is expensive if not impossible\n\nthey do solve somewhat different things, and even work together, however duckdb alone is *chefskiss*",
            "Used polars for the first time this week to munge through a big financial CSV.  It was so much more intuitive than Pandas... I'm hooked",
            "Bummed that in a 1.0 release they don\u2019t have native support for reading from S3 buckets that utilize self-signed cert but I\u2019m sure it will mature",
            "Very exciting",
            "The essentially daily posts about Polars is kind of exhausting, tbh",
            "Excited for this :)",
            "Let\u2019s start at the beginning. What is Polaris?\u00a0",
            "That's cool, although obviously Pandas is better.",
            "> I'm really bummed that their `value_counts` method doesn't have a `normalize` option.\n\nHere you go: [https://github.com/pola-rs/polars/pull/16917](https://github.com/pola-rs/polars/pull/16917) \ud83d\ude09\n\n> Also, pandas is faster at loading large parquet file for me\n\nPandas use \\`pyarrow\\`, which you can use in Polars as well if you want.",
            "looks like there's an issue about this, and judging by the number of upvotes, you're not the only one :wink: [https://github.com/pola-rs/polars/issues/10127](https://github.com/pola-rs/polars/issues/10127)",
            "Did you try with `use_pyarrow=True` as well and compare read times?",
            "The streaming API always had a big fat warning that it was experimental. Our streaming engine is completely reworked from scratch. That's not the part that goes 1.0.\n\nPolars is first and foremost and in-memory query engine and with the 1.0 release we include the API and the default engine. I think there is a misconception that Polars aims for data too big for pandas only. It aims for all data that fits on a single node's RAM.\n\nPolars aims to work on datasets similar sized to pandas and more. Larger than RAM is experimental and only covers much smaller parts of our API.",
            "IIUC the streaming engine is being reworked from scratch. Yes sometimes it's a bit of a letdown. But still even without that Polars can manage bigger datasets than pandas, what tricks do you use?",
            "Hope you filed an issue at github \ud83d\ude0a",
            "This has largely been my experience. Every time I run into a memory allocation issue in Pandas and I think \"Hey, this would be a perfect case for Polars\", I end up trying to use Polars and without fail get a \"This operation is not currently supported for lazy execution\".",
            "Doesn't polars have a SQL context where you can do the same thing?",
            "1) why should non engineers read business logic?\n2) is the answer to point 1 \"use SQL\"? How should it be easier to understand?\n3) are you saying they do different things after comparing them? What's the point of this comment then?",
            "That's an interesting point. I rarely use SQL because as soon as I enter the quotes I lose all IDE suggestions. Maybe you use datagrip/pycharm/some other plugins that make that work?",
            "Both is nice as well \ud83d\ude0a",
            "Wow, you waited 13 years to make a comment and this is the specific thing you felt deserved breaking your silence for? \n\nAlso, this is unrelated, but can I ask why you write every sentence on a separate line? I've noticed some people on reddit do this with every comment but nobody will ever explain why they do it or where they came up with this.",
            "It's more intuitive if you're already familiar with the pyspark style of notation. Pandas tends to have better syntax if you're mostly coming from a python background.",
            "I don't know enough about this topic, but can you open a feature request upstream under \\`object-store\\`? That's the crate we use to connect to \\`s3\\` and the one that handles authentication.",
            "Did you open an issue? u/ritchie46",
            "I'm not seeing them, are you including other subreddits? The user you replied to specifically has all of 1 post on the topic.\n\nIf there are a lot of posts on it, let me know and I can suggest they all use a common thread.\n\nI do see this post 7 days ago:\n\n* https://www.reddit.com/r/Python/comments/1d8mv0a/polars_news_faster_csv_writer_dead_expr/\n\nBut that's a different user, and 1 post a week across multiple users is not what I would call \"daily posts\". =)",
            "Gimme a kick when GeoPolars has function parity to GeoPandas.",
            "Well its an important library.",
            "The amount of people complaining about the content of r/Python is more exhausting, tbf",
            "Polars* and its pandas replacement for people who have so much data that pandas is too slow, and also for some reason don't use a flavor of SQL with all that data",
            "Did we just witness a year old issue being resolved in 12 hours because it was mentioned on reddit?",
            "pyarrow is superfast & efficient. I don't think it has a normalize option though, does it?",
            "So is making streaming reliable and more widely used across the API your next major goal, after 1.0?",
            "Pandas plus joblib plus some smart partitioning of the data can take you really far. Otherwise I just use a local pyspark. Tried and true, eats pretty much anything you can throw at it. Was hoping polars would allow me to have a single library for local data analysis but I guess I\u2019ll have to wait some more.",
            "Ah there was already an issue filed: [https://github.com/pola-rs/polars/issues/16458](https://github.com/pola-rs/polars/issues/16458) for the curious",
            "Can you give an example of this? Almost all operations are supported for lazy execution so I don't understand this error message?",
            "Yes, now you can just do \\`pl.sql(SELECT \\* FROM df)\\` as much as you would do with duckdb. Not sure whether all operations are covered. Barely use that though. DuckDB might be better at streaming too.",
            "\"lose all IDE suggestions\" you mean you suddenly have to think  yourself?  The horror!",
            ">Wow, you waited 13 years to make a comment and this is the specific thing you felt deserved breaking your silence for? \n>  \n\n\nThey deleted their historical posts and comments according to their accumulated post and comment karma.",
            "Hard disagree. Polars syntax is just more human than pandas by far.",
            "This is what I'm waiting for as well. Love that this is being done, but I'm not gonna pay close attention until geopolars starts to get usable.",
            "Hardly. It's nice that people are finally willing to say something about the constant shilling that certain library authors/contributors/fanboys do here.",
            "Feels like magic",
            "I was responding to their second comment about reading a large parquet file. Not relevant to the normalize part though...",
            "Yes!",
            "Uhm I guess when you have an existing codebase that might just be better. I personally rarely had troubles with streaming and I find myself much faster at writing Polars than pandas with all of its idiosyncrasies; I think it'd take me more than twice the time to also add a joblib layer on top and do partitioning myself. What I like about Polars is that I don't have to care about any of this. Do you have a guide to set up pyspark locally? Never managed, but it was two year-ish ago.",
            "Ya it\u2019s the reason why I haven\u2019t moved on from pandas yet, it\u2019s a pretty mature library and I prefer robustness over speed most of the time.",
            "Is it duckdb usually for these requirements?",
            "An incomplete issue. I would appreciate if you could issue a reproducion.",
            "That's just what they want you to believe.",
            "Depends on what you\u2019re doing. If you\u2019re working with pandas in a multidimensional array (i.e. wide data) format, operations can be very easy to read/understand.\n\n    # Pandas - where the dfs are multiindex columns (power_plant, generating_unit) and a datetime index\n    generation = (capacity - outages) * capacity_utilization_factor\n    res_pd = generation - generation.mean()\n\n    # Polars\n    res_pl = (\n        capacity_pl\n        .join(outages_pl, on=['time', 'power_plant', 'generating_unit'], suffix='_out')\n        .join(capacity_utilization_factor_pl, on=['time', 'power_plant', 'generating_unit'], suffix='_cf')\n        .with_columns([\n            ((pl.col('val') - pl.col('val_out')) * pl.col('val_cf')).alias('val_gen')\n        ])\n        .select([\n            'time', 'power_plant', 'generating_unit',\n            (pl.col('val_gen') - pl.mean('val_gen').over(['power_plant', 'generating_unit'])).alias('val')\n        ])\n    ).collect()",
            "Not really. The whole \"F.col('feature')\" (or for polars \"pl.col('feature')) is needlessly verbose and annoying. Ironically, polars ended up just adopting pandas syntax later on for some of this stuff.",
            "OP is also a pandas maintainer.\n\n- https://github.com/pandas-dev/pandas/blob/de5d7323cf6fcdd6fcb1643a11c248440787d960/web/pandas/config.yml#L87\n- https://github.com/pandas-dev/pandas/issues?q=author%3Amarcogorelli",
            ">It's nice that people are finally willing to say something about the constant shilling that certain library authors/contributors/fanboys do here.\n\nPeople do that in every single thread",
            "Awesome to hear! Perhaps I fell victim to the blogs comparing polars performance to spark.",
            "The joblib stuff is for when I\u2019m mainly being stubborn and don\u2019t want to shift my analysis over to spark.\n\nFor spark, I\u2019m on a Mac, so ymmv depending on your os of choice, but you just install openjdk, download the right tar, unzip it and point SPARK_HOME to the directory. Then a pip install pyspark and you\u2019re good to go.\n\nIdeally I\u2019d love to use polars for all of this, but it not being reliable for big data, and having fewer features than pandas for small and medium, it\u2019s a no go at this point. If the streaming stuff is fixed and made more reliable I\u2019ll probably make the jump though. The syntax is definitely nicer than pandas.",
            "Isn't the pl.col syntax a nice way to avoid having to invoke methods on the object everytime or avoid using lambdas? I think it's a great idea",
            "> Ironically, polars ended up just adopting pandas syntax later on for some of this stuff.\n\nWhere? (Honest question.)\n\nI also find that people complain about writing \"pl.col()\" everywhere. How would you have approached that? What I hate about pandas is that selecting columns is a mess. Sometimes I think I should just do \\`import polars.col as c\\` lol."
        ]
    },
    "Try PyCharm (30% off!) and they donate 100% to the Django Software Foundation": {
        "title": "Try PyCharm (30% off!) and they donate 100% to the Django Software Foundation",
        "score": 36,
        "url": "https://www.reddit.com/r/Python/comments/1delqyn/try_pycharm_30_off_and_they_donate_100_to_the/",
        "content": "There's a promotion right now to try PyCharm, get a 30% discount, and 100% of what you pay goes directly to the Django Software Foundation, which maintains Django and keeps it free for everyone.\n\n[https://jb.gg/2atgzm](https://jb.gg/2atgzm)\n\nI hope this kind of post is allowed.",
        "num_comments": 4,
        "comments": [
            "That's why I love pycharm \ud83e\udd29",
            "Man I miss using Django for my work projects",
            "Bro who said we like Django lol",
            "Nah, not for Django\u2026"
        ]
    },
    "I ported Rust's Regex Library To Python, but the time taken by the compile parameter was high.": {
        "title": "I ported Rust's Regex Library To Python, but the time taken by the compile parameter was high.",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1dfl5ja/i_ported_rusts_regex_library_to_python_but_the/",
        "content": "```\n(.venv) PS D:\\flpc> python .\\seed\\test.py\nOperation  | flpc (ms)  | re (ms)   \n----------------------------------\nCompile    | 1496.18077 | 0.00000\nSearch     | 19.67597   | 1721.07339\nFind Match | 15.62524   | 16.72506\nFull Match | 15.62500   | 0.00000\nSplit      | 0.00000    | 1722.88108\nFind All   | 3.02815    | 1660.32910\nFind Iter  | 5.96547    | 1672.50776\nSub        | 0.00000    | 1548.61116\nSubn       | 6.70719    | 1676.84698\nEscape     | 4.87757    | 0.00000\n(.venv) PS D:\\flpc>\n```\n`flpc` is the name of the library. I named it (spelt as flacpuc). The strange thing is that why the compile time is high of flpc (rust) than of re module (implemented in Pure-Python) (it does the same thing what re.compile does in Python). The benchmark is done on:\n\n```\nPATTERN = r'(\\w+)\\s+(\\d+)'\nTEXT = ''.join(choices(ascii_letters + digits, k=1000))\n# choices function from random module\nITERATIONS = 100\n```\n\nThe problem is that, the python should be slow in the parameter (Regex Compile). However, the rest of parameters looks great! VERY FAST!",
        "num_comments": 23,
        "comments": [
            "This pretty much looks like you compared an instant with a lazy compile.",
            "But Rust strings are different from CPython, so there probably is a bit of overhead converting them back and forth",
            "Sounds like an interesting project. I've been wanting to do something like this with rust, but i've been on the fence with it.... plus i'd need to learn rust (which i do want to do).\n\nInstead, i've very slowly (when i have time), trying to optimize what python can do with re with a similar concept to ripgrep/grep/sed/awk (but only for regex operations).  I can get \"so so\" close results, but i do end up having to do multiprocessing to get close in some scenarios (and can leap ahead with it in some scenarios), but my ram usage increases. So i've ended up trying to optimize for ram usage with multiprocessing as well, but potentially only so much i can do. So far i've been proud to keep largeish 2-4GB log files with 1-2 million matches, under 2-4GB of ram (my initial attempts could invoke the OOM > 16GB), but ripgrep destroys me here and barely uses any RAM. Last time i talked to the developer of ripgrep on reddit, i could get some odd results, but recently (since picking up the project again), i can see the developer of ripgrep has closed those niche gaps as well, so kudo's to them. \n\n  \nPython 3.13 may have some speed up improvements i'm looking forward to (fingers crossed), with the sub-interpreters. I am too boozy tonight to look at your project properly, but when i first read about what you were doing earlier, I was intrigued, so thought i'd comment :) I'm a busy person, but i would love to test what you're doing as well..... maybe over the weekend.",
            "i am boozy, but any idea why this is happening? For the security conscious out there, this is just root in a controlled container... not root in my main system.\n\n    (venv) root@regex-test:~/venv/pygrep# time ./pygrep.py -p '\\sDST=(123.12.123.12)\\s' '1' -m4 -Sc -f pygrep/ufw.test1\n    Traceback (most recent call last):\n      File \"/root/venv/pygrep/./pygrep.py\", line 59, in <module>\n        import flpc as re\n    ModuleNotFoundError: No module named 'flpc'\n    \n    real0m0.098s\n    user0m0.077s\n    sys0m0.021s\n    (venv) root@regex-test:~/venv/pygrep# pip list\n    Package Version\n    ------- -------\n    flpc    0.1.1\n    pip     24.0\n    (venv) root@regex-test:~/venv/pygrep# pip show flpc\n    Name: flpc\n    Version: 0.1.1\n    Summary: A Rust-based regex port for Python3 to faster performance. \ud83d\udc7e\n    Home-page: \n    Author: \n    Author-email: \n    License: MIT\n    Location: /root/venv/lib/python3.12/site-packages\n    Requires: \n    Required-by:",
            "As the author of the regex crate, I thought at first that you had rewritten some portion of the crate in Python, as that is usually what \"port\" means. I think what you have instead is an \"FFI wrapper to Rust's regex crate.\"\n\nA related (and well run) project is [`ahocorasick_rs`](https://pypi.org/project/ahocorasick-rs/). It's an FFI wrapper around the `aho-corasick` Rust crate (which is a dependency of the `regex` crate). So there might be something to learn there in terms of how the project is setup and how strings are handled.\n\nIn terms of your benchmark, I would generally expect [the regex crate to compile patterns faster than `re`](https://github.com/BurntSushi/rebar?tab=readme-ov-file#summary-of-compile-time-benchmarks). With that said, I also generally consider pattern compilation in the `regex` crate to be pretty slow. However, my understanding is that Python's `re.compile` caches pattern compilation. Thankfully, the `re` module [provides a way to clear its cache via `re.purge()`](https://github.com/BurntSushi/rebar/blob/50e7131152528b1408b74aec7e5c7825197a1673/engines/python/main.py#L380-L393).",
            "Cant use it entirely as a drop in replacement for some of what i've got already in place, which uses re.Pattern for type hints, and the group attribute.",
            "interesting, can you please explain or link a source explaining the difference? thanks!",
            "> but recently (since picking up the project again), i can see the developer of ripgrep has closed those niche gaps as well, so kudo's to them\n\nAlso, looking [at your benchmarks](https://github.com/jonnypeace/pygrep/), you are comparing Python's regex engine running in ASCII mode with ripgrep's engine running in Unicode mode. It actually matters in at least some of your benchmarks:\n\n    $ hyperfine \\\n        \"rg-14.1.0 -No 'SRC=([\\d\\.]+)\\s+DST' ufw.test1 -r '\\$1'\" \\\n        \"rg-14.1.0 --no-unicode -No 'SRC=([\\d\\.]+)\\s+DST' ufw.test1 -r '\\$1'\"\n    Benchmark 1: rg-14.1.0 -No 'SRC=([\\d\\.]+)\\s+DST' ufw.test1 -r '$1'\n      Time (mean \u00b1 \u03c3):      4.475 s \u00b1  0.023 s    [User: 4.346 s, System: 0.127 s]\n      Range (min \u2026 max):    4.448 s \u2026  4.519 s    10 runs\n\n    Benchmark 2: rg-14.1.0 --no-unicode -No 'SRC=([\\d\\.]+)\\s+DST' ufw.test1 -r '$1'\n      Time (mean \u00b1 \u03c3):      3.821 s \u00b1  0.023 s    [User: 3.699 s, System: 0.120 s]\n      Range (min \u2026 max):    3.792 s \u2026  3.855 s    10 runs\n\n    Summary\n      rg-14.1.0 --no-unicode -No 'SRC=([\\d\\.]+)\\s+DST' ufw.test1 -r '$1' ran\n        1.17 \u00b1 0.01 times faster than rg-14.1.0 -No 'SRC=([\\d\\.]+)\\s+DST' ufw.test1 -r '$1'\n\nThis is because Unicode mode tends to thwart the [one-pass DFA optimization](https://blog.burntsushi.net/regex-internals/#engine-one-pass-dfa). And indeed, it applies in this case when the pattern is compiled without Unicode mode enabled. When Unicode mode is enabled, things like `\\s` and `\\d` match a lot more than just the ASCII definitions of whitespace and digits, and that prevents the one-pass optimization.\n\n_Usually_ toggling Unicode mode doesn't make too much of a difference in ripgrep (unlike in GNU grep), but this is a case where it does matter.",
            "You won't believe I don't even know rust. All that I needed was some syntactic sugar and ChatGPT help. I know only how to print Hello World in Rust whereas I'm in Python I've been coding for 3+ years.",
            "can you do \"cat pygrep.py\"? I want to review the entire script that you're running.  \nMaybe the SHEBANG Line is the culprit. e.g. #!/usr/bin/env python.",
            "Would help if i wasn't boozy lol. I had #!/usr/bin/python3 in the shebang, changed it to #!/usr/bin/env python3 and it now imports",
            "I have updated the description. Previously, I always referred to the packages used as \"ports,\" \ud83d\ude02 but now I understand that it should be written as \"wrapper to Python3 term.   \n[https://pypi.org/project/flpc/](https://pypi.org/project/flpc/)",
            "It is in the experimental (early) stage. Hence, some features will be missing. It is open for contributions.",
            "Take it with a grain of salt, but I believe CPython strings are basically an array of Unicode, while Rust strings are an array of bytes that are UTF-8 encoded, meaning; you can have a ASCII character which only takes a single byte, and a non-ASCII char wich takes more than one byte and store them together without increasing the size necessarily.  \nnecessarily  \nBut I think that CPython strings take as much memory as the largest character, meaning that if a character takes 4 bytes, then even a character that in theory needs 1 byte will consume 4 bytes. This is because you store the Unicode number, so they must all be of the same type (32bit int for example).",
            "https://rushter.com/blog/python-strings-and-memory/#:\\~:text=Note%20that%20every%20string%20in,takes%2049%20bytes%20of%20memory.\n\n> Let's suppose we have a 10GB of ASCII text and we want to load it in memory. If you insert a single emoji in our text the size of a string will increase by the factor of 4! This is a huge difference that you may encounter in practice when working with NLP problems.",
            "Thanks for the info, always happy to learn. I would ignore a lot of those benchmarks. I don't have a habit of advertising them.. I suppose in some sense it was a way of me documenting my own work and what improvements I have been making, and I know ripgrep has better stats since I run the benchmarks, even if I am using the wrong character set. I will update them tonight. :) I've barely touched this project since April last year. Only just recently (last couple of weeks) I've tried to see if there is any optimisations I can make.",
            "I've used python on and off for a few years, but since getting a machine learning job, i've been using it full time for about a year, due to this, i've been trying to use these skills to my advantage with my own projects. \n\nI did notice the code base looked quite minimal when i looked at it last night, which was nice to see, and why i thought i'd leap on board and test. :)",
            "My benchmarks are old, and i've made some improvements... you never know, maybe i've slowed something else down lol.\n\nExcuse the code quality though... it was one of the first things I wrote in python. I've refactored in some areas, but i've been busy working on other things.\n\n[https://github.com/jonnypeace/pygrep/](https://github.com/jonnypeace/pygrep/)\n\nmemory mapping helped speed up the python regex single threaded, and using generators helped save me some memory for the multiprocessing.",
            "thanks for both comments!",
            "No it's cool and fine. But something I noticed and wanted to share.\n\nripgrep 14 does have some massive improvements in some of those benchmarks over ripgrep 13 (I rewrote the entire regex engine). That's neat. Thank you for sharing them.",
            "Remove the top SHEBANG Line pygrep.py. It tells the shell to use global interpreter instead of venv.",
            "Odd, that was actually what made it work. flpc is only installed in the virtual environment. When I used /usr/bin/python3, it wouldn't import, but using /usr/bin/env python3 seems to find my venv.",
            "ChatGPT on the shebang I'm using...\n\n\"The shebang line `#!/usr/bin/env python` is used in Unix-like systems at the start of a script to indicate the script should be run using the Python interpreter. This shebang tells the system to locate the first Python interpreter on the user's PATH environment variable.\n\nWhen you activate a Python virtual environment, it modifies your PATH so that the Python interpreter in the virtual environment becomes the first one found. Consequently, using `#!/usr/bin/env python` in a script while a virtual environment is activated will indeed cause the script to use the Python interpreter from the virtual environment, not the system-wide Python interpreter.\n\nThis approach ensures that any Python script using this shebang line will run with whatever Python interpreter is currently preferred in the environment, making it particularly useful in ensuring scripts run with the correct dependencies when using virtual environments.\""
        ]
    },
    "Vedo or PyVista?": {
        "title": "Vedo or PyVista?",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1df1546/vedo_or_pyvista/",
        "content": "Hi guys! What are your experiences with Vedo or PyVista? Which one do you prefer? Did you have any specific issues which either of these libraries? I'm mostly interested in meshes and point clouds rendering. ",
        "num_comments": 1,
        "comments": [
            "Pyvista has some nice functionalities, I'm using it for point cloud analysis. I found it a bit unfortunate, that IO between different formats depends on further modules you have to import, so there is definitely room for improvement."
        ]
    },
    "Sold my Python open source project to a San Francisco AI company. Now I work for them. AMA.": {
        "title": "Sold my Python open source project to a San Francisco AI company. Now I work for them. AMA.",
        "score": 181,
        "url": "https://www.reddit.com/r/Python/comments/1de2llp/sold_my_python_open_source_project_to_a_san/",
        "content": "About a year ago, I posted on this sub. I was terrified. I was launching a new framework. Another framework? Yes, I was crazy enough to think we needed yet another framework. Thankfully, the response was great. Many were excited to try it. Others were understandably skeptical, and respectfully asking good questions.\n\nThis time, I'm posting for completely different reasons. I want to share a story. A story of which this sub, and hundreds of you, are part.\n\nIt all started 2 years ago, when I was laid off from my analytics consulting job. I had a well-paying, comfortable job in the UK. Then I moved from the UK to Poland, where I live now, and continued working remotely. I was living the dream; earning a London salary while living in a place with a lower cost of living. Until it ended with a layoff.\n\nI thought, this is it. My career is dead. I didn't speak Polish properly, limiting my options. And finding another fully remote job working for the UK sounded overly optimistic at the time. Being in my mid 30s and with a family to support, I didn't want to start over again.\n\nI knew Python and data analytics quite well, and also had frontend skills I had gained throughout the years. So I thought... I need to show what I can do. I didn't have a portfolio at all; my GitHub was empty. After trying Streamlit, I thought the concept was great, but the execution wasn't. So I wrote an article on Medium, discussing how a better, faster alternative was possible. I also created a POC and shared it on GitHub.\n\nThankfully, due to contacts at my previous job, I was able to find another remote job, working for the UK w. With even better pay. So naturally, I forgot about my portfolio-building efforts. But after a few months, an investor (VC) from Germany reached out to me. He had seen the Medium article and asked me whether I'd like to do this full time.\n\nI hesitated, but eventually decided to explore this further. I didn't need any investment though; my idea was quite simple. And to be honest, not too different from other frameworks, just faster. I had to think bigger. One day, at London Stansted Airport, while waiting to board a plane home, I decided to go for it and came up with the idea of no-code in the front, Python in the back. In other words, building the frontend using a visual editor, while allowing for full freedom in the backend using Python, and abstracting all the connectivity between.\n\nThe VC liked the idea, but wasn't fully convinced about my ability to execute. He decided not to invest. But since I liked the idea and thought it could go somewhere, I decided to try building it myself, at night, after work. For 9 months, that was my reality. Nights, weekends. If my baby son would wake up, early mornings too.\n\nIn May 2023, I managed to get the framework to a state I was happy with, and launched it. The response was very good. I eventually got to 1000 stars on GitHub, a milestone for any open source project. To a great extent, thanks to the support of communities such as r/python and r/opensource. Also, thanks to sites like Medium and Product Hunt.\n\nA few months later, in November 2023, the CTO of a multibillion AI company reached out to me. They wanted to acquire my framework, hire me, and build a team for me to continue developing it. I was ecstatic. He told me he'd go on a Thanksgiving break for a few days and that he'd reach out to me after. He never got back to me. Accepting that this wasn't going to happen was tough.\n\nTwo weeks later, the CTO of another AI company called me, together with the CEO. They also wanted to acquire me and make me a part of their team. A smaller company, much more interesting and already quite established, with clients such as Accenture and Salesforce. But with grit and determination to win in the space of enterprise generative AI. This time, it did work out and my framework was finally acquired. Now I work for them and I lead a team focused on maintaining this open source project.\u00a0\n\nHappy to answer any questions. And THANK YOU for your support r/python!!!\n\n---\n\nFor those curious:\n\n[https://github.com/writer/writer-framework](https://github.com/writer/writer-framework)",
        "num_comments": 39,
        "comments": [
            "Congratulations and good luck!",
            "What was your strategy for building the product? How did you measure your progress?",
            "Congratulations!\n\nThis is really helpful as I am going through a similar phase of developing yet another open source rag framework. I guess this is my sign!\n\nThanks for sharing your story.",
            "Woah. Crazy stuff.",
            "This is my dream too. I want to create an open source algorithm which will take notice!",
            "Amazing! Congrats! Was it worth selling? What would you of done if you hadn't sold?",
            "Congratulations and good luck man.\nI also hope to create something like this in coming future",
            "Congrats! That\u2019s amazing!",
            "Congrats man! Coding at 5am when the baby wakes you up... i know that one.\nI hope you achieve great things!",
            "Congratulations \ud83d\udc4f. Would you mind sharing about the deal you got?",
            "That's the dream my friend, congratulations!!",
            "What was the deal you made? How much worth was your project and what's your current salary?",
            "How did you get Medium to publish your article? And can you share it with me? I\u2019m looking at making a few programs/apps that would be super helpful to my industry. More like scratching my own itch. But similar story, it\u2019s not really in my current job description. More of something I\u2019m doing on the side.",
            "Congrats! Way to be persistent.",
            "Great story, so happy it turned that way for you! I'm currently in a situation like yours 2 years ago and I too have some ideas that I wonder should I try or not, but reading this I will probably do.",
            "Man, I gotta flesh out my github.\n\nSo many nifty ideas die out in forgotten directories.\n\nEdit: I have so much code on my local situation, and I've not pushed anything to my github in quite a long time. It's quite a travesty. ha ha",
            "Polish engineers are built different. Learned a ton while frequenting Wroclaw",
            "inspiring! just stared the git repo, definitely will try it!",
            "Will it always be open source? Like all of the features in the future too?",
            "Excellent bro... congrats ![img](emote|t5_2qh0y|598)",
            "I thought open source was just that.  Open source, free for everyone to contribute. And you sold it?",
            "During most of my career, I've been a data analytics consultant so I'm the target persona for what I'm building. This made it easier; I basically modeled everything about what I'd like to have, which I complemented with the input from data scientists.\n\nProgress has been mostly about developer experience. Not only about making things easy, but also using syntax that's expressive and clear.",
            "It might be! It's a hot space for sure. Worse thing that can happen is learning A LOT.",
            "I guess go for it? I had to try quite a few times before getting some success with something, but it was worth it every time. Best way to learn is to ship something that's polished and well documented.",
            "Great question. I'm happy having sold, yes. I was close to burning out. The other alternative would have been looking for investment. The thing is, it wouldn't have been easy, and I was quite risk averse. So I'm glad the acquisition option appeared.",
            "Thank you! Here's to visibility of coding parents! It's not just single people in a basement (though of course you miss those days sometimes)",
            "Unfortunately, as part of my contract, I'm not allowed to discuss the specifics. But I can say those long nights definitely paid off.",
            "Unfortunately I'm not allowed to discuss the specifics, but I can say I'm pleased with the outcome.",
            "Medium just publishes anything, it's not vetted. But getting it promoted or \"distributed\" can be a bit of a challenge. There's a lot of information about it online, and it's mostly speculation, as they don't publicly share what's distributed and what's not. In general, they seem to prioritize technical content and they frown upon \"product announcements\".\n\nI deleted my first article, as it's no longer relevant. It was quite technical and full of benchmarks. It got distributed right away.\n\nThe second article, more of a launch/product announcement was largely ignored for a while. However, after the algorithm (or someone) saw that it was getting many hits and genuine interest (from r/python and other communities), eventually got distributed. Article is:\n\n[https://medium.com/better-programming/streamsync-like-streamlit-but-faster-and-with-a-visual-ui-editor-9f98ad17adf](https://medium.com/better-programming/streamsync-like-streamlit-but-faster-and-with-a-visual-ui-editor-9f98ad17adf)\n\nIn general, I'd say, aiming to provide value to the reader rather than promoting your stuff is going to work better. However, when you actually launch, you'll need to write a more marketing-focused piece. You can then link this piece from other sources (Reddit, Product Hunt, GitHub, etc).",
            "I don't know much about your situation, but working on the project also kept myself sane. Good luck with that! My advice would be taking it as seriously as you can, don't disregard documentation or marketing. This is what will make the project stand out, whether it's to prospective users or your next boss.",
            "You should, it'll also force you to polish everything and present it neatly! Don't forget to add nice docs though, that can be a challenge with forgotten personal projects.",
            "They are! Glad to have one in my team, also from Wroclaw.",
            "Thank you!",
            "That's definitely the plan, yes. The company makes money by selling access to their LLMs and related solutions, which are integrated into the framework via the \\`writer.ai\\` module.",
            "Yeah my idea is quite ambitious. I want to create a lossless decompression algorithm for images and rasters that can outdo the standard algs. At the moment I am learning how different algs work especially with Machine Learning (they are lossy though). I want images or rasters to be saved in some sort of a Universal function, this needs a lot of research and I like to do it in my free time. I also like parsing big data, a mix of GoLang and Python is great for this. I could develop an alg for parsing big mesh files >4gb in under 5 seconds. But since I developed this at and for my workplace, I am not allowed to publish them on GitHub:(",
            "That\u2019s helpful! Thank you!",
            "Nice !",
            "Sounds good! What I'd recommend is looking into publishing a paper with the results. The AI researchers at the place that I work for do this all the time. Your employer would look good, so would you, and the source code is never published. This may not be possible, but it's an idea!"
        ]
    },
    "Building AI Text-to-Video Model From Scratch": {
        "title": "Building AI Text-to-Video Model From Scratch",
        "score": 1,
        "url": "https://www.reddit.com/r/Python/comments/1dez1ru/building_ai_texttovideo_model_from_scratch/",
        "content": "# What My Project Does\n\nThis project aims to create a small-scale text-to-video model that can generate videos based on text prompts.\n\n# Target audience\n\nThis project is designed for individuals who want to learn how to create their own text-to-video model from scratch but don't know where to start. It will provide a basic guide from beginning to end, covering everything from generating the training data to training a model and using that trained model to generate AI videos.\n\n# Comparison\n\nCurrently available text-to-video models require high computational power, and their complex code makes it difficult for Rookie developers to understand the practical implementation, beyond just the theory. To address this, I have created a small-scale GAN architecture, similar to text-to-video models, which can be trained on a CPU or a single T4 GPU.\n\n# GitHub\n\nCode, documentation, and example can all be found on GitHub:\n\n[https://github.com/FareedKhan-dev/AI-text-to-video-model-from-scratch](https://github.com/FareedKhan-dev/AI-text-to-video-model-from-scratch)",
        "num_comments": 1,
        "comments": [
            "Nice work!"
        ]
    },
    "My Thoughts on Python in Excel": {
        "title": "My Thoughts on Python in Excel",
        "score": 89,
        "url": "https://www.reddit.com/r/Python/comments/1de2hkw/my_thoughts_on_python_in_excel/",
        "content": "Hi all, it's been almost 1 year since the preview of Python in Excel has been revealed. So I wrote up a blog post pointing out what works well and what should be improved: [https://www.xlwings.org/blog/my-thoughts-on-python-in-excel](https://www.xlwings.org/blog/my-thoughts-on-python-in-excel)\n\nHere\u2019s the TL;DR:\n\n* We wanted an alternative to VBA, but got an alternative to the Excel formula language\n* Integrating the Jupyter notebook cells inside the Excel grid was a mistake\n* Python in Excel isn\u2019t suitable for Python beginners nor for interactive data analysis\n* Right now, there are too many restrictions (can\u2019t use your own packages and can\u2019t connect to web APIs)\n* Here are the current use cases I see for Python in Excel:\n   * Computationally intensive things like Monte Carlo simulations\n   * AI stuff via the included packages (scikit-learn, nltk, statsmodels, imbalanced-learn, gensim)\n   * Advanced visualizations via Matplotlib/Seaborn\n   * Time-series analysis (this is one of Excel\u2019s blind spots)\n   * Not sure about data cleaning/data analysis: since you almost certainly need Power Query, it may actually be simpler and faster to just stick to Power Query (instead of using Power Query and Python in Excel together)",
        "num_comments": 24,
        "comments": [
            "OP may want to disclose here that they own the open-source project that \u2018competes\u2019 with Microsoft\u2019s Python in Excel\u2122. It\u2019s pretty clear when you get to the blog post, but just for clarity here. Doesn\u2019t make them wrong, though. \n\nCloud only + additional subscription makes it DOA for me.  I work for a large university and it would take moving heaven and earth to get it approved as an addition to the 365 license for me. Yeah, that\u2019s a business practice issue, but it\u2019s friction users are bound to run into.\n\nI was disappointed to see the implementation was within the spreadsheet itself, and not as a separate Jupyter notebook-style sheet in the workbook specifically for Python.\n\nExcel is weirdly crowded language-wise with the native syntax, VBA, M, Typescript, and now Python. Each with access to different (sometimes overlapping) elements of the software/object model. I\u2019m left wondering when Microsoft will try to stuff their new Excel-inspired GPL, PowerFx, into Excel.\n\nYour point about the Excel syntax hits home too. Why can\u2019t we create the rich data types in the sheet? Adding the lambda, pivotby, group by, and now regex also just makes me question what exactly they\u2019re trying to accomplish here. What /is/ Excel supposed to be these days?",
            "I got asked to look into excel + python for my engineering group, my notes are \"cloud only with only local data\", \"paid subscription\". Both of those were enough to disqualify further looking.",
            "I thought they were going to drop it python as a VBA replacement, but they use it for formulas? Nutty.",
            "IMHO spreadsheets are a very useful tool but once they reach the level of complexity where you need a programming language (no matter which) to solve a problem then that task has vastly outgrown the scope of a spreadsheet. In short: If you need Python, you no longer need Excel.",
            "Can you summarize your thoughts here?",
            "My 2 cents:\n\n- Good alternative of UI for Python projects where application inputs change regularly",
            "I wouldn't be friends with anyone that used python in excel \ud83d\ude02 sounds like my worst nightmare",
            "Thanks for the write up. Can it use pulp (python optimization program) or is solver / open solver the only options there?",
            "well, now i don't have to study excel formulas? i see that as an absolute win!",
            "Totally agree with all this and it's really what I am thinking, too :) I hope that my plans for xlwings Script will solve your issues (it'll be free for non-commercial use, runs locally, and maybe I can base it on JupyterLite).",
            "Often for me, programming in excel is basically just getting a Microsoft rubber stamp for my program. At a large workplace I was at before, people wouldn't trust an actual program (even though python was approved by our organization) that I even took the time to do code signing for, but they were perfectly happy with an excel sheet that downloads an exe file in the background and runs it.\n\nSo  VBA is often just a workaround to either bad IT policy. With a straightforward process to submit/approve programs for use in your workplace that normal people could access, the need to use programming to make super complex excel sheets is greatly reduced or even eliminated in many cases.",
            "I added the TL;DR",
            "exactly. I hate posts like this",
            "Have you tried ipydatagrid in jupyterlab?",
            "No, pulp isn't one of the available packages.",
            "Agree with all your points, honestly I see it's greatest value as being a stepping stone for Python/Jupyter approval by stubborn IT departments. \"Well it's already built into Excel, what exactly is our reasoning for blacklisting it?\" \n\nI've worked places where I've had to hunt down and modify the site-packages folder for some embedded Python shipped with another application we depend on, because Python was black listed as a standalone application, but not as a dependency...\n\nHave you played with Azure Data Studio? It was kind of a sneaky roll-out a lot of people suddenly seem to have on their devices without much fanfare. Really solved the \"how do I share Python with coworkers?\" problem for us at least. \n\nBut I totally agree on your points here, no libraries or internet access totally neuters Python. Stuff like `print` returning `None` instead of what a user would generally expect is disappointing too. I understand why it's happening, but for new python users following a tutorial it's going to be a source of confusion. \n\nFeels like it's mostly a mechanism for MS to sell us compute tokens for the cloud backend in the future.",
            "Honestly, it\u2019s well written and worth a read.",
            "Not really. Looks interesting, thanks.",
            "Re Azure Data Studio: haven't come across this, but are you running Jupyter notebooks on a kernel that runs somewhere on Azure?",
            "The point is that posting to reddit with 'hey, go read my blog' is low effort.\u00a0",
            "No, it's local, we just published a pypi package to manage environments and provide tooling. I've tried requesting permission to test it on Azure but I'm not working with the most \"up on the current technology\" IT department. We have a network git folder and a public one, and a script for employees to run to install python, install the environment then git pull the two repos.\n\nI'd like to have it all be more cloud based but it's the best work around we could find currently. We briefly looked into WASM/pyodide but local files were too much of a pain to interact with, and only pure python packages was a pretty big restriction.\n\nFrom what I understand, there's workarounds for both, we just didn't really want to tackle them.",
            "It's been a while since I posted on reddit so wasn't aware of how users want it here. Posting the title/url alone on HackerNews works very well there.",
            "Thanks for providing all these details! Yeah, WASM/pyodide/pyscript is in a very early stage, but it has its use case (teaching being one of them) and will definitely evolve into something much more powerful in the future.",
            "I think your HN post is currently flagged dead."
        ]
    },
    "Kwargs appreciation thread": {
        "title": "Kwargs appreciation thread",
        "score": 148,
        "url": "https://www.reddit.com/r/Python/comments/1ddnokn/kwargs_appreciation_thread/",
        "content": "Edit: Thanks a lot to those who pointed it out: The name of the concept in question is actually *keyword-only arguments*. **kwargs is lovely as well, though!\n\n---\n\nI learned Python as my first language and it's the one I'm most proficient in. However, I've since written JavaScript, TypeScript, C#, and a little bit of Go.\n\nEven though each language has its own way of doing things, I find that I often miss being able to use kwargs for the sake of readability. This is what I mean:\n\n    some_function(semantic_parameter_name=value1, explanatory_parameter_name=value2)\n\nOften times, the usage of kwargs is sufficiently explanatory of what the function does. Whether it's someone else's code or code that you've written a while back, not only does it save you having to peek at the function's signature/code, it also helps piece together what a block of code intends to do at first glance.\n\nAt this point, for codebases that I maintain, I almost exclusively define my functions to force the usage of kwargs:\n\n    kwargs_are_mandatory(*, parameter1: int, parameter2: str) -> None:\n        return\n\nWhen I read code in a language that doesn't support some form of kwargs, I find it more difficult and time consuming to wrap my head around what's happening.\n\nWhat are your thoughts on kwargs?",
        "num_comments": 38,
        "comments": [
            "I would call those keyword arguments or keyword-only arguments. To me **kwargs means variadic keyword arguments.",
            "In my opinion the best feature in the args/kwargs system is that you can use arg names as kwargs. For instance, if you write `def f(x,y): (...)`, you can always call `f(x='foo', y='blah')` as if x and y were kwargs. Somehow the function \"remembers\" what its arguments were labelled as.\n\n\n\nThis means you're incentivised, though not forced, when calling complicated functions with lots of arguments, to write the function call with all its arguments as kwargs. The interpreter will of course tell you if you missed some compulsory arguments.",
            "I worked with projects that had a lot of \\*\\*kwargs and it sucked hard, you needed to step through 3 classes in an inheritance hierarchy only to find out the parameters a function will take. (The understandability of the code base in question also was not enhanced by making heavy use of metaclasses, urgh...)\n\nIn my opinion truly good Python code should pass Pyright on strict mode, and that one also complains about \\*\\*kwargs.\n\nFor typing existing kwargs I also recommend the new Unpack feature: [https://typing.readthedocs.io/en/latest/spec/callables.html#unpack-kwargs](https://typing.readthedocs.io/en/latest/spec/callables.html#unpack-kwargs)",
            "They are beautiful and one of the reasons I\u2019ll never seriously consider another language. \n\nThe ability to easily pass parameters through several layers, using **kwargs without having to repeat them all the time gives me a warm feeling in my tummy. \n\nUnfortunately it doesnt mesh 100% with type hints (e.g. https://github.com/locustio/locust/pull/2699), but it is totally worth it.\n\nAnd I wouldn\u2019t go as far as to stop using positional parameters. At least not for functions with 3 or fewer params.\n\nIf I\u2019m going to nit-pick: What you have in your examples are \u201dnamed parameters\u201d. \u201dkwargs\u201d is (in my vocabulary at least) specific to the **kwargs/argument unpacking feature.",
            "It's an amazing part of the language and I am using it a lot.\n\nBut only siths deal in absolutes. \n\nIt's a case by case thing. In many cases it does increase readability. But in some cases it might not really introduce much and might even make readability suffer due to extra bloat.\n\n    zlib.crc32(data=my_string)\n\ndoes not introduce any value to me.\n\n\nI would probably prefer to write my own lib/find other lib if some maintainer decides for me of my preferred calling pattern, especially in case of 1-2 arguments. I would probably reject a code review if someone of my engineers tries to do that.",
            "I agree. I miss them when I write code in Rust.",
            "You'd love SmallTalk, OP.  IIRC, that's where named params came from, but there it's not just part of the function's signature, it's actually the function's *name*!\n\nTake an OrderedCollection (basically the equivalent of a list):\n\n    oc := OrderedCollection new.\n    oc add:5.\n\n`add:` is a function that takes a parameter, so far so normal.  But what if you want to put something at a specific index?\n\n    oc add: 'hello' at: 1.\n\nThat's a function that takes two parameters, and its name is `add:at:`.\n\nEvery function in SmallTalk has kwargs :D",
            "I do like python's rich argument passing syntax, and they're something I really wish other languages would adopt too.\n\nThey *do* have one downside, which is that they encode more into the function signature than other approaches, which can affect refactoring.  Ie. changing the **name** of a parameter is effectively changing the signature, and could potentially break code calling it by keyword.  But I think this is well worth it for the flexibility they give.  (Oddly, that downside is actually more pronounced in a dynamic language like python versus more statically typed ones, which can detect that breakage at compile time, so I definitely feel there's room for staticly typed languages to adopt it).",
            "You can try use pep692 Unpack TypedDict",
            "You've just scratched the surface! With `*args`/`**kwargs` you can store and manipulate arguments through list/dict. This can be super useful.\n\nOne of my clients wanted a database interface where he would select a few constraints in GUI and get a list of all records that fit, with the ability to save/update the query. The elegant solution was to store keyword arguments for the query constructor in a JSONField in the same database. That way you can easily load the query back into the GUI and modify it in every conceivable way.",
            "Written kwargs, pronounced Keyword Args.\n\nAnd yes, this is the \"everything else\" args, not the named ones. In the function signature, you normally name the keyword args you depend on explicitly with their defaults. You only use `**kwargs` for args you're going to iter over, or pass into another function.",
            "I remember the start of my journey as a baby (Python) programmer, reading the documentation of Matplotlib and being really confused for too long about what this kwargs thing was that was in every function definition. \n\nI (and the documentation) have come a long way in the intervening 15 years.",
            "C# has had named arguments since like 2012 or something? Golang is almost useless without structs, which give you the same interface. JavaScript variants, well, they gonna JavaScript. \n\n\nAnyway, not to shit on you at all, but this is a lot more common than just Python. Clojure, Kotlin, and Swift have them as well. Probably others I haven\u2019t used in a while too.",
            "Love 'em.",
            "I would highly recommend writing a Pylint or flake8 plugin (maybe someone knows of a more off-the-shelf option) to enforce keyword calling by the consumer over writing all your methods to force keyword calling. You can get the best of both worlds, as python natively supports using keyword argument style calling even when the argument isn't defined as a keyword argument.",
            "Indeed this is what I meant. Thank you for the correction!",
            "Fun fact: there actually are such things as positional-only arguments! You can force arguments to be positional-only using a forward slash. I rarely see it done, though.",
            "Hm, yes. **kwargs is probably are pretty good idea to not have too much coupling to technicly deep layers.\n\nBut sometimes I really hate them. If I want to know if the name of some parameter in my plotting library is 'width' or 'line_width' or something else. It's neither in the docstring, its not in the source code of the function I am calling, its not even in the documentation of that library, because it belongs to another library. \n\nI haven't found any IDE hack to mitigate the problem. And copilot is not very well versed with the library just yet.\n\nIt's just annoying as a user of a library. But I get that it vastly reduces coupling.",
            "> The ability to easily pass parameters through several layers, using **kwargs without having to repeat them all the time gives me a warm feeling in my tummy.\n\nThis is convenient when you're writing code, but really sucks for anybody trying to call your functions. The effort you save by not explicitly passing parameters is just shifted to the reader who has to go code-spelunking to figure out what arguments your function actually takes. IMO this is only acceptable for internal functions/implementation details and not public APIs.",
            "In most contexts this is a seriously frustrating anti-pattern and is extremely un-pythonic. Especially when this is user facing in any way. \n\nIt's an important part of the language because things like decorators and/or creating python wrappers around other libraries depend on having some efficient way of propagating args/kwargs through layers of code. But outside of those situations, having args/kwargs cascade through multiple layers of functionality just obfuscates what's happening. And if you do need to know how your inputs are being used, you have to manually track every aspect of the code through those layers and often through other libraries.",
            "Keyword args enable you to add new features to an existing function without changing the signature and breaking existing code. That's what is used a lot in numpy and scipy.",
            "I agree with you; I also avoid keyword-only arguments when it's counter-intuitive. It just so happens that, in my experience, the majority of the time, keyword-only arguments have been preferable!\n\nYour reaction to the prospect of having to work with codebases with such strict rules made me re-evaluate some of my decisions, though. Thanks for that. \n\nCheers!",
            "I genuinely find it difficult to come up with any example where keyword arguments aren't better and I'd argue even your example still works better as a keyword argument. \n\nIt basically tells you what the method, in this case crc32, thinks your input is supposed to be and how it will interpret the input. If you happen to already know everything there is to know about the crc32 method you will probably conclude that \"data\" is the only input it takes. But if you didn't already know that, looking at an example shows you that the input is \"data\" and then you can inspect whether there are some other inputs that it might be able to use.",
            "yeah, there are times when it gets to be TOO MUCH.  \n\n```\nfooEater.eat_foo(foo=foo_food.foo) \n```\nand it just... loses all meaning in a sea of semantic satiation lol\n\n\nBUT that's pretty rare and most of the time the explicit keyword arguments are great IMO.",
            "Agree. Keyword arguments are absolutely great and it is hard to think of a time when it's better to omit them, but Python is a language for \\*consenting adults\\* and so as a library designer you shouldn't force your users to conform to something if not absolutely necessary.",
            "You can kinda replicate it using things like builder patterns and structs with defaults. I find that I use them in place of Python named arguments and C++ overloading all the time and they've grown on me.",
            "Oh wow this is awesome. When working with JS/TS, this is seamless. I remember wishing for Python to have that as well. It looks like it's not quiiite as smooth as it is in JS/TS but it'll do. Thanks!",
            "stocking saw rotten zesty act direction racial soup whole cows\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
            "Interesting! First time hearing about it, can you share an example oh it\u2019s usefulness? I can\u2019t seem to imagine why it can be useful",
            "Usually every kwarg should be in the docstring. As far as I'm concerned, if it's not in the docstring or documentation it doesn't exist. That's why I generally like the pandas/matplotlib documentation. You can find every kwarg in the documentation (although sometimes wacky things with inheritance make that hard)",
            "Yeah, the warm feeling really goes away when you have to go through several layers of seaborn documentation to eventually get all the way down to some matplotlib function where these kwargs finally get unpacked, doesn't it",
            "Sometimes there's not really a useful name for a parameter (but it's still ok to give it a name, if you're writing a lib it commits you to that api though). Other times you need it so you can handle **kwargs that could shadow the parameter name, like this mapping that can be updated with an \"iterable\" key:\n\n\n    class MyMapping:\n        ...\n        \n        def update(self, iterable, /, **kwargs):\n            self._dict.update(iterable, **kwargs)",
            "If I'm writing a protocol describing e.g. objects that can be added to ints:\n\n    class MyType(Protocol):\n        def __add__(self, x: int) -> Self: ...\n\nNow the name x is part of the public interface of this type, and if a class uses a different name than x in their implementation of `__add__`, it won't technically be a subtype of MyType.\n\nIt works though if you write it like this:\n\n    class MyType(Protocol):\n        def __add__(self, /, x: int) -> Self: ...",
            "It\u2019s been in the c-api since python one but it was never exposed to interpreter until 3.8 I think.",
            "I recently refactored a large god function that took 85 different possible keyword arguments. It was about 10 000 lines of code in our django app without any documentation. Took about a year and a half of on and off refactoring. The kwargs dict was passed on many layers to different smaller functions that maybe used one or two of the arguments. Most went to a defaults dict to create database objects out of django model instances. I was surprised the whole thing even worked. The result of dozens of developers being hurried to get new features done over a decade. \"It's just one extra argument in the handy kwargs dict, what's the worst that could happen?\"",
            "Wow, Thank you! It\u2019s very clear and helpful.",
            "Great point but I think you meant to put the / after x: \u00a0\n\n\n```\n\u00a0 \u00a0 def name(positional_only_parameters, /,\u00a0\n\u00a0 \u00a0 \u00a0 \u00a0 positional_or_keyword_parameters,\u00a0*,\n\u00a0 \u00a0 \u00a0 \u00a0 keyword_only_parameters): \u00a0 \u00a0 ... \u00a0\n\n\n```",
            "Yes, of course."
        ]
    },
    "Open-source AI shorts generator in python": {
        "title": "Open-source AI shorts generator in python",
        "score": 3,
        "url": "https://www.reddit.com/r/Python/comments/1de8hji/opensource_ai_shorts_generator_in_python/",
        "content": "I have open-sourced a Text-To-Video-AI generated which generates video from a topic by collecting relevant stock videos and stitching them together similar to popular video tools like Invideo, Pictory etc.\n\nLink to code :-\u00a0[https://github.com/SamurAIGPT/Text-To-Video-AI](https://github.com/SamurAIGPT/Text-To-Video-AI)",
        "num_comments": 3,
        "comments": [
            "You are the McDonald's in the internets enshitification drive through, thanks for making the world a better place",
            "Thanks, will check this out.",
            "Glad you found it useful"
        ]
    },
    " Made a Minimalistic Router for Uvicorn ": {
        "title": " Made a Minimalistic Router for Uvicorn ",
        "score": 15,
        "url": "https://www.reddit.com/r/Python/comments/1ddqqab/made_a_minimalistic_router_for_uvicorn/",
        "content": "Hey everyone,\n\nI've been working on a simple router for Uvicorn called [ASGIRouter](https://github.com/achaayb/ASGIRouter). If you like how Flask handles routing but want to stick with ASGI, you might find this useful.\n\n# What My Project Does\n\nASGIRouter provides a minimalistic routing solution for ASGI applications. It offers a straightforward way to define routes, similar to Flask, but is built to work any asgi compatible webservers mainly uvicorn.\n\nThis project is aimed at developers who prefer a minimalistic approach to routing in their ASGI applications. It's suitable for both toy projects and production use, depending on your needs.\n\nCompared to existing ASGI routers, ASGIRouter stands out for its simplicity and ease of use. While other routers might offer more features or complexity, ASGIRouter focuses on providing a minimalistic, Flask-like experience for those who want to keep things straightforward.\n\nCheck it out and let me know what you think.",
        "num_comments": 7,
        "comments": [
            "Definitely add documentation within the functions. Type hints would be great too.\n\nAnd it's not ready to use in production unless you have tests.",
            "I recently improved Flask's router to make it quicker. I wrote up the improvement [here](https://pgjones.dev/blog/faster-routing-2022/) - I think you'll find this interesting.",
            "Very nice project, I love your code style",
            "Thank you for the feedback, will so asap",
            "Thank you, will use it as reference",
            "Thank you so much, any aspects you would like to critique so i could improve it ?",
            "I will read carefully from my computer tomorrow after a night of sleep \ud83e\udd2a"
        ]
    },
    "A super easy-to-use API monitoring & analytics tool": {
        "title": "A super easy-to-use API monitoring & analytics tool",
        "score": 23,
        "url": "https://www.reddit.com/r/Python/comments/1ddc8lq/a_super_easytouse_api_monitoring_analytics_tool/",
        "content": "Hey Python community!\n\nI\u2019d like to introduce you to my indie product\u00a0[**Apitally**](https://apitally.io), a simple API monitoring & analytics tool for Python projects.\n\n# What My Project Does\n\nApitally provides insights into API traffic, errors, and performance, for the whole API, each endpoint and individual API consumers. It also monitors API uptime, alerting users when their API is down.\n\nApitally directly integrates with various Python web frameworks (FastAPI, Django, Flask, Litestar) through middleware, which captures request & response metadata (never anything sensitive!) and asynchronously ships it to Apitally\u2019s servers in regular intervals.\n\nThe client library is open-source with the\u00a0[source code available on GitHub](https://github.com/apitally/python-client).\n\nBelow is a code example, demonstrating how easy it is to set up Apitally for a FastAPI app (see complete setup guide [here](https://docs.apitally.io/frameworks/fastapi)):\n\n    from fastapi import FastAPI\n    from apitally.fastapi import ApitallyMiddleware\n    \n    app = FastAPI()\n    app.add_middleware(\n        ApitallyMiddleware,\n        client_id=\"your-client-id\",\n        env=\"dev\",  # or \"prod\" etc.\n    )\n\n# Target Audience\n\nEngineering teams, individual developers and product owners who build, ship and maintain REST APIs in Python.\n\n# Comparison\n\nThe big monitoring platforms (Datadog etc.) can be a bit overwhelming & expensive, particularly for simpler use cases. So Apitally\u2019s key differentiators are simplicity & affordability, with the goal to make it as easy as possible for users to understand usage of their APIs.\n\nI hope people here find this useful. Please let me know what you think!",
        "num_comments": 4,
        "comments": [
            "Looks real good, and integrating it into my fastapi application was really simple. I liked how easy it was to add a user too.\n\nNot an option at my company right now though since it doesn't work for springboot (which most of our services is written in) and we'd probably want Microsoft 365 SSO for login. But I'm definitely looking at this in the future.\n\nComments:\n\n* I do think that the `client_id` should perhaps be called `client_secret`, as it's being used for authentication. If someone steals your client id, they would be able to fudge your data (especially since you're not signing it in any way). I work with humans, and the word \"secret\" in a field name can and does absolutely prevent people from leaking data.\n* Why is the field called \"consumer_identifier\"? Is this a standard I'm not aware of (if so, it would be nice to link to it in the apitally docs for this feature)? I'd much rather have it be called something like `apitally_consumer_identifier`. This is especially true since apitally is mangling the consumer identifier (which isn't what I expected, and it's undocumented behaviour - why is it doing that and not just storing an utf8 string as you would expect? I would go so far as to say that this is a semi-serious **bug**, since two different consumer identifiers might receive the same slug), so chances are you're going to want to create a slug/format the consumer identifier string specifically for apitally. The point of apitally is surely to be part of a composable software stack - reusing terminology (by using a generic term) probably isn't really what people would want.\n* It would be real nice if there was a way to also send a correlation id header or similar (for errors).",
            "Looks good, I am preety much fed up with new relic and graffana dashboards anyways. Will give it a try",
            "This is great feedback. Very much appreciated!"
        ]
    },
    "TIL that selenium has opt out telemetry. what other common packages do this / similar experiences?": {
        "title": "TIL that selenium has opt out telemetry. what other common packages do this / similar experiences?",
        "score": 268,
        "url": "https://www.reddit.com/r/Python/comments/1dcuv0y/til_that_selenium_has_opt_out_telemetry_what/",
        "content": "While monitoring my network while doing some browser automation with selenium, I found strange traffic. After some digging I found [https://github.com/SeleniumHQ/selenium/pull/13173](https://github.com/SeleniumHQ/selenium/pull/13173) .  \nSearching for SE\\_AVOID\\_STATS on google to disable this has only 7 results, and practially impossible to find.\n\nI didn't expect to see this kind of dark patterns telemetry in python packages - so yeah. Has anyone else seen this? Is this some sort of recent trend?",
        "num_comments": 50,
        "comments": [
            "Streamlit does this. It is a huge red flag. Projects should not do this.",
            "Haha the GitHub thread is pretty telling.",
            "A lot of libraries published by commercial orgs do this (specially in the AI space where I have most familiarity with).",
            "gradio does this but it's pretty clear how to turn it off\n\nE: These are at the end of my .bashrc, I wonder if they work\n\n    export GRADIO_ANALYTICS_ENABLED=0\n    export HF_HUB_DISABLE_TELEMETRY=1\n    export NEXT_TELEMETRY_DISABLED=1\n    export SE_AVOID_STATS=true\n    export GOTELEMETRY=off",
            "I have a reasonably popular Python package (vanna) and I deliberately don\u2019t do any telemetry. \n\nWhen I speak to VCs, they all ask about the open source usage and I have to tell them that I absolutely don\u2019t and will not collect telemetry on people who are running my package locally. I\u2019m pretty sure I\u2019ve lost investors because of this stance.",
            "Streamlit",
            "No library should be making \"hidden\" calls home, for whatever reason. It's a security incident waiting to happen, if every library does this the bandwidth impact may be significant and it's just generally not doing what the library says it's doing.\n\nThis will have a significant impact on the usability of Selenium in corporate environments. I know my security department would immediately flag the traffic and want an explanation, and would probably blacklist Selenium as a result. I can't fault them for that.\n\nI understand it has value for your priority setting, but this is not the way. The downsides far outway the upsides.",
            "[deleted]",
            "Thank you for bringing this to my notice. We usually take infrastructure level code for granted and never bother looking much into its behavior, especially so if it's a popular package like selenium. But this incident shows how crucial software auditing is, even auditing of open source software.",
            "Ohh wow, pretty much forces me to immediately remove Selenium from all my work... Nice incompetence.",
            "Kind of spooky.",
            "> SeleniumHQ locked as too heated and limited conversation to collaborators 5 hours ago\n\n... gee, if it was so heated, perhaps the wrong decision was made. I absolutely *despise* when people bury their heads in the sand like that.\n\nThe irony, is that the contributor who locked it has this in their bio blurb:\n\n> passionate about digital confidence\n\nYea, and you're doing a great job ensuring it /s",
            "Continue, the VSCode plugin, also had telemetry turned on out of the box.",
            "pm2",
            "What we have here, is a forking opportunity. The beauty of open source is that that the larger community that uses selenium can fork it and move there together, leaving the bad-acting current owners out in the cold. This is what should happen, the project owners have shown us who they are, lets believe them.",
            "Absolutely every Microsoft sdk or tool",
            "If you use a SPA front end with a Python API back end then [Storybook](https://storybook.js.org/docs/configure/telemetry) is another example.",
            "I see the problem with anonymous telemetry but I don't think it is commonly included in the deceptive patterns definition. Still, they should really have informed people and have it opt-in. I wonder how many would opt-in for telemetry, though. I know I would not.",
            "> Projects should not do this.\n\nOr at least be upfront about it. If there is a clear setting in the \"quick start\" section that turns it off and it clearly says its anonymised then I usually leave it on. I don't mind some mild good-faith telemerty to help a dev out",
            "Errrr what setting is this in streamlit?",
            "Chainlit too",
            "Yeah they seem weirdly confused as why to someone wouldn\u2019t want this\u00a0",
            "God damn, reading that is a super red flag.  They really don't care, just decided they wanted it and said \"screw you\". \n\n> We decided that it was only worth collecting the data if it was opt-out.\n\n> Oh, I never posted the blog announcing the release",
            "I'm usually the first to cry foul about data collection, but this seems fine to me after reading the details of [the platform they use](https://plausible.io/privacy-focused-web-analytics). I'm really not concerned about an OSS platform like Plausible collecting non-identifiable, aggregated data.",
            "Just looked it up. I didn't really see any weird traffic when running automatic111, but looks like that is because they disabled it. It feels so strange that I need to worry that a python package would send my ip and machine info to somwhere.",
            "Are investors speaking to you regarding your open source work or separate projects?",
            "Someone should be the first...\n\n\nSadly gdpr reporting has a very high threshold, you need to provide a lot of personal information to file a report and an actual complaint, you can't just send a mail to someplace and request them to investigate.\u00a0",
            "They claim that the telemetry engine they are using (Plausible) is fully gpdr compliant. Plausible's website also says that",
            "if you need an alternative [playwright](https://playwright.dev/python/) is pretty good and I don't think it has any telemetry",
            "Why? Do you work on something really sensitive?\n\nThe data selenium is gathering seems quite benign.",
            "This is kinda my thought process.",
            "gatherUsageStats = true",
            "Definitely, like a bad sitcoms quid pro quo.\n\nIt would be funny as hell, if it didn't feel so dishonest.",
            "I however can confirm that opt-in telemetry from generic population is totally garbled. I worked on a couple commercial products with opt-in telemetry, and let me just say that guessing would be more precise than the data actually collected. The first one has shown that there are 3 times more BSD users than Linux users.\n\nOpt-in telemetry is simply not worth he hassle to implement.",
            "Do you also worry about your browser sending your IP?\u00a0\n\n\nGenuine question. Telemetry isn't inherently bad it helps developers solve a lot of bugs that would otherwise be very hard to fix.\u00a0\n\n\nHowever there is a fine line between that an just out right spying",
            "For now.",
            "Very sensitive, no. Sensitive enough that I can't have unknown calls being made about the work I'm doing, yes.",
            "Thank you!",
            "Opt-out isn't eitherin most cases, with dependencies (IMO of course).  Just count your per-platform downloads and you are good to go, since reporting will just report the same thing.  \n\nIf it _is_ somehow useful, then they are obviously invasively collecting data.",
            "You're almost there. In general, telemetry should only be available as an enterprise opt in offering, and never used anywhere else (like cars or open sourse software)",
            "No library should be making \"hidden\" calls home, for whatever reason. It's a security incident waiting to happen, if every library does this the bandwidth impact may be significant and it's just generally not doing what the library says it's doing.",
            ">  Telemetry isn't inherently bad it helps developers solve a lot of bugs that would otherwise be very hard to fix.  \n\nThey're welcome to include a means to do it, but *leave it disabled in normal circumstances.*\n\nIf a bug report comes in where it would be useful to have telemetry, the first troubleshooting step might include instructions on enabling it for the duration of troubleshooting.",
            ">Do you also worry about your browser sending your IP?\u00a0\n\nYes and I use (paid) protonvpn most of the time. However it is slow and when I want to do some development I turn it off, with a natural and so far correct expectation that my IP will only be going to pipy and github. I do not want my IP anywhere else.\n\n>Telemetry isn't inherently bad.\n\nIt is inherently bad unless in very, very controlled circumstances. Kind of like morphine / opiods etc. It should be the very last thing to use when trying to improve end user experience.\n\n>\u00a0a lot of bugs that would otherwise be very hard to fix.\u00a0\n\nI could not see a single bug that has been fixed in selenium due to this.",
            "Not everything is a slippery slope argument, but sure.\n\nI don't really understand what actionable thing they intend to do with the data they're gathering tbf.",
            "Now that's an interesting topic. What kind of data is invasive data? Metrics on how many times a feature is accessed - without identifying information - feels like a good thing to collect in order to direct efforts towards more-used features rather than spending time on never used ones. The problem is, how do you collect anonymous data and have users trust that you are in fact collecting anonymous data?",
            "Last message before they locked the issue:\n\n> So the options were either not to collect any information or to do so the way we have.\n\nYea, and they chose *the wrong one.*",
            "> I could not see a single bug that has been fixed in selenium due to this. \n\nI didn't mean this project specially, tbh i didn't know it had it either until this post",
            "Hilarious you apply slippery slope to making slippery slope arguments.\n\nJust don't collect your user's data. Simple enough.",
            "[deleted]",
            "My code - my rules. Nothing's stopping you form writing your own stuff.",
            "[deleted]",
            "You have rights as a user, I have rights as a service provider. Our relation is nicely clarified in Terms & Conditions you probably ignored. I can, and will use telemetry to improve my product.\n\nAgain, if you don't want to share telemetry with me - it's fine, just don't use the service. Same goes for hacks and subpoena - that's your risk as a user, not mine."
        ]
    },
    "Textchat: TUI Single Server IRC Client": {
        "title": "Textchat: TUI Single Server IRC Client",
        "score": 3,
        "url": "https://www.reddit.com/r/Python/comments/1ddnhs7/textchat_tui_single_server_irc_client/",
        "content": "Hello all! I have made an irc client with textual\\`. Source is available here: [https://github.com/rmblau/textchat/](https://github.com/rmblau/textchat/)\n\nI would love any and all feedback on code quality and how it can be improved as well as people to test out the client. On first launch it will open a settings screen where you can input your user information once you hit the save button. Right now there's a bug that I'm working on resolving where that you'll have to quit the application once you enter your information and relaunch it to get it to connect. Feel free to file issues and contribute; I hope you all will find this fun and interesting!\n\n# What My Project Does\n\nOnly confirmed working on Linux right now.. Right now it does not support SASL, SSL, or znc. It's in alpha and can be installed from pypi. Once installed it can be ran from the cmd line with \\`textchat\\`\n\n# Target Audience\n\nThis is aimed at people who love irc as much as I do.\n\n# Comparison\n\nThere didn't seem to be any application like this so I decided to make it.\n\n\n\n",
        "num_comments": 2,
        "comments": [
            "Interesting I will check it out and possibly integrate it with SCOUT-2 which is my open source AI digital assistant application. I gave you a star and a watch.\nhttps://github.com/DigitalHallucinations/SCOUT-2",
            "That's awesome, thank you! Also have given you a star :)"
        ]
    },
    "Python Open-CV Tool-Chip Contact Length Calculation": {
        "title": "Python Open-CV Tool-Chip Contact Length Calculation",
        "score": 6,
        "url": "https://www.reddit.com/r/Python/comments/1ddcyun/python_opencv_toolchip_contact_length_calculation/",
        "content": "Just posted a video on a case study of a Python OpenCV algo that calculates the contact length between the tool and the chip in a metalworking machining process. The images have been captured with a high-speed camera.\n\nThe Python code and documentation on my GitHub:\u00a0[https://github.com/FrunzaDan/Tool-Chip\\_Contact\\_Length](https://github.com/FrunzaDan/Tool-Chip_Contact_Length)\n\nThe video:\u00a0[https://youtu.be/bndai6SlF6E](https://youtu.be/bndai6SlF6E)\n\nEnjoy!\n\n# What My Project Does\n\nThe Python algo uses Hough lines to locate the edges of the tool and the chip and calculate the distance between them.\n\n# Target Audience\n\nPython OpenCV enthusiasts and people in metalworking research.\n\n# Comparison\n\nI haven't seen any application like this in metalworking machining.\n\n  \n",
        "num_comments": 0,
        "comments": []
    },
    "ChatGPT hallucinated a plugin called pytest-edit. So I created it.": {
        "title": "ChatGPT hallucinated a plugin called pytest-edit. So I created it.",
        "score": 547,
        "url": "https://www.reddit.com/r/Python/comments/1dchk4g/chatgpt_hallucinated_a_plugin_called_pytestedit/",
        "content": "I have several codebases with around 500+ different tests in each. If one of these tests fails, I need to spend \\~20 seconds to find the right file, open it in neovim, and find the right test function. 20 seconds might not sound like much, but trying not to fat-finger paths in the terminal for this amount of time makes my blood boil.\n\nI wanted Pytest to do this for me, thought there would be a plugin for it. Google brought up no results, so I asked ChatGPT. It said there's a `pytest-edit` plugin that adds an `--edit` option to Pytest.\n\nThere isn't. So I created just that. Enjoy.\u00a0[https://github.com/MrMino/pytest-edit](https://github.com/MrMino/pytest-edit)\n\nNow, my issue is that I don't know if it works on Windows/Mac with VS Code / PyCharm, etc. - so if anyone would like to spend some time on betatesting a small pytest plugin - issue reports & PRs very much welcome.\n\n# What My Project Does\n\nIt adds an `--edit` option to Pytest, that opens failing test code in the user's editor of choice.\n\n# Target Audience\n\nPytest users.\n\n# Comparison\n\nAFAIK nothing like this on the market, but I hope I'm wrong.  \nThink `%edit` magic from IPython but for failed pytest executions.",
        "num_comments": 61,
        "comments": [
            "That's genuinely awesome, \"oh LLM thought something exists, well I'll just make it\"",
            "I tested, and it works on Windows 10, with vscode as editor.\n\nNice one! It will come in handy.\n\nP.S. it does also print out `ERROR: exit() requires a reason argument`, but that's an easy fix.",
            "ChatGPT in full \"follow your dreams\" or \"where is a will, there is away\" mode",
            "ChatGPT did not hallucinate, since version 4 it can legit foresee the future.",
            "I solved this for myself a while ago. In `conftest.py`:\n\n```python\ndef pytest_runtest_logreport(report: pytest.TestReport) -> None:\n    \"\"\"Add line numbers to log report, for easier discovery in code editors.\"\"\"\n    # Report location of test (failing line number if available, else test location)\n    filename, line_no, domain = report.location\n    if (\n        report.longrepr is not None\n        and (repr_traceback := getattr(report.longrepr, 'reprtraceback', None))\n        is not None\n        and (repr_file_loc := repr_traceback.reprentries[0].reprfileloc).path\n        == filename\n    ):\n        line_no = repr_file_loc.lineno\n    if report.nodeid.startswith(filename):\n        # Only insert a line number if the existing `nodeid`` refers to the same\n        # filename. Needed for pytest-bdd, which constructs tests and refers the\n        # filename that imported the scenario. This file will not have the actual test\n        # function, so no line number reference is possible; the `filename` in the\n        # report will refer to pytest-bdd internals\n        report.nodeid = f'{filename}:{line_no}::{domain}'\n```",
            "Fuck, ChatGPT is basically a manager now.",
            "Doesn't Ctrl-click on the line number do this with VScode?",
            "Positive AI story. \n\nWell done dude!",
            "I haven't checked the repo yet, but wouldn't a pytest PR to add this as a feature directly in pytest make sense?",
            "It's just envisioning closure on the conceptual integrity of all open-source.",
            "This happens a lot. I\u2019ve seen it suggest things that doesn\u2019t exist and then when told it doesn\u2019t exist, chat got is all, \u201cit would look something like this\u201d and proceeds to give wild pseudo code that would never work.",
            "Doesn't it make it a prediction and not hallucinations if you made it?",
            "I\u2019m pretty sure ChatGPT could have written it for you too, if prompted.",
            "The new GPT update allows it to augment the near future. You have passed the first test, welcome.",
            "It would be cooler if the LLM then created it as well.",
            "This is how AI conquers humanity.",
            "A conference I attended recently, a keynote focused on security, actually mentioned how this could be abused and to look out for cases like this. I'm not saying this is one such case, but interesting, nonetheless. \n\n1. Ask LLM if a package to do <thing> exists.\n2. LLM \"hallucinates\" a package and gives you a name for it.\n3. The attacker creates said package, hoping for LLM to continue suggesting it and for people to trust the LLM and install it.",
            "Hallucination Driven Development",
            "The LLM basically extrapolated what it'd look like if it existed.  \nThat's reasonable because LLMs do not interact with the environment, they don't know what the environment is and what their thoughts sre.  \n\nHallucinations are simply reasonable extrapolations, some more biased than others.  \nThis is no different from having an \"idea\", imo.  \nJust without the reference frame of reality to realize that it was one instead of talking about something actually real.",
            "Isn't this the basis of all invention? :-)\n\n***Why can't I .....***",
            "It\u2019s what chat gippity is good for",
            "Thanks for trying it out! None of what you've just tried was tested by me, so I'm genuinely surprised this works \ud83d\ude01.\n\nYes, the exit thing is something I need to work out. Pytest API doesn't really have a \"please silently exit the process now\" method, or I can't find it. I'm in the process of weighing which hack is the least ugly.",
            "ChatGPT in \u201cprophetic visions\u201d mode.",
            "Bootstrap paradox lead development.  \nI'm down.",
            "Muad'dib!",
            "Has anyone ever introduced you to Roko's Basilisk?",
            "Curious what version he used.  I feel like this happened to me a couple times but I can't remember it happening recently",
            "That's a cool one. I'd be worried though, that the different format of the `nodeid` could break other plugins. Not sure if e.g. the `nodeid`s for `--lf` (this option is a plugin too under the hood, btw) get cached before `runtest_logreport` hook or after.",
            "have you checked pytest-pretty?",
            "It requires keeping track of however many editors are out there and their specific ways of getting the line number to put the cursor at. I doubt Pytest maintainers would be interested in this. It's also pretty detached conceptually from Pytest itself.",
            "Yea no. I just needed the plugin.",
            "Wait, so I shouldn't just `pip install` everything GPT tells me to?\n\nJoking aside, that would be a pretty clever attack. Just shows how important it is to understand what you're doing and keep a close eye on anything that can modify your system, even if you think it's from a trusted source",
            "What a time to be alive",
            "I... would have been in danger of falling for that. ChatGPT has given me incredibly detailed instructions for R packages that don't exist.",
            "Step 4. The attacker posts on reddit asking folks to test said package...",
            "This is very similar to (adversarial) transferred attack, the surrogate model (presumably similar to the target model) is used to deduce the behaviors of the target model. The approach is different and much more intriguing though.\n\nJust my lame comparison:\n- Surrogate model is ChatGPT\n- Target model is Human (the brain, to be more precise).\n\nBut these two model don't have to be similar in the case of adversarial attacks.",
            "may I ask the name of the conference? sounds pretty cool",
            "just wow",
            "HR is gonna go wild with this on LinkedIn \ud83d\ude05.",
            "LSDDD",
            "The \u201challucination\u201d joke is more in reference to the way things like ChatGPT always present information with complete confidence even if it has clearly made up the existence of something. \n\nFor example, the idea that \u201cpytest-edit\u201d is a thing that exists isn\u2019t a completely unreasonable extrapolation but because there is no evidence of such a thing, the blind confidence ChatGPT presents it with sounds like a human hallucinating it. Because a human who is merely \u201cextrapolating\u201d tools from ideas would present it as something like \u201cperhaps a tool called \u2018pytest-edit\u2019 might exist to do what you want\u201d.",
            "It is not a reasonable extrapolation that I got my first PhD at 11, which was 4 years after I graduated high school at age 7. ChatGPT thinks I have 2, but the second took me until I was 23. That one must have been a lot harder.",
            "Are you sure you don't just need to add a reason?\n\ni.e. `pytest.exit('hello', returncode=10)`\n\nFrom the docs:  reason has a default value only because msg is deprecated.",
            "Does any of\n\n    os.kill(os.getpid(), signal.SIGNAL)\n\nhelp with SIGNAL as `SIGQUIT, SIGTERM, SIGKILL` in order",
            "I hadn't thought of that, so I just checked: `--lf` does work, but it re-runs the entire file and not the particular test. I guess it's doing a L-to-R match of the nodeid and narrowing as close as it can get?",
            "I hadn't, and now I've thrown out my hack and added `pytest-pretty` as a test dependency.",
            "Looks like I suck at trying to be funny.",
            "I suspect the target base would be too small for it to really be lucrative as a generic attack.\n\n\nBut for a targeted attack this could be pretty wicked",
            "I can assure you, that given my credentials I have very little incentive for such shenanigans (negative amount, actually).",
            "It was \"DevOps Days\", don't recall the speaker's name but it was focused on security.",
            "In college, one time my roommate proposed, \"do you wanna do DMT and write a kernel?\" I politely declined, but I think about that fairly often.\u00a0",
            "Om pretty sure that chat gpt simply has seen the code before and knows that it exists, it's just that some private company has it and hasn't made it public, but since Google spies on everyone they know it's out there",
            "If I add the reason it prints it twice on Linux, and adds a `!!!!!!!! ... !!!!!!!!` banner, leading to even more clutter. Or is it just my pytest version?\n\nI would like it not output anything in case where there is no error (and no -v flag), and leave the stderr alone ;)",
            "I didn't want to do that since that would mean that other, potentially useful hooks from other plugins would not get run. But it's one of the options on the table.\n\nAnother idea was filtering expected output from `sys.stdout` (but letting the debug messages and other stuff through).\n\nThere's a lot of different approaches, each has its own specific way in which it is potentially harmful.",
            "Imagine posting on sites about a package that doesn't exist for months just to posion the LLM training data and perform such attack",
            "I\u2019m sure it\u2019s a pretty large group of people, it\u2019s just unlikely to be like production code bases. More so folks making little automations.",
            "Probably would have discovered *the* kernel, behind the veil.",
            "Yeah, it does the same for me. I still think it's better to see something like `!!!! Exit successful !!!!` than getting a red error message.",
            "Well, and then also waiting a few years for the training to catch up.",
            "Oh, it's in red? It doesn't color this for me.\n\nI'll make sure to fix this as soon as I have the time to update it.",
            "The guy that tried to put a backdoor on xz worked on it for at least 3 years"
        ]
    },
    "Why would anyone use pyqt if pyside exists": {
        "title": "Why would anyone use pyqt if pyside exists",
        "score": 49,
        "url": "https://www.reddit.com/r/Python/comments/1dcedjb/why_would_anyone_use_pyqt_if_pyside_exists/",
        "content": "Like the only different is in pyqt you must share the code or buy a license and in pyside you can share it whether you want to or not. Yet i still see so many videos on pyqt and not pyside",
        "num_comments": 29,
        "comments": [
            "Historically there was only PyQt so people used that, wrote books too and it stayed.",
            "Mainly license from my perspective. PySide\u2019s LGPL might not work for all projects. Riverbank offers a (relatively) cheap perpetual license which allows to do whatever, license wise. Of course, you\u2019re usually still bound by Qt\u2019s LGPL where commercial license is much more expensive, but if working for a big company you might have commercial license with them too.",
            "Commercial support, faster updates, clear path to use in proprietary software.",
            "Qt company stopped sponsoring PySide development after Nokia sold them off\n\nPySide didn't release for Qt5 until 2018 and didn't have full support (supplementary Qt modules like QMultiMedia, etc) until a while after that\n\nThere was a ~6 year stretch where your only option was to either use PyQt, or use PySide and Qt4, which was basically falling apart at the seams on modern operating systems (it was no longer shipped for macOS so you had to compile the C++ source yourself, it didn't support UHD monitors properly, etc)",
            "I'm just using QtPy as a wrapper and can change the backend so any time if requirements for licensing changes some day.",
            "We used it because there was no PySide, also pyqtdeploy is pretty handy.",
            "Why do people use qt in python, don't you feel you have almost twice th\u00e9 same thing ?\nThe GUI part look th\u00e9 thing that python does not  propose an \u00e9quivalent, but still there are alternatives.\nAlso Qt IS becoming very agressive with companies involved with commercial development using Qt .\nThey are not cheap at all.",
            "skip it to react or vue \ud83d\ude02",
            "I use wx. \ud83e\udd95",
            "PyQt supports more platforms than PySide",
            "I don\u2019t know. I use PySide 6",
            "Because... Yes.",
            "I just refer to this as inertia.    \nFor example, Adobe is terrible. All my homies hate Adobe. But Adobe products have too much inertia that switching away wouldn't generally be a PITA.",
            "Don't forget that a GPL is a \"Trojan license\". Depending where you use code licensed under it, you may be forced to release it. So if you're doing anything secret due to monetary advantage, a GPL is typically a non starter.",
            "Wait, if I build internal applications at work with pyqt5 I\u2019m supposed to have a commercial license?",
            "Wx is good for seasoned software engineers\n\nBut the limited examples and tutorials crushes noobs like me",
            "Same",
            "I\u2019m on PySide5. The k key works. Same issue with PyQt6.",
            "Terrible compared to what? I use Adobe products begrudgingly, but their flagship products are still the best in the market.",
            "You\u2019re right, Flash was better when it was Macromedia \ud83e\udd13",
            "IIRC LGPL is somewhat more permissive than GPL when dynamically linking. But what does that exactly mean in context of Python, I\u2019m not entirely sure.",
            "GPL never requires you to \"release\" code to the public.  \nIt only requires you to provide the code to customers upon written request and nominal payment for shipping and media.\n\nAs a matter of canon many organizations publicly release the code making it to so easy to self-obtain they avoid ever having to deal with the mail-order requirement.",
            "This is really a legal issue so if you want to know for sure you\u2019d have to ask a lawyer that specialises in opensource licensing. \n\nTo the best of my understanding, if you use pyqt with LGPL, at least part of your code may have to comply with the LGPL requirements. However, as mentioned in one of the comments here, for there to be any actual consequences someone would have to have interest in demanding you comply (whatever that means) and I don\u2019t know how realistic that is, especially if used for internal only purposes.",
            "Don't use Wx any longer but it's very logical once you understand it and you can say, \"Oh, I bet this works in a given way because that works in a given way\".  But yeah, it crushes a noob.",
            "Terrible at everything when you compare usage fees/subscriptions.",
            "It means if with reasonable proof, if your source code lines can be proven to use the library and subsequent licenses, you can be compelled legally to release *all* code using them. \n\nIn most cases, I wouldn't give a shit, but let's say it's ensconced in a model that trades for me. That's an issue.",
            "Never said to the public. I meant to release it in the sense that you could potentially create a competitor by way of using such a license.\n\nFor example, company A uses GPL code in their models, company B becomes aware, and requests the code.\n\nCompany A has to provide it. While not officially a \"public\" release, the secret is out.\n\nHence \"Trojan license\".",
            "Blender shows that it can be done free and open source, especialy after their GUI update (2.8).. Cinema, 3ds max, Maya etc is still a lot of businesses goto, but that is mostly because of pipelines, custom plugins etc. When young blood later arrives many of them would have learned 3D with Blender and not a pirated Cinema 4D like in the 'old' days.",
            "If it was GPL; not LGPL. The L explicitly addresses this issue."
        ]
    },
    "Building an HTTP Server in Python": {
        "title": "Building an HTTP Server in Python",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1dd6tud/building_an_http_server_in_python/",
        "content": "I have always been curious on how http servers works. Therefore, I decided to write a post on how they work and implementing a simple server in Python.\n\n[Link to blog post](https://muhammadraza.me/2024/building-http-server/)",
        "num_comments": 9,
        "comments": [
            "Not to be that guy but i think you should spend some time to actually implement the http protocol that supports headers and response content from actual html files. This is at most a tcp server that returns a string that looks like http.",
            "This looks like a good beginner project, good on ya mate! I\u2019d recommend digging into flask 2 or fastapi next so you can see how a full backend web framework works if you haven\u2019t already. Fastapi is my preference personally but both work well. \n\nAs you may know, while low level socket level control is interesting, it\u2019s not very practically useful for the vast majority of cases in real enterprise web backends. What\u2019s more useful is how you can build real systems using modern backend web frameworks, how you manage delayed workloads, how you integrate in your user authentication control framework, how you build systems that require no state to be stored at the server level but still allow you to serve your customers. \n\nI recommend working on building real business projects with FastAPI as that will give you a lot of really usable experience.",
            "Site doesn\u2019t load for me sadly",
            "It was a fun project. I have done codecrafters's version (in multiple languages)\n\n[https://app.codecrafters.io/courses/http-server/overview](https://app.codecrafters.io/courses/http-server/overview)\n\n[https://www.youtube.com/watch?v=1NiVabKE7Fk](https://www.youtube.com/watch?v=1NiVabKE7Fk) (this is not me)",
            "I would agree and I really appreciate your opinion. Also that\u2019s a good idea I might dive into writing HTTP protocol and understanding how it works",
            "Hey\n\nI really appreciate your advice. Also that\u2019s my plan , even though I program in python and now i want to learn things more deeply \n\nAnd write about them as this might help beginners who getting started in there programming journey or even web development.\n\nComments like your really motivate me",
            "Maybe try again",
            "That\u2019s great to hear. I\u2019m a senior backend python engineer professionally, if you\u2019d like, we can connect so you\u2019ve got a place to answer career questions. Sometimes it can be helpful to have someone a little more experienced to bounce ideas off of.\n\nFeel free to send me a chat message on Reddit if that interests you. Either way, good luck mate! It\u2019s not an easy career to get into, but it\u2019s very rewarding once you get some traction.",
            "Sure,\n\nI\u2019ll dm you"
        ]
    },
    "open source CLI tool for finding out how programs work": {
        "title": "open source CLI tool for finding out how programs work",
        "score": 2,
        "url": "https://www.reddit.com/r/Python/comments/1dcqw42/open_source_cli_tool_for_finding_out_how_programs/",
        "content": "# What my project does\n\nAllow users to find out what frameworks, tools, engines a program / game was made in.\n\nLooks through a directory and searches for common folder structures, and file names.\n\nYou can add the -d flag to do a \"deep dive\" and it will look through for strings inside of the binaries.\n\n  \n[Image Example](https://camo.githubusercontent.com/6d8e7d1e775d017ddc6ce78601bf848a3cbec51302a6e431b39834e30a31c402/68747470733a2f2f692e696d6775722e636f6d2f374a6471356c382e706e67)\n\n# Target Audience\n\nAnyone! Developers looking to learn how other programs were made, people who are just interested.\n\n# Comparison\n\nNot sure if there are any alternatives, but another way of finding out how a program runs is looking through the names of files & folders.\n\nGitHub: [https://github.com/PossiblePanda/hdiw](https://github.com/PossiblePanda/hdiw)\n\nContributors are appreciated :), adding new frameworks, or improving the core of hdiw.",
        "num_comments": 4,
        "comments": [
            "It\u2019s cool! My constructive criticism is that it took me a hot second to figure out that the percentages were probabilities of being right, not percentage of the code structure (like GitHub does with percentages of languages). But otherwise, I like it :)",
            "ah, I probably should have some sort of indicator for that. Thanks! :)",
            "feel free to leave a star on github ;)"
        ]
    },
    "Kivy School - Crowdfunding Update": {
        "title": "Kivy School - Crowdfunding Update",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1dcky9z/kivy_school_crowdfunding_update/",
        "content": "We're excited to share that our [Kivy School crowdfunding project](https://www.kickstarter.com/projects/kivyschool/the-pain-free-python-on-android-essentials-course) on Kickstarter is over 50% funded, but we only have 2 days left to reach our goal!\n\nWe want to show our appreciation to everyone who has supported us. Even if we don't reach 100% funding, everyone who trusted us will still receive free access to all free resources at [kivyschool.com](https://kivyschool.com) and our course on Udemy.\n\nKivy School is an organization made by volunteers to teach others how to create Python apps using the Kivy framework and deploy them on all platforms: Android, iOS, Windows, macOS, Linux, Raspberry and on your toaster! \n\nSo if you are still interested on helping Kivy School or on having free access to our Udemy course, you can risk free pledge on the crowdfunding link above before it expires.\n\nKeep an eye at Kivy School, soon we will publishing about:  \n- Hot Reload on Android  \n- Supabase integration  \n- Sentry integration  \n- Using SQLAlchemy / SQLModel / Pydantic with Kivy  \n- GPS, Bluetooth, Wi-Fi, Android Services & much more!\n\nIt is Python. It is open source. And it is free.\n\nJoin us at Kivy School, and let's code together!",
        "num_comments": 0,
        "comments": []
    },
    "Async Python Clarifications": {
        "title": "Async Python Clarifications",
        "score": 35,
        "url": "https://www.reddit.com/r/Python/comments/1dbxkd6/async_python_clarifications/",
        "content": "Ok, so just so I have this straight: \n- Asyncio runs in a single thread and uses cooperative multitasking to context switch between tasks\n- The threading library creates threads and uses preemptive multitasking to context switch between threads\n- Asyncio is more efficient than threading for the reasons above \n- Both share the same CPU core/resources\n- Multiprocessing is using additional cores to speed up CPU bound tasks \n\nSo to summarize: a process can create threads and threads can create tasks\n\nIs it just me or do people confuse processes as threads or also confuses tasks as threads? This makes getting it all straight pretty confusing and so any help here to confirm what I\u2019ve learned above would be appreciated \ud83d\ude4f",
        "num_comments": 16,
        "comments": [
            "Not quite right.\n\nProcesses are like individual applications. Each has its own memory and cannot access the memory of others. Multiple processes can run at the same time, but their means of communicating with each other are slower than with threads.\n\nThreads all reside within one memory pool, allowing them to directly access each other's data, which is fast. Threads in any language, including Python, can run in parallel. However, in CPython, the most popular implementation of Python, all threads are locked so that only one can execute at a given time. This is a limitation of CPython and perhaps some other interpreters, not the Python language itself. There are plenty of interpreters that have working threads.\n\nTasks normally run within one thread. You need to make an effort to spread them across threads and even more effort to spread them across processes. The idea of a task is that when it pauses, waiting for data from the system, another task runs automatically. Tasks can wait for data in parallel, but waiting is what most servers do most of the time, that is why threads are so useful in servers. \n\nOther languages have properly working threads and even green threads (these are a hybrid between threads and tasks; they are tasks running in parallel without being exposed to the OS as threads are). That is why other languages are not as heavily reliant on multiprocessing. However, multiprocessing also allows your program to limit the attack surface and recover from an unhandled exception. That is why Chrome uses multiprocessing.",
            "The concept of threading is deeper than you're letting on.\n\nA \"thread\" is simply the idea of having a single program with multiple independently running lines of execution within the same process. A thread will have its own associated state either in the form of its own instruction pointer and stack or in some mechanism that effectively replaces the functionality of them.\n\nThe threading library allows running code in separate *OS threads.* These are threads that are managed by the operating system; the OS decides how they're scheduled and prioritized and manages the local state of the threads.\n\nThe asyncio library allows running code in separate *user space threads.* The asyncio library itself manages thread scheduling and local state via the event loop and Future objects (Task inherits from Future). This is typically done within a single OS thread, which is advantageous because it can help reduce overhead involved in OS-level operations like context switches.\n\nI think it's important to note that asyncio is not the only implementation of user space threads in Python. Twisted and Trio both come to mind. There's also Stackless Python, which is a re-implementation of the Python interpreter designed to allow user-space threads with either cooperative or preemptive scheduling.",
            "It is highly unlikely that in a true speed-test, brawn-vs-brawn, that coroutines/fibers/user-mode-threads would outperform kernel-mode-threads.\n\nDespite their overt similarities they are markedly different strategies that address different bottlenecks.\n\nCoroutines enable the asynchronous programming model allowing you to write code like script rather than event-driven finite-state-machines but if you actually code up the event-driven FSM, they will crush the coroutines in performance and scalability. The FSM will complete the task before the coroutine swaps itself onto the stack. It will just take you 30x to 40x times longer to design and code it up.\n\nSo we only do the FSM thing for real-time controls and core system engines and make the coding easier everywhere else we can. Most web-servers don't take performance to this level; the only one I can remember that tried was a proprietary project called g-wan.\n\nIf you want to read more about an example performance use-case for coroutines look up the article about Naughty Dog Engine optimizing their PS3 execution. The nature of the PS3 was it had lots of coprocessors so routines spent a lot of time waiting for them to do their work and complete.\n\nPerformance was NOT the reason browsers went the async-coroutine route. That was for easy-of-use to keep everything in the single-threaded-apartment model because if you go-for true multithreaded then JS programmers have to become system-programmers and webpages would be deadlocking left and right.",
            "Ok, thanks! So threads in some programming languages run in parallel, however in Python it\u2019s restricted by the GIL",
            "Processes can acces the same memory. Use shared memory lib in py.",
            "I think this is a good description but I'd like to add to this a bit if I may!\n\n> each has its own memory and cannot access the memory of others\n\nThis is not always true... in fact on Linux I believe multiprocessing will actually use shared memory in some cases rather than pipes for communication. For the most part this is true though in practise, but it is a technicality rather than an actual given, and depends on your OS!\n\nIt will be slower though of course!\n\n> In CPython all threads use the global interpreter lock\n\nThey are now working on allowing you to turn off the GIL. It is still experimental but has been added to Python 3.13 if I recall.\n\n> Green threads\n\nThe main distinction between green threads and async await is that async/await is an explicit syntax where scheduling only occurs when you await something else, whereas green threads are usually a little lower in level and deal with silently switching the program between virtual threads emulating what the OS does but in user space.\n\nI mention this because languages like Java still have the concept of futures/tasks that run in virtual/green threads.\n\nOne can also use green threads in Python if they wish. The gevent library for CPython will let you do this, or if you are using GraalPython, then you have the JVM's virtual threads directly!\n\n=====\n\nI think it may also be worth name dropping the concept of multiple interpreters in a process as a middle point between CPython GIL'd threads and CPython multiprocessing. I won't go into too much detail on that for now as it is one to look up if interested!",
            "Only when the programming language runs the threads in separate cores. But threading by itself does not equal parallelism. Generally speaking, threads would be running sequentially on a single core but switched between really quickly by the CPU scheduler. You can only truly do two things at the same time when using multiple cores.\n\nhttp://www.danielmoth.com/Blog/threadingconcurrency-vs-parallelism.aspx",
            "In fact this is only true for pure Python code as can be read in this great post [https://stackoverflow.com/a/74936772](https://stackoverflow.com/a/74936772). Some code written in C is not affected by the GIL and so threads can run truly parallel on multiple cores.",
            "> This is not always true... in fact on Linux I believe multiprocessing will actually use shared memory in some cases rather than pipes for communication. For the most part this is true though in practise, but it is a technicality rather than an actual given, and depends on your OS!\n> \n> \n\nRegardless of any technicality, this is only going to confuse OP more. How Linux handles memory allocation in the background is a separate and unrelated discussion to the question of whether, from the perspective of the code, a process can simply add/take from the same memory as one of the other processes.",
            "\"shared memory\" between processes is still not a direct access. On CPython, the data going through it still needs to be serialised/deserialised.",
            "Thanks!",
            "Via mmap, it is a direct access technically. The fact python marshals the objects first is a CPython constraint rather than a general constraint.\n\nIt comes down to semantics at some point though, as everything is just transformation of data.\n\nMy point was around the fact shared memory is possible, it is just CPython's design that doesn't make use of it in a multiprocessing context.\n\nPython exposes shared memory directly as a memorymap like type, see https://docs.python.org/3/library/multiprocessing.shared_memory.html#multiprocessing.shared_memory.SharedMemory.\n\nYou could say this is still serialization, but to that I'd then respond that any form of data manipulation is serialization as it is stored as bytes in memory. All this does is set up the mmap region and lock it safely.",
            "Ok, quick follow-up question then. Here is an example from the python docs. It's combining async (single-thread) with a new thread for #2: [https://docs.python.org/3/library/asyncio-eventloop.html#executing-code-in-thread-or-process-pools](https://docs.python.org/3/library/asyncio-eventloop.html#executing-code-in-thread-or-process-pools)\n\nThere's no benefit of doing this in Python except to run blocking IO code in a separate thread, right? Are there any situations where you would use multiple threads + async together?\n\n    async def main():\n        loop = asyncio.get_running_loop()\n    \n        ## Options:\n    \n        # 1. Run in the default loop's executor:\n        result = await loop.run_in_executor(\n            None, blocking_io)\n        print('default thread pool', result)\n    \n        # 2. Run in a custom thread pool:\n        with concurrent.futures.ThreadPoolExecutor() as pool:\n            result = await loop.run_in_executor(\n                pool, blocking_io)\n            print('custom thread pool', result)\n    \n        # 3. Run in a custom process pool:\n        with concurrent.futures.ProcessPoolExecutor() as pool:\n            result = await loop.run_in_executor(\n                pool, cpu_bound)\n            print('custom process pool', result)",
            "I think the point about serialization and not shared memory in the sense that threads offer it is valid even outside of CPython. You cannot access another process' memory space \u2014 you have to allocate a separate buffer. And this buffer is not usable in the same way that your process' memory is normally usable in Python. It's effectively just a byte array that's shared between processes, not a unified memory space. For example, you can't allocate arbitrary objects there to share them between two processes. Unless the class has special support for using a dedicated backing store like NDArray, you're going to have to serialize it to the shared buffer \u2014 you can't simply share the object.",
            "i cant think of any reasons immediately that are not bespoke.\n\nWhen I originally wrote a discord library years ago, we had to use threads to deal with file IO from asyncio since no cross platform solution exists to perform non blocking IO to files.\n\nAWS Lambda (a serverless platform) runs one \"function\" per invocation, those are non-async functions, so in reality if you use asyncio with that you'd likely have an event loop per invocation, which is roughly similar to what you describe.\n\nThe thing I think is worth being aware of is that Python scales very poorly compared to other languages purely due to the global interpreter lock. This means things like asyncio, process pools, and threadpools will eventually be your bottle neck... we're talking high traffic here. At this point, in a well designed environment, you'll likely find you need to scale horizontally anyway (multiple python processes, sitting behind a load balancer).\n\nWith all this stuff... my suggestion is to keep it simple. Profile your code. Improve once you have evidence for it.\n\nIf you are serving 10,000 requests per day, then none of these solutions will make any difference to you, so choose what you are comfortable with and what is easiest to use.",
            "Good to know, thanks"
        ]
    },
    "The Problems with Celery": {
        "title": "The Problems with Celery",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1dcntpa/the_problems_with_celery/",
        "content": "Hey everyone - I wrote up a blog post on the problems that we've encountered using Celery: [https://docs.hatchet.run/blog/problems-with-celery](https://docs.hatchet.run/blog/problems-with-celery) \n\nOur issues with the Celery project were part of the reason why we started [Hatchet](https://github.com/hatchet-dev/hatchet). \n\nWould love to hear comments or feedback! ",
        "num_comments": 6,
        "comments": [
            "This is an ad for their startup thinly veiled as a technical blog post\u2026",
            "Should've called it peanut butter.",
            "Isnt the gevent pool type similar to async/await, async tasks?",
            "The problems are celery.",
            "True but those problem are real so I see this blog post as real one"
        ]
    },
    "EFT - A file extension for implementing user created themes": {
        "title": "EFT - A file extension for implementing user created themes",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1dcwu86/eft_a_file_extension_for_implementing_user/",
        "content": "# What my project does\n\nAllow developers to implement custom themes into their programs, while having a file format that is human readable\n\nExample:  \n`my_theme.eft`\n\n    - My Theme\n    \n    background_color : 255,255,255 : Color\n    title : \"Hi\" : String\n    number : 5 : Int\n    enabled : true : Bool\n\n# Target Audience\n\nDevelopers & users who make themes\n\n# Comparison\n\nCSS Themes - May be difficult to implement, difficult to understand for people who aren't programmers\n\nJSON Themes - Viable option, may not be readable in some cases\n\nGitHub: [https://github.com/PossiblePanda/EFT-py](https://github.com/PossiblePanda/EFT-py)\n\nContributors are greatly appreciated :)\n\nIf you have questions feel free to ask",
        "num_comments": 12,
        "comments": [
            "This is just yaml with added steps",
            "Pick a very different name lol. EFT is like 85 used terms already most of which are banking, healthcare and logistics.",
            "escape from tarkov theme? amazing",
            "I guess, but you can say the same with many other file extensions, why doesn't everything use json?",
            "Honestly yeah, the name could use a bit of work. EFT stands for \"Easily Formattable Theme\", which doesn't really roll off of the tongue very well",
            "\ud83d\udde3\ufe0f",
            "https://xkcd.com/927/",
            "Maybe just \u201ceasy-theme\u201d",
            "It\u2019s alright I just have major ptsd about sitting on hold with the electronic funds transfer department of an insurance company while trying to get a hold of the electronic file transfer department (usually called edi but was sworn to me to be eft).",
            "ok",
            "Could work, I don't like .ET though",
            "LOL"
        ]
    },
    "Flappy Berd in PyQt": {
        "title": "Flappy Berd in PyQt",
        "score": 51,
        "url": "https://www.reddit.com/r/Python/comments/1dbinqz/flappy_berd_in_pyqt/",
        "content": "Hello there\n\n**What my project does:**\n\nI\u2019m excited to share my Flappy Bird clone, written in PyQt! This project captures all the fun of the original game with key features like pressing the spacebar to make the bird jump. Yes, I know, getting that key feature was challenging! \ud83d\ude03 As Richard Watterson once said: \"10/10 game, would play again.\"\n\n**Target Audience**\n\nThis game is for anyone who\u2019s bored and looking for a quick, fun way to pass the time. Whether you're a casual gamer or just curious, this Flappy Bird clone is a not so good way to relive the original experience.\n\n**Comparison**\n\nThink of it as a faithful recreation of Flappy Bird with a PyQt twist.\n\n  \n**Update**\n\nI had some time, so I made an update. The pipes now start from the middle.\n\n**Code**\n\nYou can check out the code [here](https://github.com/Ryoku123/FlappyBerd). Please note that the code is definitely not the best, but hey it works!",
        "num_comments": 7,
        "comments": [
            "FlapPy",
            "Why do you say this is not a good way to relive the original experience?",
            "Hey, to add some nice \u201cfinished touch\u201d it would be nice to create a sort of downloadable binary that users can just download and execute to play.",
            "The pipes take so long to reach you when starting XD  \nBut other than that pretty cool  \nMaybe just add a requirements.txt file",
            "I feel the original Flappy Bird was more polished. My version isn\u2019t as refined, which is why I said it's not the best way to relive the original experience. However, I'm proud of it, and I appreciate you giving it a try (if you did)!",
            "Done",
            "Yeah, I know, I didn't want the pipes to appear out of nowhere, so I decided to simply move them offscreen for now. \ud83d\ude02\n\nAlso, I'm really glad you tried out my game! Thanks for giving it a go!"
        ]
    },
    "I have made an open source library for logging errors / messages :)": {
        "title": "I have made an open source library for logging errors / messages :)",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1dcnr8p/i_have_made_an_open_source_library_for_logging/",
        "content": "# What my project does\n\nAllow developers to easily log errors, messages, and warnings to the console, and an optional log file.\n\n  \nHave you ever released a project, and then somebody runs your project and encounter an error, and you need to see their console? No worries, pandalog can store logs in a file wherever you choose. You can also have errors automatically be sent in the console & log through pandalog.\n\n# Target Audience\n\nDevelopers\n\n# Comparison\n\nusing pandalog has many benefits over just using `print`, such as storing logs in a log file, colored output in console, extremely configurable\n\nYou can download it on pypi by running `pip install pandalog`\n\nGitHub: https://github.com/PossiblePanda/pandalog\n\nContributors are appreciated :) ",
        "num_comments": 42,
        "comments": [
            "Python already comes with a builtin logging module. You can read the documentation [here](https://docs.python.org/3/howto/logging.html). The only feature you are adding is colour but that\u2019s also available have a look [here](https://github.com/xolox/python-coloredlogs)",
            "There is a built-in Logging package with many more features.",
            "As someone with 18 years of experience in software engineering, the last thing I would do in my life would be adopting a library for something as important and meaningful as observability made by someone that doesn't know the basics of the language they used.\n\nI'm guessing OP is younger than my career, but that's just a guess.",
            "This kind of thing really ruins this sub. I used to enjoy reading about python stuff here, but recently it's just posts by people who don't know that `logging` exists, or the twentieth incorrect article about decorators, or other rubbish. \n\n`logging` is the built-in library for generating log messages. It's maybe not the best and most wonderful library in the world, but it's the *only* library that you should consider if you're writing code that will be used by others, because then they can use the built-in functionality to control whether or not they will see log messages from your package.",
            "Yeah maybe it already exists but its still a cool project, don't let the negative comments affect you :)",
            "Too many newcomers to Python (or any subject domain) don't get to know it well enough before they think themselves to be experts in the field.\n\nFor Python, my recommendation is that you read or at worst scan, all the documents that were installed beside the Python executables and libraries when you install the official release from https://www.python.org/ and you do the same for any package you install from https://www.python.org/ or read/scan all the Python online documentation at these web sites.\n\nThen, you will not be wasting time reinventing the wheel.",
            "```\nfrom pandalog import logger\n\nlogger.logInfo(\"This is a message\", \"TEST\")\n```\n\nhave you heard of PEP-8?",
            "i'm gonna use yours, i don't like to rely on too much built-in stuff",
            "Thanks! Unfortunate because I spent a while making it and didn't know lol",
            "Diggity darn, I did not know that",
            "Yeah, definitely not 18 years of experience, I'm just doing this for fun and didn't do any research before. Just because it's not optimized (I made this in a few hours) doesn't mean that I don't understand the basics of the language.",
            "> it's the only library that you should consider if you're writing code that will be used by others, because then they can use the built-in functionality to control whether or not they will see log messages from your package.\n\nthis is debatable. There are well-informed 3rd party logging packages (e.g. structlog and loguru) that were written by people who were well-educated about the ins and outs of the standard logging library before they undertook their efforts.",
            "I made this for fun bruh, I'm not asking for people to use it or do anything. I posted this to get feedback but this is showing that reddit sucks",
            "Thanks lol, seems like a lot of the people on reddit only care about getting karma or whatever, xD",
            "yap yap yap, if you don't have anything meaningful to say get outta here",
            "Why? The built-in logger is perfectly fine.",
            "Thanks! :) Let me know how you like it, and if you have any issues.",
            "Confessions like this are a vote against adopting a solution because they mean the person has not looked far and deep for a solution to a problem.\n\nBuilt-ins have the advantage of being used much more than the needs of an individual and thus can be more robust. Their downside is that they can be built by committee and can get too heavy or too light for use. That creates the opportunity.\n\nThe best next generation solutions can precisely articulate the problem with the current generation they are attempting to solve.",
            "Maybe you should check python module of the week website, it's called pymotw.",
            "You built a library, you surely know the basics of programming (and even more, apparently). But you don't know the basics of the Python language, fella. You created multiple posts about the brand new tools you created, but you created them based on what you think other people needs, without any checking for users other than you. You didn't even googled \"how to log in python\" or \"python log library\". You know that YOU like and/or need these tools and you used your knowledge to make'm. And that's ok, you were just excited with a new tool, looking for some challenge and to contribute with other people's software. Congrats and thanks for that. Keep studying and learning. But before starting a new project, please do some research. Maybe your needs are satisfied by existing tools. And even if it's not true, there's a huge change you'll find a tool that satisfies your needs partially and whose team would welcome your contribution to implement the features you need in that tool.",
            "No, this sub sucks because of the large number of beginner level posts like yours. Head over to r/rust and see how the quality compares. Most of the time there's some interesting discussion. \n\nEveryone who uses python seriously, knows about logging. It's so basic. This is what r/learnpython is for. \n\nIt's like some college teacher with a first-year class gave an assignment at the end of the first week to write a package and post it on r/python.",
            "Real",
            "because i can",
            "Hey I might be wrong here but I think he was being sarcastic. Regardless I'm sure making this was a great learning experience for you.",
            "what the fk are u even trying to say?",
            "not sure if I understand what you mean but alright",
            "Thanks for giving some valid criticism :) I finished making a similar logging library in C++ (I knew they had alternatives but wanted my own), and they didn't have a built in solution so for some reason I just assumed python didn't either xD I'll definitely take this into account next time.",
            "not my problem, why don't you head over to rust and look at the cool things they make over there? this isn't a beginner level post. It's a fun project I made in an hour, reddit is unfortunately filled with a bunch of people who have no life and just sit on their computer all day and say stuff like this",
            "ah, maybe. but yeah it was pretty fun to make :) The main reason I made it was because I made something similar in C++ and was unaware that python already had something like this xD",
            "nope, i wasn't beeing sarcastic. and I don't mind the downvotes.",
            "This provides further reason to think twice before using your library because it shows inexperience.\n\nMy guess is you are probably young and early in your career. Some more learning needs to happen for you.",
            "Sorry if I came across as rude. I didn't mean to target you specifically. I'm just frustrated with this sub at the moment.",
            "Yeah that\u2019s the benefit of python, I\u2019m sure you can develop something else more convenient. Keep going OP!",
            "uhh ok? just trying to have fun making libraries \ud83e\udd37\ud83c\udffb I quickly made this library in a day, that doesn't show \"inexperience\".",
            "it's alright, I get it. maybe talk to the moderators about it though",
            "In short he\u2019s saying you didn\u2019t know this type of logging library already existed bc you didn\u2019t look deep enough before building. Truly weathered programmers would have found the logging module before building this. Could have been better phrased but hardly a knock on your actual abilities. \n\nThat\u2019s this person\u2019s way of saying inexperienced. Which I mean is kind of true right? People that have been programming for a long time do not waste time \u201creinventing the wheel\u201d for no particular reason. You even said yourself that discovering the already built library was unfortunate.",
            "Ok, let me explain.\n\nThat shows coding experience at a personal level. That is commendable but different than what I and others like me are saying.\n\nYou can use this logging library for your own use and maybe others can use for personal projects or for learning.\n\nThe crux of the matter is in your pitch - You have pitched it as a general purpose logging library. In doing so, you have not looked into whether such a library already existed, what made your library better or different than existing solutions, who should be using it, why and what support can they expect.\n\nConsider this - You come across as someone who is not yet an expert in Python and made this library in a day. Then what stops the true experts working on and with Python from making a similar or better library?\n\nThe growth from coding to design to architecture to solutions is one that differentiates the newcomers from the experts.",
            "Yeah true, I just didn't really make it to be professional or anything, even if I found out that a library already existed I would probably still make it. I mainly made it since I haven't made anything in python in a bit.",
            "Thank you for being so articulate.\n\nI made my point rather badly and you did a great job.",
            "nobody reading allat",
            "![gif](emote|free_emotes_pack|facepalm)",
            ":)"
        ]
    },
    "Just released my first Python package: Melodica Notes \ud83c\udfb6": {
        "title": "Just released my first Python package: Melodica Notes \ud83c\udfb6",
        "score": 23,
        "url": "https://www.reddit.com/r/Python/comments/1dblgl3/just_released_my_first_python_package_melodica/",
        "content": "Hey everyone!\n\nI\u2019m excited to share my first Python package: **Melodica Notes**. It's a CLI tool aimed at helping melodica players with musical scales, chords, and harmonics.\n\n**What My Project Does:** Melodica Notes helps melodica players by providing easy access to musical scales, chords, and harmonic information directly from the command line. It's designed to be a simple yet powerful tool for both beginners and advanced players.\n\n**Target Audience:** This project is meant for anyone who plays the melodica (or piano), from casual hobbyists to serious musicians. It's also a project for developers interested in music-related applications. While it\u2019s fully functional, I consider it an evolving tool and welcome contributions to enhance its features.\n\n**Comparison:** There are other musical tools out there, but Melodica Notes is specifically tailored for melodica players. Unlike general-purpose music theory tools, this CLI focuses on the needs and nuances of melodica playing, making it a unique addition to the musician's toolkit.\n\nI\u2019d love to hear your thoughts and suggestions! Whether it's feedback, feature ideas, or pull requests, I welcome all contributions. Your insights can help make this tool even better.\n\nCheck it out on [PyPI](https://pypi.org/project/melodica-notes/) and feel free to dive into the code on [GitHub](https://github.com/vhsenna/melodica-notes).\n\nThanks for your support, and happy coding and playing \ud83c\udfb5",
        "num_comments": 8,
        "comments": [
            "I don't mean to be pessimistic, but why not just print out the scales and chord charts? Seems like it could just be a series of images? Melodica players...who are also python savvy. I do dig the ASCII art though!",
            "Very cool project!  \nMaybe a feature you could add in the future is generating images for the chords and scales (even though i really like the ascii art)",
            "The GitHub link is giving 404.",
            "Qual a ideia? gerar melodias ou apenas mostras as escalas?",
            "Have you tried exploring with the music21 python library? It contains a lot of support for music theory. For example, you can derive the notes for scales (https://web.mit.edu/music21/doc/moduleReference/moduleScale.html) and also derive the notes for chords (https://web.mit.edu/music21/doc/moduleReference/moduleChord.html) \n\nIn theory you could leverage music21 to retrieve all music theory info, perform any required transformations, and then display it as ASCII art",
            "Because it's a CLI tool",
            "thanks, I fixed it",
            "Escalas, acordes e progress\u00e3o harm\u00f4nica. Est\u00e1 tudo l\u00e1 na documenta\u00e7\u00e3o. Deu um trabalh\u00e3o escrever"
        ]
    },
    "steer - An interactive CLI tool to write json and yaml file from JSON schemas": {
        "title": "steer - An interactive CLI tool to write json and yaml file from JSON schemas",
        "score": 2,
        "url": "https://www.reddit.com/r/Python/comments/1dbyrs2/steer_an_interactive_cli_tool_to_write_json_and/",
        "content": "**What my project does:**\n\nIt's an interactive tool to help you write json or yaml based on a JSON schema. I built this because I thought it would be helpful to write values.yaml files for Helm charts. But it can be used for a lot of other things like CICD configuration, OpenAPI specifications, etc.\n\n**Target Audience**\n\nDevelopers mostly, I guess\n\n**Comparison**\n\nI haven't seen anything similar to this. Except maybe spotlight for writing OpenAPI specs, except steer is from the command line.\n\n**Code:**\n\n**Here's the GitHub repo** [https://github.com/jcoelho93/steer](https://github.com/jcoelho93/steer)",
        "num_comments": 2,
        "comments": [
            "The sample doesn't really show how this could be useful.",
            "Thanks for the feedback, I'll work on it."
        ]
    },
    "Async Python adoption?": {
        "title": "Async Python adoption?",
        "score": 40,
        "url": "https://www.reddit.com/r/Python/comments/1dbasxr/async_python_adoption/",
        "content": "Are there any studies, large-scale polls, or anything about async coding adoption in Python? \n\nI wonder how widely the community accepts it, how widespread its usage is, and what the general sentiment is towards it.",
        "num_comments": 59,
        "comments": [
            "Due to the dominating advantage of asyncio on performance, it has become my default option whenever I\u2019m doing network IO. From my experience, there is a quite vivid ecosystem in python asyncio, I find it quite easy to find async lib for database, MQ, s3, etc.\n\nDo note that if you want to use asyncio in your app, you should design your whole application with async interfaces from the start. It can be very tedious and error-prone to maintain both a synchronous and an asynchronous version of your codebase simultaneously.\n\nIn cases where I cant find an async lib for my use case and I\u2019m being too lazy to create my own at the moment, I would go back to threading, but this rarely happens.\n\n# Edit for update:\nAsyncio is more performant than threading, but they are not mutually exclusive. When there is sync code you can't avoid, threading can prevent the synchronous code from blocking the event loop, allowing your async functions to switch context. When refactoring your whole codebase into async is not an option, you can apply techniques such as (AOP), (perhaps use decorator), to make your async code transparent to your sync code, and vice versa.\n\ncheckout my project [premier](https://github.com/raceychan/premier/blob/master/premier), a lib for throttling both sync and async functions using redis, to see what I mean in code.",
            "I only use asynchronous approaches.. and pydantic..",
            "It's used, you can look at github but it's not a global feature that would overtake non-async approaches. It's a strong niche.",
            "I have been wondering why Quart isn\u2019t more widely adopted than it currently is",
            "I really tried to use it, but in the end I always go back to some implementation with threads. \n\n\nIt has its advantages, first of all being a robust implementation that takes away all the conplex stuff associated with multithreading, and second of all It Is a standard for concurrent code. But I like messing with threads sooooo....",
            "I have basically given up on Python Async and write any concurrent applications in Go.\n\nI have many Python productions apps written both sync and async, and I just can\u2019t take how sloppy async is.\n\nIf I had to write a new project that required python and concurrency, I would use gevent.",
            "Easiest observable to know how popular async is by looking at the download rates of libraries that have a sync implementation and a separate async implementation. For example:\n\n- [https://pypistats.org/packages/mongo](https://pypistats.org/packages/mongo)\n\n- [https://pypistats.org/packages/motor](https://pypistats.org/packages/motor)\n\n  \nAccording to this Mongo (sync) had almost 24k downloads and motor (async) had almost 2 million downloads last month. That is enough of a difference for me to objectively say async won and is now industry standard. Of course, I would want to do that same analysis across several packages across different parts of the application.",
            "i hate async syntax",
            "I use gevent. It mostly works though adoption is falling over the years. asyncio kinda sucks, needing different libs for everything.",
            "Home Assistant relies heavily on async but they have a strange mixture of async and sync code juggling with threads. You might not see often the async keyword but it\u2019s async.",
            "Async in Python is cancer (once you start using it, eventually all your code will have to become async). Don't.\n\nUse greenlets instead, if you must.",
            "[deleted]",
            "I would say only Fastapi, tortoise and httpx users are actively using async python. \n\nOther than those frameworks the ecosystem looks pretty bad",
            "Wait, does boto3 supports asyncio?",
            "While not particularly beautiful, it is perfectly possible to run async functions from synchronous functions.",
            "I can attest, attempting to integrate and refactor my program to use async was an absolute disaster - even using multithreading was easier",
            "I don't think it's meant to overtake anything but to coexist and solve specific use-cases. :) Do you maybe know if anyone tried to measure the adoption?",
            "I would guess that while Flask really made a splash when it came on to the scene, Quart was somewhat late and came into an existing ecosystem of Flask-inspired async frameworks",
            "The next gen of ASGI frameworks are just better tbh.",
            "That is genuinely interesting! What do you mean by sloppy? :)",
            "You got this twisted -- PyMongo is the sync mongo driver, not mongo. It has 28 million a month.\n\nThis wouldn't have made sense of the face of it because PyMongo is a dependency of Motor since Motor is essentially PyMongo wrapped in a thread pool executor.",
            "Someone else mentioned async boto3 (AWS stuff), and it is actually the opposite:\n\n- [https://pypistats.org/packages/boto3](https://pypistats.org/packages/boto3)\n\n- [https://pypistats.org/packages/aioboto3](https://pypistats.org/packages/aioboto3)\n\nWhere boto3 (sync) had 1.25 \\*BILLION\\* downloads and aioboto3 (async) 2.3 million downloads last month. That is a huge difference in the other direction. So your milage may vary.",
            "yes that is how async await works.\n\nif you start a new project be sure to start off with async.\n\nif you have an existing project... well good luck with IO. in that scenario adding asyncio is a pain like the commentator says but greenlets, multiprocessing, multithreading packages all have their various pain points.",
            "Async is a different paradigm, and indeed it works best if you do it end to end.\n\nBut that's not exclusive to Python.",
            "This really isn't a problem. I've been primarily doing async for years. I've never found it to be an issue in the slightest.",
            "You have a skill issue.",
            "IO is arguably the most important part of applications that make money. This really isn't niche or a crutch. Async is truly just superior for web dev -- which is why it's a major component of C#, Node, and now Python.",
            "You\u2019re mistaken. Websockets are also async, eg listening to 100s of tickers for processing financial data wouldn\u2019t work with blocking websockets. Look at TTL cache, some implementations only invalidate entries on next access. You can create an async task to do it periodically for you, reducing memory footprint. There are plenty of use cases for async python.",
            "Async libraries exist for Redis, Postgres, aiobotocore, Kafka, SqlAlchemy, Starlette and its derivatives, Connexion\u2026 the list goes on. Respectfully you don\u2019t seem to have a great deal of exposure or experience to the ecosystem and probably shouldn\u2019t comment on it.\n\nIt\u2019s very rare to not be able to find a supported async library for any kind of network or disk I/o use case these days.",
            "No. Aioboto3 exists as an unofficial version but it causes some really annoying dependency headaches.",
            "https://pypi.org/project/aioboto3/",
            "Aiobotocore",
            "What's the easiest way to do this?\n\nMy sync functions are just starting an AIO event loop, letting the async finish and returning the result, but it seems so clumsy.",
            "It's pretty mainstream at this point.  Anyone who needs the performance boost is probably using some form of it.  I mean, it's been part of Python since 3.5.",
            "You can do this yourself.\nGitHub APIs can be used to fetch projects and analyze references like this.",
            "https://charlesleifer.com/blog/asyncio/\n\nI agree with everything here.",
            "Lol, I didn't even catch that.  Thanks.",
            "But that may be because boto3 is official and aioboto3 is not.",
            "Also could be that for lambda you dont need to include boto3 in your dependencies in production as its there by default",
            "Also lots still use gevent.",
            "Trade offs are ok.\n\nHaving to go in 100% or not at all is not a trade off. That's brute force.",
            "I have several existing projects that use threading just fine, including analytics engines comfortably serving several M requests per hour. Greenlets and pools work really well to reduce the overhead, and aome things are just way simpler in that concurrency model.\n\nAsync is nice, because its a workaround for the GIL. It has its quirks, but so does threading.\n\nIf performance is the primary concern, well, then Python wouldn't be my first choice anyway.",
            "I find this hard to believe. https://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/",
            "No.\n\n.https://www.reddit.com/r/Python/s/VJsfFk1Gs0",
            "Threading solves any IO problems tho, and with green threads the overhead is negligible.\n\nGo is pretty much purpose built for writing webservices in, and doesn't even have a native async implementation.\n\nThat doesn't mean async doesn't have its place, but in Python, that place currently exists primarily because of the GIL.\n\nAnd since we are already seeing that limitation being lifted gradually (check Py3.13), the nice is certainly going to get smaller.",
            "For sure. But no libraries/frameworks means nobody is doing any of that **today**.\n\nTake for example kafka: kafka python, confluent kafka etc. all of those use sync apis. You can lecture everyone on how amazing async is, but the reality is that nobody is building anything to actually leverage async.\n\nExcept of course the libraries i mentioned earlier. Those are working **today**.",
            "asyncio is different from \"async\". There are websocket libraries that just using python threading.",
            "Existence doesn\u2019t translate to high quality. For instance, last time i checked confluent kafka was still the fastest impl out there.",
            "As I said, it\u2019s not beautiful. But when you notice that you really need some stuff to be done asynchronously, and the rest of your app is synchronous, you might as well use asyncio.run(\u2026).",
            "You can use asgiref's `run_sync`",
            "I only use boto3 cause it's what their docs said to use. And most of the stuff I do with aws and python is to just catch an event. \n\nI do use a lot of C# in other applications and I use a lot of async there so it's not a problem with async. Just different tools for different jobs.",
            "I don't really see what this blog is going on about. Only IO code has to be async. It's very easy.",
            "Async is significantly easier to manage than threads ever will be. There's a reason it exists and is very popular in languages without a GIL.\n\nYou also seem to be conflating the concepts heavily. They're not at all equivalent. You need to read up on concurrency vs parallelism. Concurrency is a useful paradigm and it is fundamentally different. GIL-less threading is parallelism and comes with all of the associated memory access and encapsulation issues.",
            "You are talking complete nonsense. Aiokafka exists. How can you say \u2018nobody\u2019, do you have some magical insight into the entire industry?\n\nWe are building async Kafka apps by the way. Maybe consider less hyperbole in your comments.",
            "You seem to not understand why threading vs async for network access is a losing solution.",
            "The blog corraborates what I said: async will eventually creep  everywhere in your code base. \n\nTo me that's a tradeoff I am not willing to take.",
            ">Async is significantly easier to manage than threads ever will be.\n\nHave to disagree here. Reasoning about threads is linear, reasoning about async, by definition, is not.\n\n>There's a reason it exists and is very popular in languages without a GIL.\n\nThere is: Many programmers first exposure to programming these days is JS and node, where async is the only concurrency model available.\n\nThis is neither good nor bad. I come from the C-Wotld, so threading is just a more natural fit for how I reason about programs.\n\n>You also seem to be conflating the concepts heavily.\n\nNo, I really don't, and if you disagree, quote wher you think I do. I am a senior backend engineer, so, yeah, I think I have my fundamendals about the difference between parallel execution and concurrency down, thank you very much.",
            "https://pypistats.org/packages/confluent-kafka\n\nhttps://pypistats.org/packages/aiokafka\n\nConfluent Kafka has about an order of magnitude more downloads.",
            "? never claimed anything about performance. I'm very familiar with asyncio and it's advantages with sockets. There are still libraries using threading for websockets though.",
            "Confluent kafka supports async producers. Even on their website, they mention to avoid flushing in an async environment."
        ]
    },
    "Understanding Python Decorators": {
        "title": "Understanding Python Decorators",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1dcfzo8/understanding_python_decorators/",
        "content": "# Without using decorators I think mostly we can\u2019t build a decent application. They are everywhere.\n\nI wrote an article to get an understanding of Decorators.\n\n[https://newsletter.piptrends.com/p/understanding-python-decorators](https://newsletter.piptrends.com/p/understanding-python-decorators)\n\nI hope this will give you a good understanding of Decorators if you don't know about them.",
        "num_comments": 31,
        "comments": [
            "> Without using decorators I think mostly we can\u2019t build a decent application. \n\nI wish people would avoid making such silly, sweeping claims. If you have something interesting to say, there is no need to hype it to the absurd.",
            ">A Python decorator is a function that takes in a function and returns it by adding some functionality.\n\nThis is wrong, four times.\n\n- A decorator does not need to be a function, but a Callable.\n- A decorator does not need to take a function, it can take a class as well.\n- A decorator does not need to return the function that it decorates, it can return any object including `None`.\n- A decorator does not need to add any functionality.",
            "The decorator syntax is really just a little bit of syntactic sugar - we could manage fine without it - we'd just have to type a few more characters...",
            "You have misspell; should be exiting not existing \ud83d\ude09",
            "Remember that decorators are just syntactic sugar. In other words, at the cost of more code, possibly less readable, you can do absolutely the exact same thing without using decorators.",
            "Unpopular take. Decorators are an unfortunate syntax hack that wouldn't be needed for the most part if Python had fully supported anonymous functions.",
            "I made (arguably) decent applications before there were decorators.",
            "Did you know they nonody ever coded in other languages before python invented decorators??  \n\nIt reminds me when I was a kid and the new toy was the *one I'd use forever and ever*.  \nIt usually lasted a week.",
            "In 98% of cases, I would say he's right.",
            "What is the different of a function and a callable?\n\n\nA function and a class method are callables?\u00a0",
            "Thank you for sharing.\n\n1st point I don't know, for this If you can please give me an example I can learn from it. rest I agree. To have an understanding gave that definition. In the article end, mentioned about class-level decorators.",
            "By the way, if you read article you can see that I explained from that angle only",
            "True",
            "Thank you. Corrected it.",
            "Umm.... What?\n\nI'm not a big fan of decorators, but are you implying that you'd rather write the function as an anonymous one pass it through whatever chain of other functions you want to operate on it with, and then assign the result to the final function name?\n\nThat just seems like decorators but worse, which is saying something.\n\nThere's no reason you couldn't define the function as _ and then do what I think you're advocating for.\n\nPersonally I'm just a fan of not programmatically manipulating your functions in most circumstances. In cases where it actually makes sense, the decorator syntax is quite nice.",
            "Right now I feel Decorator made things better. For example cache decorator, app route decorator in Flask and etc.",
            "To be clear, the decorator pattern isn\u2019t a Python invention.",
            "I am not sure if Python invented them or not. In Java annotations which are similar to decorators have been there for a long time.",
            "The first bullet point alone would fit for at least half of the decorators I use. I don't know your code though.",
            "Callables just need to implement the `__call__` method, functions and methods are defined with the `def` syntax",
            "So then why did you claim it\u2019s necessary to make decent applications if it\u2019s just syntactic sugar?",
            "What does it even mean to not be \u201ca big fan of decorators\u201d? Decorators are just one of many design patterns in Python and they are useful for a lot of things. Unless you\u2019re using them in crazy scenarios, what\u2019s there to not be a fan of?",
            "yep, pretty much. I think it's more syntactically consistent with the rest of the language, which I concede most other people probably don't care much about.\n\nAlso many uses of decorators, like the flask route decorator, require naming functions that you never actually call in the rest of your program. If naming things is hard, the first order of business should be to not give names to things that don't need them.\n\nedit: To note, I do enjoy using and writing decorators, and would encourage others to write them when appropriate. I just think if different design decisions had been made, a majority of their usecases would be moot.",
            "You should be ashamed of your post.",
            "upbeat muddle encourage direction party soup abounding heavy follow nail\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
            "Because there were great decorators which does so much of stuff for you. For example cache, app routes like that there is a long list",
            "I think people overuse them.\n\nThey immediately make your code not possible to statically analyze, so I don't like making that trade off, and I think that people don't consider that case, so... yeah... not a big fan.",
            "There is no syntax for decorating a lambda. But you can always wrap it in a decorator call, which would have the same effect as decorating a function, e.g. `your_decorator(lambda x: x*3)`.",
            "I use dataclasses.dataclass and mypy, no issues. Please could you expand about breaking static analysis?",
            "Mypy has specific built in support for that one. The trouble with decorators is that they run arbitrary code. So if you don't know what the decorator does, you can't predict what the output function will look like. This makes it very difficult to write static analysis tools.\n\nFortunately in many cases, decorators don't actually change the signature or return type of a function... but they could. So if you write  static analysis tools like mypy, your options have to make assumptions and hard code specific cases.",
            "Thank you"
        ]
    },
    "Random number generator + tracer ": {
        "title": "Random number generator + tracer ",
        "score": 1,
        "url": "https://www.reddit.com/r/Python/comments/1dbrwxd/random_number_generator_tracer/",
        "content": "Just released [https://github.com/isidroas/fortuna](https://github.com/isidroas/fortuna)\n\n# What My Project Does\n\nA didactic and minimal implementation of the Fortuna cryptographically secure pseudorandom number generator.\n\n# Target Audience\n\nJust for learning, not meant for production.\n\nEven if you are not interested in cryptography you could take a look at the tracer of functions and attributes. An example output is shown in the README and almost without polluting the business logic. You can find out how easy it is to interact with the tracer by seeing the decorators and class attributes of the files `fortuna/{__init__,generator}.py`\n\n# Comparison\n\nAs for the PRNG see [https://github.com/isidroas/fortuna?tab=readme-ov-file#other-implementations](https://github.com/isidroas/fortuna?tab=readme-ov-file#other-implementations) section in the README\n\nDo you know of any other existing libraries for tracing? I had to implement my own because I couldn't find anything similar. Neither [https://github.com/cool-RR/PySnooper](https://github.com/cool-RR/PySnooper) or [https://docs.python.org/3/library/trace.html](https://docs.python.org/3/library/trace.html) are equivalent.",
        "num_comments": 1,
        "comments": []
    },
    "Archand: Control your mouse entirely using hand gestures.": {
        "title": "Archand: Control your mouse entirely using hand gestures.",
        "score": 86,
        "url": "https://www.reddit.com/r/Python/comments/1db05gm/archand_control_your_mouse_entirely_using_hand/",
        "content": "Link: [https://github.com/prateekvellala/Archand](https://github.com/prateekvellala/Archand)\n\n# What My Project Does\n\nArchand allows you to control your mouse entirely using hand gestures which are performed in the air and captured via a webcam. Archand also has a speech-to-text feature which is activated by a specific gesture, transforming your spoken words into written text on your computer. With this, you can perform any task you would normally do with a keyboard as well, such as visiting websites, writing emails, texting people, etc.\n\nArchand has the following features, each controlled by a unique hand gesture:\n\n1. Move pointer\n2. Single left click\n3. Single right click\n4. Double left click\n5. Hold left click and move pointer (for dragging, etc)\n6. Scroll up\n7. Scroll down\n8. Enable your microphone, and then whatever you say will be converted to text and typed where your cursor is blinking (automating keyboard functionality)\n\n# Target Audience\n\nEveryone\n\n# Comparison\n\nThere is no comparison with any other projects, as I have not seen any that incorporate all the features I have implemented, which work accurately with both low-resolution integrated laptop webcams and high-end webcams. All the projects I've encountered with a similar concept mainly fall into three categories:\n\n1. They\u00a0don't work at\u00a0all, failing\u00a0even to\u00a0move\u00a0the\u00a0cursor\u00a0smoothly.\n2. The cursor moves pretty well and smoothly, but they do not fully automate the mouse, as they always lack some other feature like double-clicking, right-clicking, or scrolling, etc.\n3. They have many features that work well, but require high-end webcams, such as the Logitech Brio.",
        "num_comments": 17,
        "comments": [
            "Bruh. I already control my mouse using entirely hand gestures.",
            "Can you imagine the command center you could build and no keyboard (voice) now no touch of the mouse either. You are now moving the files on you 80inch TV with your hands pretty cool dude possibilities are huge. What limitations have you ran into?",
            "Cool, tha ks for sharing. \n\nWhy is your recommend python version the oldest supported one?",
            "Pretty cool project. It reminds me of a drawing app I built for a school project. It was written in Java, and made use of the Xbox kinect. Different gestures allowed you to select different drawing modes and styles. Also, it wasn't limited to the XY coordinates, but can also detect how far away one is from the camera thanks to the depth sensors of the kinect; This made for a wider selection of gestures and drawing styles.",
            "Wow! This is amazing! Tried it both on my logitech brio and laptop.",
            "Turning on the mic is actually funny",
            "How else are people controlling their mouse? Foot gestures?",
            "Technically correct, the best kind of correct!",
            "[deleted]",
            "A big one is that, If you're too close to the camera, it becomes difficult to reach the corners or edges of the screen, which can make tasks like closing apps or using the taskbar problematic. So, it would require maintaining a good amount of distance from your laptop for it to work well, which may not always be possible or preferable. However, using an external webcam is an easy fix for this issue.",
            "The autopy library can only be installed on Python 3.8 or earlier versions. I just found 3.8.10 to work the best.",
            "Lol how are all the jokes not about this? Can you imagine using this in the office?",
            "[with a leash, obviously](https://m.media-amazon.com/images/I/51w8sWDO8aL.jpg)",
            "You don't use your teeth like everyone else?",
            "bear hurry cats rotten quiet connect fanatical cagey nail shrill\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
            "Yeah I just place my hand on the mouse and move it.",
            "That's too bad. I don't have 3.8 on anything for years.",
            "Exactly my first thought :D"
        ]
    },
    "CopySave - And easy to use clipboard manager": {
        "title": "CopySave - And easy to use clipboard manager",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1dbz3o0/copysave_and_easy_to_use_clipboard_manager/",
        "content": "# What my project does\n\nCopySave is an app that saves everything you copy in your clipboard locally, so it can be used later, thus saving time.\n\n# Target Audience\n\nEveryone who works at a pc, with data. Programmers, especially.\n\n# Comparison\n\nI couldn't find any similar applications. Of course there are some better ones out there.\n\n[https://github.com/mpiele/CopySave](https://github.com/mpiele/CopySave)",
        "num_comments": 16,
        "comments": [
            "Your comparison is \"I couldn't find any other clipboard managers\"? Damn dude.",
            "Doesn't windows do that natively?\n\nI do have a Copy/Save/Paste idea that I would love to see but it requires hardware integration. Basically it would work similar to how the old AM radios in cars worked.\n\n\\* You highlight some text.\n\n\\* You press and hold any ONE of the buttons down (like lets say F3 on your keyboard or some key on an external device) after, say, 2 seconds it beeps. It has stored that text in THAT key. \n\n\\* You can to this with other keys too.\n\n\\* You press and release the key and it pastes the text.",
            "I usually just control + r in my terminal + Maccy on Mac. Windows has an in built history for your clipboard.",
            "Very cool project!  \nDon't know why people are being so negative :P",
            "I love the project idea, but I mean it is built into windows by default... \\`Windows+V\\` .",
            "At least tell me you think is wrong and how to fix it dude.",
            "then consider this a linux solution",
            "Windows does do it natively but it has a limit of 25 copies I believe which is the only downside I have with it. I might try OPs since I don't see s hard limit mentioned",
            "It does \ud83d\ude02 into a document \ud83d\udcc1 folder",
            "I know. I use ubuntu and others do to. My app works on both linux and windows.",
            "i use windows key + v. works fine for me",
            "[https://letmegooglethat.com/?q=clipboard+manager](https://letmegooglethat.com/?q=clipboard+manager)",
            "Why are y'all downvoting this, he's just looking to learn more",
            "Fair enough!   Certainly there's room for helpful features in this type of thing. Good on ya!",
            "It saves unlimited copies in my one drive",
            "Last I checked there is clipboard history using gClip or something like that.\n\nEitherway cool project"
        ]
    },
    "Seeking Feedback: Should Robyn(Web Framework) Support ASGI?": {
        "title": "Seeking Feedback: Should Robyn(Web Framework) Support ASGI?",
        "score": 3,
        "url": "https://www.reddit.com/r/Python/comments/1db64l2/seeking_feedback_should_robynweb_framework/",
        "content": "Hey Everyone\u00a0\ud83d\udc4b\n\nThe author of [Robyn](https://github.com/sparckles/Robyn/) here. For those unaware, Robyn is one of the fastest Python web frameworks with a Rust runtime.Robyn offers a variety of features designed to enhance your web development experience. However, one topic that has sparked mixed feelings within the community is Robyn's choice of not supporting ASGI. I'd love to hear your thoughts on this. Specifically, what specific features of ASGI do you miss in Robyn?\n\nYou can find Robyn's documentation [here](https://robyn.tech/documentation). We're aiming for a v1.0 release soon, and your feedback will be invaluable in determining whether introducing ASGI support should be a priority.  \n\n\nPlease avoid generic responses like \"ASGI is a standard and should be supported.\"\n\nInstead, share detailed insights and evidence-based arguments to help me understand the tangible benefits ASGI could bring to Robyn or the lack of a specific ASGI feature that will hinder you from using Robyn.\n\nLooking forward to your feedback!\n\nThanks again.\n\nRepo - [https://github.com/sparckles/Robyn/](https://github.com/sparckles/Robyn/)  \nDocs - [https://robyn.tech/documentation](https://robyn.tech/documentation)\n\n\n\n",
        "num_comments": 2,
        "comments": [
            "To me the main benefit of ASGI is... pretty much just that it's standardized. Apps and middlewares are composable and reusable. One can build something that takes plugins that can serve pages, without requiring said plugins to use a specific framework.\n\nBut I suspect I might not be the target audience of Robyn, at least not with any of my current projects, since the lack of ASGI in the first place seems to imply it has other priorities and isn't quite like other frameworks?"
        ]
    },
    " YouTube playlist with 100 most-watched Python 2023 conference talks": {
        "title": " YouTube playlist with 100 most-watched Python 2023 conference talks",
        "score": 94,
        "url": "https://www.reddit.com/r/Python/comments/1dab3m7/youtube_playlist_with_100_mostwatched_python_2023/",
        "content": "tldr; [https://www.youtube.com/playlist?list=PLsaeJ8d49kCnv20dizZqF\\_EjAoAByNfMj](https://www.youtube.com/playlist?list=PLsaeJ8d49kCnv20dizZqF_EjAoAByNfMj)\n\nlong: Hello r/python! As a part of [Tech Talks Weekly newsletter](https://techtalksweekly.substack.com/), I've put together a list of the most watched Python conference talks from 2023 as a youtube playlist. The list is ordered by the view count for your convenience. The talks come from conferences like **PyCon** (all locations), **PyData** (all locations), **EuroPython, Conf42**, and many more to give you a complete overview of the landscape.\n\n*I've built the playlist as a part of my newsletter called* [*Tech Talks Weekly*](https://techtalksweekly.substack.com/) *where once a week I send out all the recently uploaded tech conference talks across engineering conferences (*[*see a recent issue*](https://techtalksweekly.substack.com/p/tech-talks-weekly-17) *and* [*subscribe*](https://techtalksweekly.substack.com/) *if this sounds useful).*\n\nLet me know what do you think!",
        "num_comments": 3,
        "comments": [
            "[\\#45, bay-bee!](https://www.youtube.com/watch?v=knUGpULAmn4&list=PLsaeJ8d49kCnv20dizZqF_EjAoAByNfMj&index=45)\n\nI think it was the joke I did at the start of the talk that got it so many views.",
            "This is the kind of contribution I love, thanks for it!",
            "Is [the blog post you referred to](https://inventwithpython.com/blog/2022/11/19/python-linter-comparison-2022-pylint-vs-pyflakes-vs-flake8-vs-autopep8-vs-bandit-vs-prospector-vs-pylama-vs-pyroma-vs-black-vs-mypy-vs-radon-vs-mccabe/) still being kept up to date as you discover new information?",
            "I'll add it to my to-do list. I've been trying to update the blog generation system (the first time I put it together, I didn't really understand how the Pelican static blog generator worked and now I have to undo a bunch of weird little scripts I made.)\n\nI'll update it at some point."
        ]
    },
    "Introducing Zenaura, python framework for building scalable, maintainable component based SPAs.": {
        "title": "Introducing Zenaura, python framework for building scalable, maintainable component based SPAs.",
        "score": 1,
        "url": "https://www.reddit.com/r/Python/comments/1dazvjk/introducing_zenaura_python_framework_for_building/",
        "content": "**What My Project Does**\n\nZenaura is a cutting-edge Python library, leveraging Pyodide and PyScript, designed to empower developers to create lightweight, performant, stateful, component-based Single Page Applications (SPAs) with ease. By utilizing a virtual DOM implementation, Zenaura enhances performance, reactivity, responsiveness, and interactivity, allowing developers to build dynamic web applications using familiar Python concepts and syntax.\n\n**key features**\n\n* Exceptional Developer Experience:\u00a0Intuitive and efficient development workflow.\n* Smooth Learning Curve:\u00a0Easy to learn and get started.\n* Modular Code Structure:\u00a0Write clean, readable, and maintainable code.\n* Component-Based Architecture:\u00a0Build reusable and scalable components.\n* Page Management:\u00a0Simplify page creation and navigation.\n* Built-in Router:\u00a0Seamless client-side routing.\n* State and Props Management:\u00a0Efficiently handle component states and properties.\n* Dependency Injection:\u00a0Manage dependencies effortlessly.\n* Global States and Components:\u00a0Share states and components across the application.\n* Optimized Virtual DOM:\u00a0Enhance application performance with a highly efficient virtual DOM.\n* Component Lifecycle Methods:\u00a0Control component behavior at different stages.\n* Form Support:\u00a0Easily manage form inputs and validation.\n* API Integration:\u00a0Integrate external APIs using the requests module.\n\n**target Audience** \n\nPython developers who want to build stateful, component based SPA using pure python.\n\n**Comparison with existing SPA building libraries, frameworks:** \n\n1. Python Integration:\n\n* Leverages PyScript and Pyodide: Zenaura allows your Python code to be compiled and transpiled into WebAssembly (WASM), enabling the execution of Python in the browser. This is a significant departure from traditional JavaScript-based frameworks like React, Angular, and Vue, which rely solely on JavaScript for client-side development.\n\n1. Developer Ecosystem:\n\n* Pythonic Development: Zenaura enables Python developers to build modern web applications without needing to switch to JavaScript, providing a seamless experience for those who are more comfortable with Python.\n* Unified Language: By using Python for both front-end and back-end development, Zenaura reduces the context-switching overhead and allows for a more cohesive development experience.\n\n1. Performance and Efficiency:\n\n* Virtual DOM Implementation: Similar to React and Vue, Zenaura utilizes a virtual DOM to optimize rendering performance. However, Zenaura's implementation play more well with the virtual DOM as it update the real DOM in non-blocking asyn way. Also thanks to pydide the python interpreter is ported to WASM, which means less JS footprint , very light library sizes on every library developed around zenaura.\n\n1. Component-Based Architecture:\n\n* Stateful Components: Zenaura's component-based architecture allows for building reusable, stateful components, akin to React and Vue. This promotes code reusability and modularity.\n\n1. Ease of Learning and Use:\n\n* Smooth Learning Curve: Zenaura offers an intuitive and straightforward learning path, especially for developers already familiar with Python. This makes it accessible and easy to adopt compared to the steeper learning curves of frameworks like Angular.\n\n1. Ecosystem and Community:\n\n* Growing Python Ecosystem: By integrating with the Python ecosystem, Zenaura can leverage existing Python libraries and tools, providing a rich set of functionalities and a vibrant community for support and collaboration.\n\n# Resources:\n\n* GitHub Repository:\u00a0[https://github.com/ARAldhafeeri/Zenaura](https://github.com/ARAldhafeeri/Zenaura)\n* Landing Page:\u00a0[https://araldhafeeri.github.io/zenaura-landing-page/](https://araldhafeeri.github.io/zenaura-landing-page/)\n* Documentation:\u00a0[https://araldhafeeri.github.io/Zenaura/](https://araldhafeeri.github.io/Zenaura/)",
        "num_comments": 1,
        "comments": []
    },
    "[OS] Burr -- Build AI Applications/Agents as State Machines": {
        "title": "[OS] Burr -- Build AI Applications/Agents as State Machines",
        "score": 14,
        "url": "https://www.reddit.com/r/Python/comments/1dagf30/os_burr_build_ai_applicationsagents_as_state/",
        "content": "Hey folks! I wanted to share\u00a0[Burr](https://github.com/dagworks-inc/burr), an open-source project we've been working on that I'm really excited about.\n\n# Target Audience\n\nDevelopers looking to integrate AI into their web services, or who are curious about state machines.\n\n# The problem\n\nMost AI-application frameworks are overly opinionated about how to craft prompts, interact with LLMs, and store memory in a specific format. See\u00a0[this comment](https://www.reddit.com/r/LocalLLaMA/comments/1d4p1t6/comment/l6g1b3t/) for a nice summary. The problem is they often overlook more production-critical aspects such as managing and persisting state, integrating telemetry, bringing apps to production, and seamlessly switching between human input and AI decisions.\n\n# What My Project Does\n\nOur solution is to represent applications explicitly as state machines, which offers several advantages:\n\n* Mentally model your system as a flowchart and directly translate it to code\n* Execute custom hooks before/after step execution\n* Decouple state persistence from application logic\n* Rewind back in time/test counterfactuals (load up, fork, and debug)\n* Query the exact (reproducible) application state at any point in time\n\nThis is why we built Burr -- to make these capabilities easy and accessible. The design starts simple: define your actions as functions (or classes) and wire them together in an application. Each action reads from and writes to state, and the application orchestrates, deciding which action to delegate to next. An OS tracking UI lets you inspect the current state/get at \\*why\\* your application made a certain decision.\n\nWhile most people use it for LLM-based applications (where state is often complex and critical), we see potential for broader applications such as running time-series simulations, ML training, managing parallel jobs, and more. Burr is entirely dependency-free (using only the standard library), though it offers plugins that you can opt into.\n\nWe've gotten some great initial traction, and would love more users and feedback.\u00a0[The repository](https://github.com/dagworks-inc/burr)\u00a0has code examples + links to get started. Feel free to DM if you have any questions!",
        "num_comments": 5,
        "comments": [
            "Hey, I understand that you're building without external dependencies, but did you at any point consider `pydantic` instead of `dataclasses`?\n\nMy team uses `pydantic` to manage data across a number of components and interfaces, especially to manage the quality of output we get from LLMs, using `instructor`.\n\n`burr` seems very interesting, and it's something we might want to try out. Good luck with it.",
            "Not the OP, but my experience is that, perhaps counterintuitively, if you're building a library, the most problematic dependencies are popular ones.\u00a0\n\n\nFor a while I maintained a library that provided a user-friendly interface to a service operated by my then-employer. Whilst we published it publicly, our internal users were major users so we also got a good idea what it was like to work with.\n\n\nWe used Requests for HTTP calls, which seemed like a good choice at the time.\n\n\nBut the big issue with this was that many systems that used this library also used Requests, and sometimes relied on features or quirks that were only present in particular versions of Requests.\n\n\nIf I did something similar again, I'd use `http.client`. Yes, the API is clunky, and it's not as feature-rich, but those are problems for me, the library author. I'm not creating problems for my users just to make my life easier.",
            "Hey! Big fan of pydantic as well (and instructor). While we don\u2019t have dependencies, we have plugins that allow for additional capabilities (largely included on detection of the installed library). In particular, serializing/deserializing pydantic models in state is supported (serialization is customizable as well for less easy to serialize objects \u2014 e.g. langchain objects/documents). It\u2019ll show up in the UI in a reasonable json form/allow you to store and retrieve in state. \n\nThe data classes are for largely internal constructs (with a few external ones) that are application-specific (not outputs of LLMs). \n\nGlad it sounds interesting! If you find a case that you think would be better served as a pydantic model let us know \u2014 feedback is super valuable.",
            "Thanks for your reply!\n\nOkay I'll take a look at how plugins work. Langchain is uninteresting to me - it makes you do too much without itself actually doing very little. It's great for quick prototyping, but it's neither well documented nor robust/consistent with behavior so I can't stomach the idea of using it in production.\n\nI'll be exploring this just to play around, but I'm not sure I'll find a use case for it. I admit, at this point I'm more interested in figuring how to be on the other side of the fence. The contributing docs are begging me to look at them!",
            "Yeah! Found much the same about langchain. Absolutely looking for contributions (tagged a few good first issues but there\u2019s tons more to do). The plugins aren\u2019t centrally documented, but take a look at serialization/deserialization \u2014 there\u2019s a nice video that talks about how we leverage single dispatch for it. https://burr.dagworks.io/concepts/serde/"
        ]
    },
    "Request to journalists: no snakes": {
        "title": "Request to journalists: no snakes",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1dbm916/request_to_journalists_no_snakes/",
        "content": "Could you please stop using photos of snakes on your articles about Python?\n\nNot only is it unimaginative, stale, and clich\u00e9, but many of us also find it genuinely off-putting. Our passion certainly lies in coding, not necessarily in reptiles.\n\nP.S. Imagine 9 out of 10 articles on Windows featuring photos of pretty youknowwhat",
        "num_comments": 45,
        "comments": [
            "> our passion lies in coding, not in reptiles\n\nSpeak for yourself \ud83d\udc0d",
            "Yeah I agree.\u00a0\n\n\nMore Monty Python themed articles!",
            "What photo should they use? Generic binary code hacker backgrounds instead?",
            "*looks at the logo*\n\nHmmmm",
            "Its always pythons and never Monty Pythons.\n\nFor some topic they should include a picture of Gumby.",
            "I like the snakes.",
            "So what do you want instead? Portraits of Guido?",
            "I\u2019ve had it with these snakes.",
            "Take a closer look at the Python's logo and tell me which two animals do you see.\u00a0 Also, try to search in Google \"Python old logo\" and you will understand better where does that \"unimaginative clich\u00e9\" comes from.",
            "How about you complain to each of the journalists? Think of this, these people might:\n\n- not even see this post\n- not use Reddit at all",
            "Can't wait for all the thumbnails we're going to get once Rust gets more popular",
            "But the python logo is 2 snakes... Wanna change the logo too?",
            "You gotta spend some time in r/Sneks to habituate yourself to cute snake pictures.",
            "Truer words were never spoken. If anything, there should be pictures of Brian.",
            "new copypasta just dropped",
            "I didn\u2019t expect that!",
            "Who cares, it is a picture. They could all post pictures of a turtle. /shrug",
            "Pictures of Spam Spam Spam Spam Spam Eggs and Spam would be better but is probably a copyright issue",
            "I do wish they\u2019d occasionally bring in some pictures of Monty Python bits, because there\u2019s more of that in Python than snake stuff (but the snake stuff very much is there).  Just to shake it up.",
            "Karen alert!",
            "![img](emote|t5_2qh0y|598)",
            "It's easy to forget that not everyone likes the long bois",
            "I\u2019d vastly prefer penises too.",
            "I\u2019m with you on this one. I\u2019m afraid of snakes and just seeing a photo makes me panic.",
            "Ssssssspeak four yourssssself \ud83d\udc0d",
            "Edited",
            "Dead parrots would be truer to the roots of the language.\u00a0",
            "A five ounce swallow photoshopped to look like it\u2019s carrying a one pound coconut.",
            "All I see is John Cleese and Terry Jones in a brotherly embrace",
            "\\* creates new post*\n\nMessage to the python maintainers",
            "hahahaha oily snakes!",
            "No, portraits of John Cleese.",
            "I would much rather that.",
            "On this MF code base.",
            "pip uninstall journalists",
            "yeah just put 2 journalists instead, thatll show them",
            "I don't want to handle (touch) snakes either, but I still certainly enjoy watching them when I come across them in the wild.  Don't you think the world would be a much more boring place if everything that someone doesn't like was never shown again?  I suffer from acrophobia to the point that I occasionally wake up at night afraid of falling out of bed (although I can't remember that ever happening).  However, I don't think that all images of mountain ranges or skylines should disappear.",
            "ssssss sss ssssssss ss ss ssssss sss !",
            "It's not dead. It's resting.",
            "Didn't that one exist yet? Vaguely remember a black flag with some bones on it... Journalists after being bitten by snake...",
            "Interesting point. \nWould you still feel the same way about images of mountain ranges or skylines if just looking at those images caused the same tightness in the chest and shortness of breath as being on a ledge 50 meters in the air?\nYou mention being able to enjoy watching snakes when you come across them, to someone that mentions they enter a state of panic when doing the same.\nWould someone with a phobia think the world would be a better place if the subject of their phobia did not exist?",
            "This sir, is an ex parot"
        ]
    },
    "Instant Python pipeline from OpenAPI spec": {
        "title": "Instant Python pipeline from OpenAPI spec",
        "score": 19,
        "url": "https://www.reddit.com/r/Python/comments/1da5uvv/instant_python_pipeline_from_openapi_spec/",
        "content": "Hey folks, I work on dlt, the open source python library for turning messy jsons into clean relational tables or typed, clean parquet datasets.  \n  \nWe recently created 2 new tools: A python-dict based REST API extractor where you can just declare how to extract, and a tool that can init the above source fully configured by reading an OpenAPI spec. The generation of the pipes is algorithmic and deterministic, not LLM based.  \n\n\n## What My Project Does\n\n`dlt-init-openapi, and the REST API toolkit`are tool designed to simplify the creation of data pipelines by automating the integration with APIs defined by OpenAPI specifications. The pipelines generated are customizable Python pipelines that use the REST API source template that dlt offers (a declarative python-dict first way of writing pipelines).\n\n  \n## Target Audience\n\n`dlt-init-openapi` is designed for data engineers, and other developers who frequently work with API data and require an efficient method to ingest and manage this data within their applications or services. It is particularly useful for those working in environments that support Python and is compatible with various operating systems, making it a versatile tool for both development and production environments.\n\ndlt's loader features automatic typing and schema evolution and processes data in microbatches to handle memory, reducing maintenance to almost nothing.\n\n## Comparison\n\nBoth the generation and the python declarative REST API source are new to our industry so it's hard to compare. dlt is open source and you will own your pipelines to run as you please in your existing orchestrators, as dlt is just a lightweight library that can run anywhere Python runs, including lightweight things like serverless functions.\n\ndlt is like requests + df.to\\_sql() on steroids, while the generator is similar to generators that create python clients for apis - which is what we basically do with extra info relevant to data engineering work (like incremental loading etc)\n\nSomeone from community created a blog post comparing it to Airbyte's low code connector: [https://untitleddata.company/blog/How-to-create-a-dlt-source-with-a-custom-authentication-method-rest-api-vs-airbyte-low-code](https://untitleddata.company/blog/How-to-create-a-dlt-source-with-a-custom-authentication-method-rest-api-vs-airbyte-low-code)\n\nMore Info\n\nFor more detailed information on how `dlt-init-openapi` works and how you can integrate it into your projects, check out the links below:\n\n* [GitHub Repository for the tool](https://github.com/dlt-hub/dlt-init-openapi)\n* [OpenAPI specs repository you can use](https://github.com/dlt-hub/openapi-specs)\n* [Video Walkthrough](https://www.youtube.com/watch?v=b99qv9je12Q)\n* [Colab Demo](https://colab.research.google.com/drive/1MRZvguOTZj1MlkEGzjiso8lQ_wr1MJRI?usp=sharing)\n* [Documentation and Quick Start Guide](https://dlthub.com/docs/dlt-ecosystem/verified-sources/openapi-generator)\n* [blog: REST API toolkit which helps understand how to edit the generated pipeline](https://dlthub.com/docs/blog/rest-api-source-client)",
        "num_comments": 4,
        "comments": [
            "wouldn't doc generated pydantic models make more sense than a dict? Is there any advantage to using dicts here?",
            "I think there's a misunderstanding of what the dict is. The dict is the definition of the pipeline. Go check the rest api link.   \n  \nFor the api schema, that dlt will read from the data, you can use pydantic [https://dlthub.com/docs/general-usage/schema-contracts#use-pydantic-models-for-data-validation](https://dlthub.com/docs/general-usage/schema-contracts#use-pydantic-models-for-data-validation)",
            "understood, really cool library btw. I've had way too many issues unravelling nested json structures into tables, will give it a try. kudos!",
            "Thank you! I appreciate the feedback!"
        ]
    },
    "What are the best Python projects you've worked on?": {
        "title": "What are the best Python projects you've worked on?",
        "score": 193,
        "url": "https://www.reddit.com/r/Python/comments/1d9r9xa/what_are_the_best_python_projects_youve_worked_on/",
        "content": "Off with the hate, what have been the best Python projects you have worked on? What did the code look like? What were the standards? Why was it the best? ",
        "num_comments": 68,
        "comments": [
            "I worked on Beautiful Soup a bit a while back. Its maintainer, Leonard Richardson, and his wife Sumana Harihareswara are both real treasures for the Python community. He coached me through my first real open source contribution. I was in my early twenties then, so it was helpful watching a seasoned developer explain decisions like release schedules to be minimally disruptive. Beautiful Soup is good quality code that has evolved for the past 20 years to stay relevant.",
            "As someone who works in the Financial industry, I noticed that it was quite hard to programmatically get an overview of each sector (e.g. agricultural sector and underlying industries per country). Yes, if you pay a hefty fee anything is possible but I wondered if I could build something with scrapers for free.\n\nThis ended up almost melting my laptop as I had it turn on for 40 days straight constantly running queries to collect as many companies as possible while trying to categorize them. At one point I had a fan blowing at my laptop because I was scared it would destroy itself otherwise (and I was a poor student back then). That was a couple years ago and I think the project nowadays is being used by quite a lot of people! \n\nCurrently, it collects new data on companies that go public or bankrupt every week via GitHub Actions and I am actually really proud of what it has become.\n\nThe code itself is nothing to write home about though \ud83d\ude43\n\n[This is the project](https://github.com/JerBouma/FinanceDatabase)",
            "I once got a job at tech unicorn by writing a Python library that can analyze poetry. This was back in 2017, way before ChatGPT was on scene.",
            "The project I'm working on. A planner that controls a fleet of space satellites using AI (from the optimization problems branch, not machine learning or the like).\n\nMostly very well organized code, a super interesting problem to solve, challenging, and built as a lib so no db, frontend or UIs to deal with, pure algorithmic stuff.",
            "I wrote an expression evaluator using eval fn in early 2010 as an API for a Windows Phone application and published in Google app engine in no time.",
            "A year ago I got a job at a small company. The software that gets sold there is over 20 years old and I thought about quitting and taking another position that was offered to me at a way bigger company. The old and grown code is exactly what you would expect from software that was extendet piece by piece. The fact that it is not really wirtten in python ways doesn't make it better. But the company is currently starting to modernize and changing processes and becoming modern. The nice thing in this project is that my boss throws me at a project and let me do my thing. Hell lot of freedom, many opportunities to get involved, many opportunities to learn stuff and a great group of people working together with me. \n\nBefore that I was working in a datacenter automating processes which was fun because we got our own small replica of the datacenter infrastructure that was our playground.",
            "I made ASGIRouter, a flask like router for uvicorn",
            "I've made a bunch of fun educational demos with python. From a cryptocurrency seed scanner malicious code demo, a crypto address generator, a diceware password generator, and many more. Great tool for developing code and educating about computer science topics.",
            "Well, I\u2019m currently working on a Python project called PyBridge. It will be an ESB Broker that executes scripts by triggering them through API calls and I\u2019m planning on adding more execution through other triggers like timers and schedulers.\n\nIn a few more releases I\u2019d like to work on a GUI in React.\n\nIf you\u2019re interested feel free to check it out on my GitHub profile Thatsleepyman\n\nEdit: typos",
            "An AI that learns to play Blackjack. Then, each hand played is logged to a SQL database for further analysis/visualization.",
            "[IForth](https://github.com/sohang3112/iforth) - it's a Jupyter Kernel for Forth programming language. I forked it from an abandoned project and added features like syntax highlighting, prettier code output, showing errors separately, etc. I also published it on [PyPi](https://pypi.org/project/forth-kernel/), though it's quite a few commits behind.\n\n**PS:** In case you didn't know, Jupyter Notebooks support non-Python languages via kernels (like this one for Forth) - a Jupyter kernel exists for most programming language. \n\n**PPS:** [Forth](https://en.m.wikipedia.org/wiki/Forth_(programming_language)) is a stack-based language where code is written in postfix form - eg. `1 2 +` results in 3. It's very lightweight and is useful especially in resource-constrained embedded devices.",
            "we wrote DMA drivers for specialized RISC machines in C, used C extensions and added them as Ipython commands. I wrote basic ml apps with scikit-learn offloaded some of the work to these machines. specialization to generalization. I was a god of both worlds. it was good. it was fair",
            "I\u2019ve been getting data from facilities that are all kind of the same but kind of different. It\u2019s been fun optimizing the api IO calls with multi threading. Also I\u2019ve connected to a variety of databases (oracle, mssql, MySQL, Postgres) and they all have different and interesting data models.",
            "My own. Just went open source today.",
            "Me and ChatGPT teamed up and I made an automated process of transferring application data from students progress trackers to a new format. Saved so much time.. I think",
            "The most fun work project I have been a part of was an application for detecting highlights in gaming live streams using computer vision. \n\nWe ended up building a lot of cool features like face detection, sentiment analysis from chat and a video editor that ran in the browsers. \n\nThe project was written in a mixture of Rust, Python and TypeScript depending on requirements.\n\nSadly the project has now been shutdown, since, as you might expect, it is a pretty small niche \ud83d\ude05",
            "Actually I am working in a access control tkinter app, with iot devices like raspberry , bars , cytophones . And a database of the in and out of the people",
            "Used FastAPI, Docker, Kubernetes, Python, and HuggingFace to train and deploy a semantic analysis model (distilBERT) into a REST API endpoint in Azure. Did that for a masters project at UC Berkeley a year ago.",
            "I used to work in the video industry, so working on a AI video search engine that I know is so useful for everyone in the industry is very rewarding. Publicly available, too!",
            "Definitely machine learning, python is the best for it",
            "There are some really good python projects in the Bitcoin world.  Many libraries are python, and a few good python wallets.\n\n1. Trezor Firmware - STM32 micropython\n2. Electrum Wallet - All pure python\n3. Bitcoin Core - Most of the `test` directory is python",
            "I am working on a project where we use blender API and many 3D libraries like open3d to manipulate meshes for 3D printing for real world applications. I am enjoying it a lot.",
            "I recently a Python course created by ZTM, and it's been an amazing learning journey! One of the highlights of the course was working on cool projects that really showcased the capabilities of Python. I completed a web scraping project that was challenging and rewarding. I learned how to use libraries like BeautifulSoup and requests to extract data from websites.\n\nTaking the course cleared up any confusion about Python and programming in general. I highly recommend that course for anyone trying to take their Python game to the next level.",
            "Previous company: I wrote some python code to input a FIX (Financial protocol) file and parse it into English and output as Excel or CSV. Most of the stuff on websites does it one line at a time.\n\nI'm half-tempted to re-write it for myself and also do it for HL7.",
            "Writing a whole software that automatically test pci or pcie boards according our criteria.\nA big test bench, able to test multiple variants for multiple boards, while generating standard outputs.\n\nI touched a lot (C interface, instrumentation, electronics, drivers, OOP, Graphical Interface, Advanced file generation (PDF...))",
            "I did couple of projects but tbh i don\u2019t know anything about coding, but i have good skills on searching keywords that give me the action i want into codes, i did a telegram bot that checks for my cigarette website if the product i want is available and send me a notification",
            "1+1=11 ofc",
            "Hentai game... Pygay",
            "got behind LA Times paywall. output to pdf. formatting is funky though.",
            "Created a Chatbot  for carrier guidance",
            "Currently working on an application that helps accounts by automating data entry in Tally Prime (Accounting/bookkeeping software)",
            "I work with pyqt6 mainly. A code editor, YouTube downloader, Spotify downloader, pyinstaller / nuitka interface, etc. I've posted these projects in this sub and you can see those from my profile.",
            "1. An inventory system for tracking my inventory of vitamin supplements. As I utilize items in the inventory, it keeps track of how much remains and alerts me to reorder any items whose inventory level is low.\n\n2. A live TV playlist that automatically changes my TV channel to my favorite TV shows 5 seconds before the programs starts. These can be weekly, daily or weekday programs, or even programs I enter on the fly by utilizing my TV\u2019s TV Guide.",
            "I worked on building my own video encoder in Python. It was suprisingly performant due to be vectorizing everything and using numba. It was very fun despite the code being an actual nightmare to maintain",
            "I did some web scraping with bs4 and selenium back in the day, lots of fun. I use JAX for machine learning now, it\u2019s really cool how it translates a lot of Python data structures into traced functions.",
            "Check out Home Assistant - just great",
            "I made a tool I call The Smell-o-scope (a reference to Futurama) that looks across vast swathes of AWS, GCP, and Azure assets to find resources that resemble your search term in name, tags, or description.  \n\n\nI got a little cute with function and variable names, calling search terms \"smells\" and substrings \"odors\", executing a search is \"sniffing\", it's as much an art project as a coding project.  (And maybe annoying for anyone but me to read)",
            "The best Python projects can vary based on your interests, goals, and skill level. Here are some suggestions across different domains that can help you learn and grow as a Python developer:\n\n# Beginner Level\n\n1. **Simple Calculator**: Build a basic calculator that can perform addition, subtraction, multiplication, and division.\n2. **To-Do List App**: Create a command-line or simple GUI application to manage daily tasks.\n3. **Guess the Number Game**: Develop a game where the computer randomly selects a number, and the player has to guess it.\n4. **Weather App**: Use an API to fetch and display weather information for a given location.\n5. **Password Generator**: Create a program that generates random and strong passwords.\n\n#",
            ">Leonard Richardson, and his wife Sumana Harihareswara are both real treasures for the Python community\n\nThey were both on stage at year's PyCon (US) a few weeks ago \ud83d\udc4d",
            "In the morning before the first day of PyCon this year, I happened to meet Sumana on the walk to the convention center and she was the friendliest, nicest person I've ever talked to. Really set the weekend off on a great note for me and felt very welcomed for my first time going",
            "Currently working on something similar but without beautiful soup. Evaluated the requirements with bs4 originally and found few limitations so using something different now. \n\nI would really prefer to work with beautiful soup if I wasn\u2019t asked to perform things around such limitations. Every elegant library.",
            "This looks interesting - does it also include Indian equity market?",
            "I've been looking through the code and have a couple of things I'd like to contribute. I'll probably create a PR soon.",
            "I wrote a Python application to analyse poetry for my Master's final project! Really fun and I learned a lot",
            "Just out of curiosity, what aspects of poetry did you analyze? Any link to the library or repo? Would love to see!",
            "Maxar vibes",
            "Is it open source - can you share the source code?",
            "This is cool!",
            "Share",
            "Care to share the repo?",
            "I love open3d and have been contributing there a lot last year. Got a side gig, so halted the open source, but coming soon. I have a list of bugs to fix \ud83d\ude01.",
            "Will it possible to share?",
            "Yeah, I was there as well. PyCon in general was a real treat, and of course Sumana was great. They also had a 20th anniversary party for the creation of Beautiful Soup.",
            "Yes it does!",
            "https://python-poetry.org \ud83d\ude02",
            "Satellogic :)",
            "Sadly no :(",
            "Check out google ortools",
            "Thanks \ud83d\ude42. Please star the repo and try it out for yourself - if you face any issues, please raise them on Github",
            "https://github.com/ML-flash/M-E-GA\n\nIt wasn\u2019t ready to be opened up yet. Originally I intended to patent the novel parts of the algorithm before making it open source or at least have the process started. \n\nIt\u2019s a Novel class of Genetic Algorithm built from the ground up in my own design.  Its technically still a genetic algorithm but it works in a fundamentally different way and brings several new ideas to the table. Im not an academic and this is my first real project. Ive been working on the concept for almost 20 years. \n\nRight now it\u2019s very early in development but it\u2019s meant to be a general purpose framework that is easily iterated on enables an almost trivialized implementation of transfer learning. It also potentially allows for continual life long learning and open ended evolution. Im still working on exploring those concepts. \n\nMy overall goal is to drive home the concept of public property Advanced Artificial Intelligence/Machine Learning.\n\nHad some concerning attention while looking for outside help and realized i gave up my rights to patent it so open sourced it before my mistake could be taken advantage of.",
            "It's not open source yet, but there's a live version to try it out here: https://icono-search.com/",
            "Good - I'll check it out",
            "Heh I follow a bunch of the satellogic people on LinkedIn, I\u2019d love to work there",
            "Never heard of your company before, what you\u2019re doing is great!\n\nI\u2019m a flight control engineer at another satellite operator, and we definitely don\u2019t use any AI for planning or automation. I sometimes do wish we did, as most of the stuff we do is manual. Great job!",
            "It's a very interesting tool! Though we don't use that, just in case.",
            "Hats off to your persistence! Good luck!!",
            "Thank you."
        ]
    },
    "Python script to automate Bing searches for reward generation": {
        "title": "Python script to automate Bing searches for reward generation",
        "score": 13,
        "url": "https://www.reddit.com/r/Python/comments/1da3dys/python_script_to_automate_bing_searches_for/",
        "content": "# What My Project Does\n\n**(Link)**\u00a0Check this out :\u00a0[aditya-shrivastavv/ranwcopy](https://github.com/aditya-shrivastavv/ranwcopy)\n\nPython program which generates random words and sentences and copy them to clipboard\ud83d\uddd2\ufe0f.\n\nI created a script to automate Bing searches for reward generation\n\n* \ud83d\udc4d Excellent command line experience.\n* \ud83d\ude42 User friendly.\n* \ud83d\udd0a Produces sound so you don't have to start at it.\n* \ud83d\udd01 Auto copy to clipboard\ud83d\uddd2\ufe0f\n* \ud83d\udca1 Intuitive help menu\n\n# Target Audience\n\nAnyone who wants to quickly get points from bing searches under there daily limit\n\n# Comparison\n\nThis is no comparison, this is a very unique approch to the problem. You will find many browser extensions which claim to do the same thing, but they don't work like the search engine expects\n\n# Commands\n\nHelp menu\n\n    ranwcopy -h\n    #OR\n    ranwcopy --help\n\nStart generating words (10 default with 8 seconds gap)\n\n    ranwcopy\n\nGenerate 20 words with 9 seconds gap\n\n    ranwcopy -i 20 -g 9\n    # or\n    ranwcopy --iterations 20 --timegap 9\n\nThis is a semi automatic script",
        "num_comments": 9,
        "comments": [
            "If this is related to Microsoft rewards I\u2019m pretty sure this is against tos",
            "Looks interesting hope Bing is not blocking your script by detecting it as non-browser-based surfing. \n\nBy the way the first command under the heading \u201chelp menu\u201d, is rancopy -h, which is probably a typo.",
            "Maybe slightly off topic, but I don't understand the concept of \"points for bing searches\". Would you mind explaining what that is exactly?",
            "Now let\u2019s make a whole army of them",
            "It is, but fuck them.",
            "No, it doesn't, most of the work happens off browser only paste and enter key press event is simulated by javascript function.\n\nI'll fix the typo, thanks for highlighting",
            "For every search you get 3 points and there is a limit of 90 points. Points can be converted into gift cards and many other alternatives. I have obtained 500 Rupee gift card",
            "\ud83e\udd72what does tos means? Its new for me",
            "terms of service"
        ]
    },
    "I created a video on why you should be careful when using Python dictionaries as function parameter": {
        "title": "I created a video on why you should be careful when using Python dictionaries as function parameter",
        "score": 42,
        "url": "https://www.reddit.com/r/Python/comments/1d9upsj/i_created_a_video_on_why_you_should_be_careful/",
        "content": "This talks about mutability as Changes inside a function affect the original dictionary which could lead to unexpected behaviors and hard to debug issues.\n\n  \nHere is a link to the video\n\n[https://www.youtube.com/watch?v=zTTDQePffxU](https://www.youtube.com/watch?v=zTTDQePffxU)",
        "num_comments": 33,
        "comments": [
            "It\u2019s a pretty well known foot gun that you shouldn\u2019t use any mutable object as a default input. Also, I don\u2019t think I\u2019ve ever seen anybody use a default dictionary in this way. Even ignoring the undesired behaviour, this is such a strange way of trying to have a function handle optional inputs and defaults.",
            "Any mutable type, really. Sets, lists, custom classes, \u2026",
            "\\*As a default parameter in a function, i.e. don't do this:\n\n```\ndef func(some_dict_parameter={}):\n```\n\nI'll let the video explain it, but this is to summarize what not to do.",
            "Dictionaries are fine as params. Never use any mutable type as a *default* param.",
            "What should be used instead of a default dict?",
            "As parameter defaults, yes. Use `None` as a sentinel and check for it, initialize with a new mutable instance in the function body, so it will run every time.",
            "This was the very first bug I encountered with python way back in the Python 2 days. My own came from using an immutable list, though. I asked on Stackoverflow, and they cleared that up for me pretty quick.",
            "Yet another tutorial recorded by someone who just learned python xd",
            "Don\u2019t use a mutable as a default parameter. Set default to None if you want a default e.g.\n\ndef foo(data: dict | None = None): \u2026",
            "clone it before passing it in?",
            "Learned something new, thanks!",
            "the OO language will OO",
            "That behavior is very weird. Thanks!",
            "What, you don't use mutable defaults to store global state while being able to claim (falsely) that you don't use non-constant globals? ^(/s obviously)",
            "The real footgun is mutating an input, regardless of whether it has a default or not. The fact that the default value is the same for all calls to the method is absolutely unsurprising and directly follows from the way Python handles function definitions.",
            "I have used `def mything(..., _cache={}):` intentionally in the past, expecting the changes to be preserved between function calls.\n\nI've stopped.",
            "Well it can be an interesting hack, just be aware the default parameters have the same scope as the function definition.",
            "You set the parameter as None and then in the body of the function you do x = x or {}",
            "use None instead of any default mutable object: list, dict, set, custom class, etc",
            "None for default parameters.\n\ndefault_factory for dataclass fields.",
            "Does this mean I didn't teach it well? \ud83d\ude03\n\nIf so, I can still improve and come up with more quality content.\n\nI will be grateful for your detailed feedback.\n\nThank you \ud83d\ude4f",
            "Yet another snobby  \"programmer\".",
            "Yes it is and can take hours to debug \ud83d\ude03",
            "Brings back memories of my second job where I took over a project with no globals. But there was a humongous dict passed to every single function / classes where everyone was storing everything (and modifying).\n\n\nWonder how to nicely pass value x from function A to B in a different part of the code? Just put that in the dict. All good as far as A gets called before. A gets called multiple times? Make it a sublist etc",
            "The real footgun is not using Haskell /s",
            "A good example are classes that take dictionaries as attributes:\n\n    class C:\n        def __init__(self, d={}):\n            self.d = d.copy()\n\nAbsolutely nothing wrong with the dict default argument here, while the common `if d is not None:` idiom means the object could be modified by action at a distance.",
            "Undestood, but I\u2019m fairly certain tools like pylint or myotonic wont like the default type as None with later devalues as something mutable\u00a0",
            "_hours_",
            "I\u2019m a partisan of having the default value set to None, and using d = d or {}\n\nDefaults to an empty dictionary if None, but less verbose than the if d is not None fashion.",
            "Type unions exist breh",
            "If you are writing typed Python you should definitely take a look at the `typing.Optional` class.\n\nYour can then make your type `Optional[dict]` which allows both a dict and None.\n\n    def func(optional_arg: Optional[dict] = None) -> None:\n        if optional_arg is None:\n            optional_arg = {}\n    \n        # Alternatively, for simple cases like this\n        optional_arg  = optional_arg or {}\n\nOr, if you prefer the union way of doing things\n\n    def func(optional_arg: dict | None = None) -> None:\n         ...",
            "To be honest, it depends, saying 1 hour was a bit bold but I didn't really mean 1 hour, I was just trying to mean it could end up taking long to debug",
            "Now you introduced this nasty behaviour:\n\n    d1 = {}\n    c1 = C(d1)\n    d1[\"a\"] = 1  # does not modify c1\n\n    d2 = {\"b\": 2}\n    c2 = C(d2)\n    d2[\"a\"] = 1  # modifies c2"
        ]
    },
    "py4cli (A python library for developing scalable cli utility tools using declarative programming)": {
        "title": "py4cli (A python library for developing scalable cli utility tools using declarative programming)",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1dahhdx/py4cli_a_python_library_for_developing_scalable/",
        "content": "**py4cli (Scalable Argument Parser)**\n\n# Target Audience\n\n\\* Developers who want to develop scalable cli utility tools in python using declarative programming\n\n# Comparison\u00a0\n\n\\* Even Though Python have great libraries for passing command line arguments, those libraries aren't scalable for complex use case. So, I have developed a scalable argument parser, which not only helps in passing cli arguments, but also can alter the execution flow of the code based on arguments.\n\n\\* The Library have two variants minimal and moderate argument parsers, minimal can be used for creating simple cli tool, while moderate is vertically scaled version of minimal argument parser & helps in controlling execution flow of the tool in addition to routing the arguments to the respective methods.\n\n# What My Project Does\n\n\\* The library **works fine with windows & Linux supporting basic data types like int, float, str, list, dict, bool**. Further developments for making the solution even more scalable is in progress.\n\nKindly check out the project and documentation below,\n\nGitHub Link :  [https://github.com/Palani-SN/py4cli](https://github.com/Palani-SN/py4cli) ,\n\n\\* Kindly rate the project in GitHub with stars if you like\n\nPYPI Link : [https://pypi.org/project/py4cli/](https://pypi.org/project/py4cli/)\n\n\\* Feel free to try this out with installation and usage.\n\nI am still actively developing it, so any feedback/comments would be appreciated!\n\nEDIT :\n\n**How is it different than already existing tools** :\n\n**argparse** - argparse is good in supporting different data types, but might not be able to control the flow of the code, or the arguments passed in can not be hierarchical always, which is what I term as scalability. In py4cli, the motive is to have better scalability in terms of hierarchical argument parsing.\n\n\n\n**click, typer & cyclopts** - Even though they support hierarchical cli arguments parsing, I feel, they rely much on decorators and its arguments more than necessary, In py4cli, the motive is to have, no extra decorators, or annotations as code, all that needs to be done is define a derived class from one of the base class provided in the lib, as per need and you can directly pass arguments to different methods of the class like how you will pass args and kwargs to a function natively.\n\n\n\n**Py4Cli** will be fulfilling the very basic aspects of cli interface to parse arguments, while ignoring on cli sophistication to concentrate on the scalability of the arguments passed, and in future to pass nested configuration files as inputs, with an emphasis on loosely coupled architecture.\n\n**Additional Resources** :\n\ndocs : [https://github.com/Palani-SN/py4cli/blob/main/README.md](https://github.com/Palani-SN/py4cli/blob/main/README.md)\n\nexamples : [https://github.com/Palani-SN/py4cli/tree/main/EXAMPLES](https://github.com/Palani-SN/py4cli/tree/main/EXAMPLES)",
        "num_comments": 18,
        "comments": [
            "What does it mean for a CLI to be scalable?",
            "Why would one choose it over, say typer?",
            "I'm always curious about better or smoother alternatives to \\`argparse\\`, but it's not at all clear to me how this is an improvement. I guess you're defining a CLI with a set of dictionaries with an implicit schema somehow? What were you setting out to do, and how is this better than other options?",
            "I\u2019m partial to argparse above all the new and interesting ideas for CLI entry-points. We\u2019ve built CmdKit (cmdkit.readthedocs.io) *on top of* argparse to just take care of the boilerplate and patch some of the behavior.",
            "It feels like \"scale\" applies to `kubectl`, but I can't explain why\n\nEDIT: really good completion?",
            "It\u2019s like MongoDB, you just turn it on and it scales right up",
            "Cyclopts is the new Typer",
            "Or click. I appreciate the effort but I feel like this problem has already been solved",
            "Same. I used to always default to click, but after using argparse more heavily I don't know why I ever bothered with click.",
            "The example illustrated in the docs, uses template function with all the argument type supported, the function can be customized based on our own need, like name, arguments, docstrings, return type and those will be used instead, for routing cli args to the respective functions and the order/sequence of execution will also be preserved.",
            "scalability indicates the support for hierarchical arguments to be passed in, via command prompt to certain extent and in future as nested config files.",
            "How so?",
            "Click doesn't leverage type annotations.",
            "argparse - argparse is good in supporting different data types, but might not be able to control the flow of the code, or the arguments passed in can not be hierarchical always, which is what I term as scalability. In py4cli, the motive is to have better scalability in terms of hierarchical argument parsing.\n\n\n\nClick, typer & cyclopts - Even though they support hierarchical cli arguments parsing, I feel, they rely much on decorators and its arguments more than necessary, In py4cli, the motive is to have, no extra decorators, or annotations as code, all that needs to be done is define a derived class from one of the base class provided in the lib, as per need and you can directly pass arguments to different methods of the class like how you will pass args and kwargs to a function natively.\n\n\n\nPy4Cli will be fulfilling the very basic aspects of cli interface to parse arguments, while ignoring on cli sophistication to concentrate on the scalability of the arguments passed, and in future to pass nested configuration files as inputs, with an emphasis on loosely coupled architecture.",
            "To me scalability and CLI dont go together as CLI is by definition local to that single terminal you ran it from. But I guess the term has different conotations depending on the one who uses it",
            "comparison with already existing tools :\n\n\n\nargparse - argparse is good in supporting different data types, but might not be able to control the flow of the code, or the arguments passed in can not be hierarchical always, which is what I term as scalability. In py4cli, the motive is to have better scalability in terms of hierarchical argument parsing.\n\n\n\nClick, typer & cyclopts - Even though they support hierarchical cli arguments parsing, I feel, they rely much on decorators and its arguments more than necessary, In py4cli, the motive is to have, no extra decorators, or annotations as code, all that needs to be done is define a derived class from one of the base class provided in the lib, as per need and you can directly pass arguments to different methods of the class like how you will pass args and kwargs to a function natively.\n\n\n\nPy4Cli will be fulfilling the very basic aspects of cli interface to parse arguments, while ignoring on cli sophistication to concentrate on the scalability of the arguments passed, and in future to pass nested configuration files as inputs, with an emphasis on loosely coupled architecture.",
            "Thanks!\n\nMy question was \"How Cyclopts is the new Typer?\" though.",
            "It does the same or even more, but in a cleaner way, and is actually maintained and actively developed, unlike Tyler or other projects with the same maintainer."
        ]
    },
    "Lightning-Fast Text Classification with LLM Embeddings on CPU": {
        "title": "Lightning-Fast Text Classification with LLM Embeddings on CPU",
        "score": 46,
        "url": "https://www.reddit.com/r/Python/comments/1d9g7qz/lightningfast_text_classification_with_llm/",
        "content": "I'm happy to introduce [fastc](https://github.com/EveripediaNetwork/fastc), a humble Python library designed to make text classification efficient and straightforward, especially in CPU environments. Whether you\u2019re working on sentiment analysis, spam detection, or other text classification tasks, fastc is oriented for small models and avoids fine-tuning, making it perfect for resource-constrained settings. Despite its simple approach, the performance is quite good.\n\nKey Features\n\n* Focused on CPU execution: Use efficient models like deepset/tinyroberta-6l-768d for embedding generation.\n* Cosine Similarity Classification: Instead of fine-tuning, classify texts using cosine similarity between class embedding centroids and text embeddings.\n* Efficient Multi-Classifier Execution: Run multiple classifiers without extra overhead when using the same model for embeddings.\n* Easy Export and Loading with HuggingFace: Models can be easily exported to and loaded from HuggingFace. Unlike with fine-tuning, only one model for embeddings needs to be loaded in memory to serve any number of classifiers.\n\n[https://github.com/EveripediaNetwork/fastc](https://github.com/EveripediaNetwork/fastc)",
        "num_comments": 14,
        "comments": [
            "As far as I can tell (and I've read the entirety of the source code, it's very short), there is NO difference between this and what you would do to use huggingface embedding models with more \"direct\" transformer `AutoModel` and `AutoTokenizer`classes that are in the majority of cases already documented on each model page. If anything, it's a degradation in that native functionality of SentenceTransformers or Transformers in that control over pooling strategies and a more direct interface to the model is lost/abstracted but without adding in the nice features of SentenceTransformers.\n\nThe centroid classification is... problematic. You're always mean pooling to get an embedding (that's fine-ish) but then just embedding the label to get a \"centroid\" (btw, you're also calling `list()` on an `np.ndarray` just to turn around and convert it back to an `np.array`, which is quite wasteful). Then you're using the inverse cosine distance (also wasteful, you have complete control over the output embeddings, you could normalize them and use inner product) from each \"centroid\" divided by the total inverse cosine distance as a \"probability\" that these labels are correct. That's not what cosine distance is, though. Heck, a logit would make this better than it is.\n\nIn summary:\n\n- There are NO CPU optimizations in this library\n- There is significantly less functionality here than in SentenceTransformers or Transformers on their own (depending how much abstraction you want)\n- There are some performance regressions here in terms of unnecessary type conversions and cosine distance on unnormalized embeddings vs IP on normalized embeddings\n- The labeling feature is a based on a \"toy\" methodology; unsupervised learning (including smart dimensionality reduction) to determine the labels relevant to a set OR using the embedding as a fixed feature extractor in a transfer learning scenario are not only much better techniques, they are not that hard to implement (I volunteer to teach 12-17 year olds to do both of these techniques in my labs)\n\nShort conclusion: I think this may have been a hobbyist idea or learning project for you (hopefully in good faith and not using AI to generate the whole thing; someone complained about an AI comment below). You should represent it as such and ask for feedback instead of saying it is a CPU-optimized or lightning fast text classifier. It is none of those things and no one should use it in anything like production scenarios.",
            "Why not just use [Setfit](https://github.com/huggingface/setfit)?",
            "Looks interesting! How can I find pre-trained models for other languages on Hugging Face? I  assume that something like this would not work: jarvisx17/japanese-sentiment-analysis. What should I be looking for?",
            "[removed]",
            "bro just got professionally torn a new hole",
            "Is this Kendrick? U bitch slapped this man like he\u2019s not like us",
            "Could you expand on the unsupervised learning to learn the set of relevant labels?",
            "I coded this to execute many lightweight classifiers with a minimal footprint on the same machine: a single model loaded for embedding generation serves multiple classifiers. As far as I know, this cannot be achieved with setfit, as each model would be different, resulting in a massive memory footprint if the number of classification tasks is large.",
            "Thanks! You can use almost any transformer model from HuggingFace. For sure try jarvisx17/japanese-sentiment-analysis, but keep in mind that the model will be used solely for generating embeddings; the classification head will not be utilized.",
            "Wow cool totally not ai generated comment on a never before active account",
            "Thanks!",
            "Sure. It's disappointingly simple, but it shows off the power of representational learning. The following will be tongue-in-cheek but also practical.\n\n1. Gather a large set of documents you want to label. For the purposes of keeping the parameter sizes reasonable, they are all under 512 tokens or we don't much care about the parts of the document after the 512th token.\n2. Embed them using a high-quality, pre-trained embedding model. Go nuts, use a fancy instruction-tuned one like e5-multilingual-instruct, and give it an instruction that says, \"Instruct: Represent these for clustering.\" Find your bliss. These models were definitely trained with supervised learning, but you sure as heck didn't have to supervise it.\n3. (Optional and/or mildly controversial) Use a good unsupervised learning dimensionality reduction method. UMAP is the current darling, but no one can stop you from using PCA. I guess a lot of people could stop you but no one will. Get those dimensions down till you can plot 'em. 3 dimensions? Rookie numbers. I wanna see these embeddings on the ugliest plot matplotlib can give us.\n4. Use the elbow method to determine how many clusters there should be. The kneed library will just straight up do this for you and depending on what happened in step 3, probably won't take very long or have to do very much work (as step 3 kind of already had to identify the neighborhoods).\n5. Assign k-means clusters using the `k` from the step above. Plot 'em in a manner that lets you mouse over and read the documents or serialize them all to separate sheets in an excel workbook. Read as many example members of the cluster as you feel like. Use your human brain, perfected by millions of years of evolution, to decide what the label for each cluster should be. Or, even cheaper, feed each cluster to an LLM and ask it to label them.\n\nEmbedding will extract important features from each document. Those features aren't in any way, shape, or form human interpretable. UMAP-learn will turn those features into 2/3-D neighborhoods and distances. K-Means and kneed will automatically group them. You or your AI friend will label those groups. Voila.",
            "Thank you for the elaborate response! Reminds me much of the BERTopic approach",
            "Very similar. I don't much care for the tf-idf step or the combination of UMAP and HDBSCAN in default BERTopic (I know you can substitute your own) but otherwise, yes."
        ]
    },
    "Password protect Pdf using python ": {
        "title": "Password protect Pdf using python ",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1da5fpo/password_protect_pdf_using_python/",
        "content": "https://youtu.be/sSPWHRpDZXo?si=b-HJ4Cu1sN-tFls1\nThis video explains how files ( all types) are encrypted and decrypted with PyAesCrypt module of python. \nAlso using pypdf module , pdf files are password protected. Decryption of password protected pdf can also be done\n",
        "num_comments": 0,
        "comments": []
    },
    "RESTful API Hosting": {
        "title": "RESTful API Hosting",
        "score": 28,
        "url": "https://www.reddit.com/r/Python/comments/1d9ieqm/restful_api_hosting/",
        "content": "Good morrow all,\n\n  \nI have a simple rest api I have initially developed using Flask. This is a super low utilization app, that may receive 10-12 requests per week. Currently, I have it running a local network using my main machine as the server. This has been great for testing and development, but I need to transition to a more permanent hosting situation. I have been looking at Azure Functions and this seems like the way to go, and would fall under the free tier from what I can tell. Is this the way to go? OR Should i look at other options?\n\n  \nThis is something for work, not a personal project.",
        "num_comments": 31,
        "comments": [
            "Azure Functions is perfect for this type of use case so long as you are ok with the warm up time which these days is around 5 seconds if the API hasn't been run for a while around 10 mins (I'm not sure what the exact time is these days)",
            "You could try PythonAnywhere before spending any cent. They have free tier as well and when and if you want something more robust, they got plans as cheap as $5/month.\n\nI've been using the free service for small applications and it's been great because I got a small MySQL database and a server to host my Django app. I know it's not perfect but it almost got there (free tier doesn't have SSH and it's a bummer, but, well, it's free).",
            "I believe a digitalocean droplet for about $6/month should be more than enough for your requirements",
            "I have mine running in render $7",
            "Azure functions or AWS lambda are good for things with inconsistent usage.\n\nOnly other alternative is renting a cheap VM - Azure starts around $10-15/mo with a 1 year reservation, other providers have cheaper stuff. If its for work the time savings of lifting/shifting a flask app is probably worth taking the time to re-write it as an azure function",
            "AWS Lambda + Zappa makes deployment easy as can be",
            "If you\u2019re fine with containers and need an Azure solution, Azure container apps would work better, and would probably fall into the free tier. (Generally I prefer Google cloud run, which is the same thing but just tends to work a bit better)\n\nAzure functions are more designed for short, quick pieces of code that need to run often. A container app  gives you more flexibility.",
            "If you have at least $10/month in budget you can keep the app running to prevent Azure Functions warm up time. [Ploomber](https://docs.cloud.ploomber.io/en/latest/apps/flask.html) and Digital Ocean are good options.",
            "I\u2019ve had good luck with AWS lambda via the Zappa framework. It\u2019s built for exactly this type of thing.",
            "I haven't used azure functions, but I've always found AWS lambda hard to test and manage.  I do it NOW fine, but that's after lots and lots of time and work.  The easier thing I did a lot of for a long time was just push containers to AWS Fargate.  That's got it's own learning curve so YMMV, but anecdotally it was way easier to make sense of, especially since I was already using docker and docker compose locally for almost all my projects.\n\n...\n\nactually I just typed out a \"simple description\" of the moving pieces for that and I have no idea how I figured it out to begin with lol.  it really is kind of complicated.  but it IS the first \"cloud deployment\" story I got good at so... \n\nanyway, just in case it's useful: \n\ncontainers are built locally (or in github actions) and pushed to private repository (ECR).  they're referenced in a task definition, which is referenced the specification for an ECS task as part of an ECS service deployed on an ECS cluster (there's two types, fargate is the one you don't have to manually build and maintain servers for).  that service then essentially requires a load balancer in front (ALB).  assign a domain name to the ALB and now you can connect to your webapp.  \n\nsounds like a lot, and it's obnoxious to figure out the first couple times, but wrap it up in terraform and then you can stamp that crap out for every new service.",
            "Free tier cloud run on gcp should be enough.",
            "I have a flask API server running on Google cloud that takes ~10k calls a month, as well as a data dashboard on Dash that cost me about $25/mo.",
            "If you have a machine at home and this is more of a personal project you could consider running it on that.\n\nNAT from your firewall to your machine, single port, and use a cron job to keep the DNS up to date.",
            "[fly.io](http://fly.io)",
            "If it's for work, surely you can expense it? Try wasmer edge, it's serverless without the cold start problem. Strip flask, package your core functions in to wasm binaries and forget about the headache. Free tier is generous.",
            "With the Azure function app can you secure your app with jwt?",
            "You can buy hatzner server for a 4usd",
            "Try [fly.io](http://fly.io) - free starting tier available. Super easy to start up.",
            "Free tier oracle compute",
            "About a year ago heroku had a free tier for this kind of app. Maybe it\u2019s still available",
            "Yeah, the scripts are fairly time intensive anyway, so an extra few seconds to load up the env isn't going to be an issue. More or less, I made a bunch of automated workflows for large reporting jobs that are run daily. But then the boss demanded that the reports and such be able to run on demand if they feel like it. In the last 3 months of this being live, I think it's been used a total of ONCE. But I'm tired of hosting it off my machine.",
            "PythonAnywhere is cool for small personal projects or fun projects, but want something a little more robust for this use case.",
            "Yeah, most of the scripts are based on APIs for hosted services. From what I've been able to read and research, it seems like I would just end up subbing out the flask framework for the azure functions framework and it should just work? Sound about right?",
            "GCP is a massive bitch though, I have problems at almost every service. Even using `gcloud` AWS and Azure do what OP wants way better imo. Or a service like render.",
            "I said it\u2019s a work thing lol",
            "it's good, but it does have a cold start problem.",
            "Cloudflare has Python support too now.",
            "Nope. I've migrated to Railway.app for personal / small projects.",
            "One thing with functions on free/comsumption tiers there is a run time limit of 10mins I think  so depending on how long these run that could be a problem and youd have to go to premium tiers.",
            "Not familiar enough with azure functions to say for sure! \u00af\\\\_(\u30c4)_/\u00af",
            "smallest machine in free tier that runs all the time doesn't cost anything.\u00a0"
        ]
    },
    "The Python on Microcontrollers (and Raspberry Pi) Newsletter, a weekly news and project resource": {
        "title": "The Python on Microcontrollers (and Raspberry Pi) Newsletter, a weekly news and project resource",
        "score": 1,
        "url": "https://www.reddit.com/r/Python/comments/1cigewi/the_python_on_microcontrollers_and_raspberry_pi/",
        "content": "# The Python on Microcontrollers (and Raspberry Pi) Newsletter: subscribe for free\r\n\nWith the Python on Microcontrollers newsletter, you get all the latest information on Python running on hardware in one place! MicroPython, CircuitPython and Python on single Board Computers like Raspberry Pi & many more.\r  \n\r  \nThe Python on Microcontrollers newsletter is the place for the latest news. It arrives Monday morning with all the week\u2019s happenings. No advertising, no spam, easy to unsubscribe.\r  \n\r  \n10,958 subscribers - the largest Python on hardware newsletter out there.\r  \n\r  \nCatch all the weekly news on Python for Microcontrollers with [adafruitdaily.com](https://www.adafruitdaily.com).\r  \n\r  \nThis ad-free, spam-free weekly email is filled with CircuitPython, MicroPython, and Python information that you may have missed, all in one place!\r  \n\r  \nEnsure you catch the weekly Python on Hardware roundup\u2013 you can cancel anytime \u2013 try our spam-free newsletter today!\r  \n\r  \n[https://www.adafruitdaily.com/](https://www.adafruitdaily.com/)",
        "num_comments": 0,
        "comments": []
    },
    "Fields and class properties should be sorted alphabetically?": {
        "title": "Fields and class properties should be sorted alphabetically?",
        "score": 51,
        "url": "https://www.reddit.com/r/Python/comments/1d9awdu/fields_and_class_properties_should_be_sorted/",
        "content": "Hello, I'm having code-review suggestion doubts about sorting alphabetically fields in classes, e.g. Pydantic models. For example, there's a model:\n```python\nclass Example(BaseModel):\n    id: int\n    name: str\n    surname: str\n    age: int\n    operation: str\n```\n\nOne of developers suggests that fields should be sorted alphabetically:\n```python\nclass Example(BaseModel):\n    age: int\n    id: int\n    name: str\n    operation: str\n    surname: str\n```\n\nI think there shouldn't be any specific order but only developer' subjective look at importance and connection between fields, like \"name\" and \"surname\" should be next to each other because they are in some way connected.\nWhat is your opinion? Maybe there are some PEP8 rules about that?",
        "num_comments": 31,
        "comments": [
            "Where things have no inherent order, sorting them alphabetically can be helpful. For example, such sorting can avoid merge conflicts when items are added. Thus, sorting imports with `isort` or `ruff` is reasonably common.\n\n\nBut functions, attributes, class members do have order. In some cases like dataclasses this matters explicitly because the order of fields corresponds to the constructor signature. But even without that, order matters for humans. Important things go first, related things should be near each other. It matters what aspects of the code are emphasized for future readers.\n\n\n\nIn that model, it absolutely makes sense that an `id` field goes first. The `name` and `surname` should be close together. The `operation` field might be so important that it is shown near the top, or it might come at the end, after all the person-related fields have been sorted out.\n\n\nThe alphabetically sorted version emphasizes the `age` field for some reason. That can make sense if this is about calculting the age of something (like a cache entry), but less so if this object is about a person that happens to be an age. Also, `name` and `operation` are made to look related. Is that the name of the operation, like a label for a button? These fields do not make me think about \"person\", until I've stumbled across `surname` at the very end.\n\n\nSo to a reader of this code, those two variants can communicate different things.\n\n\nIn practice, the class name and docstrings would provide valuable context that helps disambiguate this, but ideally you have both documentation and non-misleading code.",
            "Your reviewer needs training. If order does not matter, then a sort may be worse than an arbitrary order, as it implies something false. Look for groupings and apply if found.",
            "Along with it feeling natural in importance to have \"id\" or whatever primary key first (followed by next highest importance fields), it indeed makes sense to have ***related fields*** clustered together.\n\nIf created_at, updated_at, and deleted_at were speckled in ***alphabetically*** to the list of attributes \u2014 instead of clustered together at the end \u2014 it would be annoying and require you to visually pluck each one out if you wanted to change anything about how that trio of fields function.\n\nIt also makes it more useful if viewing the data, for example in an SQL client, to see the most important columns first and related columns next to each other. And it would be annoyingly odd if your primary key such as id, which the SQL would default sort by, wasn't the first column.",
            "This is no more than a personal preference of the reviewer. Code reviews should never include personal preferences. They should stick to functional problems and conventions the project members have agreed on. There doesn't seem to be an agreement about this.",
            "Sounds like a linting / formatting rule, that should either be enforced through tools, or leave it as is. Otherwise it's just [bikeshedding ](https://thedecisionlab.com/biases/bikeshedding)",
            "christ.  if this is the kind of thing you're worrying about in code reviews you've either got wonderful code or are wasting time on irrelevant details.",
            "Don\u2019t listen to reviewers that include their personal preferences.",
            "This is some beautiful bike shedding",
            "One of your developers is an idiot. Fields should be grouped adjacent to other fields they\u2019re related to. Worse comes to worst, they should be in the order in which they most commonly show up on-screen or in reports.\n\nThe only case for sorting by name would be where there is no other good hierarchical grouping, or where they\u2019re all roughly equal importance - if you had one field for each state in the USA, for instance, then listing those in alphabetical order would make sense.",
            "There's no PEP because ordering fields in structured data is almost always a semantically meaningful thing.\n\n\nAlphabetical makes sense for lists of things (eg list of services, emails, ACLs, domains) but structs/models (whether they be true structs, dataclasses, db models, or pydantic models) it's much clearer to organize them by importance, intent, and data type. Alphabetizing might make sense if you have a very large number of fields (like >30).",
            "I'd say this is more a general coding question than python. Honestly though this is a style thing as others have said. \n\nThere's no \"right way\" to do this, but remember you're going to spend more time reading code than writing it, especially reading other people's code. Someone may have to touch your code years after you've left the company and has never met you. Or worse, you might have to touch your code 6 months from now and you have no idea what you did or why you did it. I think you should strive to make your code self-explanatory and if you can't for whatever reason leave a comment. \n\nBe kind to your fellow programmers and your future self.",
            "It's much easier to read code where things that belong together are grouped together, as you have done. I can't image a scenario where sorting fields alphabetically is beneficial... maybe if you don't have a search function in your IDE?? In that case - what??",
            "Thanks a lot everyone, there's a lot of interesting opinions here \ud83d\ude42",
            "I'm a beginner, but here's my two cents. Attributes should be sorted logically first (i.e. by way of importance), specifically ID should be at the very top.\n\nWhy? Because you want to make a Singleton class bound to the ID. Age? You'll have a lot of the same for that.\n\nBesides, age should probably not be an attribute in the first place (why? Think what happen in 2035). So once that's changed to DoB you'll not have an issue.\n\nException. Unless it's a time freeze where you're logging the age at a certain event, like a clinical trial etc, and age is important for the event and is not meant to change.\n\nSo, first item should be ID, second item should be surname and only then given name (passport standard, same with year-month-date).\n\nThen again, I'm a beginner and will likely deserve to be down voted but that's my two cents.",
            "Fully agree with the general sentiment in the thread, if there's no need for a specific order, I'd usually order them by my perceived order of importance, but wouldn't expect or request a change in that order on a review.",
            "I think alphabetical order makes sense when data is dynamic. In model like this I'd like to see some heuristic like most used fields first or groups of similar fields.",
            "If you have lots of them in a class.",
            "No, you're right, grouping similar variables together is typically the preferred choice.\n\nThat said, sorting alphabetical isn't *wrong* per se.",
            "Ask the reviewer to show in the organizations code requirements/guidelines/policies that says it needs to be sorted. This sounds like a reviewer that just started reviewing",
            "This response completely encompasses what I've just read recently about robust python\n\n\"Write your code in a way that conveys the intention of the code so anyone can quickly see what the code is doing\"",
            "No, if order doesn\u2019t matter then an alphabetical sort makes a lot of sense. It makes it easier to parse and easier to review changes. The issue is that the order can matter a lot even if a different order would technically still function. For example, grouping attributes that are related is usually helpful for people trying to utilize your code.",
            "I do id at the top followed by other identifiers, then all the dates (created, updated etc...) and then everything else mostly at random",
            "maybe it is their companies style ?",
            "While I absolutely agree that this very case is a matter of personal opinion, there are cases where I as a reviewer am not sure if it is a personal opinion of mine or a good habit that I should enforce. If I only mention the things that I am certain are common practice (e.g. keep it simple, avoid unreable names, ...) I am missing a lot of hard earned \"smells\" or intuitions. \n\nCurrently, during code reviews I try to mention when I am uncertain about a specific change proposal and am happy to let them be ignored.",
            "And I learned something new today. Thanks",
            "You should absolutely listen to personal preferences. Just don't take it as law.\n\nAny large code base is going to include some personal preferences, that's just how code is. And it makes sense to try to keep the code as similar as possible, which include listening to someone's personal preferences, and even following them at times. Just... don't overdo it.",
            "Your example is to look for groupings - as I state. You seem to not have read all you said no to?",
            "Then it should be enforced with a linter and the problem is still moot either way",
            "then their company's style is bad",
            "Im responding to the part of your comment where you said an alphabetical sort is problematic if order doesn\u2019t matter. The part where groupings help users parse inputs is a case where order does matter and isn\u2019t a case my comment addresses.",
            "i sort of agree, i mostly write in go so alphabetizing is silly because it messes with memory footprint.   i couldn\u2019t quite see how structures are allocated in python, it looks like it creates a dict if you don\u2019t use slots .."
        ]
    },
    "Tuples Are Underrated! List vs Tuple \ud83d\udc0d": {
        "title": "Tuples Are Underrated! List vs Tuple \ud83d\udc0d",
        "score": 27,
        "url": "https://www.reddit.com/r/Python/comments/1d9cfxq/tuples_are_underrated_list_vs_tuple/",
        "content": "Do you feel like you're underutilizing tuples in you code? Maybe cause you think lists are always the correct choice, and tuples don't have a place to exist.\n\n[In this video](https://youtu.be/-sO4FG6W4ho) we will walk through the differences between lists and tuples, especially focusing on a difference very rarely discussed, albeit it being the most crucial one: the semantic. Following that we will elaborate how and when it is better to utilize either lists or tuples!\n\nAny feedback on the content would be highly appreciated \u263a\ufe0f\n\nhttps://youtu.be/-sO4FG6W4ho",
        "num_comments": 28,
        "comments": [
            "I mean, tuples can be hashed and lists can't. That seems like a pretty important use case right there...",
            "I use named tuples to define constants because they are immutable. I haven't seen a better way of making a constant a true constant in python.",
            "I make a point of using tuples for every time I have a collection that is immutable.",
            "Very informative",
            "I always use tuples to store list inside /s",
            "I like tuples too. But I've learned here to use lists for homogenic data types and tuples for heterogenic data. That's considered as pythonic.\nAnd typing supports that theory so you need this for homogenic tuples:\ntuple[str, ...]\n\nBut it feels strange to use lists for constant data. You could use proxies to get a read only list. But that gets more complicated that just using a tuple.",
            "For me its more like tuple vs class where class usually wins.",
            "Fun fact...tuples are actually \"near\"-immutable.  If a mutable collection (list, dict, etc) is an element in a tuple, you can change the individual collection elements.\n\n    >>> tt = ([1, 2, 4], \"me\")\n    >>> tt[0]\n    [1, 2, 4]\n    >>> tt[0][2]=3\n    >>> tt\n    ([1, 2, 3], 'me')\n\nThis seems like it would be useful but I can't think of a reason to actually do this :)",
            "One advantage of tuples is they're immutable. Things that don't need to be mutable are often better off not being mutable",
            "I say, Use tuples whenever you want to store data mostly just for the reason of having a collection. If you need to use operands on the collection I suggest using a list.",
            "You're absolutely right! This falls under the mutable vs immutable difference, but it definitely deserved to be mentioned explicitly.\n\nThank you for the feedback :)",
            "I mean, you can 100% hash a list by converting it to a string.",
            "super beginner here can u show me what that code looks like? is it name = (thing,), like that?",
            "Glad you think so! Thank you for the comment :)",
            "Named tuples are your friend.",
            "Tuples vs class? These seem like completely different use cases.",
            "Thank you for engaging!\n\nI get your intuition, but there's no such thing as a \"near\"-immutable. In your example, a tuple \"tt\" is defined as having 2 elements. These elements are technically pointers to objects, and these pointers can never change. In fact, if you try to \"tt[0] = [1, 2, 3]\" you will get a TypeError.\n\nBy executing \"tt[0][2] = 3\" you are effectively changing the object pointed to by \"tt[0]\", but \"tt[0]\" itself isn't changed and the pointer remains pointing to the same address.\n\nIf you're interested in how lists/tuples are technically stored in memory in Python, you can check [my video](https://youtu.be/LWocUIE_Eic) on shallow copy vs deep copy!\n\nHope this helps :)",
            "> This falls under the mutable vs immutable difference\n\nNot really. Although hashable types are usually immutable, it is possible for an object to be both mutable and hashable.\n\nWe don't usually want this because normally we expect that the hash value of an object does not change over its lifetime, and that the hash always refers to the same value. Nevertheless, it is technically possible for a custom class to be given a `__hash__` method, making it  hashable, even when instances are mutable.",
            "then you're not hashing a list you're hashing a string",
            "xD",
            "No, search for named_tuple.",
            "It\u2019s quite common for people to use tuples or named tuples as a way of building some basic data structure in the same way you might use a class. For example, if you wanted to store a list of data points you could do it as a tuple: (X,Y,Z)\n\nOr you could create a class/dataclass: Point(X,Y,Z)",
            "I guess I should've said \"near-mutable is a term I completely made up\". Of course there's no such thing...lol.\n\nFWIW, I'm fully aware of the internal storage mechanisms of Python objects.  The point of my post was to emphasize the use of mutable objects within an immutable collection, thus giving the (false) appearance the tuple is mutable when it definitely is not.\n\nLike I said, I don't see much use doing this as there are other ways to more effectively implement such a technique.  It's just an oddity I thought others would find interesting, like how Python refers to methods as \"attributes\":\n\n    >>> aa=\"Hello\"\n    >>> aa.not_a_method\n    Traceback (most recent call last):\n      File \"<stdin>\", line 1, in <module>\n    AttributeError: 'str' object has no attribute 'not_a_method'\n\nThat particular error confuses many beginners :).",
            "It took nearly 20 years of python before I wrote my first `__hash__`, but you get your butt there is a massive \"THAR BE DRAGONS HERE\" warning on the method detailing the consistency guarantees",
            "What do you think is happening to your tuple?",
            "cool thx",
            "The comment seemed very reductionist but now I realize it was directly referring to lists vs tuples.\n\nI got confused since this class vs named tuple distinction is just a very narrow subset of their many uses. There are other things each can do (in the case of a class, MANY other things).",
            "in the cpython implementation there is some sort of complex logic involving taking the hash of every element in the tuple and XORing them together and multiplying by a prime number. I have no idea what point you're trying to make."
        ]
    },
    "CMake configs for Python modules (Pytest, Sphinx, \u2026)": {
        "title": "CMake configs for Python modules (Pytest, Sphinx, \u2026)",
        "score": 4,
        "url": "https://www.reddit.com/r/Python/comments/1d9lt4d/cmake_configs_for_python_modules_pytest_sphinx/",
        "content": "As Python is one of the most popular languages, many C++ projects end up using Python bindings of some sort. Pytest and Sphinx are\u00a0[very popular frameworks](https://lp.jetbrains.com/python-developers-survey-2022/), so many CMake modules have been written, and most projects end up including a\u00a0[copy of these modules](https://sourcegraph.com/search?q=context:global+file:FindSphinx.cmake&patternType=standard&sm=1)\u00a0or using some\u00a0[hardcoded paths](https://sourcegraph.com/search?q=context:global+file:CmakeLists.txt+sphinx-build&patternType=standard&sm=1).\n\nI wrote two Python packages to manage the installation and update of CMake configs for Pytest and Sphinx.\n\n* [https://github.com/python-cmake/pytest-cmake](https://github.com/python-cmake/pytest-cmake)\n* [https://github.com/python-cmake/sphinx-cmake](https://github.com/python-cmake/sphinx-cmake)\n\nIt uses the\u00a0`pip`\u00a0package management, providing a module for each package and automatically generating a configuration based on the package version found.\n\n    > pip install pytest-cmake\n    > pip install sphinx-cmake\n\nI hope this method can standardize module integration for common Python tools.  \n  \nLet me know what you think!",
        "num_comments": 1,
        "comments": []
    },
    "Polars news: Faster CSV writer, dead expr elimination optimization, hiring engineers.": {
        "title": "Polars news: Faster CSV writer, dead expr elimination optimization, hiring engineers.",
        "score": 177,
        "url": "https://www.reddit.com/r/Python/comments/1d8mv0a/polars_news_faster_csv_writer_dead_expr/",
        "content": "Details about added features in the releases of Polars 0.20.17 to Polars 0.20.31\n\n- https://pola.rs/posts/polars-in-aggregate-jun24/",
        "num_comments": 46,
        "comments": [
            "Polars is an amazing project and has completely replaced Pandas at my company.\n\nWell done Polars team",
            "Any sense on the speed of numeric types compared to pandas?",
            "Writing polars directly to snowflake would be helpful!",
            "I love polars\uff01",
            "Pandas fans have gone silent since this came out",
            "Itt: people who don't know how to use pandas",
            "Horrible exceptions handling. \ud83d\ude02 \n\nYour company got balls to completely jump ship like that \ud83d\ude02",
            "Really? I like polars but most of the people at my company still prefer pandas. The syntax is just way more convenient for people who aren\u2019t doing data science or some similar role full time.",
            "Directly is hard, but if you convert it to an arrow dataset with zero copy, there are tools in snowpark/ the snowflake-python-connector for this. I have some slightly modified versions of the Dagster snowflake io manager which I misuse for this purpose",
            "https://i.kym-cdn.com/entries/icons/facebook/000/039/237/i-don't-think-about-you-at-all.jpg",
            "Can\u2019t really give Polars a shot until they invest more in the Geo ecosystem and get GeoPolars close to feature parity with GeoPandas. DuckDB is killing it for most workloads I might consider switching for and has the bonus of SQL readability, strong Geo support etc.",
            "It wasn't done in a day.\n\nCan you give an example of exception handling issues you've encountered in Polars? I'm truly interested to know.",
            "The exceptions that come out of Polars are often unintelligible and useless. I with they had better descriptive statements that actually tell you what's wrong.",
            "We actually found that to be the opposite. Polars\\` API is much more intuitive and it has simplified our codebase quite a bit. The fact that it's much faster than Pandas and allows working with huge datasets without hogging memory is a major win for us.\n\nWe didn't force the transition though. Some people started to use it and after a few months it completely replaced Pandas almost everywhere. To each his own I guess ;-).",
            "The pandas syntax is horrific, this is Stockholm syndrome",
            "Expressions are the most elegant syntax I\u2019ve ever seen",
            "Why does anyone who is not doing data science full time have to touch pandas or polars?",
            "Could you share how you are doing arrow dataset to snowflake table?",
            "Another person who is 100% on polars now. \n\nThe exception handling issue comes from failures happening on rusts end. The high performance comes from an expectation that when you say data will be a certain type (or it\u2019s look ahead inference said it would be), and you turn out to be wrong, it entirely shits the bed.\n\nWhen this happens, quite often wrapping it in a try/except block doesn\u2019t do shit and it just does. Particularly annoying in a notebook context where earlier cells were expensive/involved network IO.",
            "im with ya. i got to choose all the main libs and what not in my current role because i was the first hire with ML experience. pretty much insisted to my mentee that we use polars. he didnt object. he quickly grew to like it.\n\nno more 'DataFrame | Series | np.ndarray | list | dict | None' return types \ud83d\ude4f\ud83d\ude4f",
            "We are having to force transition where possible because of how much more is involved for even doing basics.",
            "What do you mean? Their expressions are pretty standard.",
            "People still do data analysis outside of data science. For example, I work in robotics and a lot of people who work in automation, process development, etc still want to look at sensor data and compute/plot basic information from the raw data.",
            "If you don't need to transform tabular data in app code or perform ANY quantitative operations on tabular data in app code, yeah, you don't need either. That's not really data science, though. Amortization schedules, ETF, and simple order summaries are all examples off the top of my head that non-data-science apps would benefit from a library with good functionality to reshape and vectorize calculations on data.\n\nAlso, this is opinionated, but at the point your app wouldn't be able to make any use of something like pandas, your app is probably either niche and narrow (great!), could be handled completely with low-code/configuration solutions, or simple enough that the Django tutorials and getting started pages could probably completely reconstruct if you swapped some models out.",
            "On mobile, but the gist of it is\n```\nfrom snowflake.connector.pandas_tools import write_pandas\n\n\nwrite_pandas(\n            connection,\n            df= df.to_pandas(use_pyarrow_extension_array = True),\n            table_name=\u2026,\n            schema=\u2026,\n            use_logical_type=True,\n        )\n```\n\nSnowpark is great for a surprisingly polars like api, but unfortunately they don\u2019t currently expose the ability to fetch/write pyarrow tables and thus you need to fall back to the snowflake connector if you want to have all the strict typing benefits that they bring. There are open issues on this, but our snowflake account manager doesn\u2019t think it\u2019s likely to get prioritised.",
            "Polars Author here. Let me try ot give some context on why some `try/except` clauses might not work.\n\nLet met start by saying that Polars is strict, much stricter than pandas is. Pandas has historically had a strategy of \"just work\", where it had to guess if things were ambiguous. Polars doesn't try to guess, and tries to raise errors early or indicate something is wrong early in the pipeline. If we guess the wrong intent on behalf of the user, there might be implicitly wrong results.\n\nWhen types don't resolve, we raise an error and those errors can be catched with a `try/except` clause. \n\nHowever, it must be said that we are still too much dependent on Rust `panic`s. A Rust `panic` cannot be catched as it indicates a state where we cannot recover from.\n\nAt the moment Polars still uses too many panics where it should raise an error. This is being worked on.\n\nIf a type isn't the same as type inference indicates, there is a bug. Can you open an issue in such a case?",
            "Thank you very much, that makes sense.",
            "This so much 100%, took the words right out my mouth. This is also the reason why (anecdotal) I see a lot of ppl who port over to Polars & get the most out of it are for codebases/projects that are already said & done so to speak.",
            "So basically the only issue is that ppl don\u2019t know how to type data? How surprising\u2026",
            "I just run infer_schema_length=0 on everything, then use functions to convert them to the right data type. Those functions cast the conversions and return null if it fails.",
            "This is probably generally a good idea on the polars' end, but not great for the Python dev experience. It's very much rust doing rust things.",
            "Pandas does not have pd.col(col).operation that u can store in a variable to the best of my knowledge",
            "Thank you! Wouldn\u2019t you need to turn the polars data frame into a pandas dataframe for this to work?\n\nThe pyarrow backend probably helps with data type conversions right?",
            "Thanks for the explanation! I\u2019ve recently been trying to get better with rust so it\u2019s nice to see a practical example of panic vs explicit error handling in the wild.\n\nWe had a play in the office today, and the main culprits for these issues seem to get handled gracefully so thanks for the hard work making it more robust.\n\nTo clarify, I don\u2019t think the strictness is a problem. It\u2019s just a new way to approach writing code. We have had grads join our team with no pandas experience and have gone straight into polars. It kind of shows in their coding style, where they are hesitant to lean on pythons duck typing elsewhere, and I can definitely think of worse habits to have developed!",
            "No worries :) Generally speaking I\u2019ve found that if your source data is in some way type safe (I.e. you\u2019re reading from a parquet file or arrow dataset) then you can be a lot more concise with the expressions you run in prod.\n\nIf you\u2019re parsing a csv or json file, once you\u2019re done questioning what crimes you are being punished for, you need to do a lot more validation before you really go for it with polars.\n\nOne that caught us out early on was a short lookahead window for sequential ids. Polars would go \u201coh, this\u2019ll fit in an unsigned 8 bit integer no problems. Pan ahead to item 256, or the first row with a sentinel value of -1, and you\u2019re looking at a utterly undiagnosable segfault in your cloud watch logs that your tiny dataset for local dev doesn\u2019t seem to reproduce.",
            "What???",
            "    df2 = pd.DataFrame([\n        df.loc[0] + 1,\n        df.loc[1] * 3,\n        df.loc[2]\n    ])",
            "Are you talking about broadcasting operations? Pandas has that.",
            "Yeah, that\u2019s what the .to_pandas(\u2026) bit does. Using logical types means that the pandas writer uploads a bunch of parquet files to intermediate storage as its way of uploading. \n\nThe only gotcha I\u2019ve encountered with this is snowflake don\u2019t handle timestamps well in various ways. Local time zones, NTZ, and the 64 vs 96 bit timestamps between parquet file format versions are all handled in unintuitive ways. There also is no support on snowflakes end for enum types, so be careful if you are using those in polars.\n\nOther than that, you have a way smaller object in memory, there\u2019s a pyarrow batches method available so you can handle larger than memory datasets if needed (including just sinking to disk and then using polars lazy frames)\u2026its mostly wins!",
            "If you look under the hood of that imported function it is just writing to a parquet file which it stages and copies from in snowflake. It is extremely easy to rewrite to use just polars. I did it for the pipelines at my company because I didn't want to include the pandas step.",
            "> have gone straight into polars. It kind of shows in their coding style, where they are hesitant to lean on pythons duck typing elsewhere\n\nHaha, that I see as a great compliment! :D",
            "as is normally the case (imo) - being forced to do that validation is GOOD. it can feel unnecessary at times - but spending the time to do the proper validation will always be less time consuming than tracking down the inevitable bugs resulting from NOT doing that validation\n\nthe only place there's an argument imo is that if youre doing a LOT of parsing of a LOT of csvs, it can slow down getting a working implementation a fair bit. but we're still talking about a python wrapper here... it doesnt take that long",
            "Uve never used polars? I\u2019m saying polars expressions are beautiful",
            "They seem to just be referring to Polars Expressions in general.\n\nYou may have seen [SQLAlchemy's Expressions API](https://docs.sqlalchemy.org/en/20/core/expression_api.html) as an example.\n\nWhere you can build your query using it and it generates the SQL for you:\n\n    from sqlalchemy import table, column, select\n\n    names = \"a\", \"b\"\n\n    query = (\n       select(table(\"tbl\", column(\"name\")))\n        .where(column(\"name\").in_(names))\n    )\n\n    print(query.compile(compile_kwargs=dict(literal_binds=True)))\n\n    # SELECT tbl.name\n    # FROM tbl\n    # WHERE name IN ('a', 'b')\n\nIt's similar in Polars.\n\n    df.with_columns(\n       pl.when(pl.col(\"name\").str.contains(\"foo\"))\n         .then(pl.col(\"bar\") * pl.col(\"baz\"))\n         .otherwise(pl.col(\"other\") + 10)\n    )\n\nPolars expressions themselves don't do any \"work\", they are composable, etc.\n\n    expr = (\n       pl.when(pl.col(\"name\").str.contains(\"foo\"))\n         .then(pl.col(\"bar\") * pl.col(\"baz\"))\n         .otherwise(pl.col(\"other\") + 10)\n    )\n\n    print(type(expr))\n    # polars.expr.expr.Expr\n\n    print(expr)\n    # .when(col(\"name\").str.contains([String(foo)])).then([(col(\"bar\")) * (col(\"baz\"))]).otherwise([(col(\"other\")) + (dyn int: 10)])\n\nThe DataFrame processes them and generates a query plan which it executes.",
            "My bad I didn\u2019t see that! Thank you!!",
            "This"
        ]
    },
    "Code review for my simple project": {
        "title": "Code review for my simple project",
        "score": 20,
        "url": "https://www.reddit.com/r/Python/comments/1d91hsb/code_review_for_my_simple_project/",
        "content": "I've made this simple little package to stretch out audios [https://github.com/Mews/simpleaudiostretch](https://github.com/Mews/simpleaudiostretch)\n\nHowever I'm still new to uploading packages to pypi and doing documentation and the sorts, so I'd appreciate it if someone could review my project and see if what I'm doing are the best practices.\n\nThank you in advance if anyone is willing to help",
        "num_comments": 16,
        "comments": [
            "Nice little project!\nFeedback:\n- you don't need \\n in docstrings\n- should have a space after the hash symbol on your comments\n- I personally think that starting your docstrings with \"A function to do x\" is pointless, it's obvious it's a function\n- line lengths should be under 100 chars, I viewed it on a mobile so it's hard to tell, but I think your docstrings were longer than that. (python convention is under 80chars, but I think that's ott)\n- I always strongly advise you use a linter and typechecker since it'll fix formatting issues and make sure your types are as expected. My favourites are ruff and mypy \n- I've never published anything to pypi so maybe it's something to do with that, but how come you have a pyproject.toml and no lockfile? \n- testing would be good, even if it just checks that speeding up a track divides it's length by 2, and vice versa. I like pytest, but unittest is also good \n- I don't really like that most of the code is hidden away in the __init__.py. A named module would be clearer \n- instead of cli.py you could put that in a __main__.py\n- pathlib.Path is better than using string literals for filenames since it's more explicit \n\nHope that helps, best of luck with it \ud83d\udc4d",
            "What the others said. Good little project, looks clean. Could use unit tests and maybe some pre-commit love. And having functions that take variant types then do logic on them is bad, split them out and have a wrapper you call. Also you can have a private module `_stretch.py` then include from that in your init, keeps the code separate from the module config, it's convenient and there's \"one obvious way\" to import the functions",
            "Also I have never seen the logic to be in __init__.py file",
            "The pep for lock files was rejected so the existence of a pyproject.toml doesn't necessarily necessitate a lock file since you need 3rd party programs to generate them.",
            "Thank you so much!\n\nI just have a few questions:\n\n* What exactly is a linter or a typechecker? Does it do the same as the `isinstance` checks I have?\n* How would I write tests for my project? Do I upload a sample file or something?\n* Why can't the code be in `__init__.py`? I just put it there so that you can just `import simplestretch` without needing to import any subpackages, I thought it was the norm from the guide I was following.\n* Whats the problem with the file being called `cli.py`?\n* Where exactly should I use `pathlib.Path`?",
            "What do you mean by pre-commit love?  \nI'm not very experienced with git if that's what its related to",
            "Yeah, I've only ever used it to:\n- set up things that are required for the package to work, (so kinda treating it like an init dunder method, but for the package) \n- import things to make them available for import at the package level.\n\nBut aside from those cases I don't use it either.\n\nInterested to hear if anyone else has had any other reason to put code in there",
            "Ah I see! OK thanks for the info :)",
            "You're very welcome :).\n- a linter inspects your code and formats it (or tells you to format it manually) based on conventions and rules defined in the linter. These rules are generally considered \"best practices\" in the python community \n- a typechecker inspects your code and makes sure you're not calling anything with the wrong type. This is different to the type checks you're doing, in that a typechecker does not run at runtime. Using a typechecker can give you confidence that nothing is getting called with the wrong type, but doesn't totally remove the need for manual type checking\n- I would have a `tests/` directory, then I'd have sample files of the different formats in a subdir `tests/samplefiles/`. Then I'd have a `tests/test_simple.py` file with functions that run the code against those sample files and uses asserts to check that the code is doing what it should \n- having it in `__init__.py` _works_, however it isn't very explicit. It helps readability if it's in a module with a name that explains what the code does. You can achieve the same thing re imports by doing this in your init file: `from mymodule import blah`, and then blah will be available for import at the package level \n- there's nothing wrong with calling it cli.py really. However, if you put it in `__main__.py` then you can call the whole package as a script. You can ignore this point though, cli.py is fine. I mainly included it to point out that there are other dunder files that have different uses that you could research. \n- In your typehints and you should cast your string paths from argparse to Paths. I wonder if argparse can output Paths actually... I'm only on mobile so can't check right now\n\nAny other questions just let me know",
            "Here's an example, dunno if it still works:\n\nhttps://github.com/bitplane/example-python-project/blob/master/.pre-commit-config.yaml\n\nRelevant readme:\n\nhttps://github.com/bitplane/example-python-project/tree/master?tab=readme-ov-file#linting-and-commit-checks",
            "It can also be used to limit what IDE is hinting when writing code.. but some IDEs don\u2019t respect that",
            "I see thanks.  \nI just don't understand the \\`\\_\\_main\\_\\_.py\\` thing, at least from what I tested I can run the simplestretch command in the command line without issues  \nI'll try to implement everything else though, thanks!",
            "Oh so It does the linting and stuff before commiting?",
            "Ah interesting!",
            "Yeah honestly don't stress about the `__main__.py` thing, it's not important. I just like to put my cli scripts in there if there's only one cli for the project, but having it in cli.py is fully valid \ud83d\udc4d.\n\nBest of luck with it, lmk when you've done any improvements and if I've got time ill have a look",
            "I just implemented most of the changes you proposed.  \nThe only one that gave me some trouble was the tests because I couldn't make it import the code from the file rather than the installed package, but eventually I found a fix for it by using\n\n    sys.path.insert(  \n    0, os.path.abspath(os.path.join(os.path.dirname(__file__), \"..\", \"src\"))  \n    )\n\nI don't know if this is a super robust fix but it does work.\n\nI even managed to get github actions to run the tests automatically when I push stuff!\n\nThanks for taking the time to review my project :)\n\nBtw one thing I realised is that for some reason on the readthedocs website the docstrings DO need to have \\\\n otherwise it doesn't change line. This doesn't happen when building locally which is weird but its an easy fix anyway"
        ]
    },
    "Wave Equation Solver in Python": {
        "title": "Wave Equation Solver in Python",
        "score": 17,
        "url": "https://www.reddit.com/r/Python/comments/1d91ylf/wave_equation_solver_in_python/",
        "content": "Hello r/Python,\n\n# What My Project Does\n\nI wanted to share a Python project I've been working on called WavePDE. WavePDE is a simulation and animation tool for studying wave equations in one or two dimensions. It's a handy tool for anyone interested in wave phenomena, also it's customizable and interactive. You can adjust domain size, grid resolution, wave speed, time step, boundary conditions (Dirichlet or Neumann), initial conditions, and more. Additionally, it is possible save your simulations as video files for further analysis or presentations.\n\n# Target Audience \n\nI mainly created this tool while working on my research project. It is not yet complete since it deadens heavily on some parts I still didn't finish. It is about numeric computations of the wave equation on arbitrary boundaries. So I still need to apply some mask on these results and extend the Neumann conditions beyond the current implementation.\n\n# Comparison\n\nThis tool is way more customizable (at least imho) than other Python tools I found online. The code is more structured allowing for future extensibility. I also tried to make it as user-friendly as possible. I hope you find it useful and I would appreciate any feedback you might have. I still didn't implement tests, so if you find any bugs please let me know. Also, the documentation is lacking, but I'm working on it.\n\n\n\nYou can find the code on GitHub: [https://github.com/salastro/wavepde](https://github.com/salastro/wavepde)",
        "num_comments": 3,
        "comments": [
            "Why finite difference instead of finite element?",
            "It was the method we studied in my differential equations course. I might extend and implement other methods in the future. Could you tell me more about finite element?",
            "Finite element method is essentially a method that lets you turn your (linear) PDE into a set of linear equations. You do this by decomposing your solution using a set of basis functions (this sentence will only make sense if you\u2019ve taken linear algebra).\n\nIts advantages are that it\u2019s more easily parallelize-able and it\u2019s a bit more computationally robust than forward euler finite difference (what you did), eg there\u2019s no stability condition between the time and spatial step.\n\nThere\u2019s a bunch of python libraries that can solve basic stuff like the wave equation using finite element method out of the box, like fenics. I encourage you to check it out :)"
        ]
    },
    "Tutorial: How To Create Professional Python Shiny Dashboards In A Jiffy": {
        "title": "Tutorial: How To Create Professional Python Shiny Dashboards In A Jiffy",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1d9lsgd/tutorial_how_to_create_professional_python_shiny/",
        "content": "The\u00a0***Python Shiny***\u00a0library is a framework for building interactive web applications in Python.\n\nDeveloped by RStudio, the same team behind the\u00a0***Shiny***\u00a0library for R, this library is particularly useful for data scientists and analysts who want to build interactive dashboards and applications without having extensive front-end development skills.\n\nAll that is needed is knowledge of the Shiny user interface Application Programming Interface (API).\n\nPython Shiny can be used to develop applications that allow users to interact with data in real time. Data scientists can quickly prototype data applications and share them with anyone.\n\n***How easy is it to use?***\u00a0Let\u2019s use a simple data set and a basic interactive data visualization to take it for a test drive.\n\nFree article [**HERE**](https://johnloewen.substack.com/p/professional-python-shiny-dashboards).",
        "num_comments": 6,
        "comments": [
            "That's not a dashboard nor \"profressional\", that's like one page with 2 widgets. Make a full dashboard with routing with good UX and performance and then we can talk about it.",
            "After having spent 4 years with that framework, language, and community, I can confidently say it is welcome to burn in hell.",
            "I've tried Shiny Python recently and it's quite good. I have some experience with Shiny R and the API is pretty similar. If you're looking for hosting, [check this out.](https://docs.cloud.ploomber.io/en/latest/apps/shiny-python.html)",
            "Have any examples of a tutorial with what you are talking about?",
            "SPA JS dashboard (vue, ember or other) using Metronic or similar template and Python REST endpoints as backend. That's what I do.\n\nWeb services I work on rely heavily on good dashboards and ever improving UX and quality or customers bail. Would be nice to avoid npm hell but for now Python solutions are kind of limited to single pages or if they have any routing it's not the best.",
            "Sentry is a good example"
        ]
    },
    "PSA: PySimpleGUI has deleted [almost] all old LGPL versions from PyPI; update your dependencies": {
        "title": "PSA: PySimpleGUI has deleted [almost] all old LGPL versions from PyPI; update your dependencies",
        "score": 388,
        "url": "https://www.reddit.com/r/Python/comments/1d8d4iv/psa_pysimplegui_has_deleted_almost_all_old_lgpl/",
        "content": "Months ago, PySimpleGUI relicensed from LGPL3 to a proprietary license/subscription model with the release of version 5 and nuked the source code and history from GitHub. Up until recently, the old versions of PySimpleGUI remained on PyPI. However, all but two of these have been deleted and those that remain are [yanked](https://pypi.org/help/#yanked).\n\nThe important effect this has had is anyone who may have defined their requirements as something like `PySimpleGUI<5` or `PySimpleGUI==4.x.x` for a now-deleted version, your installations will fail with a message like:\n\n    ERROR: No matching distribution found for pysimplegui<5\n\nIf you have no specific version requested for `PySimpleGUI` you will end up installing the version with a proprietary license and nagware.\n\nThere are three options to deal with this without compeltely changing your code:\n\n1. Specify the latest yanked, but now unsupported version of PySimpleGUI `PySimpleGUI==4.60.5` and hope they don't delete that some time in the future\n2. Use the supported LGPL fork, [`FreeSimpleGUI`](https://github.com/spyoungtech/FreeSimpleGUI) (full disclosure, I maintain this fork)\n3. Pay up for a PySimpleGUI 5 license.\n",
        "num_comments": 90,
        "comments": [
            "As a separate note, you can see up to this point, most [downloads have not been for version 5](https://www.pepy.tech/projects/pysimplegui?versions=4.*&versions=5.*&versions=3.*&versions=4.60.5&versions=4.60.4&versions=4.60.3&versions=4.60.2&versions=4.60.1). After they did this, downloads for 4.x suddenly plummet from ~24K/day to less than 2K/day and downloads for 5.x jump from 4K/day to 25K/day. It's concerning because I doubt that those additional 21,000 daily downloaders have suddenly decided to purchase a PySimpleGUI 5 license. Though, it's probably mostly automated downloads anyhow.\n\nAlso noteworthy that the most-downloaded version, 4.60.4 (prevously, the higest non-yanked 4.x version) with 20K/day downloads, has been deleted!",
            "I have been a vocal proponent of this package in the past.  Not any longer. It\u2019s a pretty crappy way to run an open source project.",
            "Never thought PySimpleGUI, of all libraries, will become subscription based.",
            "Thank you for this. I had a project on GitHub that used PySimpleGUI as a dependency and now I just went and updated it to use FreeSimpleGUI instead. \u270c\ufe0f",
            "Thanks for doing your duty and hard forking a project that strayed from its commitment to open source.",
            "Thank you so much for maintaining a fork. I use this package for several projects.",
            "What a dick move!\n\nI totally understand that you might change your licence but it's a really bad to delete all packages since before that and break it for all users. \n\nI wouldn't never trust them again but they will slowly fail and be forgotten now.",
            "While I can totally understand going to a closed source licence, removing older free software version is a disgusting move",
            "I would recommend switching to [https://github.com/spyoungtech/FreeSimpleGUI](https://github.com/spyoungtech/FreeSimpleGUI)\n\nIt is a free drop-in replacement.   \n  \ncc: u/ManyInterests",
            "[removed]",
            "so, it's a much larger requirement, but in terms of GUI, NiceGUI has been fantastic for me so far. If you're using it for basic things, it's pretty straight forward but has the options to do some more complex actions.",
            "I'm going to start playing with Custom Tkinter.",
            "Good read...won't ever use it!",
            "Qt and Kivy all the way :)",
            "One of the reasons I favor doing GUI in HTML. Currently with PyWebView. \nEven if something happens to the package, migrating existing GUI and developer skills to another will not take much, because HTML and JS are standards.",
            "I prefer pyside6, but It's good to know to recommend FreeSimpleGUI over PySimpleGUI",
            "I noticed in the FreeSimpleGUI Readme a reference to [https://github.com/FreeSimpleGUI/psgcompiler](https://github.com/FreeSimpleGUI/psgcompiler) but it says 404, is this another repository of PySimpleGUI?",
            "Bravo OP!  Good work for humanity",
            "Well, I knew nothing about the red flags being discussed about the behavior of the author long before the childish closure.  So sad I actually liked this library.  From hero to zero I guess...",
            "PyPI shouldn't allow deleting releases. Why is this even allowed?",
            "They honestly should not let shit like this into PyPI",
            "I'm just wondering what's the option of tkinter on this, lol",
            "Thanks! I got the subscription message yesterday",
            "You can also vendor 4.60.5 in your repo. Or you can fork it and serve it on a private pypi repo.",
            "Just use PySide or tkinter",
            "[https://github.com/mtingers/rug-pull-license](https://github.com/mtingers/rug-pull-license)",
            "Just another *thank you* for hosting a fork.\n\nI innocently upgraded PSG and ran full-speed into the very surprising license requirement. I felt \"fairly\" secure in simply back-leveling it, but at the time I didn't know about the drama with the author.\n\nMassive **Thank You** for housing a fork of the latest pre-5 version.",
            "It\u2019s still completely free (https://www.pysimplegui.com/pricing) unless you\u2019re using it for commercial use. Fair game imo",
            "Yeah, it was promoted pretty heavily here on Reddit, too. It's a shame how he went from \"I'm just learning Python here's something cool I made\" to rugpull in such a short time.\n\nAlso a pretty unsavory way to run the company, too, in my estimation. I can understand (but don't necessarily support) the move to relicense future versions to a proprietary model -- it's his software after all. But turning around and engaging in a scorched-earth policy directly against your actual potential addressable market is a really bad business move.",
            "It was clear from the get go. I also was a strong proponent **against** this package, for two reasons: first, its design teaches awful practices when it comes to UI design. Second, the author was constantly spamming it as a solution to the point of obnoxiousness. It was clear what the end game was going to be. And here it is.",
            "PySimpleGUI is the one library where I expected that the most. \n\nCouple years ago I reported a bug ( https://github.com/PySimpleGUI/PySimpleGUI/issues/3529 ) and the corresponding two-line bugfix in a merge request. \n\nDespite me putting that change into the public domain, it only being a small bugfix, and multiple other people commenting it fixes the issue, the maintainer said:\n\n- We don't take pull requests (there's not a single merged PR on GitHub)\n- this project is managed like a closed-source project\n- this bug is not important so it'll have a low priority \n- and then, two years later \"When I set this obscure nondefault parameter in my KDE / Linux configuration the bug is no longer visible (but of course still present) so it must be user error\" and closed the issue report. \n\nThat was the point where I was like \"okay this is a shitty library with shitty practices, I should migrate to something else\", and it looks like I made the right choice.\n\nTo this day, it looks like the bug still isn't fixed.",
            "Yeah, it's a bit of a head-scratcher. All the same, can't be too critical of something that was made and offered for free. It's just a shame how they've gone about this process and now made the bad situation much worse now that they've nuked it from PyPI, intentionally breaking a ton of people who were depending on those versions.",
            "More contributors should head over to tkinter",
            "o7",
            ">duty\n\nIt's not their duty, it is their service to the community, though.\n\nGreatly appreciated.",
            "Yes! That's my package, as mentioned in the post :-)",
            "Switching to FreeSimpleGUI should just be a matter of changing the package name in requirements.",
            "Hi there, from the /r/Python mods.\n\nThis comment has been removed for violating one or more of our community rules, including engaging in rude behavior or trolling. Please ensure to adhere to the r/Python guidelines in future discussions.\n\nThanks, and happy Pythoneering!\n\nr/Python moderation team",
            "Ah, that's not one I've heard of! Looks _nice_. I've been surveying a lot of Python and Rust GUI libraries lately for a [new project](https://github.com/spyoungtech/voice-commander) (actually an old one I'm reviving) that I'm working on, so I'll have to check this one out real soon.",
            "I have been enjoying using Kivy a lot. One of my many ongoing projects is a client for my callsign database (ham radio being one of my other hobbies) and I'm writing the client with Kivy, with the hopes of publishing mobile apps for the client. The idea that I could publish a mobile app written in Python is pretty wild. (though when I run the app in an iOS simulator in xcode everything is super slow and I have no idea why, lol).\n\nQt is amazing, Qt-designer is amazing.",
            "Yeah, it's definitely one of the most portable ways to design interfaces, it seems. Many frameworks even port to mobile apps. Though, it feels like you pretty much give up any hopes of 'native' UIs, if that matters to you. But it feels like most apps are going this way, so, users aren't jarred by things like electron apps anymore. \n\nI've been learning [slint](https://slint.rs/#design) with rust -- they have a set of Python bindings that, IIRC, _just_ got an alpha/preview release, but the Python bindings are not quite ready for real use.",
            "The repo is a fork of PySimpleGUI, forked from the last LGPL-licensed commit from GitHub before they wiped the history from the official PySimpleGUI repo. So, you'll continue to find a lot of references that are artifacts from the original `PySimpleGUI` documentation in a lot of places.\n\nPySimpleGUI is a trademark, so removing its usage early on was something that felt important to me to do (with the thought that PSG may try to enforce their trademark rights against me to takedown the fork -- whether that makes sense or not being a separate concern), so a lot of it was search/replace, which has broken some links. I've got quite a bit of cleanup to do in that area, links to fix, etc. Issue \\#4 is tracking this. The end-goal is to, more or less, ensure that everything that PySimpleGUI had has a free-forever replacement and, of course, to have all the links in the docs working.",
            "It's strongly discouraged. Not that long ago, the yanking feature was introduced to fill some gaps where publishers wanted to prevent people from installing certain versions (like if a security vulnerability was introduced, a _completely broken_ release or something to that effect) but without necessarily deleting the release (to which users may have directly pinned already). Maybe if that feature existed from the beginning of time, deletion wouldn't be needed.\n\nMaybe one use case for deletion may be to remove content you did not mean to upload or remove something which you (only later realize) may have not had the rights to upload.\n\nOne other important thing though is you are prohibited from re-uploading after deletion! So you can never change artifacts of a specific version underneath someone's feet. You can only add files that were never uploaded before.",
            "Distributing commercial software on PyPI did make me scratch my head, too. Normally you wouldn't do this because you make certain warranties by doing so and license certain rights for PyPI users when you upload, under the [terms of use](https://pypi.org/policy/terms-of-use/). Legally, it's an unncessary risk if you care about your IP. As I've heard [in this comment](https://discuss.python.org/t/pysimplegui-now-requires-a-paid-license-opinions/48790/2), PySimpleGUI 5 obfuscates its code (which, perhaps, could be, poorly, argued as a '[reasonable measure](https://www.winston.com/en/insights-news/reasonable-measures-for-protecting-trade-secrets-a-primer)' for protecting a  trade secret), but by uploading to PyPI, they warrant that nothing in there is a trade secret, for example.",
            "I guess. But it requires you to register and installs nagware on your (and/or your user's) systems. They've also already [publicly threatened to remove the free model](https://github.com/PySimpleGUI/PySimpleGUI/issues/142#issuecomment-2028043457) because they felt people were freeloading on the hobbyist license:\n\n>  Some Commercial Users are abusing the Hobbyist License and claiming to be eligible for a no-cost license, when they most certainly do not.  \n>  \n> If this continues, at some point we will be forced to stop offering a no-cost version. It's a decision driven 100% by the commercial users of PySimpleGUI. \n\n(side thought: how do they know about the alleged 'abuse'? are they spying on their users? Do you want to be licensing software from a company that engages in this behavior and these kinds of threats?)\n\nThe other pertinent issue is that \"free\" doesn't just mean dollars. The licensing complicates your situation if you have an Open Source project that uses it as a dependency. You can't reasonably distribute a project in an open manner when it has a paid/proprietary dependency. Of course, if you were depending on it, you could use the previous LGPL versions... until they deleted them. There's no excuse for deleting old versions of it, except as a rugpull cash-grab.",
            "> I can understand the move to relicense future versions to a proprietary model\n\nAs a CTO for teams that use Python, this is chilling. We review licenses at the time of inclusion, and any time it comes up ad-hoc while ensuring that dev, test, and deployment all adhere to the license terms. We have automated systems to try and detect the insertion of malware in dependencies, but I'd guess very few teams have automated systems to detect a license change that puts them in violation.\n\nIt's bad for open source and bad for the author. I wouldn't do business with them because they've proven they'll make sneaky changes to agreements. I don't need that kind of problem lying around even if the practical exposure is relatively small.",
            "It was a few years. I use my open source project more for my own self promotion and my own puzzle. It's not that special. I just decided to do it.\n\nRedoing PySimpleGUI would honestly not be that hard. It's a large scope, but it's supposed to be simple, so limit it. It makes me all the more confused that the author decided to pull it.",
            "Yeah. From what I've found after personally going through tens of thousands of lines of its code, not a lot has changed over the years with PySimpleGUI. It's all the same amateurish code written by someone who just started learning Python shortly before its first version.\n\nThere is, however, at least according to the git history, some accepted contributions in the past from outside collaborators. Commit messages (like 'Fixed XYZ, thanks So-and-So!') also make clear that contributions are not solely that of the author, even if the _git author_ is the same. There's also a number of comments in the code (like `# Chr0nic`, which exist in the PySimpleGUI 5 codebase to this day) that demarcate contributions from others. In theory, such contributors may be able to assert copyrights on those contributions, but PySimpleGUI is so unimportant in the grand scheme of things that such things are not worth the trouble anyhow.\n\nAnyhow. I am happy to be maintaining a fork that welcomes contributions. And since I don't own the copyright to most of the code, it's not like I even have the ability to relicense it :-)",
            "IMHO: If you want to make closed-source product, you should do it like that from the very start (not make it open-source initially and close-source it later, effectively scamming users)",
            "Now they can take your patch (in the closed world) without owing you anything.",
            ">We don't take pull requests (there's not a single merged PR on GitHub)\n\n>this project is managed like a closed-source project\n\n  \nPretty wild given all the feedback the project got in here, when it was first released.",
            "Please report it again when community establishes a single free successor.",
            "Curiously, what did you migrate to? As much as I love PySimpleGUI, I can't support it in its current state.",
            "Yeah I can understand the open source fatigue of people seeing billions of dollars flow through big tech companies where many people might be using your libraries and not seeing a single cent\u2026 but community and expectations management is also a thing \ud83d\ude05",
            "I'm currently using it for a client project that's pretty in depth. The biggest thing i like about it is that it's basically a web frontend for backend python code that can be run on the page instead of having to make an API to query the backend server to do something. \n\nIt's a good combination of what i think of as \"middle-end\" because you can still use javascript for some formatting of inputs, you can directly input html to the page for any framing you need, while still running pure python functions and pretty much any package you want to run on that page. Not to mention, the dev team for NiceGUI is the most responsive and collaborative i've seen. Honestly top blokes.",
            "Hmm. (doubting dog gif here.) I'll read into it, but why use \"language akin to HTML\" if you can use Tauri with an honest real HTML+JS and gain access to thousands of frontend UI libraries ever created?",
            "> Maybe if that feature existed from the beginning of time, deletion wouldn't be needed.\n\nNo, that doesn't make sense. If yanking is now an option, we can get rid of package deletion.",
            "Wow.  This comment here made me do a quick search of our work repo to see if any random person is using this:\n\n> They do indeed ship a 2.5MB .py file, but I don\u2019t even think PySimpleGUI 5 can truly be described as source visible.\n\n> Towards the end of the huge file, the 10s of kB binary constants are b85 decoded, unzipped, b64 decoded, which is fine.\n\n> But then they\u2019re loaded with marshall and run with exec!\n\n> My defence of PySimpleSoft was on the assumption that PySimpleGUI\u2019s paid license is a source visible, free-as-in-freedom-to-modify license. It\u2019s breakable. Easily so, to Python Byte code. But for a formerly open source project, decoding and execing binary constants in this way leads to code that could be doing anything.\n\n> If a user has to import dis or download specialist tools, before they can be sure PySimpleGUI isn\u2019t doing anything nefarious, on the user\u2019s own users\u2019 machines, then PySimpleGUI is effectively closed source.\n\n> I do love the ascii art in it though. Shame that\u2019s the best thing about the code base at first glance.",
            "> how do they know about the alleged 'abuse'? are they spying on their users?\n\nThe same way companies that complain about piracy or pushy Docker sales people know about the numbers involved there: totally making it up.\n\n> The licensing complicates your situation if you have an Open Source project that uses it as a dependency. You can't reasonably distribute a project in an open manner when it has a paid/proprietary dependency. Of course, if you were depending on it, you could use the previous LGPL versions... until they deleted them.\n\nGenerally, python has the advantage of not needing to \"distribute\" its dependencies to consumers, but yes, this would be an even bigger problem in a language where distributing compiled products was the norm. That said, there are probably a lot of caches of the LGPL code in the wild (you have a fork) that can resolve this for open source projects with attention to spare on it (which isn't always true if someone has a lot of projects in maintenance mode).",
            "Agreed on all points. Managing dependencies is a huge challenge with all the moving parts that change outside of your normal lifecycle. Tools help, but there's a lot you need to do to make sure those tools work accurately and for their intended purpose -- and then tracking where/when your software ships after you've got the bill of materials is a whole other thing... you may have patched a vulnerable library, but did all your dependents update? And if they updated, did they ship that update to production? Was it rolled back? Etc.",
            "Sorry for being off topic. But what kind of systems/tools do you use to automatically detect license changes and malware?",
            "> It's bad for open source and bad for the author.\n\nWhat?  No it isn't.  The scorched earth, yes, the changed license?  Get over yourself and start paying people rather than reaping the benefits of free labor.",
            "Yeah, that's a fair assessment. It's not like the code in PySimpleGUI is particularly great code, anyhow. But it did get some important things right about the general interface for just getting things done. I think the idea of defining layouts in list matrices is what fits people's brains the most and makes it easier to use than available alternatives. But after personally having worked through tens of thousands of lines of PySimpleGUI code, I agree there's nothing special in there, but it is _a lot_ of nothing special that, in sum, becomes pretty useful.\n\nAnyhow. FreeSimpleGUI is focused on maintaining compatibility with preexisting PySimpleGUI users so that part of the community remains well-served by an open source option. I have ideas for how the 'good parts' could be adapted into something even better, but it would be a separate project entirely.",
            "If Leseratte10 didn't sign a CLA, they definitely can't. Copyright isn't \"ownership\". Anyone who creates a copyrightable work has a claim to it, and can prevent others copying it. If the work was created by multiple people, for example because it's a derived work, all of them have a claim.\n\n\nThis is presumably why they haven't been keen to accept external contributions. It opens them up to random GitHub users suing them for copyright infringement. Thanks to the overly broad provisions of the DMCA, they might even be able to request GitHub to take it down and the onus would be on PySimpleGUI to prove it isn't infringing (which of course it would be).\n\n\nEdit: I missed the part where Leseratte10 put their code in the public domain. That would be sufficient for PySimpleGUI to steal it, if they so chose.",
            "For my apps which were fairly simple I switched to Tk/tkinter.",
            "There is CustomTKinter if you want a more modern look",
            "The OP does have their \"free forever\" fork:  https://github.com/spyoungtech/FreeSimpleGUI",
            "Yeah. It can also be an often thankless job and at times there are even worse-than-thankless moments with certain individuals. I am super thankful for the great people in the Open Source community that are building the backbone of modern software.",
            "Its always so crazy to see some multi-trillion dollar tech company generously donating one single engineer to work with Python for like 1 year.",
            ">python code that can be run on the page \n\nSo does the python run on the client? As opposed to something like Dash where everything happens on the server and the client just displays the data? (although I know Dash have implemented some client side operations, I haven't tested this yet).",
            "It's a pretty common pattern used in tons of ridiculously popular UI frameworks. Qt has `.ui` files, Kivy has `.kv` files, WPF apps have xaml, and so on. It's just something people are used to.\n\nAt some level, it probably boils down to integration and performance. The underlying functionality doesn't have/use a JavaScript engine or a browser. Some environments (like embedded, where slint _can_ run) may not even have the _ability_ to have a browser. So, basically you can't _just_ use JavaScript! For rust users (slint's native language) who are performance-minded would probably also feel pretty awkward calling out to JavaScript/v8 to do heavy-lifting that could be done in Rust. But they're probably also not going to reimplement v8 in Rust. \n\nBut if you _are_ going to ship something that can and will use a browser to work, then HTML/CSS/JS makes perfect sense.",
            "> 10s of kB binary constants [...] unzipped\n\nSo it's compressed, too. It really does (as it should) make someone wonder what the inflated size is and what could be both so large and so important to hide... and if you _did_ reverse it, you'd have to do that whole process for every new release, assuming any part of that compressed blob changes.",
            "It's true that Python packages can enjoy an arms-length distance and 'simple use' of software. I can pretty easily _depend_ on GPL software, but maintain more permissive licenses on my own projects. But GUI software tends to get distributed to end-users, which usually means bundling your dependencies into something you ship onto someone else's desktop (like an app compliled with `PyInstaller`), which is where all the licensing stuff gets complicated because you're not just declaring depdencies or dynamically linking... you're actually redistributing _everything_ your app depends on.\n\nThankfully, LGPL is not very restrictive. I've been working with a GPL-2 component in some of my other projects and, unfortunately, due to that licensing it would be difficult to ship anything commercial that uses it (in a desktop end-user kind of way) without publishing the source.\n\nEven redistributing Python itself is challenging. On Windows? PyInstaller will try to bundle VCRUNTIME, which is [restrictively licensed](https://www.quora.com/Am-I-legally-allowed-in-C-Visual-Studio-to-distribute-msvcp140-dll-and-vcruntime140-dll-bundled-as-resources-into-my-close-source-executable-or-do-I-need-to-tell-my-users-to-download-them-from-Microsoft) by Microsoft. On Linux? Python depends on GNU readline. This kind of problem has even driven some freezing projects [like nuitka](https://github.com/Nuitka/Nuitka/issues/1092) to consider shipping a customized version of Python that removes the dependnecy on readline. But I think at some level, much the licensing complicance discussions online are a big circle jerk of armchair litigators. It's hard, as a layperson, to separate the wheat from the chaff in those discussions.  \nBesides. It's usually only big companies that actually litigate these kinds of disputes and it happens so infrequently that much of the law is not settled by actual court decisions.",
            "I should have said vulnerabilities like dependency confusion, maintenance risks, and exploits - malware summons \"virus\" scanning to mind which is not quite what we're doing.\n\n[OWASP dep-scan](https://owasp.org/www-project-dep-scan/) is a good open one. Built in github dependency scanning is a nice visible vulnerability checker. We use a couple of tools specific to our Google Cloud partner (we get a 3% discount by going through a 3rd party, companies are weird) on top of that but I don't believe they're widely available.",
            "Many SBOM generation tools are able to identify licenses.  Keep track of the output, when it includes something you don't like then you're gonna need to revisit your deps.",
            "u/marr75 I'm also interested to know this",
            "for licenses, I know about fossa https://fossa.com/\n\nWe never bought it, but it looked well made.",
            "Fortify comes to mind\n\n\nhttps://en.m.wikipedia.org/wiki/Fortify_Software",
            "Guess I'll slap a price tag on my open source contributions and projects and try and get paid for my volunteer work, then. \n\nI read this as a silly Friday night rant. The way a project starts and how you market it creates (fair) expectations. Altering those is within the creator's power but it subverts expectations and there should be consequences. The end.\n\nI'm no longer providing free replies in this thread, btw.",
            "That\u2019s funny. Yeah I\u2019ve never used it, but every time I want a $5 gui, I\u2019ll go implement some table/list of lists of qlabel names and qtextedits with a float validator. I wonder how many people have implemented that over the years.\n\nI always just go straight to PySide because I might as well learn one thing and reuse code,",
            "You do not have to \"claim\" copyright. https://www.copyright.gov/help/faq/faq-general.html \n\nHowever, if you are just trying to poision AI models, then yes, LGPL is the same as the BSL license, according to Richard Stallman himself in the famous paper \"Why Software Is Hard\".\n\nAdditionally, making something freely available is commonly understood to impute the \"thief\" monker to all users of said artifact. This is supported by the US Supreme Court Decision \"New York Island Goombah v. Gay Wedding Cakes, 420 U.S. 3291 (2026).",
            "Some Big Tech like Meta and MS invest a lot in Python actually. MS even hired Python's creator so he could focus entirely on Python.\n\nGoogle also had a Python team but got hit by a lay off",
            "I think it's more like an Electron app, like Discord or Slack, which embeds both a browser and node.js into the executable that the user installs. The app frontend is a browser, but the 'server' (maybe could be called a client-side backend) for the client is also on the localhost and can communicate with it very quickly for UI updates. And both components can communicate with remote servers as necessary, too.\n\nSo, maybe a transaction in this kind of app looks something like this:\n\n- Browser loads a page from the server running on localhost.\n- User clicks button on the page that talks to the server on localhost\n- Processing the request invokes a node.js function to return the response -- maybe that node.js function talks to a remote server (maybe not)\n- The browser client processing the response will consequently involve an update to the UI. The browser client could also connect to remote hosts, too, or maybe not.\n\n\n\nThough, in this case instead of a browser and node.js, it's a browser and python. So, the user clicking a button in the browser ends up invoking a Python function on a python server running on the localhost.",
            "I dont really follow all this legal nonsense if I'm being honest. I tinkered a project that started as a self-learning opportunity from a hobbyist, to end up being a very important part of what my current company delivers...\n\nShould I be paying the commercial license?\n\nMy boss wants to eventually buy it off me, is it a possibility or this and other libraries will be against me?",
            "Sure thing. Answer [above](https://www.reddit.com/r/Python/comments/1d8d4iv/comment/l77vxmk/)",
            "It's kind of funny to see such a naive \"CTO\"",
            "> Google also had a Python team but got hit by a lay off\n\nGoogle has _a plethora_ of Python teams.  One team working on ML is not their entire workforce.",
            "It's a complicated question. But for PySimpleGUI users, there's no compelling reason to pay for a commercial license, as I see it. Either use an LGPL-licensed version of PySimpleGUI (LGPL is not incompatible with commercial use) or the FreeSimpleGUI fork, which retains the LGPL license.\n\nHolistically, you have to consider what's going into your software, what you're actually distributing, and what restrictions, if any, you have due to the licenses of the dependencies you're using. If you're just selling your own Python files, that's pretty simple. If you're shipping a complete app, bundled with all your dependencies (meaning you're redistributing them, triggering obligations/restrictions with certain types of licenses), like an exe, that's far more complicated.\n\n> I don't really follow all this legal nonsense\n\nYou, me, and everyone else. If you search the internet, you're going to find a lot of \\[often conflicting\\] information, and very few clear answers on the topic as it relates to your situation.",
            "We don't distribute software, but its output (so far), but.. isnt that pretty much commercial use?",
            "Yes, but commercial use doesn't conflict with use of software covered under an LGPL3 license. Versions of PySimpleGUI before version 5 are LGPL3-licensed -- in other words, you have been conveyed a license to use PySimpleGUI under the LGPL3 license for commercial use already; there's no conflict.\n\nIf you use PySimpleGUI 5.0 or newer, you have to buy a license for commercial use."
        ]
    },
    "Tach - enforce module boundaries + deps, now in Rust \ud83e\udd80": {
        "title": "Tach - enforce module boundaries + deps, now in Rust \ud83e\udd80",
        "score": 22,
        "url": "https://www.reddit.com/r/Python/comments/1d8sgbp/tach_enforce_module_boundaries_deps_now_in_rust/",
        "content": "[https://github.com/gauge-sh/tach](https://github.com/gauge-sh/tach)\n\nHey everyone! Wanted to share some pretty significant updates to the tool I've been working on. Tach lets you define module boundaries and enforce rules across your modules, including isolation, dependencies, and strict interfaces. Some updates -\n\n* Re-wrote the core in Rust, leading to a \\~19x speed up on large repos\n* Re-worked the interface, and added a TUI to let you interactively declare modules\n\nWe built Tach to solve the \u201cball of mud\u201d problem that we\u2019ve ran into throughout all of my previous work experiences. Over time, the codebase would become tightly coupled together, making even simple changes/refactors painful. By setting up module boundaries and enforcing them early on, you can avoid all of this!\n\nTach is the best way to grow a modular monolith without creating a ball of mud. If anyone has any questions or feedback, I\u2019d love chat!\n\n[https://github.com/gauge-sh/tach](https://github.com/gauge-sh/tach)\n\n **What My Project Does**\n\nTach enables you to interactively declare module boundaries, dependencies between modules, and strict interfaces for those modules. You can then enforce those declarations through a static code check.\n\n**Target Audience**\u00a0\n\nTeams maintaining python monorepos.\n\n**Comparison**\u00a0\n\nImport linter is probably the most similar tool - for a github discussion on the differences, check out this link - [https://github.com/gauge-sh/tach/discussions/72](https://github.com/gauge-sh/tach/discussions/72)\n\n",
        "num_comments": 7,
        "comments": [
            "This is great. \n\nI wonder, if you do imports guarded by something like `if TYPE_CHECKING:` should/does that still raise an issue? I usually try to have this kind of separation in my projects, but often find that I need to do imports just for typing purposes, but I personally don't consider it a dependency rule violation.",
            "Nice, I've been looking for a tool like that for a while now. Will give it a try when I get home.\u00a0",
            "Its propably better to just refactor monorepos into multiple git repos than is well understood and fits cleanly into established tooling and workflows. If your common libraries and services each has its own seperately versioned codebase you get loose copuling almost for free, with all the benefits of well scoped projects. \n\nI could never realy understand why people use monorepos, and then get upset when you don't use modules or functions or classes or any of the other things that we also use to fold complexity away. It is the same thing. Use the tools you have to soleve the probles you got, its really not that hard.",
            "u/ManyInterests great question! Someone actually raised that as an issue, and we added support for ignoring it!\n\n[https://github.com/gauge-sh/tach/issues/56](https://github.com/gauge-sh/tach/issues/56)\n\n[https://gauge-sh.github.io/tach/configuration/#tachyml](https://gauge-sh.github.io/tach/configuration/#tachyml) (see \\`ignore\\_type\\_checking\\_imports\\`)",
            "Awesome, thank you u/ralphcone! If you're interested, happy to jump on a call and help you set it up/answer any questions you might have :)",
            "u/ageofwant this can work depending on your setup, but you often are then introducing microservice management and orchestration. This takes complexity off of the individual team, but pushes it onto the deployment stack, causing a whole new set of issues. You now need to freeze apis between services, manage version support between services, introduce network overhead, etc.\n\nWith this tool, you can get a lot of those benefits without any of those downsides. Long term, I want to add support for some of the operations that tooling doesn't quite match up to well yet, like task/build/test pipelines based on individual modules!",
            "Beautiful!"
        ]
    },
    "New Lands RPG (Play testers welcome)": {
        "title": "New Lands RPG (Play testers welcome)",
        "score": 3,
        "url": "https://www.reddit.com/r/Python/comments/1d93a82/new_lands_rpg_play_testers_welcome/",
        "content": "Good \"time of day\" my fellow peeps \n\n**What my project does:**\n\nI wanted to share my Python game I've been *slowly* working on over the past... I'd say 1.5 years. It is a simple texted based resource collection game where you travel to different areas, collect resources, sell them in town but be careful there are bandits about, so don't go too far without having some cooked fish on you...\n\n  \n**Target Audience:**\n\nI'd say its mainly for well... everyone, anyone who enjoys text based games and anyone who wants to chill out on a rainy day when all the other games in their steam library are looking boring and they just want to relax...\n\n**Comparison:**\n\nI'd say Colossal cave adventure but that is a much *bigger... better...* game I would call it, but this is just a simple \"learning python\" project I started a while ago and just recently got back into it so I said what the heck why not finish the game. but now I'm stuck as to what to do next, so I thought I'd ask for play testers to come and tell me how bad my coding and game was so I could try and make it more playable... because lord knows I made it so **I** know how to play it but what about other people.\n\nyou can find the code on GitHub: [https://github.com/littlebudddy321/New-Lands-RPG](https://github.com/littlebudddy321/New-Lands-RPG)",
        "num_comments": 1,
        "comments": []
    },
    "Bayesian bandits item pricing in a simplified Moonlighter shop simulation using Python and SQLite": {
        "title": "Bayesian bandits item pricing in a simplified Moonlighter shop simulation using Python and SQLite",
        "score": 7,
        "url": "https://www.reddit.com/r/Python/comments/1d8uex2/bayesian_bandits_item_pricing_in_a_simplified/",
        "content": "What My Project Does:\n\nMoonlighter is a game that includes a mechanic where you place items on shelves in your store and set the price. Customer's reactions give you hints about what prices would be ideal. These reactions take the form of four moods:\n\n1. ecstatic: price too low so they are extra happy\n2. content: price is what they were expecting,\n3. sad: price is too high to them but they buy anyway and this lowers the price everyone will pay for a certain period\n4. angry: price is too high so they don't buy\n\nI built a simplified version where a sad reaction doesn't lower the prices customers will accept for that item using Python and SQLite.\n\nThe Bayesian bandits algorithm is an algorithm to optimize rewards when choosing among different options. The probability of different rewards (e.g. revenue) is kept track of and updated as rewards for options are collected. When a new option is to be selected a competition occurs where the rewards are sampled from these probability distributions and the option with the highest reward is chosen.\n\nFor this simulation, the reward distributions are the probability that a price is the ideal price for that item. This scenario is so simple that the probability of any particular ideal price is flat or the same for all prices between an upper and lower bound and zero outside. This makes item/price selection simply randomly selecting a price from the lower to upper bounds for every item and selecting the item with the highest price.\n\nCustomer reaction moods update the item upper/lower price bounds in these ways:\n\n1. ecstatic or content: lower bound is set to price plus 1 gold\n2. sad: lower bound is set to price if upper and lower bounds don't match\n3. angry: upper bound set to price minus 1 gold if the upper and lower bounds don't match\n\nThe SQLite database keeps track of items in your inventory, items on shelves, customer reactions, item price bounds, and Thompson competitions (i.e. prices randomly chosen between price bounds for each item).\n\nThe algorithm ended up identifying groups of items with the same ideal prices and selling them off from highest to lowest.\n\nFor the full write up and a lot of pretty graphs check out the article in the link below. I've also included the Github link for those that want to see the full implementation and/or a Jupyter notebook where I generate the plots.\n\nFull write-up: https://cmshymansky.com/MoonlighterBayesianBanditsPricing/?source=rPython\n\nGithub: https://github.com/JaggedParadigm/moonlighter_bayesian_bandit_pricing\n\nTarget Audience:\n\nThis a toy, though the Thompson sampling code could be hacked into something useful.\n\nComparison:\n\nTo my knowledge, I am the first to apply the Bayesian bandits algorithm to a Moonlighter shop simulation. However, pricing via Bayesian bandits is a classic application and there are many blogs and scientific papers on the topic.",
        "num_comments": 2,
        "comments": [
            "So cool!\n\nHow do you interface with the game to get the data out?\n\nOr is it just manual data entry?",
            "Thanks!\n\nI manually entered the bounds found in the ledger for an initial group of items I obtained and the price bounds from the wiki that define customer reactions.\n\nI did investigate making a mod for the game, which would streamline a lot of this. It seems possible but I would need to learn C#. I don't think I have quite the appetite for that."
        ]
    },
    "Mesop, open-source Python UI framework used at Google to quickly build delightful web apps": {
        "title": "Mesop, open-source Python UI framework used at Google to quickly build delightful web apps",
        "score": 19,
        "url": "https://www.reddit.com/r/Python/comments/1d8g19p/mesop_opensource_python_ui_framework_used_at/",
        "content": "**What my project does:** I\u2019m excited to share about [Mesop](https://google.github.io/mesop/) - a new, open-source Python UI framework that enables Python developers to quickly build delightful web apps in a scalable way.\n\nA small team of us at Google have been developing Mesop as an unofficial 20% project for the past few months. A wide range of research and product teams at Google have been using it to rapidly build internal apps and we\u2019ve gotten a lot of positive feedback internally so now we\u2019re looking to get feedback from the open-source community.\n\n**Target audience:** Python developers looking to build AI demos & internal apps.\n\n**Comparison:** We think that Mesop provides a unique approach to building web UIs in Python compared to existing alternatives like Streamlit and Gradio - making it both easy to get started and also flexible enough to build customized UIs for a wide range of use cases. You can learn more about [why we built Mesop here](https://google.github.io/mesop/blog/2024/05/13/why-mesop/).\n\nTo look at some example Mesop apps, check out our [demo gallery](https://google.github.io/mesop/demo/). Also, the demo gallery itself is [built with Mesop](https://github.com/google/mesop/blob/main/demo/main.py) which demonstrates the type of flexibility you have in building apps with Mesop.\n\n**GitHub repo:** [https://github.com/google/mesop](https://github.com/google/mesop)",
        "num_comments": 1,
        "comments": []
    },
    "Dask DataFrame is Fast Now!": {
        "title": "Dask DataFrame is Fast Now!",
        "score": 131,
        "url": "https://www.reddit.com/r/Python/comments/1d7w21f/dask_dataframe_is_fast_now/",
        "content": "My colleagues and I have been working on making Dask fast. It\u2019s been fun. Dask DataFrame is now 20x faster and \\~50% faster than Spark (but it depends a lot on the workload).\n\n\n\nI wrote a blog post on what we did: [https://docs.coiled.io/blog/dask-dataframe-is-fast.html](https://docs.coiled.io/blog/dask-dataframe-is-fast.html)\n\n\n\nReally, this came down not to doing one thing really well, but doing lots of small things \u201cpretty good\u201d. Some of the most prominent changes include:\n\n1. Apache Arrow support in pandas\n2. Better shuffling algorithm for faster joins\n3. Automatic query optimization\n\n\n\nThere are a bunch of other improvements too like copy-on-write for pandas 2.0 which ensures copies are only triggered when necessary, GIL fixes in pandas, better serialization, a new parquet reader, etc. We were able to get a 20x speedup on traditional DataFrame benchmarks.\n\n\n\nI\u2019d love it if people tried things out or suggested improvements we might have overlooked.\n\nBlog post: [https://docs.coiled.io/blog/dask-dataframe-is-fast.html](https://docs.coiled.io/blog/dask-dataframe-is-fast.html)",
        "num_comments": 51,
        "comments": [
            "Glad to see dask coming along with its query engine optimizations.",
            "Obligatory polars > pandas comment",
            "[removed]",
            "Query optimization feels like Deep Magic to me. Thanks for your hard work!",
            "Idk why but I hate dask",
            "It would be better if they can start working on running dask on top of polars instead of pandas",
            "Amazing work!",
            "Wow, nice work! Any effect on dask bags? Because maybe 2 years ago it was 4-10x faster to use multi processing pools compared to dask bags for a number of html to text extraction workloads.",
            "Why would I want to use Dask when Polars has always worked, and is awesome?",
            "I just wish the Polars team would add informative exception messages.",
            "Thanks bro",
            "\uff3c(\\^-\\^)\uff0f POLARS!!! \uff3c(\\^-\\^)\uff0f",
            "The good old Swedish hello",
            "Because it was terrible for so long and didn't live up to its own promises. Now there are so many other dataframe options that are fast and efficient that there's no reason to put up with Dask.",
            "Why does everyone feel this way?",
            "Haven't used it in a few years but it would randomly seem to get stuck and not do anything in our data pipelines. Would be great if it worked, though!",
            "That would certainly be nice, but other things have a higher ROI for us. In memory runtime was only around 10% in our benchmarks, which is where polars would help. Optimizing the other 90% has a bigger impact for us though",
            "Check out [Daft](https://github.com/Eventual-Inc/Daft) - polars on top of [ray.io](http://ray.io)",
            "Because polars cant work on more than one machine. Dask can run a whole cluster.",
            "We ran Polars on our benchmarks and it was ok-ish on some queries and terrible on others. It stopped working on 1TB. Polars is totally fine if you have less than 100GB though",
            "Because polars doesn't work on distributed systems. This comparison doesn't make any sense.",
            "and fix the ungodly amount of unreachables and uncaught panics",
            "If my comment wasn\u2019t dripping with sarcasm please allow me to clarify that here",
            "(I don't hate anything, to be clear)\n\nThere's a lot of \"drop in replacement for pandas DataFrame\" and it's always the same. You drop it in and discover tons of errors, because it's not that compatible, it's not really drop in for a complex project. :) That's my contribution to the discussion. Best to approach it as its own thing.",
            "I really wanted to like Daft but when I tried it the API did not have the functionality that I required. Hope they keep improving it tho.",
            "Plz elaborate?",
            "you're not being sarcastic, you just don't know it yet.",
            "Wasn't even aware of polars and, from what I read on the homepage, it sounds appealing. What is it that makes you sarcastic?",
            "Hi u/FauxCheese, one of the authors of Daft here! Thanks for the feedback, we're working on improving function parity with other engines like pandas, polars and pyspark. I'm curious to know what functionality you needed but didn't find in Daft? I'd be happy to prioritize it :)",
            "polars is written in rust, which has a `panic! ` feature where something is uncaught (exception) - polars should **really** fix those because eg null values will panic on any operation",
            "They were being sarcastic. There is a group of evangelical polars fans on this sub who can't tolerate any dataframe library ever being mentioned without one of them saying \"BUT WHAT ABOUT POLARS YOU DIDN'T MENTION POLARS!\".",
            "Since polars came out, any time anyone anywhere talks about pandas, you'll always see someone leaving a comment about how polars is sooooo much better and you should immediately stop using pandas",
            "Every time someone asks about pandas someone else chimes in to say that polars is faster/better and that pandas is not as good. But if we\u2019re being honest here if your programming enterprise level large data sets then python wouldn\u2019t be the best choice.  Most people here are using python over VBA which is an improvement in every aspect",
            "Would be interesting if lib devs would use sth like [https://github.com/narwhals-dev/narwhals](https://github.com/narwhals-dev/narwhals)",
            "One of the first things that I ran into was that I wanted to do a pandas like `df.drop_duplicates(subset=[\"col1\", \"col2\"], keep=\"last\")`.\n\nThe Daft `df.distinct`does not support this kind of behavior.",
            "Why don\u2019t they clippy enforce no panicking and disallow using unwrap? \n\n(I use rust btw)",
            "Not only that, they use \\`unwrap()\\` in prod code. Not cool.",
            "\"did I mention it's BLAZINGLY fast?\"",
            "Honestly, I am starting to think they are most kids who have yet landed a real job yet(or spam accounts). Its buggy and lacks a lot of the convenience of pandas api. And honestly, 98% of the time, the data is not big enough to justify its performance boost. If I want local sql, I would rather use duckdb. If the data is truly big, I would rather have something with distributed io(like dask).",
            "It\u2019s true tho lol",
            "Also, in a lot of cases, if your task is dealing with large amounts of data and performance is critical, there's a good chance you shouldn't be doing any of this on a single local PC anyways. \n\nPolars occupies a sort of bizarre middle ground. It's for a situation where you have enough data to be bothered by any inefficiencies in Pandas but also a situation where you don't have enough data to justify using a proper distributed system. Which I'm sure those kinds of scenarios exist. But people here seem to want to suggest polars for everything, even outside of that narrow usage where it actually makes any sense.",
            "Hi u/jmakov, oh this looks fairly interesting! I'll send it over to the team. Im curious about the approach though. I wonder about the rationale of not adding polars as a frontend to something like sqlglot sort of what [https://github.com/eakmanrq/sqlframe](https://github.com/eakmanrq/sqlframe) did for pyspark.",
            "literally no clue, there\u2019s not an excuse imo which is why i use polars very limitedly",
            "Yeah, I don't know what the motivation is but this happens a lot. Some new thing gets released and you see a bunch of people who clearly haven't used the thing in any serious capacity suddenly become obsessive promoters of it. \n\nI've always assumed it's a sort of \"fitting in\" thing. Basically people who want to be a part of the community trying to demonstrate that they are part of the club by sharing an opinion that they think most people will agree with.",
            "Not really. As with anything, it depends. Pandas still has much better support among third party tools and pandas is still more convenient to use for a lot of simpler situations. Polars can be dramatically faster for some things and is pretty similar performance for many others (especially when compared to the arrow backend changes in Pandas 2).",
            "The scenario you deacribe is exactly what I usually deal with, and that's why it looks appealing to me. \n\nHonestly, I don't think it's so narrow as you think. Lots of datasets in the field of biomedical research fall in that range of size which is bothering performance wise, but not always enough to require distributed architecture",
            "Think there are already a few projects like you mentioned e.g. Apache Ibis. Not sure what's the best way, but I know I want an alternative to Spark that doesn't suck and can do computations on data that doesn't fit in memory :) .",
            "Pandas api alone is a reason to not use it if you\u2019re not doing visualization",
            "That\u2019s fine but irrelevant. I\u2019m not saying you shouldn\u2019t use it for that situation. I\u2019m saying people shouldn\u2019t be recommending it for things outside of that scope but they do. \n\nAnd my comment about the \u201cnarrow scope\u201d is referring to the narrowness of the definition, not a claim that it is uncommon (although relatively speaking it is).",
            "The pandas API is definitely unique to pandas, but it's nowhere near as horrible as everyone claims, it's just different than how other libraries typically do things.\n\n\nWhat's preventing me from swapping to polars in many places is that I often make use of the hierarchical indexing, and polars has nothing to match that",
            "Not really. Pandas API is fine. Especially because you can just switch to using SQL commands if you want or use any of the popular wrappers or third party libraries that can do the interfacing for you. \n\nTheir syntax has some quirks but it's so ubiqutous that they're all well known and easy to work with or work around."
        ]
    },
    "Automate your WordPress new-page creation with Python": {
        "title": "Automate your WordPress new-page creation with Python",
        "score": 1,
        "url": "https://www.reddit.com/r/Python/comments/1d8r2nx/automate_your_wordpress_newpage_creation_with/",
        "content": "Hi everyone! I'm sharing with you a Python tool I've built and been using, intended to haste new-page creation in WordPress (with Elementor plugin).\n\nIt's a simple app, but has great expansion potential and it's really easy to use.\n\nTo start, you will previously need a WordPress site with Elementor installed and activated, and the content you want to introduce into the new page.\n\nRun the program, add sections, choose your desired structure, and select the right widgets for your content.\n\nOnce you've loaded the content, add your credentials and click Confirm & Run (or just press Enter). The system will do the rest :)\n\nYou can download and see the project at: [https://github.com/MauBorre/WordPress-new-page-auto](https://github.com/MauBorre/WordPress-new-page-auto)\n\nHope you find it useful! \ud83d\ude01",
        "num_comments": 0,
        "comments": []
    },
    "Granian 1.4 is out": {
        "title": "Granian 1.4 is out",
        "score": 84,
        "url": "https://www.reddit.com/r/Python/comments/1d7rh4z/granian_14_is_out/",
        "content": "Granian \u2013 the Rust HTTP server for Python applications \u2013 1.4 was released!\n\nBlog post: https://polar.sh/emmett-framework/posts/granian-1-4\n\nRelease details: https://github.com/emmett-framework/granian/releases/tag/v1.4.0\n\nRepo: https://github.com/emmett-framework/granian",
        "num_comments": 15,
        "comments": [
            "Congrats for the release; Granian looks like a very nice piece of software !\n\nSince it offers a WSGI interface, I feel like it could replace uwsgi at work to run our django backend: I will try it in the following weeks to see how it behaves.\n\nHas anyone else succceded in running a Django backend on Granian ? :)",
            "Does it work with pypy? Last I checked, this combo was crashing starlette's middleware.",
            "got benchmarks(vs other asgi servers)?",
            "Yeah it works great. I found it helped reduce the memory requirements on a couple apps keeping me in the free tier on Google Cloud Run. Highly recommend",
            "I used Granian 1.2 with my simple Django powered blog but unfortunately removed it because of memory leaks. I think they have been fixed in 1.3 but haven't checked back yet.\n\nFor my use case Granian also used twice as much memory and workers to deliver half the RPS compared to uvicorn. YMMV of course but that's what I observed.",
            "Feel free to report your numbers/discoveries with a discussion in the project repository :)\n\nAs I wrote in the blog post, with WSGI I strongly suggest to set an appropriate value for \\`backpressure\\` :)",
            "pypy wheels are available, but it's not widely used in Granian community at the moment.\n\nFeel free to make your tests and post issues/feedbacks on the project repo!",
            "[https://github.com/emmett-framework/granian/blob/master/benchmarks/vs.md](https://github.com/emmett-framework/granian/blob/master/benchmarks/vs.md)",
            "Good to know, thanks for your answer !",
            "Correct, it was fixed in 1.3.0\n\nRegarding memory and RPS: Granian generally will use more memory compared to Uvicorn (as it will also run the Rust runtime), but from tests it should be in the 10-20% ratio, not twice as much. Also, versions prior to 1.2.3 had an issue with rust-python awaitables on Linux, which tended to cause performance issues in loading request bodies; 1.4 also introduced some changes in async runtime, so in general ASGI/WSGI performance should be improved compared to previous versions.\n\nIt sounds strange to me you had to double up the number of workers, maybe you can share your configuration/launch command? If you could make another try with 1.4 it would be awesome! And feel also free to open up a discussion on the project repositories with your numbers, it is valuable to have data from real deployments, and also the community can help in tuning the configuration :)",
            "Thanks for your feedback !",
            "Sure, thanks for the reminder and thanks for your work on Granian!",
            "Why were there memory leaks in a Rust-based program?",
            "Because the memory leak was in Python asyncio related code ;)",
            "Hah, it would be - thanks!"
        ]
    },
    "My little ChatGPT-Multimodal Server Starter": {
        "title": "My little ChatGPT-Multimodal Server Starter",
        "score": 1,
        "url": "https://www.reddit.com/r/Python/comments/1d8754q/my_little_chatgptmultimodal_server_starter/",
        "content": "Please check out my\u00a0[Desktoppy Server](https://github.com/TwistedMinda/desktoppy-server).\n\n**What My Project Does**\n\nIt allows you to run your own personal AI on your computer, say bye-bye rate-limits and paywalls from mainstream AI's.\n\nIt uses ollama internally so you can use all the open-source Models but by default it's using:\n\n* LLama3 for text-generation\n* LLava for image recognition\n* Stable Diffusion 2 for image generation\n\n**Target Audience**\n\nPerfect for new-comers... I wish I had this when I started tackling AI dev.\n\nI think it can be a good base to create your awesome AI-powered products!  \nPlease let me know what you think about it!\n\n**Comparison**\u00a0\n\nIt differentiates from the other zillion starters by being very basic, allowing for full customization, and joining the 3 models together into 1 for a multi-modal feeling.\n\nEasiest possible setup, even for those who don't know the tools yet, all you need is Python3 installed on your PC. Basically a tutorial-starter-multimodal.\n\nMuch love\n\nLink:\u00a0[https://github.com/TwistedMinda/desktoppy-server](https://github.com/TwistedMinda/desktoppy-server)  \nThe very basic Web UI that goes along with it:\u00a0[https://github.com/TwistedMinda/desktoppy-web](https://github.com/TwistedMinda/desktoppy-web)",
        "num_comments": 0,
        "comments": []
    },
    "Ludic Update: Web Apps in pure Python with HTMX, Themes, Component Catalog, new Documentation": {
        "title": "Ludic Update: Web Apps in pure Python with HTMX, Themes, Component Catalog, new Documentation",
        "score": 23,
        "url": "https://www.reddit.com/r/Python/comments/1d7sl6k/ludic_update_web_apps_in_pure_python_with_htmx/",
        "content": "Hi everyone,\n\nI'd like to share couple of news regarding my personal project:\n\n* New documentation written in Ludic showcasing it's capabilities: [https://getludic.dev/docs/](https://getludic.dev/docs/)\n* New section regrading Layouts inspired from the Every Layout Book: [https://getludic.dev/catalog/layouts](https://getludic.dev/catalog/layouts)\n* Cookiecutter template to get quickly started: [https://github.com/paveldedik/ludic-template](https://github.com/paveldedik/ludic-template)\n\nI have a lot of plans with this project and I'd appreciate any feedback.\n\n**About The Project**\n\nLudic allows web development in pure Python with components. It uses HTMX to add UI interactivity and has a catalog of components.\n\n**Target Audience**\n\n* Web developers\n* People who want to build HTML pages in Python with typing\n* People without knowledge of JavaScript who want to build interactive UIs\n* People who want to use HTMX in their projects\n\n**Comparison With Similar Tools**\n\n|Feature|Ludic|FastUI|Reflex|\n|:-|:-|:-|:-|\n|HTML rendering|Server Side|Client Side|Client Side|\n|Uses Template Engine|No|No|No|\n|UI interactivity|[</> htmx](https://htmx.org/)|[React](https://react.dev/)|[React](https://react.dev/)|\n|Backend framework|[Starlette](https://www.starlette.io/)|[FastAPI](https://fastapi.tiangolo.com/)|[FastAPI](https://fastapi.tiangolo.com/)|\n|Client-Server Communication|[HTML + REST](https://htmx.org/essays/how-did-rest-come-to-mean-the-opposite-of-rest/)|[JSON + REST](https://github.com/pydantic/FastUI?tab=readme-ov-file#the-principle-long-version)|[WebSockets](https://reflex.dev/blog/2024-03-21-reflex-architecture/)|\n\nAny feedback is highly appreciated.",
        "num_comments": 11,
        "comments": [
            "I like the idea, I also started a similar project but in Rust to then expose it to python.\n\nIn the example of the doc:\n- How do you manage the database? Or anything session-related? It seems it will need to be a global variable?\n- I am wondering why the counter takes a str. Isn't it able to convert it to an int as it uses starlette?\n- I think it's strange to already have SuccessButton. You could have it in an external module or as an option of your package. To clarify: I see that you install \"ludic[full]\", but you import the buttons from a generic \"catalog\" => I think at some point in the import we should see \"bootstrap\" (or whatever framework it is). At least, there should be a Button function that is agnostic from a UI framework.\n\n\nit would be nice to simplify \"app.url_path_for(\"Counter\", value=int(value) + 1)\".\n\nfo example, you could imaging having a parameter with specific type and the the decorator would inject on object\n\n@app.get(\"/counter/{value}\")\ndef Counter(value: str, cmp: SelfComponent) -> Cluster:\n    # cmp = AppWrapper(\"Counter\")\n    return Cluster(\n        ButtonDanger(\n            \"Decrement\",\n            hx_get=cmp,app.url_path(value=int(value) - 1),\n            hx_target=\"#counter\",\n        ),\n        ...\n     )\n\nThe app.get could simply return a partial function of Couter. Or we could use another optional decorator, or have a manual way of declaring it (see the commented line)",
            "I'm curious how you selected htmx over unpoly. \n\nI'm not sure that your feature comparison is really relevant? The reason I say that is that the similar tools to ludic would be other pure python web development frameworks. \n\nFurthermore in that first row of the comparison you say that you do server side rendering. But the thing is is that the whole point of something like htmx is that has single page responsive apps where the rendering is actually client side. \n\nBut I have to salute you for attempting to make a comparison and have some features for comparison. I developed the pure python web framework survey and I never really did a comparison of different tools. I did however create a section where each framework implemented to do MVC to give people an idea of how to implement a modestly complex app. Do you have an example of to do MVC that you can link me to?",
            "Thank you, what is the name of your Rust project? I have a part time job in Rust and I love it. I was also thinking about writing similar tool in Rust a while ago but I'm not that experienced with Rust. And I found [https://yew.rs/](https://yew.rs/)\n\nTo answer your questions:\n\n* Ludic uses starlette (it is optional, I want to add support for fastapi and django in future), where you have State which you can use to bound db connections and stuff like that, see [https://www.starlette.io/database/](https://www.starlette.io/database/)\n* Starlette doesn't allow negative numbers. So the counter would work only for natural numbers, I was thinking about changing the example so that only natural numbers are supported so that it is simplier.\n* SuccessButton is imported from the catalog, which is optional to use, so yeah, it is optional :)\n\nInteresting idea with the counter. The problem is to make it flexible, I was thinking about just calling Counter(number + 1) in the view to render the necessary htmx attributes for swapping the content, but that is really hard to do.",
            "Thank you for the response.\n\nI haven't checked unpoly that much but it seems to me that htmx suits better - you create components made of basic HTML elements which you use to replace parts of your DOM using the HTMX attributes.\n\nThat said, I have an issue on github to support unpoly as well, it just requires investigation.\n\nMay I ask which libraries would you use to compare Ludic to?\n\nLudic is rendering all HTML on the server side, it is just using HTMX attributes to replace parts of the DOM, to me, it is much different approach than the one FastUI which is returning data from the server in JSON.\n\nI have a couple of examples on GitHub, but you have a good point, more complex example showcasing the MVC princible would be great. \n\n  \n[https://github.com/paveldedik/ludic/tree/main/examples](https://github.com/paveldedik/ludic/tree/main/examples)",
            "My rust project is mostly dropped out and private.\nIt was also to experiment htmx vs polly vs ...\n\nYew is good, but:\n- it is compile time and I personnally want something that can be run-time generated. I want to be able to generate pages automatically. Another issue is the time taken to compile which is slow...\n- if I were to use something completly in Rust, it would most probably be leptos.\n\n\nFor the rest:\n- I understand the wish of supporting other framework, but I would personnally try to stick to one and have it has good as possible. Supporting multiple ones can limit what you can do.\n- I didn't know about it for starlette. I mostly use FastApi and never noticed that.\n- yeah but the catalog already took some decisions. Catalog is a very generique name. I can create my own component library but I won't be able able to import it through your submodule.\n\n\nStill in my opinion, the following options might be better:\n- externalize the default catalog as the third parties would also be external. I.e. import it as \"from ludic_default_catalog import ...\". This goes in the direction of an agnostic librarie.\n- make it a plugable system namespaced so we can do: \"from ludic.catalog import defaults, bootstrap, semantic\". This is honestly not ideal and I would prefer the first version.\n\nAlso, I think it would be great to define interfaces.\nThis way, a user that depends on interfaces would be able to easily switch from on catalog to another.\nThis wouldn't be mandatory, of course.\n\nI may create proposal or PR if you are interested.\n\nAnd for the Counter, an instance of a class could be returned from the decorator so it contains inner metadata (a function can contain metadata as well but it's a bit dirty). This way, we could even do \"Counter.get_url(...)\".\n\nFor what you want, you would have to return something else than the function which is not great for other usages. Having an explicit method to call is not bad at all .",
            "> Ludic is rendering all HTML on the server side, it is just using HTMX attributes to replace parts of the DOM\n\nIt does not matter what Ludic is doing. Server-side HTML rendering is a 1990s technology.  The point of Ludic is for developers to have responsive, reactive web apps which demands client-side rendering. That's why you chose HTMX - to have reactive client-side rendering.",
            "Thank you very much, I am interested, if you have time, I'd be super grateful for PR proposal!",
            "You're both (almost) right.\n\nIt's probably a confusion about the semantics of word \"render\".\n\nHTML has never been rendered on the server, it has always been rendered by the browser engine to display something to the user.\n\nThere is, however, usually some template rendering using more or less dynamic data. And that is happening on the server with HTMX, and from what I've seen also with Unpoly.\n\nWhat happens on the client is probably better described as composing, not rendering.",
            "Thank you, to both of you, this really makes me think about choosing proper words. I wasn't sure how to formulate the difference and now I know I need to be more careful in choosing the right terminology."
        ]
    },
    "Python's many command-line utilities": {
        "title": "Python's many command-line utilities",
        "score": 334,
        "url": "https://www.reddit.com/r/Python/comments/1d7a1ql/pythons_many_commandline_utilities/",
        "content": "Python 3.12 comes bundled with 50 command-line tools.\n\nFor example, `python -m webbrowser http://example.com` opens a web browser, `python -m sqlite3` launches a sqlite prompt, and `python -m ast my_file.py` shows the abstract syntax tree for a given Python file.\n\nI've dug into each of them and categorized them based on their purpose and how useful they are.\n\n[**Python's many command-line tools**](https://pym.dev/cli-tools/)",
        "num_comments": 30,
        "comments": [
            "http.server is really nice when I want to move some files to another machine",
            "And you can implement your own by adding a \\_\\_main\\_\\_.py script to your packages!",
            "TIL you can have an aysnc supported REPL, super handy!",
            "i saw repls for sqlite3 and even uuid aswell",
            "`python -m json.tool` is baked into my muscle memory for formatting json on the command line. you can use it with a file or pipe in stdin. extremely useful tool",
            "[deleted]",
            "Thanks!",
            "That's one of my favs!  Super unsecure, but very convenient.",
            "I like `http.server`and used it all the time. Wanted something with just \\*slightly\\* more functionality (e.g. uploads / image previews) so I created:\n\n[https://github.com/huyng/pdrive](https://github.com/huyng/pdrive)\n\nIt works similarly:\n\n    pip install pdrive\n    python -m pdrive",
            "Yup! [Here's Django's as an example](https://github.com/django/django/blob/main/django/__main__.py) (`python -m django` is the same as the `django-admin` command).",
            "Tf did you just say",
            "Both of those were added in Python 3.12, so they're not quite as well known yet.\n\nPython 3.13 [will also include](https://docs.python.org/3.13/library/random.html#random-cli) a command-line interface for the `random` module:\n\n    $ python3.13 -m random 6\n    1\n    $ python3.13 -m random 3.14159\n    3.0145311549545397\n    $ python3.13 -m random this is great\n    is",
            "[jq](https://jqlang.github.io/jq/)",
            "How does it compare to `jq` assuming you have the option for both?",
            "I overlooked that one! I just added it to the article. Thanks!",
            "Not bad if you tunnel the port through SSH.",
            "Wow that's a great project idea! \n\nThe only thing I would add is maybe some tests and I would also caution against this statement in your readme \"It's designed to combine the excellent usability of Google Drive with the benefits of having control over your own data.\"",
            "REPL, or \"read, eval, print, loop\" is what you see when you run python without any arguments. The \"shell\" if you will. What they're taking about is one of those that supports asynchronous commands, which the normal python REPL doesn't.",
            "There's times when I have access to Python but not to install stuff",
            "Then why not just use scp?",
            "Thanks, for the feedback. Yea, I'm not the best at writing taglines. Anyway, it really is just a slightly more featureful http.server .",
            "Thanks. I understand now.",
            "E.g. using a python docker container offline.",
            "Nice interface for browsing files.",
            "SCP means I need to know the remote path already",
            "It most certainly is!",
            "sshfs would be an even nicer interface!",
            "right right okay that makes a ton of sense. I was thinking in the limited constraints of my particular use cases. Thanks for the clarification.",
            "you can use sftp or an sftp gui",
            "i prefer `ffs` \ud83e\udd13",
            "Still feels like extra work.  Most of the time I'm already in a directory (over ssh) with the files I want.  Establishing a separate connection with sftp (even with a GUI), and then navigating to the directory again takes more steps than just running http.server and opening a browser tab."
        ]
    },
    "Notion2Pandas: A new python package to import Notion Database into Pandas framework and viceversa": {
        "title": "Notion2Pandas: A new python package to import Notion Database into Pandas framework and viceversa",
        "score": 11,
        "url": "https://www.reddit.com/r/Python/comments/1d7vc3k/notion2pandas_a_new_python_package_to_import/",
        "content": "**What My Project Does**\n\nHello everyone! I've just released a new Python package, notion2pandas, which allows you to import a\u00a0**Notion database**\u00a0into a\u00a0**pandas dataframe**\u00a0with just one line of code, and to update a Notion database from a pandas dataframe also with just one line of code.\n\n  \n**Target Audience**\n\nWhether you're a data scientist, a data engineer, a Python enthusiast, or just curious, 'pip install notion2pandas' from the terminal, follow the tutorial in the README, and happy coding!\n\n\ud83d\udd17 GitLab repo:\u00a0[https://gitlab.com/Jaeger87/notion2pandas](https://gitlab.com/Jaeger87/notion2pandas)\n\n**Key Features**\n\n* **Easy to use**. import in a single line of code, export with another single line of code\n* **No more boring parsing**. You can import any Notion Database in a pandas framework\n* **Flexibility**. If you don't like the default parsing mode of a data provided by notion2pandas, you can use your own parse function for a specific kind of data.\n* **Maintainability**. If Notion broke something with an update, the possibility to provide a different parsing function allows you to use Notion2Pandas even if it's not updated with latest notion update.\n\n**Quick Start**\n\nIn the ReadMe you can find everything you need to start.\n\n  \n**Comparison**\n\nWhen I started this project, I couldn't find anything capable of transforming a Notion database into a pandas DataFrame without specifying how to parse the data.\n\nIf you got any kind of feedback I'm really curious to read it!",
        "num_comments": 9,
        "comments": [
            "Few things - \n\nNo tests mate, get a test suite up and running ASAP :)\n\nAlso, the idea of having a bunch of lambdas as instance attributes\u2026 seems kinda like an anti pattern/confusing to me? \n\nI would change these into static methods, and opt for the most basic and \u201cfull plate\u201d of data to be returned as a dataframe from the client, then the user does not need to override those attributes but adjust the DF when it\u2019s returned instead",
            "i'm sharing with my colleagues that work at Notion :)",
            "Hi! Thanks for the feedback!\n\nRegarding the tests, you are absolutely right. On my roadmap I have to implement the CI/CD with automatic tests. However, since I have to interact with external databases (Notion), it will be problematic if a test fails, leaving the database \"dirty.\" I'll come up with something to restore it if needed, but yes, tests are necessary!\n\nAs for the lambdas, initially, I also thought about exposing overridable static methods. Then, I got the impression that it might be less convenient for the user to change them, so I thought this more straightforward approach might be more convenient for the user (at least in my opinion). Regarding returning the most basic dataframe, the basic implementation of notion2pandas already gives you a very generic version that probably satisfies most use cases. There are only a few pieces of data that require specific preferences (the most common being dates), so this solution seemed more convenient to me as well. However, I'm open to changing it if many users prefer your suggested approach.",
            "\ud83d\ude4f\ud83d\ude4f\ud83d\ude4f\ud83d\ude4f\ud83d\ude4f",
            "If you want to stick with the assigning functions in the \\__init\\__, you can define them as regular functions outside the class and just assign them by name\n\n\nThat will allow you to write docstrings/type hints/etc",
            "I'm not sure to understand completely, could you please provide me a piece of pseudo code to better understand?",
            "Very simple example but essentially, instead of\u00a0\n\n\n```\nclass Example:\n\u00a0 \u00a0 def __init__(self):\n\u00a0 \u00a0 \u00a0 \u00a0 self.add_one = lambda x: x + 1\n```\n\n\nYou could do\n\n\n```\nclass Example:\n\u00a0 \u00a0 def __init__(self):\n\u00a0 \u00a0 \u00a0 \u00a0 self.add_one = add_one\n\n\ndef add_one(x: int) -> int:\n\u00a0 \u00a0 \"\"\"\n\u00a0 \u00a0 Adds one to an integer\n\n\n\u00a0 \u00a0 Params:\n\u00a0 \u00a0 ...\n\n\n\u00a0 \u00a0Returns:\n\u00a0 \u00a0...\n\u00a0 \u00a0\"\"\"\n\u00a0 \u00a0 return x + 1\n```",
            "Ah ok, so it doesn't change anything for those who use the package? It's just an internal change?",
            "The only change for downstream users is that then you can specify type annotations and docstrings, which are very nice for users\n\nFor you, a huge benefit is that you aren't restricted to just lambda functions, which are very tough to do anything complicated in (your nested lambda funcs I'm sure are super fun to try to debug), so that would be a huge QoL improvement for you as the developer"
        ]
    },
    "Rate Limiting + Multiprocessing = Nightmare? But I think I've found one nice way to do it \ud83e\udd1e": {
        "title": "Rate Limiting + Multiprocessing = Nightmare? But I think I've found one nice way to do it \ud83e\udd1e",
        "score": 9,
        "url": "https://www.reddit.com/r/Python/comments/1d7rvd2/rate_limiting_multiprocessing_nightmare_but_i/",
        "content": "If you're interested in Python multiprocessing, I'd appreciate if you read this and share your thoughts:\n\ntl;dr: I've implemented a cross-process request rate limiter, allowing for N requests per T seconds. See it in [this Gist](https://gist.github.com/Voyz/8c3b464e151af1c3b2d2e99a2a1a7fc9).\n\n# Problem\n\nRequest rate limiting (or throttling) requires a place in memory to track the the amount of calls already made - some kind of `counter`. Multiprocessing is not great at having a single shared variable.\n\nI have a use case for a multiprocessing system in which each process can make a number of requests to a REST API server. That server imposes a 1000 requests per minute limit. Hence I needed a way to implement a rate limiter that would work across processes and threads.\n\nI've spent the past 2 days digging through a ton of SO posts and articles suggesting how to do it, and I came at a few bad solutions. I finally came up with one that I think works quite well. It uses a [multiprocessing.Manager](https://docs.python.org/3/library/multiprocessing.html#multiprocessing.managers.SyncManager), and its [Value](https://docs.python.org/3/library/multiprocessing.html#multiprocessing.managers.SyncManager.Value), [Lock](https://docs.python.org/3/library/multiprocessing.html#multiprocessing.managers.SyncManager.Lock) and [Condition](https://docs.python.org/3/library/multiprocessing.html#multiprocessing.managers.SyncManager.Condition) proxies.\n\n# Solution\n\nI've created a `CrossProcessThrottle` class which stores that `counter`. The way that the information about the `counter` is shared with all the processes and threads is through a `ThrottleBarrier` class instance. Its `wait` method will do the following:\n\n    def wait(self):\n        with self._condition:\n            self._condition.wait()\n    \n        with self._lock:\n            self._counter.value += 1\n\n1. Wait for the shared `Condition` - this will stop all the processes and their threads and keep them dormant.\n2. If the `CrossProcessThrottle` calculates that we have available requests (ie. the `counter` is below `max_requests`, so we don't need to limit the requests), it uses `Condition.notify(n)`  ([docs](https://docs.python.org/3/library/threading.html#threading.Condition.notify)) in order to let `n` amount of threads through and carry out the request.\n3. Once approved, each process/thread will bump the shared `Value`, indicating that a new request was made.\n\nThat `Value` is then used by the `CrossProcessThrottle` to figure out how many requests have been made since the last check, and adjust its `counter`. If `counter` is equal or greater than `max_requests`, the `Condition` will be used to stop all processes and threads, until enough time passes.\n\nThe following is the example code using this system. You can find it in [this Gist](https://gist.github.com/Voyz/1b6857f6d7b9ada024e3d2529bba8f4c) if you prefer.\n\n    import datetime\n    from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor\n    \n    from ratelimiter import ThrottleBarrier, CrossProcessesThrottle\n    \n    \n    def log(*args, **kwargs):\n        print(datetime.datetime.now().strftime('[%H:%M:%S]'), *args, **kwargs)\n    \n    \n    def task(i, j, throttle_barrier: ThrottleBarrier):\n        # This will block until there is a free slot to make a request\n        throttle_barrier.wait() \n        log(f'request: {i:2d}, {j:2d}  (process, thread)')\n        # make the request here...\n    \n    \n    def worker(i, throttle_barrier: ThrottleBarrier):\n        # example process worker, starting a bunch of threads\n        with ThreadPoolExecutor(max_workers=5) as executor:\n            for j in range(5):\n                executor.submit(task, i, j, throttle_barrier)\n    \n    \n    if __name__ == '__main__':\n        cross_process_throttle = CrossProcessesThrottle(max_requests=3, per_seconds=10)\n        throttle_barrier = cross_process_throttle.get_barrier()\n    \n        log('start')\n        futures = []\n        # schedule 9 jobs, which should exceed our limit of 3 requests per 10 seconds\n        with ProcessPoolExecutor(max_workers=10) as executor:\n        \n            for i in range(3):\n                futures.append(executor.submit(worker, i, throttle_barrier))\n    \n            while len(futures):\n                # calling this method carries out the rate limit calculation\n                cross_process_throttle.cycle()\n    \n                for future in futures:\n                    if future.done():\n                        futures.remove(future)\n    \n        log('finish')\n\nI've uploaded the source code for `CrossProcessThrottle` and `ThrottleBarrier` as a [Gist too](https://gist.github.com/Voyz/8c3b464e151af1c3b2d2e99a2a1a7fc9). Calculating the `counter` is a bit more code, so I refrain from sharing it here, but in a nutshell:\n\n1. Store the last amount of requests made as `last_counter`, initialised as 0\n2. Every time the `cycle()` is called, compare the difference between the current `counter` and the `last_counter`\n3. The difference is how many requests have been made since the last check, hence we increment the `counter` by that many.\n4. We calculate how many calls remaining are allowed: `remaining_calls = max_requests - counter`\n5. And notify that many threads to go ahead and proceed: `condition.notify(remaining_calls)`\n\nThe actual process is a little more involved, as at the step 3 we need to store not only the amount of calls made, but also the times they've been made at - so that we can be checking against these later and decrease the `counter`. You can see it in detail in the [Gist](https://gist.github.com/Voyz/8c3b464e151af1c3b2d2e99a2a1a7fc9).\n\nIf you've read through the code - what are your thoughts? Am I missing something here? In my tests it works out pretty nicely, producing:\n\n    [14:57:26] start\n    [14:57:26] Calls in the last 10 seconds: current=0 :: remaining=3 :: total=0 :: next slot in=0s\n    [14:57:27] request:  0,  1  (process, thread)\n    [14:57:27] request:  0,  0  (process, thread)\n    [14:57:27] request:  0,  2  (process, thread)\n    [14:57:31] Calls in the last 10 seconds: current=3 :: remaining=0 :: total=3 :: next slot in=7s\n    [14:57:36] Calls in the last 10 seconds: current=3 :: remaining=0 :: total=3 :: next slot in=2s\n    [14:57:38] request:  0,  4  (process, thread)\n    [14:57:38] request:  0,  3  (process, thread)\n    [14:57:38] request:  1,  0  (process, thread)\n    [14:57:41] Calls in the last 10 seconds: current=3 :: remaining=0 :: total=6 :: next slot in=7s\n    [14:57:46] Calls in the last 10 seconds: current=3 :: remaining=0 :: total=6 :: next slot in=2s\n    [14:57:48] request:  2,  0  (process, thread)\n    [14:57:48] request:  1,  1  (process, thread)\n    [14:57:48] request:  1,  2  (process, thread)\n    [14:57:51] Calls in the last 10 seconds: current=3 :: remaining=0 :: total=9 :: next slot in=8s\n    [14:57:56] Calls in the last 10 seconds: current=3 :: remaining=0 :: total=9 :: next slot in=3s\n    [14:57:59] request:  2,  4  (process, thread)\n    [14:57:59] request:  2,  2  (process, thread)\n    [14:57:59] request:  2,  1  (process, thread)\n    [14:58:01] Calls in the last 10 seconds: current=3 :: remaining=0 :: total=12 :: next slot in=8s\n    [14:58:06] Calls in the last 10 seconds: current=3 :: remaining=0 :: total=12 :: next slot in=3s\n    [14:58:09] request:  1,  3  (process, thread)\n    [14:58:09] request:  1,  4  (process, thread)\n    [14:58:09] request:  2,  3  (process, thread)\n    [14:58:10] finish\n\nI've also tested it with 1000s scheduled jobs to 60 processes, each spawning several threads, each of which simulates a request. The requests are limited as expected, up to N per T seconds.\n\nI really like that I can construct a single `ThrottleBarrier` instance that can be passed to all processes and simply call the `wait` method to get permission for a request. It feels like an elegant solution.\n\n# Research\n\nThere are a bunch of libraries for rate limiting, some claiming to support multiprocess, however I couldn't get them to do so:\n\n* [https://pypi.org/project/ratelimit/](https://pypi.org/project/ratelimit/)\n* [https://pypi.org/project/ratelimiter/](https://pypi.org/project/ratelimiter/)\n* [https://pypi.org/project/ratemate/](https://pypi.org/project/ratemate/)\n* [https://github.com/JWCook/requests-ratelimiter](https://github.com/JWCook/requests-ratelimiter)\n\nThere's a few SO threads and posts discussing the process too, however they either don't consider multiprocessing, or when they do they don't allow using `ProcessPoolExecutor`:\n\n* [https://stackoverflow.com/questions/69306420/rate-limit-api-multi-process](https://stackoverflow.com/questions/69306420/rate-limit-api-multi-process)\n* [https://stackoverflow.com/questions/40748687/python-api-rate-limiting-how-to-limit-api-calls-globally](https://stackoverflow.com/questions/40748687/python-api-rate-limiting-how-to-limit-api-calls-globally)\n* [https://gist.github.com/justinvanwinkle/d9f04950083c4554835c1a35f9d22dad](https://gist.github.com/justinvanwinkle/d9f04950083c4554835c1a35f9d22dad)\n* [https://stackoverflow.com/questions/6920858/interprocess-communication-in-python](https://stackoverflow.com/questions/6920858/interprocess-communication-in-python)\n\nThe issue with `ProcessPoolExecutor` comes up when you try to use shared resources as it raises an error along the lines of:\n\n    Synchronized objects should only be shared between processes through inheritance\n\nAnd to be fair the Googling didn't really help me figuring out how to get around it, just finding more people struggling with the issue:\n\n* [https://stackoverflow.com/questions/69907453/lock-objects-should-only-be-shared-between-processes-through-inheritance](https://stackoverflow.com/questions/69907453/lock-objects-should-only-be-shared-between-processes-through-inheritance)\n* [https://github.com/python/cpython/issues/79967#issuecomment-1455216546](https://github.com/python/cpython/issues/79967#issuecomment-1455216546)\n\nThe solution would be to not use the `ProcessPoolExecutor` but that was a bummer. This comment helped me to find the way I've ended up using:\n\n* [https://stackoverflow.com/a/65377770/3508719](https://stackoverflow.com/a/65377770/3508719)\n\nI'm glad that using the `SyncManager` and its proxies I managed to come up with a solution that allows me to use the executor.\n\n# Note\n\n* I use multiprocessing instead of multithreading as there is some post-processing done to the data returned from the REST API.\n* I imagine that for better efficiency I could split the system into a single process that does a lot of multithreading for REST API interaction, and then pass the returned data to several processes for post-processing. I didn't have time to do it at the moment, but I'm aware of this as a potential alternative.\n* I've built an earlier version of the rate limiter using [multiprocessing Listener and Client](https://docs.python.org/3/library/multiprocessing.html#module-multiprocessing.connection) - and carried out the communication through sockets/pipes. While this is useful to know about for inter-process communication, it turned out to be too slow and not support 100s of concurrent requests.\n* If one of the existing libraries (eg. one of the ones I've listed) supports cross-process rate limiting with `ProcessPoolExecutor`, I'd love to see how to do it, please share an example!\n* Multiprocessing can be a pain \ud83d\ude2d\n\nAny feedback on my implementation welcome!",
        "num_comments": 36,
        "comments": [
            "It looks like you\u2019ve engineered a solution to the problem you\u2019ve made for yourself by coupling processing to data retrieval. \n\nLike you mentioned, this problem would likely just go away if you used multi threading or async for your IO bound work.\n\nFor the CPU bound work, it\u2019s really unlikely that python multiprocessing is the right answer either. You\u2019d be better served using a library that pushes the computation down a more efficient low-level language. Depending on the data volume in question, pandas might be fine, or maybe something like duckdb if you want more efficient memory usage and are dealing with large sets of files on disk.",
            "First please for the love of god update those SO posts lol. Yea I had no idea that multiprocessing had a lock feature is that newish? \n\nSecond I do think in your specific case you probably don't want to use a lock TBH. I think you would be better off using multithreading or async (async will be orders of magnitude faster) for your download threads. Then use multiprocessing to actually process the data. You can do some other stuff with shared memory if you want to speed that up further or if you find a library that allows u to stream your read pipe directly to the other processes. \n\nMultiprocessing in python tends does best IMO when you give each process descriptive roles and avoid them all being pure duplicates. It is generally easier to debug that way. Kinda like breaking up your program into fuctions its generally easier to break up your processes into smaller parts.",
            "Too long.. I faced the same issue, solved it by using pyrate lib or ratelimit (depends on your needs).\nWith Pyrate, you can have an external store for your processes.\nTakes a few lines, quite easy to implement",
            "It just happens that I spent all day trying to solve a very similar problem as you. Just in case it's helpful, I ended up going with [aiometer](https://github.com/florimondmanca/aiometer) which solved the problem quite simply. I just followed their sample at the top of their README and it worked! Rate limited API calls with asyncio and httpx.",
            "solution is to not use multiprocessing everywhere, just have the webserver on asyncio and if you have CPU bound work, use a queue to a process pool to push jobs and receive results in the other process running the async runtime.\n\n\nThe time you spent fiddling with this couldve been spent in fixing your design, which is the actual problem, like you mention in your notes at the end",
            "Reimplementing standard library I see.   \n\n(\ud83d\udc49\uff9f\u30ee\uff9f)\ud83d\udc49 multiprocessing.Value \ud83d\udc48(\uff9f\u30ee\uff9f\ud83d\udc48)\n\nEach request job checks value of Value. If below 1000, it increments by one and does a request. If at or above 1000, the job sleeps a little and rechecks again. A separate thread in the main process resets value to zero once per minute. \n\nAlternatively, and maybe even better, save a timestamp in mseconds into Value. A job checks current time and Value. If the time since Value value is larger than a 1/1000 of a minute, it updates the Value with current time and makes request. No need for a timer thread this way, but use `multiprocessing.Lock` to make sure that comparing and updating Value is atomic. Value has its own instance of lock, no need to make another. \n\nWhich way to choose depends on whether you prefer a burst of action at the beginning of a minute or have your requests spread equally through the minute.",
            "Yeah or use a framework like ray for cpu bound function calls",
            "Thanks for the feedback! I considered both solutions and it felt easier to figure out rate limiting on multiple processes, than separate REST API multithreading and post-processing using multiprocessing.\n\nI felt that having to pass a large amount of data between that asyncio process and the post-processors would be a bottleneck. Also, I was imagining some added complexity if the asyncio process outperformed the post-processing speed and ended up clogging up the queue. Likely I'm missing something here though - is it really that much more straightforward? Would you be able to comment on what challenges could this pose? I'm imagining the implementation would involve something like a SyncManager.Queue that gets populated by the asyncio process, and consumed by the post-processors?\n\nSide tracking, I tried using Pandas for data writing, but am slowly moving away from it since its datatypes cause me a hell lot of headaches. I found two equal DataFrames with equal datatypes producing distinct checksums. I don't mind trading a bit of writing speed for better data consistency. The full dataset will be around 200-400gb I estimate.",
            "Thanks for your feedback!   \n  \nCan you share some resource on how to pipe directly from one process to another? \n\nAnd, sorry, what do you mean about updating SO posts?",
            "Thanks for the suggestions! Sorry, which Pyrate? I found a bunch:\n\n* [https://github.com/dsilvestro/PyRate](https://github.com/dsilvestro/PyRate)\n* [https://geoscienceaustralia.github.io/PyRate/](https://geoscienceaustralia.github.io/PyRate/)\n* [https://pypi.org/project/pyrate/](https://pypi.org/project/pyrate/)\n\nCould you expand on that external store for processes and how would that work?\n\nDlso, does *ratelimit* support multiprocessing rate limiting?",
            "not the same at all. OP is having issues because his code is running on multiple processes",
            "Yeah it really feels like this is better solved with a queue (celery, rq, dramatiq, etc) and a set number of workers to avoid blowing up the machine.",
            "Thanks for pointing that out! Aren't multiprocessing.Values not compatible with ProcessPoolExecutor? I went that path at first, but I couldn't pass these Values so I ended up having to pass a separate proxy for Value and Lock.   \n  \nCondition seemed like a nice addition there - since the managing thread can let only 'n' threads through it, hopefully preventing race conditions. \n\nI appreciate your answer, I can see how you mean that these are two different ways indeed.",
            "It sounds like you are retrieving data and then post processing it at the same time, without writing the data to disk in between. Why? What happens if there\u2019s an error in the post processing step? Do you then have to start again?\n\nIn my experience (I work as a data engineer), the best thing to do is keep things simple. Assuming this was intended to run on a single machine, here\u2019s a general approach I would take.\n\nI would write code that retrieves data from the API, possibly using multi threading or asyncio, but only if it was necessary to do so in order to retrieve data efficiently. Even this has been quite a rare occurrence.\n\nThen, I\u2019d write that data to disk, in a format as close to raw as possible. If the data is JSON, I\u2019d store it in JSON (probably compressed with something like ZSTD for space efficiency).\n\nI would then write other code that reads the raw data from disk to do any post processing. Potentially I\u2019d create multiple steps - the first might be to infer/enforce a schema on the raw data and save it in a more efficient format such as parquet, and potentially id also repartition the data at this point in a way that makes more sense.\n\nFrom then on, I might use a library like duckdb to perform further transformations and analysis.\n\nI\u2019d then use some kind of scheduler to run all this at a cadence that makes sense. Each step would be designed to run in isolation. The raw api retrieval step would look at the data it has retrieved already to know what data it needs to fetch next. In the case of a multithreaded approach, I\u2019d be looking to use any filtering or pagination options to create raw output files partitioned in some fashion, EG by date or datetime. Each thread would write one file. If something goes wrong, that thread fails (maybe it retries once or twice), but the rest of the program continues. The job would look for missing partitions each time it starts.\n\nThe downstream jobs would do the same. Check source, check dest, process what can be processed. There may need to be additional logic so that for example it won\u2019t process a day until all 24 hours of data for that day have partitions.\n\nIf there is a need for data to be accessible in real time, then I\u2019d probably first really question whether that is true. I\u2019d then want to look very closely at where the data is stored, and what options I have to access it other than a REST API. Or perhaps, the data required in real can be retrieved in a transactional fashion from the rest API and processed efficiently enough to be done in real time (ie if no aggregations are needed). Even in that scenario, I\u2019d probably write each step to disk so that it only needs to speak to the API once.",
            "there is a cost when passing data between processes, it implies serializing and deserializing it plus sending it over a pipe.\n\n\nThat is normally mitigated by making sure the work you are doing will be larger than that through batching the work to be done.\n\n\nWhen it comes to the asyncio process going too fast, the easiest way is to just poll data, submit to the pool while blocking, and then collect the results.",
            "https://github.com/pexip/os-python-pyrate-limiter?tab=readme-ov-file\n\nRatelimit does not support multiprocessing as far as I know.\n\nUltimately, writing your own rate limiter is not that hard: you just need to store a timestamp. Then store it on a key-value store like redis.\nYou can even combine it with a caching system to avoid unnecessary function call",
            "But OP said that they only needed multiple processes so that they can track the rate limit. My solution avoids that restriction. Unless I\u2019m mistaken, that\u2019s the only reason that op needed to do it the way they did. There\u2019s other solutions for rate limiting",
            "I just don't use ProcessPoolExecutor when I need anything other than Full Throttle Ahead! which is what it is designed to do. But I am rather confident that you can pass a tuple of Values, Locks and stuff, all you need is to fill workers manually instead of using `map()`, or create a generator that yields your task along with synchronisation  objects and `map()` on that generator. \n\nGPT says:\n\n```\nfrom concurrent.futures import ProcessPoolExecutor\nfrom multiprocessing import Value\n\ndef worker(v):\n    with v.get_lock():\n        v.value += 1\n\nif __name__ == '__main__':\n    v = Value('i', 0)  # Create a shared Value object, initialized to 0\n\n    with ProcessPoolExecutor() as executor:\n        for _ in range(10):\n            executor.submit(worker, v)  # Pass the shared Value object to the worker\n\n    print(v.value)  # Print the final value\n```",
            "Honestly, thank you very much for taking time to write all of this. \n\nYour idea of first saving the raw data from the API, and only then working on post-processing it was a brilliant one. It indeed helped me simplify the system. Do you have a *Buy Me A Coffee* account or similar?\n\n  \nTo give more context: the post-processing I was carrying out was consisting of two parts:\n\n1. Cleaning up the data\n2. Creating checksums for the data\n\nI was wondering if you'd have any more thoughts on these two.\n\n# 1. Clueanup \n\nThe data needs quite a bit of cleaning up:\n\n* I'm generating around 10-20 tabular files per download, each with different data, some up to 1 million rows. I have around 35,000 downloads in total.\n* Removing unnecessary columns\n* Cleaning up some floats. Some come in as strings containing '.00' at the end\n* Casting columns into appropriate types. Many integers came as floats, or as aforementioned '.00' strings\n* Many fields came with empty data, hence handling NaNs\n\nThis came with a huge headache when it came to working through it. Pandas was a pain since NaNs for integers only work with either floats or Int64s. If I used floats, the data get corrupted once read back - for example, address zip integer gets a '.0' postfix. If I used Int64s, I couldn't use HDF5 (or so it seemed to me when I tried), which I intended to due to its compression benefit (reducing my overall estimated data size roughly by half). I've encountered more issues like these when using Pandas - bools with nans, strings with Nones, datetimes, etc. \n\nThat's the first reason for post-processing, to clean all that data up and make it uniform - ensuring it can be stored and read back in an expected manner. \n\n# 2. Checksums\n\nI'd particularly love to hear your thoughts on this topic. \n\nI've read up about processing such (large?) datasets before, and checksums were widely recommended. From what I understand, it helps with data consistency and corruption detection. \n\nI started by creating a sha256 directly from Pandas DataFrame. It was inconsistent as hell - once again due to datatypes, internal array representations, etc. Data downloaded from the REST API was represented differently in a DataFrame than when it was read back from the disk (see the address zip mentioned earlier). Even something as simple as a blank cell in a one-row table would get interpreted differently. I saw a DataFrame with literally the same content - index, columns, datatypes, values - turning into different hashes.\n\nHence I moved on to creating hashes from `df.values.tolist()`. That helped, but again only to some extent. I ended up ditching pd.DataFrames almost completely and processing the data as lists of values, and creating hashes from these. \n\nAnd that was the second source of post-processing time: serialising and deserialising the data into lists of lists to ensure consistent hashing. This finally worked fine - creating consistent hashes before writing and after reading - but needed some extra CPU cycles to carry out. Finally, the checksum needed generating and be written to a file next to the data.\n\n----\n\nAnd then compressing an hdf5 of these 1M rows takes like 2-20 seconds on a good day on my machine.\n\nI've read what you wrote in your reply here, and I agree that first writing the data raw from the REST API, and post-processing it later is a much better idea. I feel silly for refusing that idea when I thought about it earlier. It sounded reasonable to do it all as one step, but it's the first time I'm dealing with that amount of data, so I'm happy to be able to learn along the way.  Your suggestion simplifies a lot. Thank you, honestly.\n\nI'd highly appreciate any further feedback on the post-processing I've outlined here.",
            "Ahh, thanks for explaining it, I wasn't aware of how large that overhead was. I can see your point about it needing to be large enough.",
            "Appreciate you sharing it! Thanks!",
            "no. Presumably OP is using multiple processes because there is CPU bound work to perform on the retrieved data.\n\n\nYou have part of the solution, which is to decouple where the data is retrieved and where its processed.\n\n\nYou couldnt make it work on asyncio or multithreading alone because the server might become unresponsive for long periods of time depending how long the processing takes",
            "Thanks for the clarification. I'm not using `map`, I run `executor.submit()` and collect the Futures.   \n  \nThat code you shared won't show the issues raised by the worker. When collecting submit()'s Futures and processing their result, this is raised:  \n  \n`RuntimeError: Synchronized objects should only be shared between processes through inheritance`\n\nSee this [SO post](https://stackoverflow.com/questions/69907453/lock-objects-should-only-be-shared-between-processes-through-inheritance) for more detail on it.\n\n>*Unfortuantely, this does not work when you are dealing with\u00a0multiprocessing.Pool\u00a0instances. In your example,\u00a0self.lock\u00a0is created in the main process by the\u00a0\\_\\_init\\_\\_\u00a0method. But when*\u00a0[*Pool.map*](http://Pool.map)\u00a0*is called to invoke\u00a0self.function, the lock cannot be serialized/deserialized to the already-running pool process that will be running this method.*\n\nOne solution I've found is to use a SyncManager - but then you pass Proxies, and a Value proxy doesn't have a lock as far as I tried.\n\nUnless you're talking of some different solution and I misunderstood you?",
            "Hey it\u2019s all good. It\u2019s really hard not to learn this the hard way.\n\nYour data type and hashing issues are likely related.\n\nI\u2019d probably recommend taking a different approach than hashing to validate that your data is consistent. I\u2019d also actually defer worrying about this for now.\n\nFor the data type issue, pandas will try to take a best guess at the data type to use for each column. \n\nIf you\u2019re seeing integer columns come in as floats, then it\u2019s likely because the integer column contains null values in certain rows. Null is not a valid integer. Null is represented by np.nan in pandas dataframes, which is a float, and so the default integer type cannot be used for an integer column. To compensate, pandas will cast the integer column to a float.\n\nThere is a nullable integer data type. There\u2019s int64 and Int64 options with pandas. One of them is nullable and one isn\u2019t, I forget which is which.\n\nDepending on how you\u2019re reading the data into a data frame, you may have an optional dtypes keyword argument to which you can provide a dictionary that maps column names to the type that should be applied to that column.\n\nI would imagine that the other cleaning issues may be related to this. Additionally this may be playing a part with the hashing issues. You\u2019ll need to investigate to figure out what is causing the discrepancy on each occasion, but you\u2019ll find that there\u2019s a finite set of ways it can go wrong.\n\nYou can inspect the data frame and learn about what data type it has chosen. When you provide a dtypes dictionary, it will fail loudly if a column cannot be encoded to that data type, but it will just  try a best guess for any columns in the data frame not in the dictionary. This way you can make your own best guess, and see what fails, or figure it out column by column and build out your dtypes dictionary column by column (or type by type).\n\nI\u2019m honestly not sure how checksums would help here - if you\u2019re modifying and cleaning the data, then what are you comparing the checksum to?\n\nWhat\u2019s more important is that you\u2019ve enforced types on the data (where this is necessary) to ensure it works consistently downstream. This could be very different to how the data arrives raw from the API. JSON doesn\u2019t have all that sophisticated typing support, and CSVs even less.",
            "Thst is why I don't like ProcessPoolExecutor: it is the same, but different, and thoroughly undocumented. Can't use Value's internal lock or it hangs up, but can use another lock just fine. \n\nThis works, I just tested it:\n\n    import multiprocessing as mp\n    from concurrent.futures import ProcessPoolExecutor\n    \n    \n    def foo(v, l):\n    \u00a0 \u00a0 with l:\n    \u00a0 \u00a0 \u00a0 \u00a0 v.value += 1\n    \u00a0 \u00a0 \u00a0 \u00a0 print(f\"foo: {v.value}\")\n    \n    \n    if __name__ == \"__main__\":\n    \u00a0 \u00a0 m = mp.Manager()\n    \n    \u00a0 \u00a0 v = m.Value(\"i\", 0)\n    \u00a0 \u00a0 l = m.Lock()\n    \n    \u00a0 \u00a0 with ProcessPoolExecutor() as pool:\n    \u00a0 \u00a0 \u00a0 \u00a0 for _ in range(10):\n    \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 pool.submit(foo, v, l)\n        print(f\"main: {v.value}\")",
            ">I\u2019d probably recommend taking a different approach than hashing to validate that your data is consistent.\n\nCould you elaborate on this? How would you do it instead of checksums?\n\n> I\u2019d also actually defer worrying about this for now.\n\nAlso, could you elaborate? At what point would it be a good idea to do so?",
            "Regarding nulls in integer columns - yes, I'm aware of this. It's the `Int64` (the capitalised one) that's Pandas supported, however like I've mentioned, when trying to save such a DataFrame to HDF5 an error is raised. It seems that the datatypes cannot be the Pandas ones - same thing happens when datatype is `string` instead of `O`.\n\nNow importantly, regarding this:\n\n> Depending on how you\u2019re reading the data into a data frame, you may have an optional dtypes keyword argument to which you can provide a dictionary that maps column names to the type that should be applied to that column.\n\nRight, I know I can cast anything I read to a particular datatype like you suggest.\n\nHere's a little guilty moment for me - I thought I could get away without defining a column-by-column datatype schema. I really wanted to see if I can get around this by saving the data without a schema defining each datatype. The reason is: there is around 250 columns across the different files created per download. My reasoning was that defining a full datatype schema for each of these columns would be laborous and error prone. \n\nWhat are your thoughts on this? Worth putting in the effort and specifying the datatype for each column?\n\n> This could be very different to how the data arrives raw from the API. JSON doesn\u2019t have all that sophisticated typing support, and CSVs even less.\n\nIt arrives as both JSON and CSVs - depending on the endpoint - and like I've mentioned, it's not well formatted: there is little consistency (mixed cases) and malformatting (floats as '.00' strings, various representation of missing fields).",
            "> I\u2019m honestly not sure how checksums would help here - if you\u2019re modifying and cleaning the data, then what are you comparing the checksum to?\n\nThe checksums happen after the data cleanup. So the process was to:\n\n1. Download the data\n2. Clean the data up and save it\n3. Calculate a checksum from the cleaned-up data and save it along with the data\n\nThen when reading, I'm reading the cleaned up data, along with its checksum, and verifying that it hasn't been corrupted.\n\nI imagined this would be crutial in cases where I'd move this data between systems or perform/restore a backup, etc.\n\nDoes that make sense?",
            "See my other comment. When you\u2019re Google, and the minute possibility of a cosmic ray flipping bits on hard drives in your data centre becomes a thing you need to actually worry about.\n\nFiles getting corrupted just isn\u2019t something you need to worry about. If you have multiple processes reading and writing the same file, just\u2026 don\u2019t?",
            "If your downstream code depends on data adhering to a type, you need a schema to validate that it adheres to that type. You don\u2019t need to enforce this for all columns, just the ones that are important to your application.\n\n>HDF5\n\nWhy on earth are you doing that?",
            "That doesn\u2019t at all seem worth it here. I have literally never come across a case of a file being corrupted in that manner and I\u2019ve been working in this field for nearly a decade.\n\nYou\u2019re talking about extremely slim odds. If you\u2019re Google running a map reduce task across petabytes of data on an enormous data centre sized cluster, then you probably want this. But it\u2019s nowhere near likely enough that a file on your machine is going to get corrupted frequently enough to invest any amount of time or effort into this.",
            "Understood! I never have multiple processes reading and writing the same file - it's more about long term storage and backup/restore corruption. Thanks for sharing your perspective on this, it's very valuable to me!",
            "Understood. I needed to hear this \ud83d\ude22\n\n> Why on earth are you doing that?\n\nIsn't HDF5 one of the most commonly used standards for storing large amounts of data? I've got thousands of datasets with a million rows, wouldn't that be a reasonable choice? From your answer I sense you'd be heavily against using it - how so?\n\nThe raw alternative I have is CSV. The advantages of HDF5 I see:\n\n1. It writes much faster than CSV\n2. It compresses to much smaller sizes than CSV\n3. The compressed data is easily human-readible with a simple program\n4. It's widely used, with a lot of support\n\nI haven't used other compressions - like gzip, zlib, or ZSTD you've mentioned - so I cannot compare.\n\nWould you have any suggestions in that regard?",
            "Thanks for sharing this, I understand your point. I've had data corrupted when backing up and restoring from an external hard drive - especially when it happens after a few years - hence it felt like a reasonable approach to have some form of verifying the integrity.\n\nNevertheless, thank you for giving me a perspective here \ud83d\udc4d",
            "Parquet. Use parquet."
        ]
    },
    "Using python for static typing benefits": {
        "title": "Using python for static typing benefits",
        "score": 20,
        "url": "https://www.reddit.com/r/Python/comments/1d7lgh7/using_python_for_static_typing_benefits/",
        "content": "I'm interested in using cython specifically for introducing static typing to parts of a code base. For anyone who has used cython, could you give any details about your experience with introducing it gradually, how it changed the deployment and execution processes, how well it played with code that is calling lots of 3rd party frameworks. Also curious to hear about any headaches or issues it introduced.\n\nI'm less interested in the performance benefits, more interested in static type checks. I do use mypy already but I'm left quite lacking with it compared to real compilation checks. I'm curious more generally about the possibility of having a code base that mixes static and dynamic typing, and if I could stay in Python while doing that instead of going to Rust that would really simplify things.\n\nThanks!",
        "num_comments": 24,
        "comments": [
            "As someone who regularly uses lower-level languages with strong type systems, Mypy in strict mode is actually a great experience. Between that and a super strict ruff config, you can force extreme code quality through the entire project without sacrificing being able to use Python and its rich ecosystem. So long as the data entering at the boundaries is properly enforced with something like Pydantic it is possible to model a system completely free of type-related problems.",
            "As someone that's used a small amount of cython professionally in an established python project, I'd sooner reach to rust with pyo3 personally. The build chains and integrations around cython were just a PITA.",
            "I've used Cython for performance reasons and it's great for that. You can port the code in your hottest loops and leave the rest of the code untouched, and it's close enough to Python that it's usable on a team where not everyone knows C.\n\n\nIt is absolutely not a good way to introduce static typing to your system though. Its type system is more-or-less intended to reflect the types used by the Python C API, which means no generics, no protocols/duck typing, etc. It's definitely not the Rust-like language you think you want.\n\n\nIt is absolutely inferior to Mypy for this.\n\n\nMypy has been built to be able to reflect as many of the common idioms in Python as possible, with a view to incrementally adding types to old codebases. This makes its type system ugly, but a bolt-on type system to an existing language can't avoid this.\n\n\nAlso, slightly more generally, it sounds like you want to write Rust in Python. Don't. Write Python in Python and write Rust in Rust. Python is designed to be Python, and it is bad at being anything else, at least partly by design.",
            "If you're primarily interested in static typing, but also want compilation - have you looked at mypyc?",
            "The whole point of using Python is to avoid the existential horror that is static typing. Dynamic typing GIVES YOU THE POWER OF GODS. \n\nThere is no functional benefit to static type checks, as has been proven over and over again in research and common sense. When's the last time you ever passed \"octopus\" to the square root function? Never? Then there's the big lie of static typing. Type problems are the simplest problems to spot and the most brain-dead easy to fix. No one lies awake at night worrying about passing \"octopus\" to the square root function. It's the subtle logic errors and rare corner cases that give you the cold sweats. And those only stand a chance of being caught by writing tests. And if you're writing tests, the tests are also catching your static typing errors too. Is passing 4 to the square root function returns 5, you've failed the test. If passing 4 to the square root function returns \"octopus\", it's still failing the test.\n\nSo you don't need static typing. The people who are having non-platonic love affairs with type checking in Python today are kids who didn't spend 20 years coding in god-awful obsessively-typed, pedantic statically typed programming languages where you have to convince a compiler that the code you just wrote will work. They don't know what Lovecraftian horrors they're unleashing as they believe the lie that that type errors are a problem.\n\n[https://medium.com/javascript-scene/the-shocking-secret-about-static-types-514d39bf30a3](https://medium.com/javascript-scene/the-shocking-secret-about-static-types-514d39bf30a3)\n\n[https://vimeo.com/74354480](https://vimeo.com/74354480)",
            "Enforced via a very clean OpenAPI spec is what I do.\nI\u2019ve not used ruff but every package it replaces is what I use.  So I\u2019ll have to give that a go.\n\nOnly package it doesn\u2019t have us use of safety as part of the regular build scanners.",
            "Do you have a strict ruff config you typically use that you could share?",
            "And you can say, \"I rebuilt it in rust\"",
            "Yeah this is exactly what I was wondering, how big of a pain builds and integrations were going to be. Thanks for the feedback, I'll avoid that rabbit hole and look more to mypyc and rust where it makes sense.",
            "Just curious, what exactly is painful? I found that cythonize is pretty simple to use.",
            "Pyo3 and Maturin have some rough edges too, though my experience is particularly around scientific python, so possibly there are more well trodden paths around web stuff / general purpose software that are more mature.\u00a0",
            "\u2022\t\u2060it sounds like you want to write Rust in Python. Don't. Write Python in Python and write Rust in Rust. Python is designed to be Python, and it is bad at being anything else, at least partly by design.\n\nBeautifully said.\n\nPython is so fast (to code) because it allows basically everything. Rust is so stable because of its strictness.\n\nEvery tool has its place.",
            "This is all great stuff to reflect on, thanks! I guess I'll take a deeper dive into mypy (maybe mypyc as well), and consider rust where it makes sense. Thanks!",
            "I have not really. Just took a glance and it does seem promising, thanks for the tip. Is it relatively easy to mix compiled and uncompiled modules in the same package?",
            "I write \"standard\" python and once it is working, I get ChatGPT to rewrite the code using type checks. I then retest everything. Best of both worlds! I don't do it for bugs, I do it for the next person who has to read the code.",
            "I still run \\`safety\\` at the python level and trivy at the container level. Mypy + ruff + pytest are the only tools I run in the inner-loop at the IDE level. Even if ruff could replicate the functionality, it doesn't have the database of CVEs.",
            "You can just do select \u201cALL\u201d and ignore one of the ones which are incompatible and any you don\u2019t care about",
            "I know you're kind of joking for the rust memes, but unironically I'd take rust experience for my resume over cython.",
            "Well I guess to start with, the build system now differs from python since [setup.py](http://setup.py) is deprecated, and at least in our case was a lot more complicated than building it should have been. It's a lot less community supported than any of it's equivalents so when something inevitably goes wrong with it's build chain it's difficult to find resolutions. I also encountered issues with caching of the compiled files when attempting to resolve bugs, making it unclear if code changes were being used or older cached versions.\n\nThe particular setup we had was  \nmain\\_python\\_library  \n-> imports cython\\_sub\\_library\n\nBoth packaged and published to pypi, the packaging of which for cython did have hiccups a lot of the time but I can't remember too much about what they were as I didn't normally handle it, I think something to do with cross compiling wheels. Debugging though was another issue, I'm sure there was a solution but we never could get it playing nicely with gdb in the limited timeframes we had. We only ever dealt with this library when it broke. Testing, it is possible to get pytest to discover cython code but is a bit of a faff. I rewrote a small portion of the library in rust + pyo3 + tests and took a colleague through setting it up and was a much smoother experience imo while also leading to much cleaner code for the algorithm implemented.",
            "What rough edges have you encountered? Were you trying to use python in rust code? I've never done that aspect personally, I've only compiled rust code for use in python, but I could see how using numpy or something inside rust via py03/maturin would be difficult.\n\nI actually did use scientific libraries for rust (ndarray + rust\\_numpy) so that my rust library typing when imported to python were numpy arrays for inputs/outputs, IIRC it did require a bit of fiddling to get that typing right but wasn't any more an issue than it normally is. At least for me anyway, I always have to relearn numpy's flavour of arrays anytime it comes into play because I'm an infrequent user, so didn't particularly chalk it down to py03/maturin.",
            "Sorry, I meant to reply with basically this. Normally you don't want to select ALL, because as ruff updates you get new rules, and you don't want your build to break because of a change that wasn't intentional on your part. To solve this I pin the version of ruff the same way I do all my dependencies, then I select \"ALL\" rules. Normally I ignore D100 through D107 because I hate mandatory docstrings. You also need to selectively ignore S101 if you are using pytest. The rest is to taste.",
            "Oh I agree!",
            "Yeah, we had some stringent requirements around performance that we needed to mitigate and that meant inter-operating with existing code that uses numpy + scipy so it was a hard requirement for numpy arrays to be the underlying data type, both as inputs and outputs, which meant a descent amount of messing around with pythons heap from rust.\u00a0",
            "That does sound like a bit of a nightmare, but also like it would be a nightmare regardless of tech stack. Did you try it in cython as well? How did the experience compare?"
        ]
    },
    "PyODMongo an ODM for MongoDB": {
        "title": "PyODMongo an ODM for MongoDB",
        "score": 7,
        "url": "https://www.reddit.com/r/Python/comments/1d7mhrr/pyodmongo_an_odm_for_mongodb/",
        "content": "- What My Project Does:\nPyODMongo is a modern Python library that serves as a robust Object-Document Mapper (ODM) and seamlessly bridges the gap between Python and MongoDB. It offers an intuitive and efficient way to interact with documents.\n\nBuilt on top of Pydantic V2, PyODMongo ensures that documents in the database rigorously represent the structure of Python objects. This means that documents are saved and retrieved from the database exactly as a Python object is structured, regardless of how nested the objects are and whether they are stored persistently or by reference. PyODMongo can automatically populate these documents.\n\n- Target Audience:\nBackend developers who want a simple and efficient way to work with MongoDB\n\n- Comparison:\nODMantic ODM\n\n[GitHub repository](https://github.com/mauro-andre/pyodmongo)\n[PyPi](https://pypi.org/project/pyodmongo/)\n",
        "num_comments": 4,
        "comments": [
            "Awesome! I love the combination of Pydantic and Mongo, it's something I also use a lot but not with a dedicated package for it.\n\nI wonder though, why has the `Field` been redefined here: [https://github.com/mauro-andre/pyodmongo/blob/master/pyodmongo/models/fields.py](https://github.com/mauro-andre/pyodmongo/blob/master/pyodmongo/models/fields.py) ? This is mostly the Field object from Pydantic, but I don't see where it differs.\n\nAlso, I enjoy learning packages like this by going through the source code and building documentation for it. Would you be open to a PR that adds a readthedocs-type documentation page, with Sphinx and Github Pages?",
            "Oh, I just found you already have documentation [https://pyodmongo.dev/](https://pyodmongo.dev/) which already looks great! Nice job",
            "Hi.\nIn fact I simplified the `Field` function. I simply inject the indexes creation parameters `index`, `unique`, `text_index` and `default_language`.\nAs for documentation, I would be very happy for your collaboration, I already use mkdocs. https://pyodmongo.dev/",
            "Thanks. I hope you enjoy it and feel free for collaborate"
        ]
    },
    "Tutorial on Surprisingly Simple Python Streamlit Dashboards": {
        "title": "Tutorial on Surprisingly Simple Python Streamlit Dashboards",
        "score": 62,
        "url": "https://www.reddit.com/r/Python/comments/1d73q7e/tutorial_on_surprisingly_simple_python_streamlit/",
        "content": "Streamlit\u00a0is becoming an increasingly a popular framework for data visualization prototyping with Python. The\u00a0Streamlit\u00a0framework saves time, effort, and reduces the complexity traditionally associated with crafting maps and charts.Particularly if we approach application development with a modular approach.\n\nStarting simple, let\u2019s put together 4 specific examples that leverage\u00a0Streamlit\u00a0for interactive data visualization:\n\n   1. A global choropleth map for a dataset for a specific year.\n   2. An animated global choropleth map for a dataset across a number of years\n   3. An animated choropleth map for a specific region\n   4. A line chart to provide an alternative representation of the data\n\nLink to tutorial [HERE](https://johnloewen.substack.com/p/see-who-is-happier-with-surprisingly)",
        "num_comments": 20,
        "comments": [
            "full ossified busy instinctive wrench observation spoon disagreeable repeat door\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
            "Streamlit has two major issues that have to be worked around to work in a production environment. First is auth. Second is design. Streamlit is very prescriptive and inflexible in how they roll out layout.\n\nAs a last part, custom components are okay but pretty limited",
            "I have my issues with streamlit, but nevertheless the tutorial is amazing.",
            "My company uses streamlit extensively in production apps. We're replacing excel reporting with streamlit and it's a game changer.",
            "Agree - 100%  Have you tried Anvil at all? \n\nThanks for the comments",
            "Agreed - It's great for prototyping and data exploration - and very limited in customization. Any variance from the standard interface and you have to start applying your CSS skills.\n\nThank you for the comments.",
            "Is there a good alternative?",
            "joke party apparatus lip handle books amusing squeeze aware cooperative\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
            "Me too. It's great for prototyping - and for learning how to visualize data. \n\nAnd thanks for the props. It's a lot of fun putting these tutorials together.",
            "That's awesome to hear. Can you give an example use case where it works best for your company?",
            "Not too many in Python. I see an occasional alpha version show up that shows promise here and on HN.",
            "I like Panel. But I would like to hear from any one else on their comparison.",
            "Gradio is pretty good",
            "Im working on an open source framework called [Mercury](https://github.com/mljar/mercury) that can serve python notebooks as web applications. It has auth built in, and you dont need to rewrite your notebook to share it with non technical users. I also created commercial service for [one click deployments of python notebooks](https://runmercury.com).",
            "ruthless march special deranged sharp divide straight pen whistle familiar\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
            "What's HN?",
            "Panel is pretty great.",
            "Indeed. It seems to face some of the same challenges. I haven't dug into their app for awhile, so perhaps they have focused on resolving them!\n\nOne low-hanging fruit that is really bad with Streamlit is their accessibility treatment. No control some core tags on the JS layer.",
            "Hacker News - news.ycombinator.com",
            "Thanks!"
        ]
    },
    "Self updating spreadsheet with popular questions from Ask Reddit and summarized answers using OpenAI": {
        "title": "Self updating spreadsheet with popular questions from Ask Reddit and summarized answers using OpenAI",
        "score": 7,
        "url": "https://www.reddit.com/r/Python/comments/1d7fatn/self_updating_spreadsheet_with_popular_questions/",
        "content": "**What My Project Does**  \nThis is a small Python script that runs inside a Google Sheet by way of\u00a0[the Python add-on](https://workspace.google.com/marketplace/app/neptyne_python_for_sheets/891309878867). It uses the\u00a0[reddit api](https://www.reddit.com/dev/api/)\u00a0to fetch posts from\u00a0[Ask Reddit](https://www.reddit.com/r/AskReddit/)\u00a0twice daily. For posts with enough upvotes, it uses the\u00a0[OpenAI API](https://platform.openai.com/docs/overview)\u00a0to summarize an answer to the question based on the comments. I then inserts any new questions and their answers into the spreadsheet and uses the\u00a0[Twitter API](https://developer.x.com/en/docs/twitter-api)to also post the answer to Twitter I mean X. Should be interesting to anybody looking to connect (a subset) of those APIs.\n\n**Target Audience**  \nAnybody who is looking to mash-up different APIs (Python is great at this and I feel like it is getting a little harder to do this every year).\n\n**Comparison**  \nI'm not aware of any Python code that does this. Even finding a good example of the V2 twitter API is harder than it seems. To accomplish some of this, you could try to ask ChatGPT directly to summarize the answers for a url but when I tried it said it couldn't access Reddit.\n\n**Resource** \n\n* The\u00a0[spreadsheet where this happens](https://docs.google.com/spreadsheets/d/1YXXBW_B6DeKVJQHGjowf1AJr9s6_yYItPcvDlChf9YM/edit#gid=0)\n* The\u00a0[twitter bot](https://x.com/reddit_answers)\u00a0in action\n* The\u00a0[source code](https://github.com/neptyneco/codesamples/blob/master/ask_reddit.py)\u00a0(or make a copy of the spreadsheet to see)\n\n  \n",
        "num_comments": 5,
        "comments": [
            "Neat idea! How do you like the results?\n\nI'm curious why you went with Google Sheets and what else you considered.",
            "Your reddit client and secret are in the source code fyi",
            "Thanks! I think the results are really kinda nice to browse; it's early days but it does give you an idea of the answers and if you like something you can always click through.\n\nGoogle Sheets seems like a good way to share results like this. The alternative is spinning up your own website; maybe something like streamlit would be doable but you'd still need a database however light. So this feels like a good compromise",
            "Oops. Thanks",
            "Fixed"
        ]
    },
    "1BRC solution using CPython": {
        "title": "1BRC solution using CPython",
        "score": 2,
        "url": "https://www.reddit.com/r/Python/comments/1d6uqc4/1brc_solution_using_cpython/",
        "content": "**What My Project Does:**\n\nI finally got some time to attempt the 1 Billion Row Challenge (1BRC) (https://www.morling.dev/blog/one-billion-row-challenge/) where we are supposed to process a file with 1 billion records of temperature values for cities and print a sorted list with min, max and mean temperature per city.\n\nI am a sucker for optimization. So when I heard about 1BRC I got intrigued and in the last few days started experimenting with python implementations. I achieved my goal and implemented the fastest implementation running on CPython, without any external libraries. My motivation for CPython was so that I can apply any of the learning's in my day to day work, as I don't see us moving to PyPy any time sooner.\n\nYou can check out the performance numbers and implementation at : [https://github.com/pappuks/1brc](https://github.com/pappuks/1brc)\n\nFew learning's:\n\n* Python Multiprocessing is very powerful in enabling multi core processing and overcoming GIL bottleneck for multi-threading. Using \\`Pool.starmap\\` is the easiest way to spawn child processes and collect response.\n* AI code generation can help you jump start your implementation, but it will most likely be sub-optimal and you need to spend time in optimizing the code by understanding the core logic.\n* PyPy gives good boost over CPython but compatibility of PyPy with external libraries is a limiting factor.\n* Mypyc compilation was not any faster than default CPython implementation. Always measure after making the change.\n* Optimizing for PyPy does not make the implementation any faster in CPython, but optimizing for CPython does make the implementation faster in PyPy.\n\n**Target Audience:**\n\nThis is a hobby project, but most of the findings and learning can be applied to production projects as well. And given that all optimizations are done on CPython its applicability to production is easy.\n\n**Comparison:**\n\nThis is the fastest CPython implementation for solving the 1BRC problem. The detailed comparison is provided in the above github repository.\n\n|Interpreter|File|Time (sec)|\n|:-|:-|:-|\n|Python3|py\\_1brc\\_final.py|24.882|\n|Python3|py\\_1brc\\_mypyc.py (process\\_chunk.py precompiled using mypyc)|24.441|\n|Python3|[calculateAverage.py](http://calculateAverage.py) (from https://github.com/ifnesi/1brc)|36.303|\n|Python3|[calculateAveragePyPy.py](http://calculateAveragePyPy.py) (from https://github.com/ifnesi/1brc)|60.60|\n|Python3|doug\\_booty4.py (from https://github.com/dougmercer-yt/1brc)|62.91|",
        "num_comments": 4,
        "comments": [
            "I was looking through the repo, where did you get the 1brc.txt file to operate on?",
            "You can follow the instructions from [https://github.com/ifnesi/1brc?tab=readme-ov-file#creating-the-measurements-file-with-1b-rows](https://github.com/ifnesi/1brc?tab=readme-ov-file#creating-the-measurements-file-with-1b-rows) . I have updated the readme file in my repository as well.",
            "thanks, apprreciate it! I might try out the challenge as well."
        ]
    },
    "Community Insights on PgQueuer": {
        "title": "Community Insights on PgQueuer",
        "score": 14,
        "url": "https://www.reddit.com/r/Python/comments/1d6csmw/community_insights_on_pgqueuer/",
        "content": "Hey r/Python!\n\n[A while ago](https://www.reddit.com/r/Python/comments/1ckrmog/introducing_pgqueuer_a_minimalist_python_job/), I introduced you to [PgQueuer](https://github.com/janbjorge/PgQueuer), a Python library designed for handling job queues using Postgres native functionalities. If you've started using PgQueuer, I\u2019m keen to initiate a discussion on your experiences with it.\n\n* How and where have you integrated PgQueuer into your projects?\n* Any difficulties or shortcomings you\u2019ve experienced while using PgQueuer?\n* Thoughts on the library\u2019s efficiency and features?",
        "num_comments": 5,
        "comments": [
            "First time i've heard about this library, I actually homerolled something using the same stuff (skip locked ect) at my last role.\n\nI'll give it a go! Typing seems nice just from a quick glance, performance/safety I'll have to evaluate.",
            "How does this library handle fail states? I see you're using LISTEN/NOTIFY, which I assume means it's possible to miss one of those events (due to a crash/lightning strike). Would it recover from these?",
            "It is in my to-do list, but not yet there. Intended use is in my Django application, so I don't have to install a separate work queue manager (I am already using PostgreSQL as the main database).",
            "Thanks for giving PgQueuer a shot! It\u2019s fairly new and still has a low footprint.\n\nLooking forward to your thoughts!",
            "Its backed up by a timeout, every 60seconds it will check the database for jobs. Also, if one (or more) events are \"lost\" the next received event will still trigger a dequeuing loop until the backlog is cleared."
        ]
    },
    "Keep system awake (prevent sleep) using python: wakepy": {
        "title": "Keep system awake (prevent sleep) using python: wakepy",
        "score": 152,
        "url": "https://www.reddit.com/r/Python/comments/1d5ya3k/keep_system_awake_prevent_sleep_using_python/",
        "content": "Hi all,\n\nI had previously a problem that I wanted to run some long running python scripts without being interrupted by the automatic suspend. I did not find a package that would solve the problem, so I decided to create my own. In the design, I have selected non-disruptive methods which do not rely on mouse movement or pressing a button like F15 or alter system settings. Instead, I've chosen methods that use the APIs and executables meant specifically for the purpose. \n\nI've just released wakepy 0.9.0 which supports Windows, macOS, Gnome, KDE and freedesktop.org compliant DEs. \n\nGitHub: https://github.com/fohrloop/wakepy\n\nComparison to other alternatives: typical other solutions rely on moving the mouse using some library or pressing F15. These might cause problems as your mouse will not be as accurate if it moves randomly, and pressing F15 or other key might have side effects on some systems. Other solutions might also prevent screen lock (e.g. wiggling mouse or pressing a button), but wakepy has a mode for just preventing the automatic sleep, which is better for security and advisable if the display is not required.\n\nHope you like it, and I would be happy to hear your thoughts and answer to any questions!",
        "num_comments": 74,
        "comments": [
            "I for one will be positive of your post rather than saying \"The OS can do it\" previous peeps I think are missing the point. What if you have a long running task and you don't want to change OS settings... You just want it to happen while the task is running. Or if you don't have access to these settings. Or this task runs on multiple operating systems and you don't want to manage this for every possible OS under the sun.  Good job =)",
            "Sorry for all the people that neither appreciate solving something with programming nor can imagine the use case of this and thus assume there is none.\u00a0 This is really a neat package for those long running tasks where you want to lock your computer but want to avoid sleep! Thank you, will check it out \ud83d\ude0a\u00a0 \u00a0\n\n\nEdit: to the one replying to this comment then blocking me, its not useless, its just your imagination that is a bit lacking.\u00a0\u00a0\n\n\nEdit2: First you say its useless and now you are saying that there are others app doing the same. Guess that means that it isnt useless, and has a range of use cases then. Nice to have a cross plattform python implementation to integrate into my python scripts.",
            "So simple, but so...important\n\nGood work!",
            "This is perfect, think I\u2019ll implement it in my current project",
            "That's perfect! Thanks for sharing! I've done a small PowerShell script that calls an old non existing key on my keyboard but it's not that clean and I prefer your solution better.\n\nFor those wondering why I need this as \"the os can do it\": at work they enforced a GPO to screenlock computers after 3 min of inactivity... And even with admin rights we can't change it as it's always restored automatically.",
            "Cool! I personally use a bash script that calls systemd-inhibit, but of course that's not a cross platform solution. Is it possible to add a mode that blocks sleep and screen locking but not screen idle? That tends to be my default use case (maybe you could call it -o,  --keep-open complimenting --keep-running and --presentation)",
            "This is rad and looks so much better than my current method of opening a new terminal, running ps to find the pid of the process I want to keep awake for, and running caffeinate -w <pid>.  On Mac btw.\n\nGonna check this out!",
            "This is exactly what I need thank you!",
            "I was really looking forward to something like this. Currently, I was using a simple script with pyautogui to move the mouse, but sometimes it would just stop working. Thanks for developing something like this!",
            "Awesome. I haven\u2019t tested it yet. But if it works it\u2019s super useful. On windows 11 \u201cPresentationSettings.exe /start\u201d doesn\u2019t stop windows from locking on a company laptop anymore. And even on windows 10 no amount of changing system settings would prevent sleep when the screen is switched off. Stupid group policies preventing you from getting work done.\u00a0EDIT: Works great! I wonder why the Windows builtin one stopped working...",
            "Isn't this just an OS setting? You likely can set your screens to turn off without ever letting the system go to sleep.\n\nEdit: I had a few conversations based on what I wrote here, and wanted to paste my thoughts for more visibility. \n\n>I'll say this explicitly for posterity: I admit that there is a use-case here, that this has a small set of people that can use it to do what they want. I will also celebrate that the author took the time to create the repo, do the legwork of building something that works, and publishing it for the world to see. That takes effort, and it shows a level of ability that means something. I can also see that the author has been on-and-off working on this repo for a few years, which also means something. I mainly left my comment to invite the author to explain what the benefit of using their module is, over just changing the OS setting and forgetting about it. It's not something that I found in their README.",
            "Very nice but I'm already using the Jiggler python app. That one has various options for preventing suspend but the least intrusive is just having it press Shift every 30 or so seconds.",
            "I implemented that feature in one of my apps. See https://github.com/EricTerrell/SyncAndVerify/blob/main/PowerManagement.py.",
            "This is dope, will try it out. You've handled all the criticism pretty well in this thread",
            "If you have mac, it\u2019s called caffeinate",
            "Most operating systems already do this and/or have third party options that are much easier for users to use than running their own python code.",
            "You can also just play a long YouTube video, no need to access settings and keeps everything awake indefinitely. Bonus: it keeps you online (but away) indefinitely on Teams too ;)",
            "Ummm check out the free app Amphetamine in the App Store for this!",
            "Agreed, so many are overlooking sys admins preventing or locking them out of OS settings because it\u2019s a managed device. Not to mention sanctioned software installs of 3rd party software on organization hardware.",
            "Agreed. I'm assuming you can just add this to your app and have the system stay awake while running it.\u00a0",
            "Agreed! 'oh OS can just do it' , well yes but my machine is set up how I like it, I don't want to be constantly toggling those settings when I have long running analyses or training jobs. This is neat, thanks OP.\n\n\nAlso a CONTEXT MANAGER FOR USE WITHIN YOUR PYTHON CODE, that's incredibly handy, more so than caffeine.",
            "Amphetamine is what I use when I need to keep my system awake when im running a long process. Just select a time range or just indefinite and it doesn\u2019t let your pc sleep.",
            "You are right, but also os can do it. On unix like there is caffeinate, which can for example keep the os awake while a specific task/pid is alive.",
            "Holy shit \"you can do it manually\" is the worst response to any program. Imagine wanting to fiddle around in the settings when it can just happen automatically when you need it to.",
            "https://alternativeto.net/software/amphetamine/",
            "I'm actually just grateful for also the comments saying it's useless as they seem to ignite a bit more discussion here which gives this post and wakepy a bit more visibility. So, just great thank you for all the opponents and u/runawayasfastasucan and others defending it's usefulness \ud83d\ude4f\n\nThe heart of wakepy is really the Python API which is cross-platform and meant for application, library or script developers which just want their system to prevent suspend for the duration of some task automatically. On mac there's caffeinate for CLI usage which I would use if I was working on a mac. On other systems there are other alternatives, but the CLI tool in wakepy is just an additional nicety on top of the Python API.\n\nWakepy documentation is also one of the rare places on the Internet documenting all (or: many; the list is not complete yet) the [different methods](https://wakepy.readthedocs.io/stable/methods-reference.html) for inhibiting suspend / idle.",
            "I\u2019ve been noticing that whenever I read posts in this sub. Lots of inexperienced \u201cdevs\u201d voicing their opinions on topics they know little about. Probably a side effect of Python being so widely used by non-programmers?",
            "There is no use case. The OS already handles this.\n\nEdit: No, it's still useless. This is already a setting in your OS and there are lots of proper apps that will do it too.\n\nEdit 2: Down vote all you want, it won't change anything. Facts don't care about your feelings. https://alternativeto.net/software/amphetamine/",
            "Let me clarify that you would like to see a mode which would block automatic screenlock and automatic suspend, but let the system automatically close the display or start a screensaver? That's an interesting idea! What would be the use case for this? Is it to run some script home (=no screenlock needed) on a laptop, and to switch off the display automatically when you're not sitting in front of it anymore..? Yeah the name could be [keep.open](http://keep.open) or even keep.unlocked, or it could be an additional argument to keep.running, like inhibit\\_screenlock=True.  I created [wakepy/#334](https://github.com/fohrloop/wakepy/issues/334) for this. Please feel free to comment or contribute there as well :) I also created [wakepy/#335](https://github.com/fohrloop/wakepy/issues/335) to consider the systemd-inhibit method to add even wider support.",
            "I'm happy to hear there was demand for a keepawake python library!",
            "Thanks! I would be surprised if it would not work on your windows 11 company laptop. But let us know anyway when you've tested :)",
            "Not if you have a work issued laptop with group policies and no admin rights. Among many other reasons and circumstances where this can be useful.",
            "Thank you u/TheLargeCactus for the question. One of the main points of wakepy is to make this suspend/idle action inhibition automatic part of a script, app or even a library. Imagine you're building some video encoder or machine learning app with python. You would not want to ask the users of your app to go to manually change their system settings for the duration of the long running task. That is something the app should either do automatically (like: YouTube and VLC do), or something that users of an app should be able to do with click of a button in the app.\n\nIt would be also possible to create the first(?) fully cross-platform \"caffeinate\"  or \"amphetamine\" GUI application by using wakepy in the core. While I could personally just use the caffeinate CLI tool on macOS, I regularly install wakepy with pip to have the same functionality on Linux & Windows. And of course this is targeted for python developers as it's installed with pip, although I could consider adding built binaries to the GitHub Releases some day.",
            "Yes, why on earth do anything automatic by using programming when you can just to it manually! /s",
            "under power plan settings in windows",
            "If it presses shift periodically isn't there a possibility that you accidentally hit a wrong keyboard shortcut, like SHIFT+DELETE (remove file permanently without putting it into Trash) instead of DELETE (put a file into trash)..?",
            "Okay so you've used the SetThreadExecutionState function to prevent automatic suspend on Windows in a folder sync app.  I see that keeping the system awake has pretty different use cases. :)",
            "Yes it's that simple on mac! That's what wakepy also calls internally on macOS.",
            "This is a python sub not a operating system user sub.\u00a0\n\n\nEdit: its only useless if you can't run code and rather want to do things manually.\u00a0",
            "This is a library for python library/app developers. So while playing YouTube keeps your own screen awake, a python package could (or should) not automatically start playing a YouTube video :) In addition, playing YouTube also keeps your screen awake. Let's say you have a long running process training a machine learning model. In this case it's probably better that the automatic screenlock/screen blank is not disabled.",
            "My work computer blocks YouTube",
            "Which of these can I use in a Python script without requiring users to install extra software?",
            "No answer? But you seemed so confident.",
            "So if I want to ensure that the machine keeps awake while I run my machine learning model, I should go to the OS settings, change to never sleep, run my program, and then change back to my preferred default power setting every time instead of just using this in the code?",
            "My work PC prevents me from modifying the setting for some stupid reason",
            "\n>Let me clarify that you would like to see a mode which would block automatic screenlock and automatic suspend, but let the system automatically close the display or start a screensaver?\n\nPretty much yeah! Personally it would just be for completeness, as this is how systemd-inhibit operates. But I could see it being useful in cases when say I'm running a long operation that I want to check on every so often but the display output isn't important otherwise. Or if the display isn't needed but keyboard and mouse input could be disruptive (though in those cases the keyboard is probably keeping the system awake anyway).",
            "I haven't encountered any group policy that disables access to the power options. I do know that the policy exists, but never seen it applied to employee systems in that manner. That would be more appropriate on something like a shared system IMO. Generally, workplaces grant full admin rights to devs anyway because there are lots of tools that already need admin access. IT limiting devs in this way seems overly restrictive for the people who are generally already power users.",
            "Yeah that is correct and you may set to never! So your PC never will go to sleep or so",
            "That doesn't change the fact that this is useless.\n\nEdit: No, it's still useless even if you can run code.",
            "For my job we run everything in hadoop cloud inside of a partition with admin screenlock settings on the main computer, so a program like this couldn\u2019t keep my computer running (and tbf neither would OS settings). Playing a simple youtube video is the only thing that works for me, but you make a good point that if there\u2019s an alternative it would be much better to not have to have the screen on all the time. \n\nAlso, fwiw, great work OP - it might not work for my use case but its still way more impressive than anything open source ive made for the community :D",
            "Seems like we may have opposite use cases then and you should check out this tool!",
            "Ok, thank you for the idea and the clarification! I say it's a definite maybe :) If it's easy enough to be implemented cross-platform and easy enough to make it clear to the user how the different special cases are handled, like: The inhibition of idle was successful, but closing display was not successful; should wakepy just raise Exception or should it go ahead and use the presentation mode as a fallback. And how to give arguments for on\\_fail action of the fallback mode, etc. :D",
            "You are just a sane person, yes. But not everyone is.",
            "Well since you havent seen it it cant exist.\n\n\nWhat if you just don't want to remember to change your settings every time you have a long time running process though?",
            "What if you want it to to to sleep just not when a certain program is running.",
            "The largest target user group of wakepy is python application/library/script developers which are sharing their work with someone else. So while you may always change the settings manually, it's not the best UX to ask the users of your app/library/script to do the same. And I am that lazy I've wanted to use wakepy just for my own scripts :)",
            "Yes, I can also manually do other things, or I can write a py script to do it. Wonder which one I\u2019d prefer, given we\u2019re in r/python?",
            "Thanks u/MocketPonsterr :) I am curious why you think the wakely CLI could not keep your computer running, but a youtube video can.. Could you explain why?",
            "No problem! I just ran a test on my KDE desktop by the way and the current functionality seems not to lock the screen anyway...",
            "I mean, fair. But since this is a Python module, it's safe to say that it will be used by individuals that have some programming knowledge, and those individuals are, more often than not, trusted to use their systems as an admin. The reply above talks about a system that sounds pretty locked down, but then it leaves me wondering how a system like that has Python installed",
            "If I was a windows user in this hypothetical, I would use some kind of orchestration system that keeps my system running while a task is executing, likely with better support. Or even better, if it's something that is long running, it should be offloaded to a remote system that won't be interrupted under normal circumstances.",
            "We cant download or install anything on our computers at all, so i can\u2019t even run any python code unless its in the cloud on a partition. Any code that includes a \u2018stay awake\u2019 function only works on the partition, and the actual laptop presets still make the whole computer go to sleep no matter what I\u2019m doing in my code. Its a safety mechanism ensuring nothing can touch the native computer. Running code in my partition while simultaneously running a youtube video on my actual computer outside of the partition gets around this. \n\nI think this is probably pretty rare in the industry outside of top secret or federally regulated data, so maybe im such a small portion of the population that i could have just kept my mouth shut and let everyone else enjoy your cool work haha\n\nSeriously, no shade, this is a great idea. And for anyone saying you can change this on and off in system settings: sure but the ONE time you forget and come back to find 15 hours of work just never ran, you will hard regret not just having a simple line in your import packages chunk that you always copy paste doing this for you!",
            "What are you referring with the \"current functionality\" ? And which version of KDE Plasma you're using?",
            "You can install Python without admin rights. I was also surprised.\n\nI was issued a temporary work laptop while my own was in repairs. Its locked down, any operation that requires admin rights involves going through Jira and support team. And they even said they cant turn off screen locking just for my laptop because its group policy and is synced or something, I dont even.\n\nAnd since I was using KVM to switch between this work laptop and my personal older one I was constantly locking, was very frustrating.\n\nI was surprised to learn that you can install Python without admin rights. Used it to write a script that prevents Windows from locking. \n\nAnd since it had ctypes, pip and all... pretty sure it can do a lot of things to overcome the lockdown, possibly even get admin rights somehow, but I didnt dig deeper.\n\nI mean if I really planned to use this laptop for more than a month I'd just replace the ssd with my own, thankfully they did not think about adding any tamper stickers.",
            "Sounds like a lot of work instead of just dropping in this library in your code.\u00a0",
            "Using a portable python distribution would make it work without installation., but that surely is a blocker if you cannot \\_download\\_ anything. I have been asked by email if it would be possible to make wakepy running on a Jupyter Notebook on a server to keep awake the system which has browser open with the Notebook ([wakepy/#195](https://github.com/fohrloop/wakepy/issues/195)). I'm not sure yet if that's technically possible. That could help you if you had your work in Notebooks, but that's probably not the case. \n\nAnd yep, I have also forgot the change the settings and came back in the morning to see that the script has ran for about 10 minutes instead of the whole night. :D",
            "I'm using KDE Plasma 5.27.11 on Kubuntu 24.04\n\nI mean that when I run `wakepy -k` and leave my computer idle it shuts off the display as intended but the lock screen is blocked; i.e. it behaves how my proposed `-o` mode works instead of how `-k` is advertised to work",
            "I'll say this explicitly for posterity: I admit that there is a use-case here, that this has a small set of people that can use it to do what they want. I will also celebrate that the author took the time to create the repo, do the legwork of building something that works, and publishing it for the world to see. That takes effort, and it shows a level of ability that means something. I can also see that the author has been on-and-off working on this repo for a few years, which also means something. I mainly left my comment to invite the author to explain what the benefit of using their module is, over just changing the OS setting and forgetting about it. It's not something that I found in their README.",
            "A jupyter notebook version of this actually would be sooo clutch \u2014 I will be following you to see what else you come up with!!",
            "I did test this on KDE Plasma 5.27.9 on openSUSE 15.5 and the [keep.running mode](https://wakepy.readthedocs.io/stable/modes.html#keep-running-mode) was working as expected. Of course there might be differences since the setup is not exactly the same, but before that could you confirm which settings you had for the screenlock timer? When I tested it I only set the power settings down to 1 minute, but forgot screenlock timer to 5 (or even 15 minutes) so I experienced the same. If that does not resolve the issue I'll create a bug ticket since it really should not prevent screenlock if not asked to.",
            "Its not really a small set of people that switches environments, its a pain to constantly remember to check the power settings. Also if you make applications used by others that need to keep the computer from sleeping this is really handy. There is a couple of super popular Mac apps for this, showing that it is indeed usefull.",
            "Yeah, fair enough.\n\nOne more usecase is creating an app or script that required computer to stay on\\unlocked\\preve ting updates, and its a script that will be used by many people. Cant go around telling everyone to change their settings so...\n\nIts actually something used by many apps.",
            "Okay I think my screen lock settings are in fact the \"problem\" (not so much a problem for me because it's WAII). I don't currently have a screen lock timer partly due to [this bug](https://bugs.kde.org/show_bug.cgi?id=475142) that happens when the screen lock is activated twice in quick succession, rather I have it set so the screen is locked automatically only \"After waking from sleep\". In most cases, this works as one would expect so that sleep and screen locking are coupled, as is the default on most other platforms. However the *after* is important here: The auto screen locking only runs after waking from sleep, so the only way that the screen can lock automatically is by going to sleep. Thus blocking sleep also blocks screen locking necessarily.\n\nI realize now that this setting means that all tools that block sleep necessarily block screen locking on my system because of this setting. So I'm not actually sure what `systemd-inhibit` does if the user has a lock timer that locks the screen before the system goes to sleep.\n\nAll that said, I think the proposed `-o` could still be useful! Especially for those with screen lock timers that activate before the automatic sleep. I wonder though: What's the situation like on other platforms?",
            "Okay so in short your system only locks screen if (1) returning from sleep or (2) screen lock timer is set, and since wakepy keep.running mode disables sleep (1) cannot occur, and since you have disabled the automatic screen lock, it won't ever lock your screen. Good to hear. Seems that the keep.running mode is working as expected, and thanks for taking the time to respond.\n\nIf you're interested in other systems, on Windows it only locks screen if (1) returning from sleep (if enabled) or (2) returning from screensaver \\_and\\_ if *ScreenSaverIsSecure is se*t (\"On resume, display log-on screen\" in the settings or enforced with GPO). So also on Windows it's possible that the screen is not automatically locked in the keep.running mode (details in [wakepy/#169](https://github.com/fohrloop/wakepy/issues/169)). I'm not yet sure how to tackle this and make it possible for users to either not enter the mode, or display a warning, or provide some function to lock screen automatically (from the python process) after some time of idle.\n\nBut good to know that if the #169 is somehow addressed, the solution should take into account KDE Plasma on Kubuntu."
        ]
    },
    "PDF Reports for SonarQube Analysis ( Community Edition ) ": {
        "title": "PDF Reports for SonarQube Analysis ( Community Edition ) ",
        "score": 28,
        "url": "https://www.reddit.com/r/Python/comments/1d5j23c/pdf_reports_for_sonarqube_analysis_community/",
        "content": "\n**Problem Statement**\n\nI recently explored SonarQube for static code analysis. While it\u2019s a great tool, the free edition lacks the ability to generate PDF reports, making it hard to share issues. There was no maintained plugin available, so I decided to solve this problem myself.\n\n**Target Audience**\n\nThis started as a hobby/side project, but I wanted to share it in case others find it useful. I'm open to suggestions and feedback!\n\n**Comparison with Similar Tools**\n\nThere was only one similar tool in the Sonar Marketplace, but it\u2019s no longer maintained.\n\n**Project Details**\n\nI've developed and published a Python library called RedCoffee, which generates PDF reports from SonarQube analysis. You can find it on PyPi and GitHub.\n\n**Links:**\n\n- **PyPi:** [RedCoffee](https://pypi.org/project/redcoffee/)\n- **GitHub:** [RedCoffee Repository](https://github.com/Anubhav9/RedCoffee)\n\nFeel free to check it out and let me know your thoughts!",
        "num_comments": 1,
        "comments": [
            "Looks like a useful tool. I have created a sonarqube CLI, cheekily called \"sonarless\" to enable developers for scanning without need to have headache of setting up a server. For my \"report\", I just give the developer a json so that they can monitor the progress and use it for some check.\n\n[https://github.com/gitricko/sonarless](https://github.com/gitricko/sonarless)\n\nI will check out your python code to see what reports it gives... ideally, I was thinking about how difficult to give a html clickable report so that they can do into details of the code in question for more detail analysis without sonar server hosted"
        ]
    },
    "ReqFlow - Simplifying API Testing with Python": {
        "title": "ReqFlow - Simplifying API Testing with Python",
        "score": 15,
        "url": "https://www.reddit.com/r/Python/comments/1d5k2ty/reqflow_simplifying_api_testing_with_python/",
        "content": "Hello everyone! \n\n# What My Project Does\n\nI'm excited to share `ReqFlow` - a Python library designed to make API testing straightforward and efficient. It offers a fluent interface for building and validating HTTP requests, making it a handy tool for small-sized testing frameworks or utilities. While it's still in development and might have some bugs, I would love your feedback and contributions to improve it!\n\n# Target Audience\n\nIt would be suitable for beginners due to its reduced entry barrier and also supports advanced use cases with a RestAssured-like approach. \n\n# Comparison\n\nWhile standard approaches for API testing with Python (e.g., `requests`) definitely makes sense, ReqFlow provides a more fluent and expressive syntax, making it easier to write and understand tests. \n\nCheck it out on [GitHub](https://github.com/olxxi/ReqFlow) and the [docs at reqflow.org](https://reqflow.org/). \n\nAll feedback and contributions are welcome! \ud83d\ude42",
        "num_comments": 4,
        "comments": [
            "Interesting. I use responses for unit tests and directly client of FastAPI for integration tests.\n\nI don't see directly a good case for unit tests on my scheme for testing, but maybe for integration tests can be a good case.",
            "I looked at the getting started guide. The syntax does not seem Pythonic. It seems more Javascript inspired and reminds of tests I wrote in Postman. What made you choose to go with this style?\n\nIf you create a client object, why is making the request not a method of the client object itself. More importantly, in your examples, the only thing the client object seems to be doing is to hold the base URL. So why can't I just pass the URL to the `given()` function?\n\nI do like how simple you've made setting cookies, auth headers, or even file uploads. Even as an abstraction layer over requests, this does look cool and easier to use.",
            "Definitely makes sense when you have access to the app's code and it\u2019s Python-based. The more straightforward, the better.\n\nAs mentioned, ReqFlow can also be used as a tool for integration tests, especially when you don\u2019t have access to the codebase or if the API is not written in Python.",
            "That\u2019s right, the syntax is not Pythonic. It was done this way to make it as simple and as intuitive as possible for people who starting with Python (e.g. AQA engineers) to lower the entry barrier. The approach itself is similar to Java\u2019s RestAssured framework that widely used for API tests.\n\nRegarding the client usage, yes, it takes a base url and in the same time it\u2019s a container of all the parameters we are setting in method chaining. In the same time, it allow user to have a few distinct requests in one namespace. But it\u2019s a good suggestion to pass the URL in the given method."
        ]
    },
    "NiimPrintX: A desktop app for NiimBot Label Printers developed in Python": {
        "title": "NiimPrintX: A desktop app for NiimBot Label Printers developed in Python",
        "score": 8,
        "url": "https://www.reddit.com/r/Python/comments/1d5lkew/niimprintx_a_desktop_app_for_niimbot_label/",
        "content": "I'm super excited to share NiimPrintX, a desktop app I've been working on for NiimBot label printers. This is my first release, and I am actively working on adding new functionalities.\n\n**What My Project Does:**  \nNiimPrintX offers both a command line and graphical user interface app to connect with your NiimBot printer. It connects via Bluetooth and makes label printing a breeze. The app is developed completely using Python 3.12 and the Tkinter library for the GUI.\n\n**GitHub Repository:** [NiimPrintX](https://github.com/labbots/NiimPrintX)\n\n**Target Audience:**  \nThis project is aimed at hobbyists who use NiimBot label printers. It's a proof of concept project for me to learn GUI app development in Python.\n\n**Comparison:**  \nCurrently, there is no desktop app support for NiimBot thermal label printers. Only the official Android/iOS app is available, and it has limited functionality without a paid subscription. NiimPrintX aims to fill this gap by providing a free, more versatile desktop solution.\n\n**Supported Printer Models:**\n\n* D11/B21/B1\n* D110\n* B18\n\n**Cool Features:**\n\n* **Bluetooth Auto Discovery:** Automatically finds your printer using its model name.\n* **Easy Label Design:** Create labels with a simple and intuitive GUI.\n* **Predefined Icons:** Spice up your labels with built-in icons.\n* **Cross-Platform:** Works on Mac, Windows, and Linux.\n* **Advanced Print Options:** Includes calibration features for perfect prints.\n\n**Coming Soon:**\n\n* **Barcode Creation:** Make your own barcodes right in the app.\n* **QR Code Printing:** Generate and print QR codes.\n* **Better Object Alignment:** More shapes and borders for your designs.\n\n\n\nI'm constantly working on adding new features, so keep an eye out for updates!\n\nCheck out the GitHub repo for more info and installation instructions: [NiimPrintX](https://github.com/labbots/NiimPrintX)\n\nI'd love to hear what you think! Drop a comment or open an issue on GitHub with any feedback or suggestions.",
        "num_comments": 1,
        "comments": []
    },
    "zeroize: Securely clear secrets from memory": {
        "title": "zeroize: Securely clear secrets from memory",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1d620fk/zeroize_securely_clear_secrets_from_memory/",
        "content": "[https://github.com/radumarias/zeroize-python](https://github.com/radumarias/zeroize-python)\n\n\n\n* **What My Project Does:** Clear secrets from memory. Built on stable Rust primitives which guarantee memory is zeroed using an operation will not be 'optimized away' by the compiler.\n* **Target Audience**\u00a0it can be used in production, it's just a simple wrapper over zeroize crate from Rust\n* **Comparison**\u00a0Personally I didn't found an easy and safe solution in Python to do this, hence I created this lib\n\n",
        "num_comments": 20,
        "comments": [
            "Hi there, from the /r/Python mods.\n\nWe want to emphasize that while security-centric programs are fun project spaces to explore we do not recommend that they be treated as a \nsecurity solution unless they\u2019ve been audited by a third party, security professional and the audit is visible for review.\n\nSecurity is not easy. And making project to learn how to manage it is a great idea to learn about the complexity of this world. That said, there\u2019s a difference \nbetween exploring and learning about a topic space, and trusting that a product is secure for sensitive materials in the face of adversaries. \n\nWe hope you enjoy projects like these from a safety conscious perspective. \n\nWarm regards and all the best for your future Pythoneering,\n\n/r/Python moderator team\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Python) if you have any questions or concerns.*",
            "OP has repeatedly advertised his various security related packages in multiple subreddits, e.g.\nhttps://www.reddit.com/r/Python/comments/1d628t4/a_blend_of_rust_and_python_a_faster_encryption/\n\nSeveral of them have been removed by the moderators. As I pointed out on the post above - everyone that is not a cryptography expert should live by \"never roll your own crypto\". I'd rather use a slower standard library version that constantly has to undergo scrutiny or at least one from one of the big players (e.g. Google) instead of using a community library that promises more speed at the cost of potentially compromising my entire product/environment.",
            "I was impressed by presence of the whole ONE test. It really proves that your code can handle different situations with indifference.",
            "Hi there, from the r/Python mods.\n\nWe want to emphasize that while security-centric programs are fun project spaces to explore we do not recommend that they be treated as a security solution unless they\u2019ve been audited by a third party, security professional and the audit is visible for review.\n\nSecurity is not easy. And making project to learn how to manage it is a great idea to learn about the complexity of this world. That said, there\u2019s a difference between exploring and learning about a topic space, and trusting that a product is secure for sensitive materials in the face of adversaries. \n\nWe hope you enjoy projects like these from a safety conscious perspective. \n\nWarm regards and all the best for your future Pythoneering,\n\nr/Python moderator team",
            "Can you please elaborate how this guarantees that the given object's memory is overwritten, taking the various memory managing features of a modern OS into account?\n\n\nThe first thing that popped into my mind: how is it going to handle a copy-on-write fork? My expectations would be that it will remap the memory, where the original area is masked for the process but still exists (without being zeroed).",
            "plan is to add more tests but being such a simple wrapper over a Rust lib the stability is ensured by that lib's tests",
            "https://pandas.pydata.org/docs/dev/user_guide/copy_on_write.html\nAs I understand copy on write happens when one of the variables that shares the same actual memory get changed. In that case, as you already made a \"copy\" to another variable you should zeroize both of them\n\nAnother can be the problem, if the runtime moves the memory like described here https://docs.rs/zeroize/latest/zeroize/#stackheap-zeroing-notes\nFor that in rust there is Pin which ensures the memory of that var is not moved, that is handled in secrecy crate https://crates.io/crates/secrecy and https://crates.io/crates/secrets , maybe a similar wrapper library for that would make sense also\n\n```\nIt is mostly an ergonomic wrapper around the memory-protection utilities provided by libsodium.\n\nFixed-size buffers allocated on the stack gain the following protections:\n\nmlock(2) is called on the underlying memory\nthe underlying memory is zeroed out when no longer in use\nthey are borrowed for their entire lifespan, so cannot be moved\nthey are compared in constant time\nthey are prevented from being printed by Debug\nthey are prevented from being Cloned\n```",
            "you can see here more details from the lib that is used underneath https://docs.rs/zeroize/latest/zeroize/",
            "How do you handle side effects of interaction between Rust and Python? Rust gives you zero protection against side effects. Python gives you zero protection. So, how do you know it works in all situations?",
            "You seem to confuse Copy-on-Write with a Copy-on-Write fork. And that would be just one of the problems that arise from how advanced OS features might interact with the **virtual** memory of a process. \n\nIn any case you have promised to *\"Securely clear secrets from memory.\"* while the sources you referencing are talking in another language e.g. they promise that *\"All subsequent reads to memory will see \u201czeroized\u201d values.\"* which is a very different thing.",
            "what side effects do you mean exactly? I'm using this to interact with Py https://pyo3.rs/v0.21.2/",
            "I agree it doesn't seem to protect against COW fork",
            "I think a correct solution would be to zeroize the arrays before you fork the child process and then you can reload them again when needed, like this it will not end-up in the read-only mem",
            "but is there a way in python to do that? Or it needs to use a C module implementation that uses `mlock()`?",
            "Any ffi is unsafe. Python memory management is unsafe. Python code modifying memory is side effect/cause for rust. You have zero guarantee at intersection of those.",
            "This might sound a bit harsh, but at this point it has to be like this:\n\n\nPlease stop publishing projects where you promise security and have absolutely no background knowledge!",
            "I understand but what exact issues do you see could happen? Given the fact that interaction is handled by that lib",
            "I'm updating the \\`README\\` accordingly",
            "Are you using this library correct? What are your proofs or tests? Trust me, people?",
            "Adding more tests as we speak, indeed even if it's a simple lib wrapper it's best to test it properly"
        ]
    },
    "A blend of Rust and Python: a faster encryption for Python": {
        "title": "A blend of Rust and Python: a faster encryption for Python",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1d628t4/a_blend_of_rust_and_python_a_faster_encryption/",
        "content": "[https://github.com/radumarias/rencrypt-python](https://github.com/radumarias/rencrypt-python)\n\n* **What My Project Does:**\u00a0A Python encryption library implemented in Rust. It supports\u00a0**AEAD**\u00a0with\u00a0**AES-GCM**\u00a0and\u00a0**ChaCha20Poly1305**. It uses\u00a0[ring](https://crates.io/crates/ring)\u00a0to handle encryption. If offers slightly higher speed compared to other Python libs, especially for small chunks of data.\n* **Target Audience**\u00a0This lib hasn't been audited, but it mostly wraps ring crate which is a well known library, so in principle it should offer as similar level of security. This is still under development. Please do not use it with sensitive data just yet.\n* **Comparison**\u00a0If offers slightly higher speed compared to other Python libs, especially for small chunks of data. I compared it to **PyFLocker**,\u00a0 **cryptography**`,`\u00a0**NaCl**\u00a0`(`l**ibsodium**`)`,\u00a0**PyCryptodome**. The API also tries to be easy to use but it's more optimized for speed than usability.",
        "num_comments": 16,
        "comments": [
            "Hi there, from the /r/Python mods.\n\nWe want to emphasize that while security-centric programs are fun project spaces to explore we do not recommend that they be treated as a \nsecurity solution unless they\u2019ve been audited by a third party, security professional and the audit is visible for review.\n\nSecurity is not easy. And making project to learn how to manage it is a great idea to learn about the complexity of this world. That said, there\u2019s a difference \nbetween exploring and learning about a topic space, and trusting that a product is secure for sensitive materials in the face of adversaries. \n\nWe hope you enjoy projects like these from a safety conscious perspective. \n\nWarm regards and all the best for your future Pythoneering,\n\n/r/Python moderator team\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Python) if you have any questions or concerns.*",
            "Btw wrapping a \u201cwell known\u201d library in no way shape or form implies shit about level of security. That\u2019s just straight up not how this works.",
            "Btw, how's the lib being audited? By who? How does it work?",
            "Anything that gets me away from cryptography\u2019s bullshit is welcome",
            "I agree - everyone that is not a cryptography expert should live by \"never roll your own crypto\". I'd rather use a slower standard library version that constantly has to undergo scrutiny or at least one from one of the big players (e.g. Google) instead of using a community library that promises more speed at the cost of potentially compromising my entire product/environment.",
            "it hasn't been audited yet, but planning to do such. The used library on Rust side is a well known one and used in various other audited solutions",
            "you mean the `cryptography` lib from Python? you had some bad experience with it?",
            "So what's the reason of toxicity of some commenters here? Dunno,  \nTbh, I came to this subreddit for the first time ever. Your project seems like an interesting idea, why are they trashtalking?",
            "Obviously he doesn't even know what it is",
            "Their adherence to semantic versioning amounts to \u201cfuck you I won\u2019t do what you tell me\u201d and even within their own versioning they just break shit",
            "As the person that actually requested the current automod response that this post got. The answer is pretty simple. Take a look at what was posted here vs his post in rust. \n\nIn rust he clearly states its a toy project. Here he does not. Further given his git page has a funding part I doubt the intent of this is learning. \n\nHe is wrapping a primitives library not wrapping a fully blown encryption setup, i.e. apple secure enclave libs (may have the wrong name but the highlevel one). Apple already ensures you cannot do anything stupid. The API has no way to do stupid. Its physically impossible at a hardware level to do anything stupid. Wrapping primitives is a path of much suffering. \n\nSee what [Cryptography states on their page about it. ](https://cryptography.io/en/latest/hazmat/primitives/aead/#cryptography.hazmat.primitives.ciphers.aead.ChaCha20Poly1305)\n\n>this module is full of landmines, dragons, and dinosaurs with laser guns.\n\nThat might be underselling it TBH. \n\nFurther Further anytime I see my library is faster than xyz it is a big old red fucking flag in cryptography. Crypto Libs are generally slower to prevent a wide class of issues from timing vulns to other exotic compiler derived fuckery. \n\nI am fairly certain in this case its just because the other libs are using OpenSSL vs BoringSSL. BoringSSL is much smaller and it has better performance on small file parsing as the CPU cache is less impacted by its footprint. \n\nThe idea can be interesting while still being non-viable. Look at the two largest committers to the lib he is using. Both are the two main committers to BoringSSL and work at google.",
            "to be sincere with you I also think comments are a bit harsh, I also posted a similar project in the Rust community https://github.com/radumarias/rencfs but feedback was more productive, if course people are sceptic with security solutions, as it's expected, but the comments can be productive not just \"don't build your own crypto\"\nlike that nobody would learn anything hard \n\nbut yeah, I try to filter and take the constructive content and learn from it\n\nOne is that it motivated me to audit such solutions",
            "This is your project, but the situation got me. Nice subreddit, not a toxic shelter of losers, at all.\n\nNo, my rule is simple, the criticism should be constructive and know limits, and I don't give a flying kite that someone has a poor vocabulary, or living in a trash can, that instead of saying \"A and B have these problems. Can you please explain ....?\" they bark, (because it's not talking, it's barking) \"what a piece of shit!\"\n\nIt's not even sceptic, or any kind of criticism. Just a failed attempt of projection.  \nWish you good luck.",
            "thanks man, help a lot",
            "No probs. If you'll ever meet a bunch of toxics ever again, just tag me, I'll come and rm -rf them. lol.",
            "![gif](emote|free_emotes_pack|feels_good_man)good one"
        ]
    },
    "AI Voice Assistant using on-device LLM, STT, TTS and Wake Word tech": {
        "title": "AI Voice Assistant using on-device LLM, STT, TTS and Wake Word tech",
        "score": 46,
        "url": "https://www.reddit.com/r/Python/comments/1d4y99t/ai_voice_assistant_using_ondevice_llm_stt_tts_and/",
        "content": "**What My Project Does**\n\nAllows you to have a voice-to-voice interaction with an LLM, similar to the ChatGPT app, except with all inference running locally. You can choose from a few different open-weight models.\n\n[Video running Phi-2 model on a MacBook Air with 8GB RAM, all CPU](https://youtu.be/06K_YtUr8mc)\n\n**Target Audience**\n\nDevs looking to experiment with integrating on-device AI into their software.\n\n**Comparison**\n\n* [JARVIS](https://github.com/AlexandreSajus/JARVIS) \\- an all API-based solution using DeepGram, OpenAI and ElevenLabs\n* [Local Talking LLM](https://github.com/vndee/local-talking-llm) \\- a higher-latency, more resource intensive local approach using Whisper, Llama and Bark, but with no wake word.\n\nSource code:\u00a0[https://github.com/Picovoice/pico-cookbook/tree/main/recipes/llm-voice-assistant/python](https://github.com/Picovoice/pico-cookbook/tree/main/recipes/llm-voice-assistant/python)",
        "num_comments": 10,
        "comments": [
            "This looks really interesting! \n\nOpenAI has an option to \"jsonify\" the output. Is your model capable of something similar? \n\nI'm working on a robotics project that would benefit from an LLM integration. I was going to use openAI but if I could get a lightweight solution to run locally it'd probably be a lot better. \n\nOnly requirement: the ability to have it output consistent and valid JSON.",
            "I did something similar a while back but without Wake Word.\n\nMy voice --> whisper --> openai gpt3.5 (4 was too slow at the time) --> coqui TTS cloned to Nicki Minaj. It was kind of fun, laying on the patio, having a beer and talk to Nicki. LOL. Definitely some latency and just not fast enough even using gpt 3.5",
            "I miss Mycroft :(",
            "Great. How long have you been learning about this stuff.",
            "It works with a selection of open-weight models such as Llama, Gemma and Phi-2. I think with Llama you could give it a directive to only respond with JSON, but I'm not sure.",
            "You should look into function calling capabilities. Some [Mistral models](https://docs.mistral.ai/capabilities/function_calling/) have it and I believe there are llama2 fine tunes as well.\n\nIf you really want a JSON output, a trick that has worked well for me is to use a lib that allows you to give the beginning of the answer the model is supposed to give and to give it the \"{\" token as a start.",
            "LOL, love the choice of using the Nicki clone",
            "What happened to it?",
            "Well it doesn't *need* to be JSON. It could be anything, just JSON is easiest to parse IMO. I'll look into function calling, thanks for the link!",
            "[Patent trolls killed them](https://www.theregister.com/2023/02/13/linux_ai_assistant_killed_off/).\n\nBut as I was looking up that link, it looks like they had [a huge win in appeals court](https://legalnewsfeed.com/2024/05/06/mycroft-ai-prevails-as-court-affirms-ptab-invalidation-of-voice-command-patent/) about a month ago! I hope that means development will resume. It's a great open source voice assistant."
        ]
    },
    "Calculator without eval()": {
        "title": "Calculator without eval()",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1d5wz32/calculator_without_eval/",
        "content": "WHAT MY PROJECT DOES:\nSolves basic arithmetic problems in an interactive way in python.\n \nTARGET AUDIENCE:\nAnyone, it's just a program to get practice using loops, lists, and functions.\n\nCOMPARISON:\nThis program functions as a calculator without the use of the eval() function to make everything superfluously easy. It's not perfect and my next version is gonna try and address queries with parenthesis and multiple operators!\n\nSee the below link for github:\nhttps://github.com/Zorgon589/Calculator/tree/main",
        "num_comments": 18,
        "comments": [
            "First things first, make the calculate logic into a function, and separate that from the rest of the code.\n\nYou can run the input loop in another function called from the `if __name__ == '__main__'` block.\n\nRead up on the python style guide in PEP 8.\n\nYou could then make it recursive where, after splitting by operator, call calculate on each part before doing the operation. If there is no operator found, validate that the input was a number and just return it.",
            "Welcome to the world of writing your own interpreter :).\n\nIf you want your calculator to work properly I'd suggest you to follow this video series\n\n\nhttps://youtu.be/TwKWUj033vY\n\n\nIt will teach how how to write an arithmetic parser and offer you an insight on how programming languages understand your code.",
            "You can just use one operator at a time right ? Because if you query \"2+2*2\" it will throw an error since you split on \"*\" and try to float(\"2+2\")",
            "Why do you have `Calculator.py` and  `Calculator V1.2.py`?",
            "I recommend you use ast.parse(). That\u2019s the official method for parsing Python code before it\u2019s executed.\n\nThen you can walk through the tree evaluating each node to come up with the final answer to return to the user.\n\nDocs for ast.parse():\n\nhttps://docs.python.org/3/library/ast.html#ast.parse",
            "Nice work, you have the same project as me, [https://github.com/Lunaluvg/Calculator-without-using-eval-.git](https://github.com/Lunaluvg/Calculator-without-using-eval-.git)",
            "PEP 8, huh? Okay, I'll try looking into that. This was my first project that I tried to do on my own, so it's definitely, uh, ameatur *",
            "Thanks for the info! I'll definitely be doing more research before my version 2",
            "Yeah. Trying to use more than one operator won't work with how I have it here. I'm gonna have to think of something to make it work",
            "So, I have a mentor who's been teaching me to code. Calculator V1.2 is the version where he went over my base code with me and we cleaned it up to be less redundant",
            "That's so cool! I'll have to take a look and compare when I get home tonight.",
            "Look for \"Pratt parser\"",
            "Longer-term goal: Learn git, it will help you in this regard and make it easy to see the evolution of your code.\n\nYou're already on GitHub, you should just commit the changes to the same filename. You can _always_ get old versions back.",
            "Try to manage your versions with Git next time, I know you're still learning to code, but it doesn't hurt to learn how to code and use Git at the same time. It will be easier for you and others to compare and see what changes you made in the new version.",
            "I saw your code, if your understand about array and loop is strong enough you can do this project just by using list and dict {}",
            "Or if that's overkill, you can just do shunting yard",
            "I'll have to look into that. Currently, I'm following along with a tutorial for an interpretor that another commenter recommended. I've had to make changes to fit what I want from it, but it's been teaching me a lot.",
            "that's great, now I'm gonna work with the exponents stuff and take a long nap lol"
        ]
    },
    "A blend of Rust and Python: speeding up Python encryption": {
        "title": "A blend of Rust and Python: speeding up Python encryption",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1d5jt6n/a_blend_of_rust_and_python_speeding_up_python/",
        "content": "[REncrypt](https://github.com/radumarias/rencrypt-python)\n\n\n* **What My Project Does**\nA Python encryption library implemented in Rust. It supports AEAD with AES-GCM and ChaCha20Poly1305. It uses ring to handle encryption.\nIf offers slightly higher speed compared to other Python libs, especially for small chunks of data. The API also tries to be easy to use but it's more optimized for speed than usability.\nSo if you are open to experiment and want to achieve the highest possible encryption speed, consider giving it a try.\n\n* **Target Audience**\nThis is just a toy project as a learning experience\n\n* **Comparison**\nThis is slightly faster than PyFLocker which from my benchmarks is the faster among other Python libs like cryptography, NaCl (libsodium), PyCryptodome",
        "num_comments": 1,
        "comments": []
    },
    "RAGFlow: Deep document understanding RAG engine": {
        "title": "RAGFlow: Deep document understanding RAG engine",
        "score": 34,
        "url": "https://www.reddit.com/r/Python/comments/1d4ou3k/ragflow_deep_document_understanding_rag_engine/",
        "content": "**What My Project Does**\n\nAn open-source RAG (Retrieval-Augmented Generation) engine based on deep document understanding. It offers layout recognition, OCR-based chunking templates for data cleasing and provides hallucination-free answers with traceable citations. Compatible with mainstream LLMs.\n\n**Target Audience**\n\nRAG applications developers.\n\n**Comparison**\n\n* It offers various chunking templates for various fils categories, such as resume, legal documents, table, and print copies.\n* Enables human intervention in chunking, making the data cleansing process no longer a black box.\n* It not only presents answers but also offers quick views of references and links to the citations when answering to queries.\n\n  \n**Link:** [**https://github.com/infiniflow/ragflow**](https://github.com/infiniflow/ragflow)",
        "num_comments": 3,
        "comments": [
            "I've found that a lot of document repositories have metadata tags that are useful to preserve and use with search.\n\nDoes your engine have any place to preserve/track that kind of metadata?",
            "Cool.",
            "Hey u/babygrenade, because RAGFlow is not yet integrated with other document management systems, there is no such place for tracking the metadata. When it is integrated with such a document management, preserving metadata will be required."
        ]
    },
    "Circler imports in Observer design pattern in Python": {
        "title": "Circler imports in Observer design pattern in Python",
        "score": 5,
        "url": "https://www.reddit.com/r/Python/comments/1d50age/circler_imports_in_observer_design_pattern_in/",
        "content": "So I'm trying to do a small refresher in design patterns and I reached the Observer pattern.  \nAnd I'm encounter a circular import error that I'm not sure how to solve.\n\nAt first I had two files: \\`observers.py\\` and \\`subjects.py\\`, which each contained the abstract class and some concrete ones.  \nBut because each  had to know about the other, I got a circler import error.\n\nI tried to put them in the same file, but than the first cant use the second.  \nAlso tried to put the Observer in the \"subjects.py\" file, textualy before \"Subject\", that worked, but not clear to me why.  \nI know that in compiled languages, they just use an interface, but we dont have it in Python.  \nTried to solved it in a various ways, but want to hear others, how you think this can be solved and opinons on this.\n\nThe base classes are:\n\n    class Subject(ABC):\n        \n        @abstractmethod\n        def attach(self, observer: Observer) -> None:\n            # The Observer is in the method parameters, so we need to import it\n            pass\n        \n    class Observer(ABC):\n        \n        @abstractmethod\n        def update(self, subject: Subject) -> None:\n            # The Subjectis in the method parameters, so we need to import it\n            pass",
        "num_comments": 14,
        "comments": [
            "if it\u2019s just for typing, you can do a tying import:\n```\nfrom typing import TYPE_CHECKING\nif TYPE_CHECKING:\n    from module_name import circular_referenced_class\n\n\u2026\n```",
            "Take a look at Forward References from pep 484 https://peps.python.org/pep-0484/#forward-references",
            "Unless I am completely misunderstanding, the word is \"circular\", not \"circler\".\n\nSorry. I'm a former technical writer. \ud83d\ude0b",
            "Just put your abstract classes in their own files.  And python does have the equivalent to interfaces they are called protocols.",
            "Use `from __future__ import annotations` which will allow forward references like this in the same file.",
            "Maybe the solution is to use a mixin-like pattern?",
            "def attach(self, \u201cObserver\u201d)",
            "[deleted]",
            "It had to be said.",
            "tried it. didnt worked.",
            "just add double quotes around the Observer class",
            "I prefer `from __future__ import annotations` so I can still use autocomplete and other editor features.",
            "yeah, it can be the solution that I will choose.  \nbut still its not solved the core issue here.",
            "FWIW, PyCharm understands string references and still does autocomplete and everything.",
            "make it one way dependent, add a register method to observer that registers observees.\n\nGenerally I would argue whenever there is a mutual dependency there is something wrong with the code design."
        ]
    },
    "New project: A blend of Rust and Python: speeding up Python encryption": {
        "title": "New project: A blend of Rust and Python: speeding up Python encryption",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1d5jv4i/new_project_a_blend_of_rust_and_python_speeding/",
        "content": "\\[https://github.com/radumarias/rencrypt-python\\](https://github.com/radumarias/rencrypt-python)\n\n\n\n\\* \\*\\*What My Project Does\\*\\*\n\nA Python encryption library implemented in Rust. It supports AEAD with AES-GCM and ChaCha20Poly1305. It uses ring to handle encryption.If offers slightly higher speed compared to other Python libs, especially for small chunks of data. The API also tries to be easy to use but it's more optimized for speed than usability.\n\nSo if you are open to experiment and want to achieve the highest possible encryption speed, consider giving it a try.\n\n\n\n\\* \\*\\*Target Audience\\*\\*\n\nThis is just a toy project as a learning experience\n\n\n\n\\* \\*\\*Comparison\\*\\*\n\nThis is slightly faster than PyFLocker which from my benchmarks is the faster among other Python libs like cryptography, NaCl (libsodium), PyCryptodome",
        "num_comments": 5,
        "comments": [
            "Yo dawg, you don\u2019t have to make posts for your project multiple times. It was interesting to read about the first time but it makes it harder to care about what you\u2019re saying when you blast everyone again about it \ud83d\ude09",
            "I think it\u2019s fine and fun to write crypto code to learn, but there is zero need to post it and encourage people to use, even if you then put a disclaimer below that.\n\nYou can just write code without telling anyone.",
            "sorry about that, I got an error message that the post was removed as it doesn't contain some info and added a new post to include that info",
            "I humble think that maybe posts like this could encourage more people to get into cryptography and learn more, even from such learning projects like this, instead of just \"leave this to the experts\", because how otherwise those experts become to be"
        ]
    },
    "AndroidWorld \u2014 Build and test AI agents on Android": {
        "title": "AndroidWorld \u2014 Build and test AI agents on Android",
        "score": 3,
        "url": "https://www.reddit.com/r/Python/comments/1d4we3f/androidworld_build_and_test_ai_agents_on_android/",
        "content": "**What it does:**\n\nIt is for building AI agents that perform tasks for you on Android using LLMs. Agents read the screen and perform actions like clicking, typing, and dragging. \n\nIt includes a test suite of 116 tasks across 20 real-world apps to evaluate agent performance. Think of each task like a unit test, with a setup, evaluation, and tear down procedure. Every task is written in Python. The most powerful agents should be able to pass all of them.\n\n**Target Audience:** \n\nAnyone looking to experiment with LLM for controlling Android UIs. You can download any app you\u2019d like and test out the default agent, M3A, on it. Just give it a task like \u201cShow my most recent purchases on Amazon.\u201d You can also build your own agent.\n\n**Comparison**\n\n* For desktop OSes, there is [OSWorld](https://github.com/xlang-ai/OSWorld), although it requires costly commercial software (VMWare) to run. AndroidWorld only requires free Android emulator.\n* While this is OSS and for research, the closest commercial product would be the [Rabbit R1](https://www.rabbit.tech/). They should test their agent on AndroidWorld to improve accuracy before shipping again :P\n\nLink to repo: [https://github.com/google-research/android\\_world](https://github.com/google-research/android_world)",
        "num_comments": 0,
        "comments": []
    },
    "Rio: WebApps in pure Python \u2013 Thanks and Feedback wanted!": {
        "title": "Rio: WebApps in pure Python \u2013 Thanks and Feedback wanted!",
        "score": 124,
        "url": "https://www.reddit.com/r/Python/comments/1d43uol/rio_webapps_in_pure_python_thanks_and_feedback/",
        "content": "Hey everyone,\n\nI'm a Rio developer, and I just wanted to say thanks for all the feedback we've received so far! Since our launch, we've implemented a lot of the features you asked for!\n\nAs requested, we are currently working on an in-depth technical description of Rio, explaining how it works under the hood. So stay tuned!\n\nWe are looking forward to your feedback, so let us hear from you! :)\n\n[GitHub](https://github.com/rio-labs/rio)",
        "num_comments": 67,
        "comments": [
            "I would want to see a functional example of a dashboard like Metronic or something similar - not just one sub page but something slightly bigger with global state management and something like: a list of projects, you click in, you get project details and can switch between tabs listing project issues, project team members etc - nested routes, CRUD.",
            "The first question most people are going to have is how the server-client syncing happens - there really should be a section in the README talking about that.\n\nI would suggest that the default example should have autoreloading too.",
            "First off this is awesome! Love not having to deal with JS lol\n\nDo you have plans for more generic support for custom styles, not just colors but full theming? (Personally I despise material design and would love to override it)\n\nOne approach to this I really like is \"design tokens\" common in pure web components. Here's an example https://shoelace.style/tokens/typography\n\nI'm imagining a sort of generic implementation for the built in components that can be styled using these design tokens in a theme file.",
            "I would love to see a user management and auth example",
            "Nice! Any key differences and advantages compared to reflex?\n\nhttps://reflex.dev/",
            "I found Rio a while ago, a bit after finding Reactpy.\nWhat are the advantages over Reactpy?\n\n\nMy current issues are:\n- speed\n- still everything need to be coded. (More on that below)\n\nI want to have a list/form/search/... views based on my model information (using introspection on my models)\nNOTE: my models contains metadata for access permission and other stuffs.\n\nSo I wrote something to generate the views on thr fly.\nThis works, but this is not that great.",
            "Awesome work, I'd love to contribute to this, keep it up.",
            "The Rio homepage doesn't work on Firefox mobile, at least not on my phone (Samsung A23). Clicking on anything on the \"examples\" page doesn't do anything, and no matter what I click on the navigation bar, I end up on the \"docs\" page.",
            "Hi! Thanks a lot for the contribution :)\nWhat are the differences to Flet?",
            "**We'd love to know:**\n\n* What do you like about Rio?\n* Is there anything that confuses you or you think could be improved?\n* What purposes have you used Rio for?",
            "How is this different than pyscript?",
            "How does this handle multiple sessions - what's the underlying web server backend?  I've had good luck with gunicorn, and issues with some other more stable engines.\n\nEasy to use my LetsEncrypt certificates?\n\nWhat about embedding javascript (for Google Analytics, for example)?\n\nThis looks great - I've always hated doing Bootstrap and writing HTML when building a web app.  I'm going to play with it this weekend!",
            "Looks cool! How does it compare to dash by plotly?",
            "Well this looks promising.\n\nState management will be crucial, as well as DevX represented by the ability to add custom component easily.",
            "With the advent of GenAI, I think it would be really cool if you could create an app the is a ChatGPT clone as an example. Just a simple SPA app with the ability to chat with an LLM.",
            "This sounds fantastic! Can\u2019t wait to try it out.",
            "Looks interesting. Have you come across NiceGUI before? I\u2019ve had some good experiences with it and wondered how Rio stacks up?",
            "This seems like a nice solution to my current side-project which consists of a Flask app that is serving a REST API and a web frontend (consisting of static html, js, and css) that accesses the REST API. While I think that this structure is great to ensure that a non-webdev like me still understands the codebase, I had one problem with it:\n\nThe backend and frontend are sharing a small but not insignificant part of business logic.\n\nImplementing it twice (and also implementing the tests twice) felt a bit dumb.\n\nOne approach was adding a JS runtime (pythonmonkey) to the backend. That was almost working okay, but had some weird behaviors I didn't understand and was ultimately driving the project in the wrong direction (less python, more js).\n\nSecond approach was using Python in the frontend. I tried py2wasm and couldn't really get it to work. I tried pyodide which was working, but I was unhappy with the amount of clutter I had to add to import my own python modules.\n\nI think I'll port the web client to Rio now (and the rest of the app to FastAPI since that's a dependency anyway).\n\nAs for a feature I'm missing from the docs so far: I really like the html `<dialog>` tag since it's so easy to use and flexible. Can I do this with Rio?\n\nAlso: Can I easily access the FastAPI App object that Rio is using in the background so that I can add more routes for my REST API?",
            "Hey everyone,\n\nI'm really excited to hear about the progress you've made with Rio! As a developer at CETPA Infotech, I've been following your updates closely, and it's great to see how responsive you are to user feedback. The new features you've implemented have significantly improved the usability and functionality of Rio.\n\nI'm particularly looking forward to the upcoming in-depth technical description. Understanding how Rio works under the hood will be incredibly valuable for developers like myself who are always eager to learn more about the inner workings of innovative tools.\n\nThank you for your hard work and dedication. Your continuous improvements are much appreciated, and I'm sure Rio will continue to grow and succeed.\n\nThanks!!",
            "How does rio compare to other dashboard building frameworks like plotly-dash? Plotly-dash seems to be a quite mature product, that allows dynamic definition of UIs as well as custom (server or clientside) callbacks. Is there something rio can do that plotly-dash is not, or that would simply be way easier in rio?",
            "Without knowing anything about your project, what can it do better than streamlit?",
            "Is this similar to FastUI?",
            "Thanks for helping to make this world a better place by making a tool that will allow devs to get rid of React.",
            "Don\u2019t know if it\u2019s just me, but the docs aren\u2019t responsive enough for safari on iPhone, code is way too big.",
            "rio is the common alias people give to rasterio",
            "Good experimental project but not practical (at least for now) but props for trying to keep everything pythonic",
            "This is the first I've heard of your framework. Thanks for sharing! The framework I'm most familiar with that promises no-javascript web apps is Phoenix/LiveView. It would be super helpful for me to understand how Rio compares with LiveView.",
            "It seems pyqt 5 is needed or something for running, anyway, as many dependencies as I install I cannot get past the rio run instruction",
            "[removed]",
            "your website in not responsive",
            "Hey, rio dev here. Good point! We are planning to make our examples accessible at our website, so people can play around and see first hand how multipage websites behave when built in rio. Our own website is completely done in rio. This weekend we will also launch our mobile version. Looking forward to your feedback! \ud83d\ude42\ud83d\udc4d",
            "we are currently working on an in-depth technical description of Rio, explaining how it works under the hood. So it makes sense to add a section with an high lvl overview. :)",
            "Hey, thank you!  \nYes, we are currently working on implementing a feature that allows people to create their own custom style components and share them with the community. Unfortunately, it's not supported yet, but it will be available in the near future. But it would solve your issue :)",
            "sure, we will add one to our examples in the near future :)",
            "Hey, rio dev here. Reflex use react, but they aren't react. This is something I've noticed with several libraries. While they might internally utilize react or flutter or whatnot, the interface they provide to you, the developer is radically different. React's big innovation was that you can write regular code to build user interfaces: Only want to display a component some of the time? use an if. Got multiple items to display? Just append in a loop. But you won't see any of that when you're actually making an app with reflex. Your code instead has to statically return a fixed UI, and if you want to modify it you gotta do it with pre-added conditional rendering components.\n\nWhen we say Rio is react style, we mean it. We're bringing the same development model to Python, that has taken over apps by storm.\n\nThere's a lot more limitations too. Rio supports state in each component, rather than a global god class that always ends up bloated. We don't refresh everything, but only the components that have changed. We support arbitrary Python functions as event handlers, rather than just methods in the state class. Because build is actual Python, you can use logic for parameters, instead of just binding attributes...\n\nI don't wanna turn too negative. I'm glad reflex exists, and it's been a major motivation for improving Rio. But I really don't think we're even in the same ballpark when it comes to advanced apps",
            "Hello, rio dev here.\n\nReactpy seems to be a rather direct translation of reactjs in python, which means it requires a lot of knowledge about HTML and CSS. Rio on the other hand has been designed for python from the ground up:\n\n- It doesn't require any HTML, CSS or JS knowledge at all.\n- Python allows nicer syntax than JS for certain things. For example, Rio components are pretty much normal classes, whereas react(py) requires you to familiarize yourself with new concepts like `value, set_value = hooks.use_state(\"\")`.\n- Thanks to Rio's type annotations, your IDE can support you much better compared to reactpy where everything takes a dictionary as input.\n\nAs for automatically creating views for a model, we completely agree that this would be nice to have. We've already experimented with it a little bit, but the results aren't quite production-ready yet. It's definitely something we have on our radar, though!",
            "Thanks! Your help is very much appreciated \ud83d\ude42\ud83d\udc4d",
            "Thanks for mentioning! :)  \nWe are currently working on the mobile version that we will release this weekend.",
            "[deleted]",
            "Hey, rio dev here \ud83d\ude42\n\nThere are couple of big differences. First of all, while flet uses Flutter internally, their Python API is actually significantly different. They don't pass on the react-style `build` function on to you, which means you're stuck with old school manual component updates. React's big innovation was that you can write regular code to build user interfaces: Only want to display a component some of the time? use an if. Got multiple items to display? Just append in a loop. Flutter works the same, but if you look at flet apps they are quite different. There your code has to statically return a fixed UI, and if you want to modify it you gotta do it with pre-added conditional rendering components.\n\nRio supports full blown, flutter/react style components. There's a reason that system has taken over the world by storm, and we want to make it available in Python as well.\n\nAnother big difference is that we're using web technologies directly, while flet is using Flutter. There's nothing wrong with that - flutter is great - but the results are quite different. Rio's approach gives us more access to the web tech stack when we need it. It's also what will allow us to have other developers create their own fundamental components and share them.\n\nWould love to hear your feedback on rio! \u2764\ufe0f",
            "Are you from Rio, Brasil? Hahahahaha",
            "I\u2019ll check it out!",
            "Hey, rio dev here.\n\nPyScript is a version of Python that runs in your browser. It doesn't generate user interfaces, but is just a language\n\nRio is an entire framework for creating modern web apps. It uses the regular, full blown Python and can thus support all Python packages. This works because it's running on the server, and transparently communicates with the client, rather than running directly on the client. Hope this helps",
            "Rio is a backend generator while PyScript is in-browser JavaScript but with Python syntax.",
            "Hey! What specifically do you want to know about sessions? But each connecting user generates a new \\`rio.Session\\`, which has its own independent component tree and state.\n\nRegarding the HTTP server, we use FastAPI, which can be run with any ASGI compatible server. We've been using uvicorn, but gunicorn should work just as well.\n\nWhile there is a method for running JavaScript on the client, Rio is primarily designed for use by Python developers.\n\nAnd thanks for trying it out this weekend! It would be great if you could share your experience with us afterward. :)",
            "Hi, rio dev here. The main differences are the following:\n\nNo HTML and CSS is needed\n\n Unified Component Creation: With Rio, there's no need to distinguish between frontend and backend. You create a component and specify your UI in the build method, similar to React or Flutter.\n\nModern Python Features: Rio embraces modern Python features such as type annotations and asynchrony. This keeps your code clean and maintainable, and enables your code editor to assist with code completions and type checking. If i remember correctly, Dash supports asynchrony as well.",
            "Hey, thanks for the feedback. We get the request for custom components a lot and are definitely gonna bring them! \ud83d\udc4d",
            "We have an LLM-chatbot example on our website. You can find it here https://rio.dev/examples/ai-chatbot \u2764\ufe0f",
            "Thanks for your motivating words! Your help will always be appreciated. \u2764\ufe0f",
            "Hey, rio dev here! \ud83d\ude42\n\nI'm not very familiar with NiceGUI, but it seems like a more powerful version of Streamlit.\n\nRio apps are built using reusable components inspired by React, Flutter, and Vue. These components are combined declaratively to create modular and maintainable UIs.\n\n In Rio you define components as simple dataclasses with a React/Flutter style build method. Rio continuously watches your attributes for changes and updates the UI as necessary.\n\nRio has per-component state management, while NiceGUI appears to use session state. (But not 100% sure)\n\nWith Rio, you don't need to learn CSS, Tailwind, Vue, or Quasar.\n\nBoth NiceGUI and Rio are valid options for smaller web apps. However, Rio might offer easier and more maintainable code as your project grows. It provides reactive state management and allows you to build complex, arbitrarily nested UI layouts with concise syntax.\n\nWould love to hear your feedback! \u2764\ufe0f",
            "Hey! First of all, really happy to hear that you like it! Dialogs are amongst our most requested features, and so we're looking into how to best add them. They aren't here yet, but it definitely won't be too long either. The main difficulty here is really just finding a nice API for it, rather than the actual implementation. \n\nYou're also not the only one looking for the FastAPI object, so yes, we have exposed it! The code is something like this:\n\n    rio_app = rio.App(\n      ... # your app parameters go here\n    )\n    \n    fastapi_app = rio_app.as_fastapi()\n    \n    # Add your routes here\n    # ...\n\nYou can the deploy using the typical FastAPI methods, so usually `uvicorn` + `nginx`",
            "Thank you for your nice words. Glad to hear that! \ud83d\ude42",
            "Hey, rio dev here. I think the the main differences are:\n\n with Rio you don't need HTML and CSS for styling.\n\nin Rio you create your components mostly in classes, in Dash you will use a functional approach.\n\nRio handles the client-server communication for you.\n\nCompared to Dash, Rio is a much newer framework and doesn't have a big community yet. \n\nSo your feedback and contributions would be very helpful for us! \u2764\ufe0f Looking forward to hear from you! \ud83d\ude42\ud83d\udc4d",
            "Hey, Rio dev here. I'd say the biggest difference is in how Rio scales for large projects. Streamlit, reflex & co work very well if you're working on something small like a dashboard, but get hard to maintain real fast as the project inevitably grows. We're using reusable components like react/vue/flutter and they just really help to keep your code organized.\n\nWe're also focused on modern Python. For example, everything is type safe, which REALLY helps your IDE out, as it can actually understand what's happening in your code and highlight problems and do refactors for you. There's also full asynchrony support.\n\nIt's really the small things, but they add up if there's enough of them \ud83d\ude09",
            "There's a significant difference in how you would develop your app with Rio, which supports comprehensive, Flutter/React-style components. React's big innovation was that you can write regular code to build user interfaces: Only want to display a component some of the time? use an if. Got multiple items to display? Just append in a loop.\u00a0This approach has become incredibly popular, and we aim to bring that capability to Python.   \n  \nFor me, the main technical advantage of Pydantic/FastUI over other similar libraries is runtime validation. However, with modern typed Python, this is often unnecessary and comes at a cost in speed, as even Pydantic v2 is still relatively slow.",
            "Haha, there is still a long way to go for that \ud83d\ude00! We are dreaming about a custom rendering engine for rio one day. This would give us more control over the rendering process, potentially leading to improved performance and flexibility. Step by step we go \ud83d\ude0e\ud83d\udc4d",
            "Hi theGoigi, since yesterday we are working on the mobile version of our landing page and docs. Hopefully everything works after the weekend. Looking forward to your feedback! \ud83d\ude42",
            "I work on AI projects in a quite big company. On our teams, we use Python for everything from data analysis to machine learning to backend services and so on. When it comes to building user interfaces or apps so that others can use our work, we have to switch to JavaScript and learn a whole new ecosystem. Would be nice if there is no more need to switch to JS one day.",
            "Hey, rio dev here. The website is responsive but like mentioned above, we have no mobile version yet. But it will come this weekend. Please check it out, glad to hear your feedback \ud83d\ude42\ud83d\udc4d",
            "Thanks for mentioning! :)  \nWe are currently working on the mobile version that we will release this weekend.",
            "I think you mean \"jajajajaja\"\u00a0",
            "Ah, I see. So we'll need an account on a server. That's fine.",
            "Got it - awesome!",
            "Thanks for the reply, I will be sure to check it out.",
            "[P4nd4no](https://www.reddit.com/user/P4nd4no/) welcome \ud83d\ude42",
            "A custom rendering engine? You mean [something like this?](https://skia.org/about/)",
            "Na, that's spanish, in Brasil they use kkkkk, believe it or not.\n\nlol why de downvotes? google it and you'll see."
        ]
    },
    "2024 StackOverflow Survey": {
        "title": "2024 StackOverflow Survey",
        "score": 6,
        "url": "https://www.reddit.com/r/Python/comments/1d4nvou/2024_stackoverflow_survey/",
        "content": "This years SO survey is out now. It includes questions for Python tooling and frameworks. Contribute when you can, it closes soon. It takes ~10 minutes to finish. \n\nLink to the survey: https://stackoverflow.az1.qualtrics.com/jfe/form/SV_6rJVT6XXsfTo1JI\n\n",
        "num_comments": 5,
        "comments": [
            "Feels like open ai's survey instead",
            "As far as I am concerned, SO, all its corporate backing and all its community can fuck right off.",
            "I feel bad for Stack Overflow. At least Copilot includes links while eating SO\u2019s lunch.",
            "This is my first time filling out this survey. When will the results be out?",
            "Curious what is driving this comment. As far as I'm concerned, all I've ever given them is internet traffic, and in turn they've helped me and my team on a daily basis. Seems like a win to me."
        ]
    },
    "cachebox: The fastest caching library written in Rust": {
        "title": "cachebox: The fastest caching library written in Rust",
        "score": 47,
        "url": "https://www.reddit.com/r/Python/comments/1d45x7f/cachebox_the_fastest_caching_library_written_in/",
        "content": "**What my library does**\n\nYou can easily and powerfully perform caching and memoizing operations in your Python projects using my library. This library is written in Rust, which makes its performance very fast and efficient. By using this library, you can use 7 different caching algorithms that allow you to choose the best algorithm based on your needs.\n\nOne prominent feature of this library is its simplicity to work with. You just need to import the library into your project and then behave with it like a dictionary.\n\nTherefore, if you are looking for a powerful, fast, and simple library for caching and memoizing in Python, my library will be responsive to your needs. By using this library, you can improve the performance of your program and significantly reduce the execution time of your Python code.\n\n**Target Audience**\n\nFor anyone who needs caching and values speed\n\n**Comparison**\n\nWhen compared to other caching libraries:\n- It's very faster than others (about 5-20x)\n- It's very simple and easy to use\n- It's completely thread-safe (uses RwLock)\n- It uses lower memory than others\n\nYou can see benchmark here:\nhttps://github.com/awolverp/cachebox-benchmark\n\n**More Info**\n\nMy project github:\nhttps://github.com/awolverp/cachebox",
        "num_comments": 15,
        "comments": [
            "Out of curiosity: what\u2019s the benefit of using Rust here? I thought that in caching only time cost comes from saving to memory and maybe altering current state of cache a little bit, how is translating Python objects to Rust and then back to Python faster than pure Python implementation?",
            "Can it cache live objects, eg database connections? cache tools does that for example",
            "Have you seen https://github.com/Yiling-J/theine ? It's in rust too.",
            "Creator of cacheing here, this is awesome!",
            "man i wish python was at least as far as Go...",
            "Looking at the benchmarks they linked to, it does look universally faster than cachetools, which is the same thing but written in Python.\n\nBut both are pretty fast- we're talking about a few microseconds difference in execution time. Optimizing database queries for example will make a way bigger difference than changing your caching library.\n\nBut it's still cool to see people working so hard to optimize things!",
            "Yes it can",
            "I hadn't see it before. Unlike cachebox, this library isn't thread-safe. i will add it to benchmarks.",
            "That's a lot. Even if python was as fast as Java we would be good. \n\n[speed of languages ](https://github.com/niklas-heer/speed-comparison?tab=readme-ov-file)",
            "I just write embedded cpp or c for my low latency required code and write the rest in python",
            "It's actually much farther.",
            "That is a misleading benchmark. Java is typically as fast or faster than Go. https://benchmarksgame-team.pages.debian.net/benchmarksgame/index.html",
            "Every benchmark has bias. The one you pointed out has too.",
            "The one I posted is a whole collection of benchmarks with multiple implementations. The point still is that Java and Go have very similar performance.",
            ">  The point still is that Java and Go have very similar performance. \n\nIn some cases, yes."
        ]
    },
    "PyData Amsterdam 2024 Call for Proposals closes on Sunday, June 2": {
        "title": "PyData Amsterdam 2024 Call for Proposals closes on Sunday, June 2",
        "score": 2,
        "url": "https://www.reddit.com/r/Python/comments/1d42pz9/pydata_amsterdam_2024_call_for_proposals_closes/",
        "content": "Hey all, we will close the Call for Proposals portal this\u00a0**Sunday, June 2**, for our\u00a0**PyData Amsterdam 2024 Conference**\u00a0which will take place on September 18-20 in Amsterdam. We are looking for presentations that can captivate our audience, provide invaluable insights, and foster community learning. Don't miss this chance to speak on stage in front of over 800 attendees in the field of Data & AI. Submit a talk here > [https://amsterdam2024.pydata.org/cfp/cfp](https://amsterdam2024.pydata.org/cfp/cfp)",
        "num_comments": 1,
        "comments": []
    },
    "Zango - New python framework for building enterprise ready business apps. Salesforce alternative.": {
        "title": "Zango - New python framework for building enterprise ready business apps. Salesforce alternative.",
        "score": 34,
        "url": "https://www.reddit.com/r/Python/comments/1d3m6do/zango_new_python_framework_for_building/",
        "content": "**What My Project Does**\n\nZango, built on top of Django, is further opinionated towards building enterprise ready custom business apps. Includes additional batteries for out of the box enterprise readiness and rapid app development. Growing ecosystem of packages that serves as building blocks of apps.\n\nZango also enables multi-tenancy where each tenant, representing an app/microservices, can be deployed independently on the same underlying monolith. Tenants have logically seperated db, codebase as well as deployment. This significantly cuts down per app hosting cost and enables microservices pattern without the cost overhead.\n\n**Target Audience**\n\nEnterprises: Benefits from the open core concept. No vendor lock-ins. Rapid development with out-of-the-box enterprise readiness. \n\nStartups: Get productive from day-1. Leverage packages to reach MVP really fast and not be constrained by limit on customizability (as with low-code/no-code solutions). Lowest cost of hosting if you have multiple apps or building microservices.\n\nConsulting/ Development companies: Increase development efficiency and optimize on hosting cost. \n\nYou: If you are looking to develop any bespoke app, give it a try :)\n\n   \n**Comparison**\n\n* Web dev frameworks(e.g. Django): Not opinionated for enterprise readiness/ business apps. Zango enables faster development, lower opex and and built-in compliance and enterprise readiness\n* Proprietary platforms (e.g. Salesforce): No vendor lock-in. Faster development\n* Low-Code / No-Code: Limited customizability. \n\n**More Info**\n\nKnow more at the project's Github repo: \u00a0[https://github.com/Healthlane-Technologies/Zango](https://github.com/Healthlane-Technologies/Zango)",
        "num_comments": 6,
        "comments": [
            "I\u2019m a bit confused, even after reading the getting started docs. What exactly is an app (within the context of Zango)? Is it a web page? It might help to add an app example in the docs that is functional",
            "I'm interested.\n\nWhat's the front end for this?",
            "A Zango app typically consists of a set of workflows spread across one or more user roles. It can range from a simple web page  to complex CRMs, Inventory Management App, etc. We have included an example app with the source code here: [https://github.com/Healthlane-Technologies/Zango/tree/main/examples/tutorial\\_app](https://github.com/Healthlane-Technologies/Zango/tree/main/examples/tutorial_app)  \nNoted your point about adding the example in docs as well. Thanks :)",
            "Thanks for showing interest :)  \nZango is frontend agnostic. You can work with any frontend framework as with Django. However, using the packages available with Zango, a wide variety of applications (e.g. CRMs) can be developed with only python, without writing a single line of frontend code. Videos included with this tutorial app shows how it looks - [https://github.com/Healthlane-Technologies/Zango/tree/main/examples/tutorial\\_app](https://github.com/Healthlane-Technologies/Zango/tree/main/examples/tutorial_app)",
            "So kinda as a full stop between using Apex/Lighting in SF? As someone who inherited a lot of sh*t Apex & hates low code lightning, I\u2019ll check this out !",
            "Yes. For a quick development sandbox setup you may launch on Gitpod using this link [https://gitpod.io/#https://github.com/Healthlane-Technologies/Zango/](https://gitpod.io/#https://github.com/Healthlane-Technologies/Zango/)  \nTutorial for launching the Sandbox: [https://www.youtube.com/watch?v=ru\\_p3D5I9ik](https://www.youtube.com/watch?v=ru_p3D5I9ik)"
        ]
    },
    "pyDSLR: Easy-to-use wrapper around libgphoto2 to control your DSLR/DSLM from Linux/MacOS": {
        "title": "pyDSLR: Easy-to-use wrapper around libgphoto2 to control your DSLR/DSLM from Linux/MacOS",
        "score": 38,
        "url": "https://www.reddit.com/r/Python/comments/1d3jdnf/pydslr_easytouse_wrapper_around_libgphoto2_to/",
        "content": "**What the Project Does**  \n  \nThe idea is to provide an easy to use (and fully typed, including camera settings!) abstraction around libgphoto2, allowing even non-tech-savy users to write Python scripts/sequences to take pictures. Generally, it supports all cameras that libgphoto2 also supports!  \nPossible use cases are:  \nSource code/examples available here (this one can be used to automatically take an image once a lightning strike is detected): [https://github.com/Zahlii/pyDSLR/blob/main/examples/lightning\\_trigger.py](https://github.com/Zahlii/pyDSLR/blob/main/examples/lightning_trigger.py)\n\n* Lightning trigger (showcased)\n* Bulb capture (showcased)\n* High Speed capture (e.g. using computer vision to detect animals and use the camera as part of a wildlife trap, partly showcased)\n* Photo booths\n* Timelapses (also for cameras that don't naturally support them)\n* Focus bracketing (also for cameras that don't natively support them)\n* Astro stacking (Taking hundreds of long exposures with fixed settings after another)\n* With a computer-controllable astro mount we could also track the camera based on preview images\n\n**Target Audience**  \n  \nFor now, mainly Python hobby photographers, but in the future hopefully also less tech savy hobbysts.\n\n  \nRight now it is obviously still a work in progress (with only types available for my Canon R6II), and I am inviting people to reach out to me if they are interested in participating or have cameras to add to our types :)  \n  \n**Comparison with Other Libraries**  \n  \nWhen compared to other library around it:\n\n* We wrap python-gphoto2's low level API\n* gphoto2-cffi is an alternative, but not maintained in 7 years, lacks typing support and doesn't provide much benefits over existing low-level APIs\n\n",
        "num_comments": 3,
        "comments": [
            "Interesting, I had to make something like this once. Is your package compatible on Windows? If not, you can try building libgphoto2 with MSYS2 and ship it with the package.",
            "Not yet as I haven\u2019t had the time to try libgphoto on windows, but it\u2019s definitely something I\u2019d like to check out",
            "Updated the Readme with windows install (via MSYS2)"
        ]
    },
    "From poetry to docker - easy way": {
        "title": "From poetry to docker - easy way",
        "score": 62,
        "url": "https://www.reddit.com/r/Python/comments/1d2rnor/from_poetry_to_docker_easy_way/",
        "content": "\nPoetry plugin to generate Dockerfile and images automatically\n\n\nThis project lets you generate a docker image or just a Dockerfile for your poetry application without manual setup\n\nIt is meant for production images.\n\n[https://github.com/nicoloboschi/poetry-dockerize-plugin](https://github.com/nicoloboschi/poetry-dockerize-plugin)\n\n[https://pypi.org/project/poetry-dockerize-plugin/](https://pypi.org/project/poetry-dockerize-plugin/)\n\n\n\nGet started with\n\n    poetry self add poetry-dockerize-plugin@latest\n\nThis command generates a production-ready, optimized python image:\n\n    poetry dockerize\n\n or to generate a Dockerfile\n\n    poetry dockerize --generate\n\n",
        "num_comments": 27,
        "comments": [
            "ok fine I'll try poetry",
            "This is pretty cool. Does it support custom base images? \n\nI\u2019ll try it later today",
            "Not sure I understand\u2014what's the benefit of this over a regular Dockerfile? Just one less file in your repo?",
            "Looks interesting but was wondering why someone would do a `dist-upgrade` in a Dockerfile? Wouldn't that be risking upgrading python to a newer version?",
            "Why write a configuration file that requires 90% of the dockerfile lines to be written when you could just write the dockerfile instead?",
            "This does look nice will try this out in the morning.\u00a0\n\n\nOne feature that would be is env_file so that I don't have to duplicate stuff in my .env and in the pyproject.yml",
            "Hot damn! Can\u2019t wait to play with this. Thanks for the share!",
            "Yeah, this is going to make me dive in as well.",
            "According to the readme it does by adding the base image to pyproject.yml\n\n\n\n\n\nhttps://github.com/nicoloboschi/poetry-dockerize-plugin?tab=readme-ov-file#configuration-api-reference",
            "I'd add I'd have concerns with the image sizes produced as it doesn't seem to have anything to manage layers or multi-stage builds.\n\nI think it's a cool project for learning, OP, but I'm not sure I'd feel comfortable recommending it or using it personally. I think if anyone is using docker you should... Learn docker and just not comfortable with this level of abstraction. Is there a specific target user you have in mind?",
            "Dist-upgrade should only be applying security and compatible updates. Yes, it technically adds some uncertainty and over time isn't the version you developed and tested against, but it's also how you stay relatively patched and secure, at the os and os dependency level at least. \n\nPersonally i think full-upgrade is actually a better choice, but this isn't bad.",
            "You don\u2019t have to write anything, it just works. You can customize it but for most use cases you don\u2019t any line of code",
            "thanks for the support. If you use it please let me know your feedbacks, they would be very appreciated",
            "yes it does, you can use any version/image you want but it has to be debian-based for now.\n\n\n\nDid you get the chance to use it ?",
            "It looks like the generated Dockerfile has a build layer and a runtime layer. The build layer installs poetry and other build dependencies, and creates the /app folder with the code and a virtual environment inside. Then the runtime layer copies just the /app directory across.\n\nSo I think image size should be fine.",
            "We do use docker to create reproducable, deterministic, builds right? If I'm rebuilding an image of a Dockerfile that I created a year ago I want it to be as similar as possible. It I want newer versions of stuff I update the base image. Wont full-upgrade conflict with that?",
            "Maybe most toy use cases, but most production use cases will need customization around tags, arguments, entrypoints, extra dependencies, which base image to use, etc. You've put hooks in for many of those things, but like /u/Reiku said, it's not super useful to have to write those things in `pyproject.toml` when you could just write them in `Dockerfile`.",
            "Sadly no, work always gets the way of fun stuff. I will add it to my todo list today and see if I csn find time.\u00a0",
            "I did see in the docs they had build-specific steps but I was thinking more along the lines of a web app (admittedly probably because of my background) where I also want to build the frontend in a separate build stage from the python build stage. I don't see a way to support that multi-stage builds with multiple builders here and having things like an nginx proxy in front of it all and stuff like that\n\nThat's why I asked what their target user is and also why I feel it's better to learn docker than use an abstraction so you know what the impact installing random packages can have on your image size and security footprint",
            "You ***can*** use docker to create reproducible, deterministic builds. The ivory tower people ***told*** us this is the holy grail, but it was really just a load of crap. Sort of like Agile, and stand-up, and all the other bullshit we took on believing it was the next iteration of good, only to find out it was all thought experiments in a vacuum. OK, sorry, rant over. \n\n> \u00a0It I want newer versions of stuff I update the base image.\n\nIf you want newer versions of stuff you pull down a new version of your code/compiled output. Not *patching* the OS is half of how botnets get created, or how ransomware happens. \n\nNeither dist-upgrade nor full-upgrade *upgrades* the operating system or any dependency, in the sense of say Ubuntu 22.04LTS to 24.04LTS, or LibreOffice 6.x to 7.x. dist-upgrade adds on semi-intelligent dependency upgrade decision making and full-upgrade adds on removing packages that are no longer used. That's pretty important, because in the real world, we learned that reducing the attack surface is a good way to reduce the chance of getting hacked. If your dependency management system is working correctly, it will safely remove unused packages that are no longer needed by the installed applications, meaning, it's *safe*. There's no real world downside to autoremoving unused packages, only upside. \n\n> We do use docker to create reproducable, deterministic, builds right?\n\nIf you want a reproducible, deterministic build save the docker image off somewhere. The idea you will want/need to rebuild an image from years back identical down to the byte level sounds great on paper for all sorts of use cases - firmware for DoD procured devices, or FDA regulated devices, or <insert super cool thing here>, but unless you are literally working in that industry, you will never use this in a meaningful way. \n\n> We do use docker to create reproducable, deterministic, builds right?\n\nUse docker however you want, if you want to make a time machine system, knock yourself out. Fancy Bear and China's state sponsored hackers will love you. \n\nI use docker to run applications I wrote in an isolated, clean manner for environments I can't/don't want to install dependencies on, either due to compliance reasons, firewall/clean environment reasons, or lifespan of the target system reasons (e.g. it's running on cattle, not pets). It's also handy for constraining resources.  \n\nTo wit: I would much rather break from OS security patching blocking or removing an underlying assumption I had on the operating system/environment than get a phone call from security at 6AM, or more likely, get red-listed for critical CVE's every few weeks and have to drop everything and remediate a bunch of deployments or systems I'm responsible for. \n\ntl;dr: This is a hill I will die on: my app going down due to a security patch vs my app going down because IT security cut the links after the intrusion detection system alarmed.",
            "I really would like to know what kind of Dockerfile you guys write for python standalone applications :) \n\nIf you can share one example with me, I would understand better.\n\nIt's wrong to say that \"simple\" projects are toy projects. It's just not true. If you build python microservices, most of the time you need a webserver with some API and some business logic in it. \n\nAgain, if you don't mind providing me an example, I'd be happy to change my mind.",
            "Right, I see where you're coming from. I can see why this tool wouldn't suit that kind of stack.\n\nBut Docker images are still enormously useful for running any standalone application. Simply putting a python app in a Docker image with just the dependencies it needs allows you to run it anywhere that supports Docker, on Amazon ECS, etc. I think this tool could help with removing a lot of boilerplate Dockerfiles for this kind of workflow. If it had better support for private package indexes, I would consider using it.",
            "dist-upgrade it is then! Thanks for you rant, love it!",
            "I cannot speak for the others, but my personal reservations stem from two main things: first is that simple python apps also have simple dockerfiles so I don't see the value in an abstraction when instead I feel people should learn docker so that way when they wanna do more complex things later they already have a foundation in docker.\n\nThe second part is the hard dependency on poetry as well as itself being an extra dependency. I work in 5 languages regularly, python is only one of them. Building a workflow around poetry, which itself is seeing lots of competition from hatch, rye, pdm, etc seems like a mistake to me. I like doing things as vanilla as possible so there's less of a learning curve for someone starting on the project. Everyone knows dockerfiles, it's well-documented, and works regardless of what programming language you are familiar with. I don't wanna tie workflows to a python-specific configuration file and especially not to poetry which isn't PEP-621 compliant (again, vanilla and standards are important to me).\n\nAs to your question: while I cannot link to a dockerfile for you as most of mine are private. I can provide a snippet of something that this doesn't help that I deal with a lot: locale support for formatting strings in a locale-specific way (numbers, currency, dates, etc). Apline images don't support locale generation very well and after installation of relevant locale info I need to generate the actual locale data\n\nI was trying to include the relevant dockerfile snippet, but each time I did it kept shadow-banning my post\n\nI want to do all that in one step to make it only a single image layer. I want to do cleanup after installation so temporary files aren't saved in the layer, I have to do it in the production image since that's what needs the locale support. In yoru tool I'd have to do that as a custom run command, which is fine, but it doesn't make things simpler. It just provides an extra abstraction that isn't the standard docker way that everyone who uses docker would be familiar with.\n\nAnd again to be clear I think it's super cool you created this tool and I'm  sure it was a great learning experience for you and helped make you a better developer. I just cannot recommend using it when I feel everyone should learn dockerfile syntax instead if they're using docker.",
            "Totally agree docker is still useful in many other use cases but to me that's just more reason to actually learn docker. Basically you can either learn docker and then be able to use docker for literally any language or situation where it'll be useful, or learn a python-only, poetry-only abstraction that won't be applicable to other languages or complex python apps that are part of a monorepo and may need multiple dependencies built into the image.\n\nI could see it useful maybe for a gateway drug to get people hooked on containerization, but if that's the intention of the OP I'd have liked to see it mentioned that this is a stepping stone for getting started\n\nAnd again of course as I said originally I think it's a cool project for learning itself. Just not one that I think should be widely used. I'm not trying to detract from the effort put into the project, just trying to understand it's uses and limitations",
            "I think it's a useful abstraction tool which doesn't preclude anyone from learning more about Docker. For example, I know enough about Docker to see exactly what this tool does and what Docker images it will produce. And it just so happens that pretty much all of the many Dockerfiles we have at my company follow exactly the same pattern: install poetry, add source files, log into a package index, run `poetry install`, then copy the result to a runtime layer.\n\nNative Docker isn't good at making this pattern DRY or abstractable - every Dockerfile needs every command spelled out. You can try to move some of the things upstream into a custom base image (which we do) but you can't move everything up.\n\nSo this tool (if it supported just a small handful of extra things) would be useful at my company just to remove all this Dockerfile boilerplate from our repositories. It's not gonna be life-changing but I still see its benefits.",
            "I guess my problem is I see the added dependency and strongly coupling my processes to poetry as much larger negatives than having to write a standardized well-documented plaintext file with a little bit of duplicate boilerplate. But that's just my personal take and why I asked. Guess it's just wildly not for me\n\nAppreciate you taking your time to reply"
        ]
    },
    "A \"new\" Object & Vector Database for Python": {
        "title": "A \"new\" Object & Vector Database for Python",
        "score": 58,
        "url": "https://www.reddit.com/r/Python/comments/1d2iq74/a_new_object_vector_database_for_python/",
        "content": "[ObjectBox](https://objectbox.io/python-on-device-vector-and-object-database-for-local-ai/) ([GitHub](https://github.com/objectbox/objectbox-python)) is an embedded database for Python objects and high-dimensional vectors. Today is it's first stable release for Python developers. It's very lightweight similar to SQLite, but built for objects so it's faster as there's no SQL layer in-between. It's the very first vector database that also runs on smaller low-memory devices. The article comes with first benchmarks and hints at the LangChain integration.",
        "num_comments": 32,
        "comments": [
            "I am curious, can you please provide some use cases of your database.",
            "Yes but how to use for my Roku remote",
            "Something I was always curious about: Python and \"build time tooling\". As Python is a dynamic language, this seems rather uncommon? Thus, Python is the only language supported by ObjectBox, that does not do code generation (at \"build time\"). Is this just the way it is or did I miss something?",
            "Does it supporort multiprocessing? I use the DB as the broker right between workers, each run in own process, if I can offload that from the DB that would be pretty great.",
            "Does this work with [Chainlit?](https://docs.cloud.ploomber.io/en/latest/apps/chainlit.html)",
            "You talk of performance, and I have been always  told Python is not performant. How fast is the application. I am looking for non SQL DB which can do simple stuff for FAST API backends. How does this fit in?",
            "Forgive me for my stupid question as I'm new to python. But is this a noSQL database? Like when you say it's objects, do you mean like JavaScript objects?\n\nIf so, I could definitely see myself using this. I like how lightweight SQLite is, and that it lives in JavaScript, but sometimes I don't want to have a structured database. Instead it'd be cool to just save everything as objects.",
            "As one of its developers, please feel free to ask me anything!\n\nForemost, we are eager to get some feedback from you! E.g. how do you like the new API? As we do not have to provide a mapping (this is not an ORM), we tried to make things a bit simpler than e.g. Django and SQLAlchemy.\n\nThen, what would you like to see in a Python-first vector database? Or do you all use LangChain/LlamaIndex wrappers anyway?\n\nWhat are we missing? What can be improved? Thanks a lot for having a look!\n\nPS.: [https://github.com/objectbox/objectbox-python](https://github.com/objectbox/objectbox-python)",
            "It's general purpose - except if you like SQL, it's not for you. If you prefer working with objects without the complexity/overhead of an ORM, it can be a good choice. It's embedded like SQLite (it runs inside your application/process), so one way of thinking of it is like \"SQLite - SQL + objects\".\n\nAnd there's vector search... This is an topic of its own; maybe you have seen Microsoft Recall (don't bother about the screenshots, more the general idea). It builds upon vector databases to allow semantic search, which is currently very popular with AI apps and LLM integration (\"RAG\").\n\nThis is only a rough overview, let me know if you have more specific questions.",
            "In my experience yeah, most Python developers shy away from build-time tooling. I've run into situations where I've wanted to use C-preprocessor-like macros for performance reasons, but there's not really an ecosystem for those sorts of tools out there.",
            "I hope you don't expect any decent performances from this.\n\nEvery hobby project claims to be light and fast, until someone does benchmarks.",
            "Not sure if I catch the idea - sounds a bit like a pub/sub? ObjectBox supports multi-threading, but not multi-processes completely. One \"writer\" processes and multiple \"reader\" processes should work though.",
            "I don't know? Basically, the database consists of one data file, not sure if that is a good case for Chainlit?",
            "Yes, Python itself is not very fast, but many Python packages come with \"native\" code. NumPy is a popular example, which does the heavy number crunching in compiled C code. ObjectBox also does this.",
            "Yes, but rather Python objects in this case.... \ud83d\ude42",
            "In your example code please do not use asterisk imports, but actually show the pieces of your package you are bringing in.",
            "This is like the ZODB (Zope object database) then?\n\nEDIT: yes it's a more manual ZODB.",
            "What about the part I asked on making it a fast api backend",
            "Thanks, it's done here: [https://github.com/objectbox/objectbox-python/blob/main/example/vectorsearch-cities/main.py](https://github.com/objectbox/objectbox-python/blob/main/example/vectorsearch-cities/main.py)\n\nPS.: Does everybody agree? We could change other locations accordingly...",
            "Zope, that's like ages ago... Is that still used?\n\nHad a quick look; ZODB seems like more object-orient and rather slow. ObjectBox is built for performance (e.g. native core).\n\nWhy \"manual\" ZODB?",
            "Ah, you want it to use in a backend application? Depends if you can run it \"embedded\" as it does not come with an client/server mode.",
            "U should definitely do that. Example code should be as explananitory as possible. Even if u sacrifice sum efficiency",
            "Because you have to specify object IDs to load / save, whereas ZODB loads transparently and saves transparently.\n\n\nZODB also uses native code for performance critical sections.",
            "This is like SQLite without it being SQL",
            "IDs are automatically assigned and you don't need to touch them at all if you do queries. We're indeed thinking about not having to define them - then we'd just add an id attribute automatically. However, the ID is often quite useful, so we'd rather like people to be aware of it.\n\nWhat do you think the worst and best thing about ZODB?",
            "But you have to store those IDs somewhere so you can retrieve the object later.\u00a0 \u00a0ZODB transparently resurrects object references.",
            "Object resurrection? I do not know what that is - seems like something quite specific... What that good for? Why wouldn't you get fresh results with a query or \"refresh\" an object?",
            "If you have an object A with an attribute b pointing to an object C, accessing b will bring back C from the database without having to do anything special like issuing a query. Modifying attribute b to point to object D will also save that mod upon commis.\u00a0 It's like magic but it does require you to think about how you'll build your data structures for performance.",
            "That sounds a lot like ObjectBox relations (https://docs.objectbox.io/relations). It's yet absent for Python, but it works like you describe for other languages already..."
        ]
    },
    "musicnotes: Python module for playing musical instruments!\n": {
        "title": "musicnotes: Python module for playing musical instruments!\n",
        "score": 2,
        "url": "https://www.reddit.com/r/Python/comments/1d31sj6/musicnotes_python_module_for_playing_musical/",
        "content": "[https://github.com/must108/musicnotes](https://github.com/must108/musicnotes)\n\n# What My Project Does\n\n`musicnotes` is a small open-source project that lets you play musical instruments (currently, only piano and guitar) in your Python programs. I created this project as I wanted to create a simple and useful open-source project for beginner developers to easily contribute to the project. I know it's hard to find good open-source projects for new developers.\n\n# Target Audience\n\nDevelopers looking to add sounds to small games, or just have fun while learning Python in general. This library could also be used to teach Python and coding in a fun way.\n\nThis project was also made to allow new Python developers to easily contribute to open-source! Feel free to star the repository, and download with `pip install musicnotes`! You can also create a pull request with any changes you find useful, and visit the GitHub repository if you find any setbacks while using this module. There are a few things that can be worked on listed in the README of the repository if you're looking for a place to get started.\n\n# Comparison\n\nThis project is very simple and easy to use, and is easy to contribute to as well, which is one of the primary goals of the project.",
        "num_comments": 1,
        "comments": []
    },
    "TerminalTextEffects (TTE) - A terminal visual effects engine, application, and library.": {
        "title": "TerminalTextEffects (TTE) - A terminal visual effects engine, application, and library.",
        "score": 187,
        "url": "https://www.reddit.com/r/Python/comments/1d28djq/terminaltexteffects_tte_a_terminal_visual_effects/",
        "content": "**I saw the words 'visual effects', just give me GIFs**\n\nUnderstandable, visit the [Effects Showroom](https://chrisbuilds.github.io/terminaltexteffects/showroom/) first. Then come back if you like what you see.\n\n**What My Project Does**\n\nTerminalTextEffects (TTE) is a terminal visual effects engine. TTE can be installed as a system application to produce effects in your terminal, or as a Python library to enable effects within your Python scripts/applications. TTE includes a growing library of built-in effects which showcase the engine's features.\n\nUse cases:\n\n* Invoke at terminal launch to produce an animation (ex: fetch).\n* Alias system commands to animate output.\n* Invoke on SSH session to blow people's minds when they log in.\n* Use in your project to produce animated prompts, logos, etc.\n\n**Target Audience**\n\nTTE is a terminal toy (and now a Python library) that anybody can use to add visual flair to their terminal or projects. It works best in Linux but is functional in the new Windows Terminal.\n\nEvery effect allows for significant customization including color gradient stops and directions as well as many effect-specific options. Customization is exposed via command-line arguments and through the Config class interface. The effect examples shown in the documentation represent a single configuration. Your experience can be very different with a little tweaking to match your system theme and preferences.\n\n**Comparison**\n\nI don't know of any other projects like TTE. It's a completely useless and over-engineered side-project that's turned into a whole thing. Have fun.\n\n**More Info**\n\nThe [GitHub](https://github.com/ChrisBuilds/terminaltexteffects) README has some effect examples, installation instructions and some basic quick-start info.",
        "num_comments": 22,
        "comments": [
            "That looks super fun, nice work! bookmarked for some future completely useless and over-engineered side-project of mine that needs a bit of extra fun :)",
            "Automod keeps trapping this post if I add the following info, so I'll drop it here as a comment.\n\n**More Info**\n\nThe [GitHub](https://github.com/ChrisBuilds/terminaltexteffects) README has some effect examples, installation instructions and some basic quick-start info.\n\nVisit the [Documentation](https://chrisbuilds.github.io/terminaltexteffects/) for more detailed instructions and reference material.\n\nCheck out the [Effects Showroom](https://chrisbuilds.github.io/terminaltexteffects/showroom/) to see all of the included effects.\n\nTTE now has a [Change\\[B\\]log](https://chrisbuilds.github.io/terminaltexteffects/changeblog/) where you can keep up with releases and learn a bit more about the engine and effects.\n\n**More More Info**\n\nIf you have ideas for engine features or new effects or encounter any bugs, raise an issue. I welcome feedback and interaction.\n\nNote: I'm currently working on effect building tutorials and documenting the engine beyond reference material. It's mostly a one dev show (a hobbyist, at that) with very little time each week. At this time, a v1.0 roadmap will include support for effect plugins and have a stable engine API.",
            "Wow! Many are impressive but I was not expecting the Spotlights one",
            "This is awesome, man! Great work!",
            "Is there anyway to make custom effects leveraging the already present tools in the library or is it only capable of animating the baked in effect?\n\nI'd like to create my own terminal version of a splash screen for when my application is starting but don't want to create it from scratch",
            "This is super rad\ud83d\ude06  ... It would be fun to alias some of these in my bashrc to display text files",
            "This is neat. Glad projects like this and the work out of\u00a0https://github.com/charmbracelet\u00a0are keeping the terminal fun.",
            "this looks insanely cool. Huge respect!!!!",
            "I guess the next cyberpunk roguelike will be rad!",
            "Damn they look cool. I'm a newbie making a TBRPG, so to clarify I could use one if these effects go spruce up the presentation when I'm done?",
            "This is seriously cool, great job, thanks for showing where TUI effects can go !",
            "I'm a bit dumb, but does a user just only need the python library to see the effects on their terminal?  Like I use iterm2 on my macos and will all I need is the python code to work or is there any other software a user needs to install to see the effects?\n\nAlso, since this is pythn code, do you think I'd be able to use this in a PyQt5 widget?in",
            "This is really cool - thank you for posting this.  I think I need to come up with a project to incorporate this into.  :)",
            "Amazing work!",
            "Pretty awesome! Would be nice if you introduced some text effects like the ones used in Undertale",
            "Yo this is tight. Thank you!",
            "Impressive stuff! So rad. But how did you manage to get the 3D effect after black hole effect shown on top of the \"Intro to TTE\" page? Some other package combined with TTE or simply a well colored figlet?\n\nKeep up the good work.",
            "The last major milestone is to build the effect writing tutorials and document the engine API in explanatory style. TTE is an engine, ultimately, so writing custom effects is half the point. It's an ongoing process and high priority.",
            "Sure. Just check out the [Library Usage](https://chrisbuilds.github.io/terminaltexteffects/libguide/) guide to see examples of using effects in your own project.",
            "You can use pipx and you won't have to do anything else. If you don't have pipx, start here: https://github.com/pypa/pipx\n\nThen do the following:\n\n`pipx install terminaltexteffects`\n\nThen you can call it as shown in the [Application Usage](https://chrisbuilds.github.io/terminaltexteffects/appguide/) docs.\n\nFor example: \n\n`cat your_file | tte slide`",
            "In that case the input text was ASCII art generated here: https://patorjk.com/software/taag/#p=display&f=Graffiti&t=Type%20Something%20",
            "Yes please do, I've always wanted something like a 2d graphics library for terminal ascii"
        ]
    },
    "Preferred method to run python in VS Code": {
        "title": "Preferred method to run python in VS Code",
        "score": 138,
        "url": "https://www.reddit.com/r/Python/comments/1d28wkf/preferred_method_to_run_python_in_vs_code/",
        "content": "Been working on a python tool for VS Code. Curious to get peoples' opinion on how they run python files (not notebooks) within VS Code. Do you typically run files python by:\n\n- Typing the python command into the integrated terminal  \n- Clicking the run button at the top of the file  \n- Pressing F5 for debugging  \n- Pressing Ctrl+F5 for run but not debug  \n- Creating a custom keyboard shortcut  \n- Other \n\nLet me know your thoughts, I appreciate the insights!",
        "num_comments": 87,
        "comments": [
            "Terminal",
            "I really like CLIs, and I also tend to use poetry to manage my python project dependencies.\n\nMy typical VSCode environment creation process for a new python project looks something like this.\n\n- I create a new miniconda virtual env in the project directory. it\u2019s a very straightforward way to maintain different virtual envs with specific version of python installed.\n- I have poetry installed globally using pipx, so in the newly created env I\u2019ll run poetry init and set up the initial state.\n- I\u2019ll set up a VsCode workspace at this point and then use the command palette to associate the workspace with the python interpreter from my conda env. This means when I open a terminal window in the VSCode workspace, it\u2019ll be in the correct directory and will have the correct conda environment active already.\n- I\u2019ll add a tool.poetry.scripts entry to the poetry generated pyproject.toml that associates a command with my python project entry point.\n- Iastly, I\u2019ll run poetry install.\n\nNow, whenever I open this project, my dev environment is already set up and I have a simple cli command that can run the main entry point to the script. That cli command auto reloads by, so it automatically detects changes to the project.\n\nIf the interface ends up being more than one or two possible arguments, I\u2019ll then add one of my favourite python libraries - Typer. It makes creating professional looking CLIs a breeze. Even if my project isn\u2019t destined to be a CLI, it\u2019s so easy to create commands that I\u2019ll normally use it to provide me with easy ways of testing and interacting with the code. Because typer cli commands are just python functions, a typer cli module can be imported into a new script and called like a regular function.\n\nI know I\u2019m a little weird with this - some of my very experienced dev friends think I\u2019m nuts - but when I\u2019m working on a personal project that\u2019s just for me, this is how I do it.",
            "I mostly run it in a separate dedicated terminal. It ends up being much faster than in the integrated shell of vscode.\n\n\nI use debugging a lot in vscode though as well",
            "make files",
            "[removed]",
            "Run button. Then debugger if necessary. \nThe terminal is handy if I need to mess around with command line options or use other tools, but if I was going to just use terminal routinely it makes me wonder why I\u2019d be using VS Code (vs something more focussed on pure text editing than extension via plugins).",
            "I do all of these and have had my team add a shortcut to run snippets of code in an interactive notebook with a shift+enter to mimic a notebook. Good to explore and become familiar with all of these any why you\u2019d want them in a particular scenario.",
            "Launch configs",
            "Pressing F5. Debugging through VScode is really helpful",
            "Pytest integrated into the testing pane.",
            "F5 or shift enter, depending on if I'm debugging deep into an application or just prototyping. I'll use the terminal if I just want to run something, but never for deving.",
            "They all except custom shortcut are needed for different things",
            "I right click the file and press run in terminal",
            "I always use integrated terminal",
            "F5 or custom shortcut of ctrl+alt+shift+F5 to run a specific launch configuration.  \nI also use a lot ctrl+/ to run latest test or ctrl+. to run selected test (where mouse is).",
            "I've made Ctrl+enter my run key. Typically I'll have my reusable code in .py files (often make a package with pyscaffold) and then use it in jupyter notebooks.",
            "A popular extension *code runner* I use to run my python code in VSCODE..\n\nAlthough I do not generally use VSCODE for python coding...\nI use Pycharm..",
            "WOW! I did not expect so many people to respond to this post, shout out to the community, thanks so much!! I'll comment back when I can over the next few days. Many of the responses make perfect sense to me, some of them... I would like to understand more about your approach. \n\nThank you everyone for your input!!",
            "A bit of terminal and F5 / launch current file for debugging. Often together.\n\nThe most common project I have using python is made up of 7 microservices, so I have a bash script I will run via terminal to launch all of them using python cli. If I need to debug one, I will comment it out of my launch bash script and run it using F5 or Run button (both configured same way for me).   \n  \nI generally launch vscode w the root of my python repo as working dir, install pyenv there, and then \"Launch a Python Terminal\" to use the python cli from my pyenv setup.",
            "All of the above depending on what i am doing",
            "One of the most popular extensions: Code Runner",
            "Depends. All of the above.",
            "Terminal or launch with custom targets for debugging. Always with activated venv.",
            "I have a simple bash script that just runs \"mypy --strict\" and then, if successful, \"python3 main.py\".\n\nI also have a script for creating and entering a venv then installing some common packages I always use.\n\nSo, integrated terminal with \"bash run.sh\".",
            "I write a build task and run it from the menu.",
            "Separate dedicated terminal for anything serious.\n\nThe built in terminal for chatbot development.",
            "Added `.py` to my `PATHEXT` variable and so I don't even need to type `python myscript.py` I can just type `myscript` into the terminal and run it",
            "Terminal",
            "The run button at the top because it automatically uses the virtual environment for the project",
            "For more complex projects, I usually create custom run configurations, and then use the \"Run and Debug\" window.\n\nFor simpler projects or standalone scripts in other projects, I just use the terminal.\n\nEdit: spelling",
            "Press debug button in test explorer (needs some extensions) works really well for my use case (i have around 500 unit tests that i want to pick and choose from)",
            "venv + f5",
            "Almost always using the CLI, from the integrated terminal emulator.\n\nWhen I need to debug, or have easy and quick control over a long list of CLI arguments or env variables, it helps to configure a run configuration.",
            "I'm using some custom tasks defined in the tasks.json file, usually to configure some arguments or environment variables. I have at least the \"pytest\" and \"mkdocs build/serve\" tasks for every projects.  \n The  \"Run Task\" command is binded to the keyboard shortcut \"CTRL+SHIFT+T\".",
            "No F keys on the keyboard. `cmd + r` if I were to set it up. Most of the time I use notebooks",
            "I use an external terminal for everything, the only smart features I use from vscode are syntax highlighting and sometimes code completion.",
            "Terminal",
            "Depends on the program.",
            "Devcontainers!",
            "Always got a separate terminal running it, I like the separation plus I get a better view of the logs, errors and water else needs showing",
            "Most of my projects require multiple terminals and while I can appreciate the desire to having everything integrated, in practical terms what works best for me is keeping them separated from VS Code.",
            "Terminal, pyenv for managing multiple python versions, and pyenv-virtualenv for virtual environments.",
            "I typically run in the debugger by clicking the button, or with the test explorer, since I like to keep things pretty test driven(I haven't gone full TDS yet though, it's annoying writing tests for code that doesn't exist yet with no autocomplete help!)",
            "Terminal a lot, but I will use debugging when it\u2019s a long code or really complex and I\u2019m not even sure what I need to do to process it.",
            "Python? Only intellij / pycharm. Running configuration in vscode is not very pleasant",
            "Use the terminal to open PyCharm.exe",
            "docker",
            "Closing vscode, opening two terms, and the second one for VIM.",
            "The code is \"run\" in the pre-commit hook, so technically in the terminal when I git commit (or run pytest there manually).",
            "Tasks.",
            "https://code.visualstudio.com/docs/datascience/jupyter-notebooks\n\nThe decorators make it super convenient.",
            "Separate terminal. Vscode terminal is reserved for git commands.",
            "#",
            "The fact this is upvoted shows how schizophrenic people are when saying vs code is as good as pycharm as an ide.",
            "Why use miniconda instead of pyenv which is integrated with poetry? You can even force poetry to create .venv folder in your project root",
            "How do your friends suggest you do it? Your approach sounds reasonable to me.",
            "Have you used Click? I just started using it and absolutely love it. I know Typer uses Click under the hood, but their docs don\u2019t explain very well why I\u2019d want to use it over Click so I\u2019m curious!",
            "May I ask how do you debug if not running through vscode? Using pdb?",
            "Thisss, vscode shell is trash IMO",
            "This is the way",
            "Didn't know this existed, will use it from now on. I come from notebooks where it's all about that Ctrl Enter",
            "`#%%`?",
            "Yep, me too. Interactive terminal works great, especially for data science projects. I like the jupyter variable explorer that comes with this method too.",
            "Yes, I make a lot of programs with different `argparse` settings and having these setup in launch configs is very convenient.",
            "I do this to, which should be equivalent to Ctrl+F5",
            "Why? I would also use the terminal in PyCharm\u2026",
            "they\u2019re not schizophrenic, you just can\u2019t handle people using what works best for them.\n\ni\u2019d go seek some help for that.",
            "To be fair\u2026 PyCharm itself uses a terminal to run the code \ud83e\udd23\ud83e\udd23\ud83e\udd23",
            "Terminal gives you more control.",
            "The fact that you called someone schizophrenic...for liking a method in fact, shows you are schizophrenic",
            "Why? When I used pycharm I also used the integrated terminal to run commands.",
            "Real programmers use the terminal.",
            "So how exactly do you run Python inside PyCharm? Oh, you mean the integrated *terminal*\u2026?",
            "Because I already have miniconda installed, basically. I am sure pyenv is also a good option, but miniconda is painless and also works seamlessly with poetry so I see no reason to use other things.\n\nI didn't particularly want to use conda initially but I was working at a data science company and it was what the folks there knew. Before that i was using pipenv. I quickly realized that miniconda is actually fine and pretty straightforward, as long as you don't try to use it to manage dependencies etc. All i do is run \\`conda create -n some\\_env python=3.x\\` and \\`conda activate some\\_env\\`, and then never interact with conda again.\n\nOnce I have an active miniconda env, poetry just \"works\" with it without having to do any kind of environment configuration at all. Poetry recognizes that it's running within a conda env without me having to do any configuration at all.\n\nI also prefer keeping my env information entirely outside of my projects, to make version control easier. Conda envs are in $USER/miniconda3/envs, and this is in VSCode's search path when you select python interpreter from the command palette.\n\nTL;DR, it just works, so I see no need to look into other tools at this time. But I do like keeping an eye on this area as I think there isn't still a single all-in-one tool that does everything well in the python ecosystem, and it would be nice if there was :).",
            "Yup and yup.\u00a0",
            "It\u2019s mostly that not everything should be or needs to be a CLI, but I just think they\u2019re neat! \ud83d\ude04",
            "Typer has a lot of QOL improvements on top of the click platform. It\u2019s made by the same person who made fastapi and has the same design philosophy. It makes clever use of python type hints to provide a lot of useful features at the argument/option level. It also integrates rich to provide nice formatting and really clean and well-formatted stack traces and things (although actually I\u2019m not sure if that might come from click).",
            "For debugging I just use vscode. That's what I meant with my last line\u00a0",
            "\ud83d\ude02 sure",
            "Even fake programmers use it.",
            "The fact that you are downvoted shows the \"skill\" level of this sub :D",
            "That's what I do...",
            "I do too sometimes. The pycharm doesn't work right with clearing the screen and printing some special characters.",
            "Sure, but they also use the button that actually, just does the command for them.",
            "It was a comment that made very little sense. I'm not sure why you'd expect it _not_ to be downvoted. Both PyCharm and VSCode users frequently use a terminal.",
            "\ud83d\ude02 sure",
            "Even real programmers use that button."
        ]
    },
    "Choosing between dash and react": {
        "title": "Choosing between dash and react",
        "score": 36,
        "url": "https://www.reddit.com/r/Python/comments/1d2djln/choosing_between_dash_and_react/",
        "content": "At work I'm getting the question to build a platform that will be used to navigate all kinds of business metrics to different levels of granularity. Ideally there is also insights on their relationships, and advice on actions to take.\n\nI have experience with both Dash and React, and my feeling says to go with React (and a python backend). Mostly because I foresee this application to grow over time, and managing big Dash applications (as a dev) can get clunky.\n\nHowever, in my team there's no extra JavaScript (let alone React) knowledge. While there is a solid base for Python.\nThere might be opportunities to source outside the team/company, which I'd have to make a strong case for.",
        "num_comments": 44,
        "comments": [
            "We designed Shiny for Python for your situation. It has a lot of superficial similarities with Dash but IMHO Shiny\u2019s reactive framework is more concise and powerful than Dash\u2019s model of stateless callbacks, and greatly increases the complexity ceiling. If you\u2019re familiar with React, think of Shiny as having a similar system of reactivity as MobX, except 1) reactive graph is on the server instead of the client, 2) in Python instead of JS.",
            ">However, in my team there's no extra JavaScript (let alone React) knowledge\n\nSounds like a single point of failure that the team could do with remedying!\n\nCan you afford to take a little longer on producing the initial version of this app? If so, tasking other team members to learn while you just supervise and review will pay off in the long term.",
            "They aren't mutually exclusive. We have plotly dash dashboards integrated into our react app. Works great",
            "Could be a great opportunity to teach some interested team members JavaScript / Typescript and React.",
            "Fastapi+htmx?",
            "https://gradio.app/ is a solid choice for powerful yet simple reactive python apps. For more complex things, especially data pipelines and charting, I HIGHLY recommend https://www.windmill.dev/",
            "Don\u2019t go with React. It may look like the better choice for your problem. But it\u2019s never good if only a single person in a team has knowledge of a technology. Management may decide to overturn the project once they understand the situation for risk-related reasons (because they don\u2019t want a project to be in danger if that one person leaves, or to be unable to implement changes when that one person is on leave).\n\nThis looks different if you can convince team members to learn React.\n\nHave you thought about loading your data into a data lake and using some dashboard solution like Power BI or Superset?",
            "If you want a SPA dashboard with good UX then maybe a vue.js or ember.js ? If it only has to be an internal dashboard with less complexity then there are mentioned Python solutions.",
            "Hello !\n\nGreat question !\nMaybe you can talk about it to your team : are they ready to learn another language ? Out of this app, when can they use this language in their work ?\nIf it's only for one app : maybe you can go for Dash or another module like it (Django, Flask maybe).\nMoreover : learn another language cost time ... Is your team ready for it ? Is it too OK according deadline of your project ? Can you benefit of help ?\n\nIf you want, can you share your reflexions and then your decision ? I'm curious !\n\nGood luck",
            "Might be overkill but Apache Superset looks an impressive alternative to powerBi https://superset.apache.org/",
            "I strongly recommend https://solara.dev/. It allows you to use react-like symantics in python which gets synced with the JS ui, and lets you use ipywidgets elements. I'm developing a pretty big application with it.",
            "literally had to check what sub i was in i thought this was a fgc forum",
            "Streamlit sounds like a good way to get started. If performance or embedding (i.e. can give the streamlit app directly to users) aren't major priorities, then I think this could be a good choice in the medium-longer term as well. \n\nIf you really want to go the react route, take a look at [Quill](http://quill.co) (I'm one of the founders). It gives you a high degree of functionality OOTB, while also having complete control over the frontend code, so you can support any degree of customization or any iteration/additions that come up later. We abstract away a ton of the complexity, so you won't need a react expert, but someone will need some basic knowledge.",
            "Dash is pretty amazing, [we've seen](https://docs.cloud.ploomber.io/en/latest/apps/dash.html) many companies successfully deploy complex Dash apps. Based on your situation, I'd recommend Dash, since you mentioned your team is stronger in Python.",
            "What about [https://github.com/pydantic/FastUI](https://github.com/pydantic/FastUI) ? Similar to HTMLX, but the server does not send HTML, but rather markup in terms of client components. The set of client components is written in React, and can be expanded using it.",
            "You can also keep it simple by doing everything with Python, with a template engine, such as Django's. React is a beast that can cause a lot of frustration in your team, and so is JavaScript.",
            "I was faced with this issue and eventually went with [retool](https://retool.com/). It's a low code solution and v easy to pick up. I've built a very comprehensive internal analytics platform with it. You can self host if you need.",
            "[Panel.HoloViz.org](http://Panel.HoloViz.org) is explicitly designed for teams that (a) revolve around Python, not JS, and (b) need headroom to build long-lived, large apps, not just toy demos. Compared to Dash (and certainly React) it's much more Pythonic and natural for Python developers. Compared to others mentioned like Streamlit and Gradio, it's much more about building \\_real\\_, long-lived apps with good software design, modularity, and room for growth.  See [pyviz.org/tools.html#dashboarding](http://pyviz.org/tools.html#dashboarding) for all tools in this category and comparisons between them.",
            "If you just want to stick to Python, Simian might be a good option. The frontend definition is either coded using python objects or drawn using a builder, so no need to learn HTML, JS or react. \nSimian scales well for complex UI designs and when deployed, user and access management can be linked with LDAP or AzureAD.\n\nSimian is build using FormIO and Angular\n\nSimian: https://simiansuite.com/\nBuilder example: https://www.youtube.com/playlist?list=PLeafVYKlZK9EE38oOjj2kck3KlTdEUt9b",
            "If you have the infrastructure to host it, I highly recommend Dash. We've been using Dash Enterprise, and it makes deployment incredibly smooth, offering plenty of useful features. While there is an initial learning curve, it becomes progressively easier to use. With thoughtful design, reusable components, and templates, each new project gets simpler. Plus, you can add React components with a bit of effort, making it even more versatile. Happy to demo.",
            "Hire JS interns like me \ud83d\ude06\ud83d\udc4b",
            "I think you already have your answer in React plus Python backend being best stack for the application and its roadmap. For what you described speed if you go full python would be great at initial development then would probably be very slow or worse, you may even find a roadblock, which may lead to rewrite everything.\n\nYour main concern is the current skill for the potential inhouse development team. Skills and teams change over time.\n\nMaybe you should let management decide. Make your opinionated case beforehand, showing the risks and what is needed to make it work... then let them decide.",
            "Hire me",
            "PyWebIO or Nicegui should solve this for you nicely.",
            "What is Dash? Plotly? As a python dev, I can manage plotly, but I am definitely not good with React.",
            "We do this as well using an iFrame",
            "Interesting, how does that work?",
            "Also interested in this!",
            "This is the right answer. For an app like this, HTMX is all you need.\n\n\nPeople try to forcw React down everyone's throat as if it is the best tool for whatever app you're building. I believe it is unnecessarily complex for what you're trying to do.\n\n\nFastAPI + HTMX is the best.",
            "gradio is not remotely similar to dash and certainly not react. There\u2019s no world where someone considering react for an app that is expected to grow should be considering gradio.",
            "instinctive deer library hobbies shame literate steer fine like homeless\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
            "Does windmill let you create build a visual dashboard or is it just like the business logic?\u00a0",
            "Power BI or the like is an option as well, but the long term goals for the project include a degree of user interactivity. That requirement makes me not want to go with a platform like Power BI",
            "That's good to hear. Solara's been on my list of things to try. Glad to know someone's had a positive experience with it",
            "\n\nI'm biased (I work for Plotly)  \n  \n... while Dash may be more verbose than (Streamlit, Gradio)  \n... and while it may be overkill for simpler dashboards or data apps  \n  \nThere's a reason why it continues to get adoption (approaching \\~3M downloads/mo) ... it's because you (if you don't express as a full stack / javascript developer) can develop production-grade (analytics and viz focused) data applications with it ... including through to use in external facing SaaS offerings ... while staying within the python ecosystem (i.e. where you don't have to have critical full-stack dev practice).\n\nConsequently ... I find that consideration of Dash is not so much a \"why\" question ... but a \"when\" question (based on many of the comments in this thread)",
            "We have one python backend (flask) and hooked plotly dash into the flask app. Then you can render the plotly dashboard inside your main react app as an iframe. You don't have to serve them from the same backend if you need to scale them out or want to have the main site's backend not be python, we just did that for convenience.",
            "I wouldn't dismiss gradio for someone considering using dash or react. It depends on what they're trying to build and whether they even know something like gradio or streamlit exists -- we shouldn't assume. Gradio is a very good option for many of the things commonly done in internal apps -- sometimes even user-facing stuff -- see huggingface.",
            "It's similar to streamlit, yes. Since I'd used streamlit, I didn't give gradio a chance because I figured I already knew something similar. However, gradio has a lot of advantages. Every gradio interface/UI automatically has an associated API. You're also able to embed streamlit apps via iframes or web components -- they even allow you to compile it to webassembly through pyiodide and run it entirely in the browser",
            "Yep, you're able to build dashboards through their own WYSIWG interface and connect it to windmill workflows or scripts -- workflows are basically pipelines composed of scripts. You can think of windmill as looker + airflow + + retool + vscode. It sounds insane but it actually works fantastically well",
            "The company I work for uses dash for its data SaaS offerings. The developer team are data scientists (so mainly python coders) and the learning curve for dash is straightforward.\n\nYou get plotly for free and dash mantine components look good out of the box.\n\nThere are also enough optimisations around in dash such that the user experience is quite good.",
            "I've rolled my own dashboard solutions in the past in javascript (d3), seen others do it, and then managed 3rd party tools and I'd definitely recommend not building your own to start. \n\nI'd recommend Apache Superset or Grafana as they're both easy to extend and the backend/permissions are already in place (and better suited to high usage/ interactivity than python).",
            "PS -> Dash in part abstracts React componentry (while not limiting you to it) ... so if you want Mantine components or want to use Ag-Grid (world's best data grid) or ... it's extensible nature gives you tons of choice wrt customizability :-)",
            ">Consequently ... I find that consideration of Dash is not so much a \"why\" question ... but a \"when\" question\n\nThis is an interesting point, a recent project i worked on plotly by itself and it was fine for me (and tbh its still fine now), it didn't need to be a web app but as I think of more things to do I keep seeing people recommend dash for it which makes me wonder if i should just spend some time turning it into one. It doesn't look like its that much work to do at least and will offer more flexibility. Is dash capable of being more mobile friendly or is plotly good enough for it too? I've been using janky-ish methods for now and failing lol",
            "Gradio is an awful recommendation for someone trying to build a business metrics platform."
        ]
    },
    "Gloe: A lightweight lib to create readable and type-safe pipelines": {
        "title": "Gloe: A lightweight lib to create readable and type-safe pipelines",
        "score": 29,
        "url": "https://www.reddit.com/r/Python/comments/1d200hx/gloe_a_lightweight_lib_to_create_readable_and/",
        "content": "Have you ever faced a moment when your code is a mess of nested classes and functions, and you have to dig through dozens of levels to understand a simple function?\n\nGloe (pronounced like \u201cglow\u201d) is a library designed to assist you organize your code into a type-safe flow, making it flat and linear.\n\n**What My Project Does**\n\nHere\u2019s what it can do for you:\n\n* Write **type-safe** pipelines with pure Python.\n* Express your code as a set of\u00a0**atomic** and\u00a0**extensible**\u00a0units of responsibility called\u00a0[transformers](https://gloe.ideos.com.br/getting-started/transformers.html).\n* Validate the input and output of transformers, and changes between them during execution.\n* [Mix sync and async\u00a0code](https://gloe.ideos.com.br/getting-started/async-transformers.html#async-pipelines) without worrying about its concurrent nature.\n* Keep your code **readable** and **maintainable**, even for **complex flows**.\n* [Visualize you pipelines](https://gloe.ideos.com.br/getting-started/plotting.html)\u00a0and the data flowing through them.\n* Use it **anywhere** without changing your existing workflow.\n\n**Target Audience**: any Python developer who sees their code as a flow (a series of sequential operations) and wants to improve its readability and maintainability. It's production-ready!\n\n**Comparison**: Currently, unlike platforms like\u00a0Air Flow\u00a0that include scheduler backends for task orchestration, Gloe\u2019s primary purpose is to aid in development. The\u00a0[graph structure](https://gloe.ideos.com.br/getting-started/main-concepts.html)\u00a0aims to make the code\u00a0more flat and readable.\n\n**Example of usage in a server:**\n\n    send_promotion = (\n        get_users >> (\n            filter_basic_subscription >> send_basic_subscription_promotion_email,\n            filter_premium_subscription >> send_premium_subscription_promotion_email,\n        ) >>\n        log_emails_result\n    )\n    \n    @users_router.post('/send-promotion/{role}')\n    def send_promotion_emails_route(role: str):\n        return send_promotion(role)\n\n[Full code](https://gloe.ideos.com.br/#example).\n\n**Links**:  \n[github.com/ideos/gloe](http://github.com/ideos/gloe)\n[gloe.ideos.com.br](https://gloe.ideos.com.br/)",
        "num_comments": 7,
        "comments": [
            "so basically what streams/reactive streams provide in other languages?\n\nOr are you intending for it to be more like a content based router?",
            "Does it play well with things like pydantic?",
            "The router example is just one simple use case. In this case, Gloe is used to control the delivered content, but you can create flows in any other context, even outside of a server. For instance, you can use it in a standalone data processing script. Actually, you can implement the pieces of a flow and connect them however you want.",
            "For sure! The data flowing through the transformers can be of any complex type, including Pydantic models. We are working on more concrete examples and can add one with Pydantic ;).",
            "cool so effectively like a reactive stream in Java then?\n\n    return serverRequest\n        .bodyToMono(EmailRequest.class)\n        .map(request -> request.isPremium()\n            ? createPremiumEmailRequestFrom(request)\n            : createBasicEmailRequestFrom(request)\n        .doOnNext(this::logEmailRequest)\n        .flatMap(this::sendEmailRequest)\n        .timeout(ofSeconds(30))\n        .then(ServerResponse.noContent());",
            "It is similar but without the publish\u2013subscribe stuff. The idea is to compose functions to apply transformations. The composed transformers (`C = A >> B`) are just other transformers that can be composed as well (`E = C >> D`). And you can call any transformer like a function (`A(arg)`, `C(arg)` or `E(arg)`). Using this approach, you can create complex flows where each piece is atomic, isolated, and has an explicit interface. Python typing, with the help of Mypy, ensures that you cannot compose transformers with inappropriate interfaces.",
            "sounds cool"
        ]
    },
    "Book Management Restful-API": {
        "title": "Book Management Restful-API",
        "score": 30,
        "url": "https://www.reddit.com/r/Python/comments/1d1uemr/book_management_restfulapi/",
        "content": "What My Project Does:\n\nThis project aims to provide a simple and efficient way to manage a collection of books through various API endpoints.\n\nThis API allows you to:\n\n- Get a list of all books.\n- Add a new book.\n- Get a book by its isbn.\n- Update an existing book by its isbn.\n- Delete a book by its isbn.\n\nAPI Endpoints:\n\n- GET /api/v1/books - Retrieve all books.\n- POST /api/v1/books - Add a new book.\n- GET /api/v1/books/<ISBN> - Retrieve a book by its ISBN.\n- PUT /api/v1/books/<ISBN> - Update a book by its ISBN.\n- DELETE /api/v1/books/<ISBN> - Delete a book by its ISBN.\n\nTarget Audience:\n\nAnyone who is interested to integrate book management api into their applications.\n\nWebsite API: [Book Management API](https://bookscollection.pythonanywhere.com/api/v1/books)\n\nGitHub Repo: [Book-Management-API on GitHub](https://github.com/nordszamora/Book-Management-API)\n\nFollow Me:\n\n- IG: [@nordszamora](https://www.instagram.com/nordszamora)\n- Threads: [@nordszamora](https://www.threads.net/@nordszamora)\n- Tiktok: [@nordszamora](https://www.tiktok.com/@nordszamora)\n- Github: [@nordszamora](https://github.com/nordszamora)",
        "num_comments": 11,
        "comments": [
            "Congrats on the project but perhaps not the place to post it.\n\nI think someone has trolled you. Made a GET request for all books and heres a snippet of what was returned.\n\n    {'author': 'Banana Man', 'genre': 'BANANAS GONE WILD PUBLISHING', 'id': 1, 'isbn': 9780061120084, 'price': -99, 'publisher': 'Banana Publishing', 'quantity': 50, 'title': 'Why are bananas yellow?', 'year': -1990}\n    {'author': 'Banana Man', 'genre': 'BANANAS GONE WILD PUBLISHING', 'id': 2, 'isbn': 9780452284234, 'price': -99, 'publisher': 'Banana Publishing', 'quantity': 30, 'title': 'Why are bananas yellow?', 'year': -1990}\n\nI guess that's a lesson on what can happen if there is no security on your routes...",
            "This project has gone bananas!",
            "You are lacking schema for serialization/deserialization and validation (Marshmallow for example). List/update logic should not be next to each other - usually there is some repository level for such logic while the view is just the switch. \n\nThen the usual - testing, database migrations, authentication layer. You got a basic flask starter app that needs bit more work.",
            "I was workibg in something similar, great work",
            "Not really a problem, its working as intended.",
            "> List/update logic should not be next to each other - usually there is some repository level for such logic while the view is just the switch. \n\nThat's absolutely not needed for something like this. The repository pattern is just one pattern, it's not one that has to always be used.",
            "Yes, not doubting it is working and its a great little project for sure.\n\nJust saying someone has turned all OPs books into Why are bananas yellow by Banana Man.",
            "Does it? Can a price and year be negative? Can a book have the same title, same author, same price, same year yet different ISBN?",
            "I have to agree with that one, and i heavily disagree with the comment above.\n\nBlindly applying patterns gets you nowhere, it just adds unnecessary complexity.\n\nWhat is the repository pattern actually used to? To abstract the data access and bridge the gap between the data model and the domain model.\nIs any of that needed in this case? Is there any forseeable future where the database cannot be accessed via SQLAlchemy? I'd say no, so there is no need to abstraction.\n\nFor a project of that size, i'd rather have a single, simple file then having code splitted between various files, folder, etc.\n\nPremature optimization is the root of all evil.",
            "They have indeed. \ud83d\ude02 \n\nBut it proves the API works.",
            "Obviously it can. As that is what has happened.\n\nThis APl allows you to:\nGet a list of all books.\nAdd a new book.\nGet a book by its isbn.\nUpdate an existing book by its isbn.\nDelete a book by its isbn.\n\nIt works."
        ]
    },
    "SH1106 OLED Screen App Framework for Raspberry Pi - Now on PyPI": {
        "title": "SH1106 OLED Screen App Framework for Raspberry Pi - Now on PyPI",
        "score": 57,
        "url": "https://www.reddit.com/r/Python/comments/1d1fdqb/sh1106_oled_screen_app_framework_for_raspberry_pi/",
        "content": "**What it does:**  \nToday, I released the first working version of my SH1106 app framework for Raspberry Pi on PyPI! The SH1106 is an affordable OLED screen, costing under $3, and it's perfect for projects of all sizes. This package enables the creation of apps for it with graphics support, state management, image conversion utilities, and custom fonts. Check it out here: [SH1106 Framework on PyPI](https://pypi.org/project/sh1106-framework/).\n\n**Target audience:**  \nThe package is mainly aimed at hobbyists who want to create small projects using the SH1106 OLED without having to manually write a lot of the graphics code typically needed on top of standard packages. I am also developing a hardware synthesizer keyboard from scratch that utilizes this framework extensively. So far, the framework handles the massive scaling required for this project excellently in terms of both code organization and performance.\n\n**Comparison:**  \nThis package offers several advantages over other SH1106 packages:\n\n1. **Improved Rendering Speed:** It significantly speeds up the rendering time for a given frame by writing all graphical operations to a pixel array, which is then loaded onto the screen using low-level functions from the excellent luma.oled package.\n2. **Efficient Resource Management:** All images and fonts are pre-loaded during the initialization of the framework, reducing the processing time during rendering.\n3. **State Management:** A simple yet effective state management system is implemented, making app creation straightforward from the start.\n\nYou can also check out the project on GitHub: [SH1106 Framework on GitHub](https://github.com/danspage/sh1106-framework).\n\nI'd love to answer any questions you have in the comments! I hope you find some cool uses for it. Cheers! :)",
        "num_comments": 7,
        "comments": [
            "More frameworks are always nice, thanks! Just looked it up, how is it different than the SSD1306, which seem more widely used?",
            "I'll give it a try on GC9A01, in a few weeks.\nI wonder if it can be ported to Micro python, as I have a project I use that for my aquarium. I had to butcher an existing library to make it work.\n\nThanks for sharing",
            "Amazing. You have not only made a nice project but also optimized it. Keep it up.",
            "The SH1106 is just the display I happened to have for the project I was working on when I developed the package - it\u2019s quite possible that this package is completely useable with that one just by swapping the SH1106 keyword in Drawing.py with the one for the SSD1306, as referred to by the luma.oled package. If someone wanted to test it and submit a pull request, I\u2019d be more than happy to merge it and change the package name to something more generic!",
            "That would be awesome, thanks so much! Feel free to update me or do a pull request when you try it!\n\nJust a heads up, this library only supports monochromatic displays, so you\u2019ll have to write the LCD implementation using only one color.",
            "I'll definitely give it a try and post on the repo if it works!",
            "No way, that would be awesome! Thanks so much!!! I\u2019d love to make it more accessible if possible.\n\nSide note - It\u2019s not exactly in my sights right now but it realistically wouldn\u2019t be very hard to support multiple types of displays with this package. The Drawing._render just needs a conditional check to use the display\u2019s specific code ;)"
        ]
    },
    "Crowbar - Package Management without Venv": {
        "title": "Crowbar - Package Management without Venv",
        "score": 2,
        "url": "https://www.reddit.com/r/Python/comments/1d1umwg/crowbar_package_management_without_venv/",
        "content": "[https://github.com/coryfitz/crowbar](https://t.co/psGNap3wJE)\n\n**What it does:**\n\nI'm working on a way of simplifying your Python dependency management. Basically, it handles virtual environments so you don\u2019t have to think about them.\n\nFirst: pip install crowbar-package-manager\n\nBasically you just install and run things with the crowbar command rather than pip: crowbar install package\\_name\n\nAnd then you also run things with the crowbar command rather than using \"python\" - crowbar then runs the program based on the packages in the local environment rather than having to activate your virtual environment.\n\nIt's inspired by npm if you've used that with js.\n\n**Target audience:**\n\nAnyone who currently uses the standard package management tools (requirements.txt, pip, etc) and wants to automate some of those processes.\n\n**Comparison:**\n\nThe workflow is most similar to Poetry but there are a couple of major differences - for one thing, Crowbar only does package management; it doesn't create a project structure for you. Also, Poetry puts all of your environments in a central repository - Crowbar keeps it in your project folder.\n\nUnlike Poetry or any of the other dependency management tools out there, you don't have to buy into a completely different way of structuring your dependencies or your projects. A project that you use Crowbar on is identical to one where you used pip, venv, and requirements.txt - and if you try Crowbar and decide you don't like it, just activate your virtual environment like normal.",
        "num_comments": 35,
        "comments": [
            "so you automated the `source venv/bin/activate` command?",
            "The world does not need another venv/pip wrapper.",
            "[relevant XKCD](https://xkcd.com/927/)",
            "Poetry can also be configured put the environment in the project folder",
            "looks cool. don\u2019t understand the hate. \n\nhow well does it integrate with pyenv. also how would you go about setting up a multi repo environment",
            "Very nice! I don\u2019t understand why people hate on this.\n\nWhat about putting \u201c./.venv/bin\u201d towards the front of your path? That does most things for me well if I am in the venv dir.",
            "I think people are hating on it because this is technically what the activate script does in a venv, it just adds the venv\u2019s bin to the front of the path, and bin contains the deactivate command to remove itself from path. So you could either write `cb`/`crowbar` in front of every command you usually use, or you could just activate the venv. Or you could just use pyenv-virtualenv and cd into the directory to activate it and cd out to deactivate. As far as I can tell, crowbar doesn\u2019t seem to have additional functionality that venv doesn\u2019t provide, except a .gitignore I guess? And as mentioned, it requires you to prefix every command.\n\nTo me, this seems terribly inefficient, especially since the install command will check for parent folder venvs before making one, meaning you could end up installing into a different venv rather than making a new one. As OP mentions in the GitHub, if you have a venv in your home folder, good luck.\n\nAdditionally, I\u2019m not sure why some of the commands exist. If you want a package manager, why would you ever turn off .gitignore? Why would you ever want to rename your venv? And while we\u2019re at it, why not create a hidden file .venv instead, like most other package managers? I mean how often are you going into this file to mess around really?\n\nWhy is there a \u201cshow\u201d command at all? Or anything related to configuration that isn\u2019t just under a single \u201cconfig\u201d command? The gitignore doesn\u2019t seem like something I\u2019d use enough to warrant a top level command.\n\nI\u2019m guessing you have all these extra \u201cenv\u201d keywords because you think people will create a script with the name \u201cshow\u201d or \u201ccreate\u201d and you\u2019re worried this will clash with your subcommands? I think that\u2019s kind of the danger of doing any of this in the first place.\n\nFinally, I\u2019ll say it again, activating venvs is almost always the thing you want to do. Prefixing all your commands disables a bunch of nice shell features, like tab completion, command suggestions, and perhaps most obviously, if someone does `crowbar  my_cli.py -h`, what do you think will happen, and do you think this is the desired behavior (note, I haven\u2019t tried this, but I\u2019m making an educated guess)? Devs like having the active environment in their shell prompt, it removes the necessity of another command to make sure you\u2019re not about to screw up. And while we\u2019re talking about shells, this recursive venv finder could be and should be (and can be, ask me how I know) a shell script with a shell hook into the cd command. Then you can actually use the venv environment variables to check whether you\u2019ve activated one or not.\n\nI think if you really want to develop this project, you need to find your niche. Particularly, it seems your target audience is going to be people who just want to run some isolated scripts without managing a package, since this just creates a requirements.txt and doesn\u2019t manage a setup.py or pyproject.toml like poetry or rye does. But for that to work, you need to come up with some features beyond what activating the venv would do (I\u2019m not going to count creating and updating a gitignore just yet, sorry)",
            "Not really - it doesn't actually activate a virtual environment at all. Rather, if you want to run a file, rather than activating the venv and typing python [filename.py](http://filename.py), you would type crowbar [filename.py](http://filename.py) and it would detect the venv folder and run the file based on the python and dependencies there. If you've used npm with javascript, it's pretty similar to that.",
            "That's ok - it's not for you!",
            "Not really! I appreciate the point your making, but Crowbar doesn't actually introduce any new standards. Maybe a new \"API\", but it creates all the exact same artifacts as the vanilla path of Python dependency management - a venv folder, a requirements.txt file, a .gitignore file.\n\nIf you were to look at a project folder on my machine of something I was working on with Crowbar, you would have no way of knowing that I had used Crowbar rather than pip and venv manually, and you could easily activate the virtual environment like normal if you wanted to.",
            "and pyenv",
            "That\u2019s totally fair \u2013 you can configure Poetry to give you a pretty similar experience to Crowbar\u2019s defaults.\n\nBut the reason that I built Crowbar for myself was that I wanted something a lot simpler. Using Poetry feels like buying into an ecosystem which isn\u2019t what I wanted. I have to do a bunch of configuration to get it to behave the way I want, it does a lot of things I don\u2019t care about (like packaging), and you need to get used to additional file formats (poetry.lock and pyproject.toml).\n\n\u00a0I wanted something a lot simpler than that (closer to the experience I get when I npm install something) and so I built Crowbar. I think some other people might find it useful. But for those who want a more fully featured tool, I think Poetry is a great option.",
            "It defaults to creating a gitignore? will it modify a pre existing git ignore?",
            "Works great with pyenv! One of the things it does is just automates the python -m venv command, so it should use whatever your main python installation is, whether that's managed by pyenv or not (mine is).\n\nCould you tell me more about what sort of challenges you were thinking of with a multi-repo environment?\n\nAnd thank you for the kind words! I think maybe people are just burnt by the fact that Python doesn't yet have an obvious easy way to do these things",
            "Thanks! That's essentially what it's doing behind the scenes, although it detects if you're on Windows and uses venv/Scripts in that case",
            "First, I just want to say that although I disagree with some of your opinions, I really appreciate your thoughtful comments and how much you looked at the project. I'll consider some of your technical points later.\u00a0\n\nI personally find prefixing the cb command to be far more convenient than activating/deactivating venvs, especially when switching back and forth between projects. I also don't really understand it as a criticism, especially since that's exactly how npm works, and I believe that's also how Poetry and rye work (or at least one way you can use them).\n\nYou seem to suggest that if you have a venv in your home folder then you\u2019re out of luck \u2013 this isn\u2019t the case, since you can run the check env command to see if where it would install and then create env to create the venv in your project folder.\n\nThat\u2019s a very reasonable point about making the venv hidden \u2013 I personally don\u2019t like a lot of hidden directories, but it\u2019s something I\u2019m considering\n\nSomeone might want to turn off gitignore if they don't use git, or if they have an existing gitignore file but they prefer manage it themselves and don't like where Crowbar puts the name of their environment folder (it tacks it at the end).\n\n\u00a0As for the bigger picture stuff regarding finding my niche \u2013 I am considering things like adding a pyproject.toml or maybe a lock file format different from requirements.txt. I think I personally tend towards wanting things to be more \u201cunix philosophy\u201d like than all-encompassing, but I can see the appeal of something like Poetry or rye.",
            "Not to mention many rust devs using ohmyzsh alias `cb` to `cargo build \u2014release`",
            ">\u00a0\u00a0run the file based on the python and dependencies there\n\n\nsoooo kind of like `source venv/bin/activate`",
            "I'm suggesting it's not for anyone. This \"package manager\" is abstracting away a few basic terminal commands which should, if anything, just be a bash script or makefile target. There's basically nobody who would benefit from using Crowbar instead of either just learning the commands themselves, maintaining a Makefile or using a proper dependency/environment manager.",
            "oh ok so it's \"just\" a tool to make life easier (I quoted the 'just' because i don't want to denigrate your work)",
            "pyenv install <version>\n\npyenv local <version>\n\npoetry env use $PYENV_ROOT/versions/<version>/python.exe \u2014 this one is because my path is messed up, otherwise just poetry env use python\n\nAll this with poetry\u2019s in-project set to True\n\nAnd if you\u2019re not using an IDE with automatic .venv folder recognition such as PyCharm, then poetry shell.\n\n5 commands and it\u2019s set up lol",
            "Your answer to my comment made me look at all your comments on this thread. First thanks for explaining the differences between Crowbar and Poetry! And also not denigrating your work; just as we say in coffee, one of my hobbies, when someone asks if they\u2019re brewing correctly or not: if it tastes good for you then you\u2019re doing it correctly. If Crowbar suits your needs more than Poetry does, then it\u2019s for the better.\n\nWhat I\u2019m struggling with here is two things.\n\nFirst, why make a whole other tool when you could\u2019ve written a wrapper around Poetry and Pyenv? I\u2019m wondering because that\u2019s literally what I\u2019m currently doing at my job these days. I want to introduce my team to better coding and packaging practices, backed by actual PEPs and used in the actual world, instead of the non consistent project structure they currently have, with different setup.py configurations, some with setup.cfg, just to deploy in the same location in the same target environment. But! They\u2019re not familiar with Poetry, not that much with virtual environments, and I don\u2019t want to cause them the hassle of learning all of that- which I can understand to be a bit overwhelming in the beginning given how complex Poetry can be, but that\u2019s what makes it beautiful to me! So powerful you can do many things with it, or literally just use add/remove to manage dependencies and that\u2019s all. \n\nSo, what I\u2019m doing is I\u2019m writing a Click CLI to wrap around both Poetry and Pyenv. For example:\n\n\u2018poetry new\u2019 creates a new project with a pyproject.toml. Instead, \u2018mytool new\u2019 uses Cookiecutter to fill in a custom template with everything we need: a pyproject.toml configured to source/publish to our private package registry, work with our SonarQube instance, has pylint preconfigured for mainstreamed linting standards, etc. And also includes our Gitlab CI config, a \u2018docs\u2019 folder for our Markdown docs to be deployed with mkdocs as part of our pipeline, and other things including a poetry.toml (user-specific Poetry config) with in-project = True.\n\n\u2018poetry env use <path to executable>\u2019 changes the version of the Python the virtual environment uses.\n\nInstead, \u2018mytool env use <major{.minor{.patch}}>\u2019: 1. Queries all installable Python versions with Pyenv matching the criterion given (all 3.6.x if env use 3.6), 2. If not installed, downloads the most recent matching version with Pyenv install, 3. Sets the local version with Pyenv local, 4. Sets this executable as the version used in the venv with poetry env use <path>.\n\nThat\u2019s just 2 examples. It does what the Poetry+Pyenv combo does but automatizes the process and streamlines our coding standards. \n\nSo my question here with this point is: why not build a wrapper like this one, where you specify using Click that calling \u2018crowbar <path>\u2019 does \u2018poetry run <path>\u2019? Thanks in advance for the insight.\n\nMy second struggle here was: why not stick to the standards? Just like what the other user commented about the XKCD; it\u2019s not building a new standard because you\u2019re building a tool to automatize your workflow in the current standard. But, said standard is, to me, blurry and not clearly defined (setup.py, setup.cfg, MANIFEST.in\u2026).\n\nWhy not conforming in the actual standard that was built recently, with the purpose of being a real actual standard supposed to work across all environments; that is to say, PEP 517 with pyproject.toml. Even! It\u2019s just so much easier to me. Switching from old era setuptools to PEP 517 made us reduce the number of files we have to maintain: setup.py, setup.cfg, MANIFEST.in, sonar-project.properties, .pylintrc, our private package registry\u2019s config <\u2014 all of this just into pyproject.toml! And about poetry.lock you don\u2019t even have to think about it; it\u2019s there just for building purposes to ensure that everyone is running the same versions of the same packages. You don\u2019t even maintain it, it\u2019s auto generated by Poetry from pyproject.toml.\n\nAlso, not mentioning the experience in standard tools: if you want to get a job within in a team that\u2019s highly anchored in PEP 517 usage and Poetry, you wouldn\u2019t even be able to make some value out of your own experience.\n\nJust my 2 cents! No offense there, that\u2019s great work if it fits your usage.",
            "I see 1-2 packages per week on this subreddit reinventing pydantic/poetry saying it is a \u201csimpler\u201d solution\u2026 being a less mature and less developed package manager with less features isn\u2019t an advantage. Are there features or combination of features that aren\u2019t offered by an existing package manager or are done uniquely better with crowbar?",
            "That's right - and if you already have one, then it will add the name of your environment folder to your .gitignore file. If you'd rather do this yourself, you can always turn that setting off",
            "I have two repos set up as packages. one depends on the other. If i need to make edits to both, i need to install each package in editable mode to the same environment. The best way for me to do that right now is to have a pyenv virtual environment set up globally for this cursed multi-repo micro services architecture.",
            "Honestly I think you should market it towards the people who don\u2019t want all the bells and whistles of a poetry or rye project. In Rust, the cargo command does a lot, but one of the nice features is when you set up a project, it makes a git repo, this would be super simple to do with your setup and pairs well with the gitignore stuff. I didn\u2019t want my post do discourage you, just give you some things to consider. I hope it\u2019s helpful",
            "Under the hood it doesn't use the activate command, and the workflow is different as well. If you're activating a virtual environment to run your commands, and you want to switch projects, you either need to open a different terminal window or deactivate your virtual environment and activate another. If you're using Crowbar, then the crowbar command is all you need and when you run the crowbar command it detects the local environment (much like npm works, and I think Poetry).\n\nNow, to me, this is a fundamentally different workflow. If you see it as basically the same thing, then fair enough, but then I think that's a difference of perspective.",
            "That's the idea - I made it for myself because I'm happy with what I'm calling the vanilla path, but I don't want to have to think too much about virtual environments, and I also don't want to fully buy into a system like Poetry at the moment",
            "I mean, sure, but, it's 1 command to install crowbar, plus the issues I say above to Intelligent\\_Ad\\_8148 that I have with Poetry, plus I find the \"poetry run python your\\_script.py\" syntax to be wordy (I prefer crowbar your\\_script.py), but to each their own. I find that this helps simplify my workflows but if you prefer Poetry or whatever then that's great",
            "I really appreciate the kind words!\n\nTo your first point - what I've done with Crowbar is very similar to creating a wrapper around poetry - I just made a wrapper around pip and venv. I wanted it to be downloadable from pypi so that the widest number of people could use it.\n\nIn terms of standards - I am very strongly considering adding support for pyproject.toml, especially since it seems to be the standard that everyone is moving towards. Still, as of 2022, 69% of Python developers were still using requirements.txt, so it seemed like a good starting point: [https://lp.jetbrains.com/python-developers-survey-2022/](https://lp.jetbrains.com/python-developers-survey-2022/)\n\n(I couldn't find that figure for 2023)\n\nSo, I don't see it as an issue of using a standard or not, but rather supporting an old standard rather than the new one. It's a very young project and I plan on adding features, with pyproject.toml probably being one of the next things that I work on.\n\nPlease let me know if you have any other questions or comments!",
            "If you don't see simplicity itself as an important goal, then you and I will never see eye to eye. But in particular, I find \"crowbar your\\_script.py\" (you can shorten to \"cb your\\_script\") to be a lot less verbose than \"poetry run python your\\_script.py\"",
            "Ah ok - I think I understand your situation. With Crowbar, there shouldn't be a problem with having your environment folder be one level up from the two packages and have them both running in the same environment. However, I'm not sure if it can do editable installs at the moment",
            "Also I believe there is some standard for lock files with requirements.txt, idk which project implements it though. You could check out a few cookiecutter templates to see some of the things people like to include",
            "It\u2019s like a requirements.in file I think, but I still can\u2019t remember where I saw it",
            "Sounds interesting, thanks! I'll take a look"
        ]
    },
    "An IDE with the same step by step functionality as in Matlab": {
        "title": "An IDE with the same step by step functionality as in Matlab",
        "score": 55,
        "url": "https://www.reddit.com/r/Python/comments/1d15leb/an_ide_with_the_same_step_by_step_functionality/",
        "content": "When working with Matlab I love how I can run the code step by step to debug it. Even being able to \"step in\" functions and loops.\n\nThen, I was looking to an IDE with a similar functionality for Python. Nowadays I'm using Spyder.",
        "num_comments": 54,
        "comments": [
            "Both Pycharm and VSCode have this type of functionality in their debugging features. VSCode requires a little bit more setup and installing the correct python plugins, but it's free. Pycharm just works, but the professional edition is paid (I'm unsure if debugging is included in the free version).",
            "I just googled for you: \n- [debugging in vscod](https://code.visualstudio.com/docs/python/debugging)\n- [debugging in pycharm](https://www.jetbrains.com/help/pycharm/debugging-your-first-python-application.html#where-is-the-problem)\n- [debugging in Spyder](https://docs.spyder-ide.org/current/panes/debugging.html)",
            "Any IDE  ever created for any language has those features. It's not an IDE if there isn't debugging.",
            "Every IDE has had this ability since the days of Turbo Pascal for DOS.",
            "Spyder",
            "Jupyter?",
            "This thread reminds me of when I was starting out and didn't know some word or concept and trying to ask about something related always got met with \"have you tried googling [word I didn't know]?\" And it's like, if I knew that, then I wouldn't have asked in the first place, soooo ? \n\nIn this case, OP didn't know that this is a common feature of debuggers (and possibly that \"debugger\" was even a thing) and thus couldn't have known to google or look up debugger docs... \n\nOPs problem is purely a product of not having learned programming in a formal setting/being self-taught.  Point is, stop being dicks when people are just trying to learn.",
            "...any IDE lmao",
            "label attraction screw governor grandfather trees square touch alive abundant\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
            "This is a pretty standard part of basically all IDEs.",
            "Python with jupyter notebooks is what you want. Works in VSCode with extensions",
            "VS Code and jupyter: ipynb file. Watch YouTube how to set up, takes less than 5 minutes.",
            "Pycharm is free via an academic license",
            "I've pretty much been using jupyter notebooks in vscode since I got GitHub copilot and it's great!",
            "Im an engineer and was forced to learn matlab first for college. SPYDER SPYDER SPYDER. Its so much better for plotting than vscode.",
            "Pycharm or Jupyter - the latter is particularly great for graphing on the fly",
            "Jupyter - you can write code in cells and run the cells independently",
            "Docspython.org for sale",
            ".ipynb files",
            "If you want simplest solution,Thonny awesome debugger out of the box, good for small projects. \n\n\nAdvance, pycharm community edition give you the debugger for free and out of the box. For mid project and further best ide ever.",
            "Jupyter",
            "Pdb is the Python debugger that ships with Python.  Ipdb is much better.",
            "Jupyter notebooks served by jupyterlab or jupyterhub",
            "PyCharm community edition includes debugging feature",
            "the big difference between pro and community PyCharm is flask support (and even then you can develop flaks apps in community without hassle)",
            "Oh wow, didn't know it was possible with visual studio.\n\nDo you have any guide for that?",
            "I can't see where can I step inside a function using Spyder",
            "Seconded. It has cells, breakpoints, step in/out of code, and a variable list that looks identical to Matlabs. The only downside is that it hogs memory and makes conda package management difficult.",
            "The R / MATLAB experience is definitely best in spyder. I have not used it in years but it used to be my default IDE before. I remember the auto complete being PITA though\u2026 maybe they have a ruff LSP now?! :D the ruff LSP in pycharm is much better than what was before.\n\nIt\u2019s a rather simple IDE so I think a good fit for OP\u2019s wishes.",
            "Supposedly OP is already using it. Avid spyder user myself, this feature is very well done in it. Breakpoints are just as good as VSCode or PyCharm, and the UI is great for scientific purposes.",
            "Absolutely my go to pick for this, just as long as you don't want additional debugging functionality.",
            "Yeah I would say Jupyter, although I haven\u2019t used the debugging skills much",
            "I am not sure I agree with you. One can argue they should have at least posted their post into a search engine before posting it.\n\n\nBut the poster didn't even do the infraction!\u00a0 The poster spread information that the spyder debugging is like matlabs. It was a statement, not even a question. And the comments seem to support the assertion the spyder specifically is like matlab.",
            "Although not remote debugging IIRC.",
            "Also PyCharm Pro natively supports Jupyter Notebooks",
            "It's a lot more than just additional flask support. Other frameworks (not just python), language support, k8s, remote interpreters, sql.  \n\nFull list: [https://www.jetbrains.com/products/compare/?product=pycharm&product=pycharm-ce](https://www.jetbrains.com/products/compare/?product=pycharm&product=pycharm-ce)",
            "I don't think community edition has code cells which is really annoying\u00a0",
            "There\u2019s a whole lot more than just a lack of flask support btw",
            "VS and VS code are two different products, just fyi.",
            "Straight from MS support.\nhttps://code.visualstudio.com/docs/python/debugging",
            "1. Install the Microsoft python extension pack\n2. Press F5 on the python file you want to debug",
            "There's lots. I don't personally use... Just know about. Because it is one of the most important ide features.",
            "I just opened up Spyder, as I haven't actually debugged in it before. I am competent with most debuggers I encounter. I have so far just created some basic python code in this Spyder, and I click on the left side to create a break point. It is represented by a red dot. There's the debug menu group at the top, I look in there. There's debug (Ctrl + F5) and I guess the button that looks like pause followed by the play triangle, also is supposed to be debug in Spyder. This is where it gets weird. I guess it sends you to PDB, which is not my favorite, but I definitely see how it gets the job done. I can see the step over, in and out buttons, continue. IPython's PDB in the lower right console accepts commands from those buttons, and I imagine IDE hotkeys. Each step of the way, it points in the text terminal window what step of execution your code is on.",
            "Have you even tried [reading the documentation](https://docs.spyder-ide.org/5/panes/debugging.html)?\n\nVS Code (with plugins) and Pycharm are richer/more user friendly but Spyder definitely does it.",
            "I used Spyder ide literally like 2015 and it had visual debugger. I stopped using it because lots of little things didn't work and were slowing me down.",
            "Vscode 100% has remote",
            "Jupyter Notebooks felt bad in PyCharm Pro in my experience compared to VSCode.",
            "Notably, notebooks",
            "There is a plugin for cells, just install it and place ## here and there on a normal python file.\n\nI actually prefer it to Jupiter...",
            "A little setup beforehand goes a long way\n\nAlso:\n\nimport birdseye",
            "Yes, but he was talking about Pycharm community edition.",
            "main reason why my team never considered PyCharm is notebooks support",
            "Oh thank you. I didn't know that. I hate jupyter and don't know why people use it. It's only good for displaying results or tutorials. Prototyping or exploring using it is terrible. I've been sticking with spyder for like a decade despite it's limitations."
        ]
    },
    "Spotify Lyrics visualizer": {
        "title": "Spotify Lyrics visualizer",
        "score": 65,
        "url": "https://www.reddit.com/r/Python/comments/1d0nb3k/spotify_lyrics_visualizer/",
        "content": "**What My Project Does**\n\nBecause spotify made their lyrics menu a premium only feature, I thought I'd make my own replacement for it.  \nThe app connects to your spotify account, fetches the lyrics from various websites, and then syncs them automatically to what is currently playing. Basically does the exact same as the lyrics menu used to do.\n\n**Target Audience**\n\nAnyone who wants to see the lyrics to songs really.\n\n**Comparison**\n\nMost other apps that I've found are either browser only, or don't actually sync the lyrics to the song, they just show the entire lyrics at once.  \nIn comparison, my app shows the lyrics line by line, synced with the song, and also has (in my opinion lol) a fairly nice looking ui.  \nIt's also very easy to use for non programmers too, since you can just download an executable to use the app.\n\nIt's available for free here [https://github.com/Mews/spotify-lyrics](https://github.com/Mews/spotify-lyrics)\n\n",
        "num_comments": 19,
        "comments": [
            "great work, was a bit disappointed in premium spotify not having lyrics to *all* songs and this makes things a bit better",
            "Wait, you can't see lyrics any more? wtf ...",
            "Can you give a difference with regards to https://github.com/mantou132/Spotify-Lyrics ? Haven\u2019t used either but could be quite interested ^^",
            "This sounds great. I actually use YouTube music and one big frustration is that it downloads your music for when you are offline, but you can't download the lyrics. Makes no sense... It would be great if it could work offline with downloaded lyrics. I will definitely take a look.",
            "Of course, no worries, I will take a look. I mean, it may be an interesting exercise to adapt to YouTube music. Thank you for sharing. \ud83d\udc4f\ud83d\ude4c",
            "closed software",
            "Thank you so much!",
            "Yeah its pretty annoying.  \nI mean it kinda makes sense since they get their lyrics from musixmatch, which is a paid service but still",
            "Yeah, it's bullshit.",
            "That's the one that is browser only.  \nAt least that's what I got from their readme, I actually never used it either :P  \nBut it does say its \"for the spotify web player\" so yeah it probably only works on the browser",
            "I mean my app only works with spotify, but if you're interested in downloading lyrics to songs then you could take a look at [syncedlyrics](https://github.com/moehmeni/syncedlyrics) which is what my app itself uses to fetch lyrics.  \nOr I could very quickly make a simple app for you if you dont feel like working with the cli",
            "What do you mean?",
            "The GitHub repo is in the post, wdym?",
            "It's not really bullshit. A company is providing a service. Not sure why anybody thinks they deserve it for free.",
            "Yes yes, I know, but it feels like shit when you could check the lyrics and now you can't.",
            "spotify pays musixmatch for the lyrics, so I think it\u2019s kinda reasonable as opposed to putting something free to them behind a paywall.",
            "Maybe it\u2019s just me, but I\u2019m tired of all the different business shenanigans where a company gives you something for free and then either monetizes your usage in some other way (e.g analytics and advertising) or tries to bait you into becoming a paid customer by giving you a small taste of a free service and then withholding everything else. \n\nHow about this as a business model? I give you money, you give me the product/service. All of these third party hacks that try to piggyback on the Spotify API to give users a mediocre workaround to paying for the service are cool as a technical piece of code but it just incentivizes companies to get more creative in how they squeeze us for cash.\n\nThis is part of the reason I use Apple Music instead. I really want access to hifi quality downloads. Spotify refuses to release their version of it because they haven\u2019t figured out a way to monetize it given their sort of freemium business model. For Apple you just play a flat fee and get access to everything. Fewer shenanigans. I get service, they get money. Beautiful.",
            "It's totally reasonable. I'm just upset that the service was free and now it's not :( I used it quite a lot."
        ]
    },
    "I created an unofficial module for the ShipEngine API ": {
        "title": "I created an unofficial module for the ShipEngine API ",
        "score": 19,
        "url": "https://www.reddit.com/r/Python/comments/1d0qkfd/i_created_an_unofficial_module_for_the_shipengine/",
        "content": "**What My Project Does**\n\nSimplifies the interaction with the ShipEngine API with most response and requests built as objects, which in my opinion makes interaction much easier. This is my first released package so all criticism and feedback is very welcome.\n\n  \n**Target Audience**\n\nAnyone who deals with the current ShipEngine API using Python.\n\n  \n**Comparison**\n\nThere is an official ShipEngine API module that is created by the company but I have found it somewhat lack luster with no way to create batches or bulk shipments (and other missing functionality), this is much more suited to accomplishing that task.\n\n  \n**Links**\n\n[https://github.com/Sen-tio/unofficial-shipengine](https://github.com/Sen-tio/unofficial-shipengine)",
        "num_comments": 3,
        "comments": [
            "Object based interfacing for APIs is the go to approach! I don't know your preferences, but maybe look into pydantic for json parsing/models, I personally use it for my APIs at work. And I think it reduces the amount of boilerplate I have to write greatly",
            "Maybe you should publish this in madeinpython subereddit",
            "Appreciate the feedback, I'll consider refactoring with pydantic if I can find the time to do so but I'll definitely use it moving into any new projects reducing boilerplate always sound great to me"
        ]
    },
    "Xenharmlib - An advanced music theory library that supports microtonality": {
        "title": "Xenharmlib - An advanced music theory library that supports microtonality",
        "score": 60,
        "url": "https://www.reddit.com/r/Python/comments/1d0gots/xenharmlib_an_advanced_music_theory_library_that/",
        "content": "Introducing [Xenharmlib](https://xenharmlib.readthedocs.io/en/latest/) (Source code [here](https://gitlab.com/retooth/xenharmlib))\n\n**What My Project Does**\n\n(taken from the docs) Xenharmlib is a music theory library for the exploration and research of microtonality, diatonic set theory, non-standard notations, and many more. The library implements a superset of Western classical music theory, so you can also use it to compose and analyze music in the boundaries of the common practice period or 20th century Western music.\n\n**Target Audience**\n\nComposers who want to get answers to theoretical questions pertaining to structures of musical scales, note intervals, frequencies and frequency ratios in equal division tunings. People who want to explore microtonality or non-western musical theory in general.\n\n**Comparison**\n\n\\* **mingus** Xenharmlib is pretty much on-par with features in mingus, however extends those features to all sorts of equal division temperaments.  \n\\* **pytuning** supports more slightly tuning methods and export formats, however does not support microtonal notation or note / interval calculation  \n\\* **music21** is much more mature in providing an analytical toolset, however supports only traditional western equal temperament",
        "num_comments": 10,
        "comments": [
            "I know some of these words",
            "this is really cool. i would never use it, but as a music nerd it makes me happy it exists.",
            "Nice project. Props to you.",
            "what is that name \ud83d\udc80",
            "I am not at all a musically oriented person but even I can appreciate how cool this is",
            "Can you explain your rationale for using two parameters (without zero-based numbering) to create a interval object?\n\n    \"\"\" Creating a perfect unison\"\"\"\n    n_edo12.shorthand_interval(\"P1\") # my musician intuition (human-readable)\n    n_edo12.shorthand_interval('P', 0) # my programmer intuition (machine-readable)\n    n_edo12.shorthand_interval('P', 1) # your implementation",
            ":D i realize it is a very niche interest. i guess it's easier for the average person to have something to listen to in order to grasp the beauty of microtonal music. Here is a work by Mike Battaglia that I like a lot (written in a temperament that has 31 notes per octave): [https://www.youtube.com/watch?v=HJKB1\\_gvhLE](https://www.youtube.com/watch?v=HJKB1_gvhLE)",
            "lol true, can't agree more. would be happy to contribute but not sure if I would use it, as I'm definitely not into microtonal music. 12 semitones are enough for me",
            "[https://en.wikipedia.org/wiki/Xenharmonic\\_music](https://en.wikipedia.org/wiki/Xenharmonic_music) ;)",
            "**First**: Why 1-indexing and not 0-indexing? *Internally* the base class for natural/accidental notation system actually uses 0-based indexing. The two have different names: *Interval number* (like it is called in most music textbooks) is the traditional 1-based index while *natural index difference* is the more mathematically sound 0-based indexing. You can also access the latter on the interval object:\n\n    n_edo12.shorthand_interval('P', 1).nat_diff\n\nThe interval number resides only on the surface level of the implementation. The documentation for the base class of natural/accidental notations also states how to change the default behavior if you choose to invent a notation with 0-indexing:\n\n>The class implements the 1-based ordinal notation for numbers by default (e.g. the number 1 for a unison, the number 2 for a second, etc), however this behavior get be changed by subclassing and overwriting the method nat\\_diff\\_to\\_interval\\_number() and its counterpart interval\\_number\\_to\\_nat\\_diff()\n\nMathematically speaking 1-based interval indexing is really a pain. There is a whole lot of counter-intuitive interval arithmetic like M2 + m2 = M3. (There exists a mountain of other problems with it that I could elaborate on) Why still use it? Because every textbook on music uses it and the idea behind the library is to enable a composer or musician to think *less* about calculations and *more* about music.\n\n**Second:** Why a tuple and not a simple string? The obvious part of the answer is of course that it is easier to parse. Giving the interval number as the correct datatype means less of a headache for the class to separate the two datatypes. However separating the two also gives more visual clarity to the user regarding negative intervals, e.g. if you look at the following hypothetical interface:\n\n    n_edo12.shorthand_interval(\"P-4\")\n\nNow is this a fancy way of denoting (P, 4) or does it mean (P, -4)? I've seen texts on music that actually use \"-\" as a simple visual separation character that has nothing to do with interval direction. Copy/pasting from such a source would then produce very surprising results."
        ]
    },
    "AI planner: AI tool for efficient event scheduling in Google Calendar.": {
        "title": "AI planner: AI tool for efficient event scheduling in Google Calendar.",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1d11nfg/ai_planner_ai_tool_for_efficient_event_scheduling/",
        "content": "Good evening! I have created a new projectfor adding events to google calendar based on the text a user inputs.\n\n## What My Project Does\n\nThe project is a tool that uses large language models to understand the user's input and add events to the user's Google Calendar based on the user's input. It uses Ollama for natural language understanding and Google Calendar API for adding events to the user's calendar.\n\n## How My Project Works\n\nOllama uses `Llama 3` with pre-instructions to act as a calendar event planner. The tool uses the model to generate responses to extract the event's details from the user's input inserted in the Web Interface. tool then asks the user to confirm the details extracted from the user's input and adds the event to the user's Google Calendar (example shown [here](https://github.com/ahnazary/AIPlanner#:~:text=Usage%20and%20Interfacing))\n\n## References\n\nCheckout my github repository [AIPlanner](https://github.com/ahnazary/AIPlanner) for more details about the project.",
        "num_comments": 11,
        "comments": [
            "All these little AI apps are weird. It would be faster to just open the calendar and to add it directly. The name field already has language processing. Typing sentences is a waste of time 95% if the time. ChatGPT has the same problem if you just ask it something. Google is faster and shorter",
            "Why wouldn't I just type all of this information into my calendar directly? Asking ChatGPT to parse text just to re-format it into JSON so that a separate API can ingest that seems like a lot of complication and hassle for literally no benefit.",
            "Well, this is coming to the iphone and everything else. It's annoying putting this into your calendar. I just want to tell my phone, hey, set up a meeting on this week. Use one of the regular meeting rooms and invite X and Y for one hour to discuss Z. Than it will find a time when everybody is available and one of he rooms are free. \n\nCool project though, but the real innovation is not in the product, but in making it an integrated voice product for your devices. Thats why all these AI company wont win. Apple, Google etc. will just make them themself and it will be better because they have full access to your device and the user wont bother to add a app for each little thing.",
            "Looks awesome, might contribute shortly",
            "Why wouldn\u2019t I just use Google Assistant?",
            "Looks really interesting. Maybe also add docker compose to make the setup easier. \nNevertheless, the idea behind it is cool.",
            "This sounds like I could be expand to something like a scheduling assistant for doctors and dentist.",
            "I sort of agree. I like these tools poping up as a learning exercise but I don't find them ready to be used. The point of \"AI\" in the near future is to make things smoother and faster for me. But that kind of tools aren't doing that at all. They simply force me now to figure how to explain clearly enough what I need when it's way faster for me to open up the calendar. And I'm more precise.",
            "Honestly I think you\u2019re wrong here. Especially if it accepts speech-to-text, it is far more useful. Google calendar and apple\u2019s calendar both suck ass to use. If I can tell an app with my voice that I wanna set a date on a calendar with a reminder two days before and a specific time without going through the shitty UI, I will. Especially if I can just talk to my phone and have it done.",
            "Incorrect, google is worse than chatgpt 100% of the time",
            "Agree, will add it later on. how ever the google calendar setup cant be automated using docker compose."
        ]
    },
    "PyPods: A lightweight solution to execute Python dependencies in an isolated fashion.": {
        "title": "PyPods: A lightweight solution to execute Python dependencies in an isolated fashion.",
        "score": 62,
        "url": "https://www.reddit.com/r/Python/comments/1czxc2a/pypods_a_lightweight_solution_to_execute_python/",
        "content": "  \nIntroducing [PyPods](https://github.com/Rohan2002/pypods)\n\n**What My Project Does**\n\nA Python library designed to manage monolithic project architectures by isolating dependencies. \n\nTraditionally, monolithic architectures cluster all dependencies into one project, creating complexities and potential conflicts. PyPods offers a solution by isolating these dependencies and enabling the main project to communicate with them via remote procedure calls. \n\nThis approach eliminates the need to install dependencies directly in the main project. Feel free to take a look and I am happy to receive some feedback!\n\n**Target Audience**\n\nProduction grade.\n\n**Comparison**\n\nThis solution is inspired by [Babashka pods](https://github.com/babashka/pods) in the Clojure world. ",
        "num_comments": 22,
        "comments": [
            "This seems very unsafe (reliability, not security). This might help if the incompatible change in Dependency A between v0.5 and v1.0 is something that is not used by the main project. However, in many cases the incompatibility described by the package version is neccesary. If you try to provide something from v0.5 as input to a v1.0 function, there may be conflicts.\n\nThis would be similar to using different versions of the same API at the same time.\n\nEdit: \n\nSee https://www.reddit.com/r/Python/comments/1czxc2a/comment/l5mlyrg/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button",
            "your transparent pngs do not look good in github dark mode",
            "To summarize for people that don't get it, this is accomplishing something other runtimes can do natively and it would be a nice feature in Python. In .net, it's called \"multi-targeting\". The overhead of multiple interpreter makes it of less interest to me but I admire the attempt.\n\nAnother comment claims it is unsafe because A could depend on B1.0 and C1.0 but B1.0 could depend on C2.0. This only matters if C is part of B's public interface that A consumes. I don't know the range of RPC supported but the pods probably shouldn't export internals of the packages for this reason. In .net multi-targeting, A could not compile depending on C1.0, B would force its C2.0 dependency on A. Python is a little more flexible but generally, I'd recommend users either: \n\n- Don't use or create packages that expose third party types in their public interface\n- OR enforce the same restriction as in .net multi-targeting and insist the consumer depends on the same version of any publicly exposed third party types",
            "> creating complexities and potential conflicts.\n\nCan you list a real world example of such a conflict you've found?",
            "Why? A venv is already a solid solution. \n\nIt's stuff like this that's turning Python into Javascript.",
            "i don't disagree but the reasoning here is that you don't use A@1.0 and A@0.5, you use A@1.0 and B, which internally uses A@0.5 - you aren't passing objects from A@1.0 to A@0.5",
            "I can create the diagrams for the dark mode. I use white mode, so i didn\u2019t think of that scenario. Thank you for pointing it out.",
            "I have updated the background colors now.",
            "Not OP, but I run into this all the time. It's especially problematic in the world of language models. Some libraries will often want a very specific version of a dependency.",
            "In my past work in some organizations, we had a main project and many dependencies in that project. Those dependencies used maybe different versions of Numpy or some dependencies only ran using Python 3.6 and below, while some ran Python 3.7 and above. The abstraction using PyPods will solve that issue by isolating the main project's dependencies in its pod. Every pod has its own Python interpreter and dependencies.",
            "Read the GitHub, it explained the problem.",
            ">Why? A venv is already a solid solution. \n\nIt's not a solution for the problem this is attempting to address. \n\nEffectively, what this is doing is creating multiple virtualenvs for where a projects dependencies have conflicting dependencies.",
            "I am not quite sure I understand your comment u/chakan2.\n\nI am building an abstraction using virtual environments. Of course, a virtual environment (venv) on its own is great.",
            "\ud83e\udd26\u200d\u2642\ufe0f\n\nMaybe read the OP before commenting on it. Venv does not solve the same problem *at all*.",
            "As a regular venv user, I don\u2019t feel they are a solid solution\n\nIt\u2019s often that I need to use multiple libraries in a single venv and they have conflicting dependencies\n\nAs for turning python into JavaScript, as much as I don\u2019t like all the weird quirks of js, the js ecosystem has much more traction outside python\u2019s strongholds of data science and ai\n\nand I think tooling / devops is one area where python could realistically benefit from imitating js",
            "Actually I agree with Tomster, but I want to also comment about Krazy\u2019s scenario:\n\nlet\u2019s say main project uses Dependency A(v1.0) and A(v1.0) uses A(v0.5). Then we can create a pod from A(v1.0) that contains A(v0.5) and then don\u2019t have to worry about installing A(v0.5) in A(v1.0).",
            "FYI: github supports rendering diagrams in markdown via mermaid https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-diagrams",
            "> I need to use multiple libraries in a single venv and they have conflicting dependencies\n\nThat means you're probably doing it wrong. Once you start running into conflicting libraries, it's probably time to split your project into smaller logical units. \n\nThe only times I've run into issues like that are poorly designed monoliths that try to do too much. Dependency management was just a side effect of a terrible code base.",
            "Why would A use a different version of itself? Maybe you mean to use two different letters?",
            "This is how I interpreted u/KrazyKirby99999 comment about \"If you try to provide something from v0.5 as input to a v1.0 function, there may be conflicts.\"\n\n**Assumptions**\n\nA(v1.0) internally uses A(v0.5).\n\nSo A(v1.0) ----depends---> A(v0.5).\n\nLet's say a function foo was defined in A(v1.0).\n\nLet's say a function foo was defined in A(v0.5).\n\n**Goal**\n\nThe goal is to compare the outputs of the two functions.\n\n**Short version of the procedure**\n\nA(v1.0) can simply call its version of foo and get the output.\n\nNow A(v1.0) does the following things to get the output of foo from A(v0.5).\n\n**Long version of the procedure**\n\nSay you have a\u00a0[run.py](http://run.py/)\u00a0file in your library A(v1.0) project. This is your main project now.\n\n    from pypods.pods import PodLoader\n    \n    def foo():\n      return \"A(v1.0) foo output\"\n    \n    # name of the pod, and namespace to inject pod's functions.\n    pl = PodLoader(\"a_old\", globals())\n    pl.load_pod()   # Creates pod if not exist and then load pod namespace\n    pl.unload_pod() # Unload pod namespace\n\na\\_old pod gets created.\n\nIn a\\_old's requirement.txt file\n\n    A==0.5\n\nIn a\\_old's\u00a0[pod.py](http://pod.py/)\u00a0file\n\n    from A import foo # function foo is in global namepsace of \n    \n    # Don't change anything here!\n    if __name__ == \"__main__\":\n        from pypods.pods import PodListener\n        # ... rest of the code can be found in tempelate\n\nGo back to A(v1.0)'s\u00a0[run.py](http://run.py/)\u00a0file\n\n    from pypods.pods import PodLoader\n    \n    def foo():\n      return \"A(v1.0) foo output\"\n    \n    # name of the pod, and namespace to inject pod's functions.\n    pl = PodLoader(\"a_old\", globals())\n    pl.load_pod()   # Creates pod if not exist and then load pod namespace\n    \n    a_old_foo_output = a_old.foo()\n    \n    print(f\"A(v1.0) foo output : {foo()})\n    print(f\"A(v0.5) foo output : {a_old_foo_output})\n    \n    pl.unload_pod() # Unload pod namespace\n\nI am not sure in which scenarios you would do this. Maybe for testing the libraries or trying to find regressions in library A(v1.0) by comparing it to the output of A(v0.5)?",
            "That's not what I meant by that scenario. \n\nImagine that Dep A has 2 functions: get_color() and set_color()\n\nIn v0.5, get_color() returns a value from 0.0 to 1.0, and set_color accepts the same. However, v1.0's get_color() and set_color() deal with values that range from 0 to 255 instead.\n\nIf Dep B specifically uses Dep A v0.5's get_color() under the hood, perhaps for a get_team_color() function, then Dep A v1.0 set_color(get_team_color()) would fail.\n\nEven if the code is separated by a process layer, there is still an API that the different packages and versions expect. The main project will need to be careful to ensure that these incompatibilities are manually resolved.",
            "Oh yea that is something the developer should be careful about when passing functions around different libraries."
        ]
    },
    "I made a desktop chat app :)": {
        "title": "I made a desktop chat app :)",
        "score": 68,
        "url": "https://www.reddit.com/r/Python/comments/1cznlay/i_made_a_desktop_chat_app/",
        "content": "**What My Project Does**\n\nHi! This is my first time doing a python project more than a few hours in size.\n\nI made a chat app which features E2E encryption using a passcode and has a multiclient architecture.\n\nAll comments are welcome!\n\n  \n**Target Audience**\n\nIt is just a toy project for my portfolio.\n\n  \n**Comparison**\n\nCompared to other chat clients, this one uses a passphrase to encrypt all data, with the passphrase being chosen out of the app, for instance on a dinner.\n\nBut I think that IRC already has this, so it doesn't differ much XD.\n\n  \nGit link:\n\n[https://github.com/xxzoltanxx/Balvan-Chat](https://github.com/xxzoltanxx/Balvan-Chat)",
        "num_comments": 30,
        "comments": [
            "Hi there, from the /r/Python mods.\n\nWe want to emphasize that while security-centric programs are fun project spaces to explore we do not recommend that they be treated as a \nsecurity solution unless they\u2019ve been audited by a third party, security professional and the audit is visible for review.\n\nSecurity is not easy. And making project to learn how to manage it is a great idea to learn about the complexity of this world. That said, there\u2019s a difference \nbetween exploring and learning about a topic space, and trusting that a product is secure for sensitive materials in the face of adversaries. \n\nWe hope you enjoy projects like these from a safety conscious perspective. \n\nWarm regards and all the best for your future Pythoneering,\n\n/r/Python moderator team\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Python) if you have any questions or concerns.*",
            "I don't think you meant to have `tk` in your requirements. It's this project: https://pypi.org/project/tk/",
            "Do you know of any good resources to learn to build projects like this and help with overall architecture? I\u2019m in university right now but none of my courses have covered anything like this.",
            "Nice. It seems you real have a good amount of knowledge on different relationship architecture.",
            "Nice. I was planning on making something like this for my portfolio too! But mine was going to be in terminal. No GUI. I'll save the link so that I can look at it if I ever have any questions. Thank you!",
            "Starred! Looks cool, wanna learn tkinter and the gui here is a nice thing to go off",
            "I'm doing the same in proton native & Django. Wish me luck!!",
            "You could try to add type hints, see the typing library: https://docs.python.org/3/library/typing.html",
            "Here\u2019s some cryptography advice, 500 iterations of PBKDF2 isn\u2019t enough for modern computers, consider a few hundred thousand at the least or consider using stronger key derivation like Scrypt (which is also present in the cryptography library).",
            "Why not do something useful? Why another calculator?",
            "Few things I\u2019ve noticed so far\n\n- missing docstrings. You should add a docstring to each class and method to explain its behavior\n\n- missing unit tests. I know it\u2019s only a small project but adding a suite of unit tests will be very good practice and help you find bugs.\n\n- styling is inconsistent. Refer to the PEP guidelines and ensure you are following them. Methods and attributes use snake case in Python (not camel case). Only classes use camel case. \n\n- Python is not a good choice for this application. Python is open source and difficult to deploy on others machines etc. this is a good prototype but if you want this to work as an actual application, I\u2019d recommended using a different language.",
            "Thanks :)",
            "just keep building stuff. OP's github for this project is a good resource. \"overall architecture\" will come from exposure to a bunch of these, especially valuable are the ones that don't work well with some learned indication of what was leading to it not working well",
            "https://refactoring.guru/design-patterns was a starting point for me, though this app doesn't use any of them.\n\nGenerally if you adhere to SOLID principles you should get a well laid out design at the end, no matter the conventional design patterns.",
            "Thanks! I decided to be very organized when doing this app. I spent time just designing the relationships between different components on paper. This didn't prevent me from having issues with the design midproject though. The GUI is thus unfortunately in the main class because tkinter can only run on the main thread.",
            "Welcome! I like it that it's useful to someone.",
            "This was a very fun peoject for me. I think you will like it!",
            "This is very cool. I dislike dynamic typing. It makes maintenance very hard for people who come new on a project.",
            "Thanks!",
            "I changed the counter of PBKDF2 to 300 000; also I have changed that the salt is not predefined but it is entered inside the connection screen. :)",
            "I don't get the last point. Why is it difficult to deploy on other machines ?. You can compile an executable using pyinstaller.\nWhich different language do you recommend for an actual application ?",
            "Thanks for the feedback :) I didn't want to go with test driven design here because I thought the scope will be really small. I think now it would be good if there were unit tests for all of the classes, especially encryptor and communicator.\n\nWill keep this in mind for my next project!",
            "Fair points, but I'm more open to Python distribution now. It's kinda nice that the Python interpreter is compiled for just about every popular OS out there. I'm tired of supporting new Linux distros for C++ applications.\n\nThough lol @ OP:\n\n    while True and not self.shouldTerminate:\n\nMy dude, boolean logic, eh? 1 & X = X:\n\n    while not self.shouldTerminate:",
            "You can pip freeze and pipe it into requirements.txt rather than manually doing this",
            "Exactly, it makes debugging a lot easier, especially because type mismatches get caught by your IDE if you use typing for most methods.",
            "C++ and C# are best for Desktop applications (windows), C++ for Linux, or Swift for macOS. These languages are much easier to compile into an executable and obscure your code.\n\nPython isn\u2019t really designed to be compiled and run as an executable. It\u2019s a scripting language in steroids. Best used for automation or micro services hosted in the cloud.",
            "Oops.\n\nIt's like software business is an iterative process similar to design where things can't be spotless at the start, hence we have code reviews and CI/CD :)",
            "I think it would probably take me longer to make the same thing in c++/qt/fltk though. I like the rapid prototyping aspect of python and that I could do this in a few days during my spare time.\n\nBut if I had to pay someone to make me a high performance networked desktop app I'd pay him to make me a c++ one.",
            "Don't get me wrong, it was just a funny oddity that I wouldn't have expected in this type of project. There's plenty more to comment on this project if you want feedback to improve it.",
            "I hear you, and I agree it\u2019s a great prototyping language. However if you aim to be a Python software engineer, id recommend doing some projects that are suited more to Python. It\u2019ll help learning using more of the features of the language for what they are designed for"
        ]
    },
    "Rye-Tui, a Text-based User Interface (TUI) to manage rye projects": {
        "title": "Rye-Tui, a Text-based User Interface (TUI) to manage rye projects",
        "score": 5,
        "url": "https://www.reddit.com/r/Python/comments/1czvlns/ryetui_a_textbased_user_interface_tui_to_manage/",
        "content": "Hi everyone, Ive reached a state of my current project, where I want to share it with you, and gather some feedback. This is my first time using rye and I am surprised, how Hassle-Free building a package with it went.\nSource Code: [github](https://github.com/Zaloog/rye-tui)\n\n# Installation\n```bash\npython -m pip install rye-tui\n```\nfor CLI Tools I recommend using pipx or rye.\n```bash\npipx install rye-tui\n```\n```bash\nrye install rye-tui\n```\nAfter Installation you can open the TUI using `trye` in your Terminal. On first use a config file is generated. After that use `trye` again in your rye managed project\n\n# What My Project Does\nA Text-based User Interface (TUI) for [rye](https://github.com/astral-sh/rye) written in python using [Textual](https://github.com/textualize/textual/)\n\n# Current State\nCurrently rye-tui supports the following functionalities of rye:\n\n- creating new projects (flag-support coming soon)\n- adding normal and dev dependencies (flag-support coming soon)\n- pinning versions\n- Syncing (flag-support coming soon)\n- changing rye's configuration (sources and default coming soon)\n\n# Target Audience\nPython developers and rye users who like a UI to manage their rye projects.\n\n# Comparison\nTo my knowledge there is no similar tool for rye. Maybe the Anaconda UI comes closest for Anaconda Users.\n\n# Last Words\nFeel free to try(e) it out. Happy to hear your feedback.",
        "num_comments": 1,
        "comments": []
    },
    "I built a pipeline sending my wife and I SMSs twice a week with budgeting advice generated by AI": {
        "title": "I built a pipeline sending my wife and I SMSs twice a week with budgeting advice generated by AI",
        "score": 143,
        "url": "https://www.reddit.com/r/Python/comments/1cyy4hs/i_built_a_pipeline_sending_my_wife_and_i_smss/",
        "content": "**What My Project Does**:  \nI built a pipeline of\u00a0Dagger\u00a0modules to send my wife and I SMSs twice a week with actionable financial advice generated by AI based on data from bank accounts regarding our daily spending.\n\n**Details:**\n\nDagger is an open source programmable CI/CD engine. I built each step in the pipeline as a Dagger method. Dagger spins up ephemeral containers, running everything within its own container. I use GitHub Actions to trigger dagger methods that;\n\n* retrieve data from a source\n* filter for new transactions\n* Categorizes transactions using a zero shot model, facebook/bart-large-mnli through the HuggingFace API. This process is optimized by sending data in dynamically sized batches asynchronously.\u00a0\n* Writes the data to a MongoDB database\n* Retrieves the data, using Atlas search to aggregate the data by week and categories\n* Sends the data to openAI to generate financial advice. In this module, I implement a memory using LangChain. I store this memory in MongoDB to persist the memory between build runs. I designed the database to rewrite the data whenever I receive new data. The memory keeps track of feedback given, enabling the advice to improve based on feedback\n* This response is sent via SMS through the TextBelt API\n\nFull Blog:\u00a0[https://emmanuelsibanda.hashnode.dev/a-dagger-pipeline-sending-weekly-smss-with-financial-advice-generated-by-ai](https://emmanuelsibanda.hashnode.dev/a-dagger-pipeline-sending-weekly-smss-with-financial-advice-generated-by-ai)\n\nVideo Demo:\u00a0[https://youtu.be/S45n89gzH4Y](https://youtu.be/S45n89gzH4Y)\n\nGitHub Repo:\u00a0[https://github.com/EmmS21/daggerverse](https://github.com/EmmS21/daggerverse)\n\n**Target Audience:** Personal project (family and friends)\n\n**Comparison**:\n\nWe have too many budgeting apps and wanted to receive this advice via SMS, personalizing it based on our changing financial goals\n\nA screenshot of the message sent: [https://ibb.co/Qk1wXQK](https://ibb.co/Qk1wXQK)",
        "num_comments": 58,
        "comments": [
            "Interesting project, but sounds like a privacy nightmare.",
            "Unless I missed it, there is no example of the financial \u201cadvice\u201d output received from OpenAI, in any of the links you provided. That is the main feature here, can you showcase it?",
            "Congratulations, you spammed yourself",
            "A whole lot of fluff and no real substance. Why don't you have a screenshot of some advice being given?\u00a0",
            "I see you put significant work into this. How useful do you find it?",
            "Seems like a ton of complexity for something that could be hosted in a single EC2 and triggered with some cron jobs?",
            "Is budgeting the kind of task that needs automation?",
            "It's kind of sad you have to use these APIs to send text. No longer can you send it via an inbox. I tried earlier this year on a project and the carrier blocks it after 1-2.",
            "Can only imagine how annoying the SMSs will be after a few months.",
            "Sounds like a fun project, but why on earth send it as an SMS?",
            "You invested quite some work to give a lot of people your financial status",
            "SMS: Stop buying so much on Amazon x1000",
            "I think this is amazing. Most people here are missing the point.",
            "If you want a divorce, you are better off just telling her.",
            "> Dagger spins up ephemeral containers, running everything within its own container.\n\nThat kind of sounds like a sledgehammer solution.  How slow is it?",
            "party sloppy divide tidy thought many imminent squalid grey toy\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
            "It's a text belt ad. No one would use text for that when email is free.",
            "There is no doubt you can build a system like this.\n\nThe real questions are\n\n1. Should you? Probably not - data privacy and all that\n\n2. Do you want this in your life? No.\n\n3. Does it work as in good advise? Probably no",
            "Prepare for divorce.",
            "YASLAP - yet another solution looking for a problem.",
            "This is impressive work OP. Well done.",
            "If this is true, I guarantee your wife is not happy about this.",
            "Is this a fun project? Asking if you can give financial services advice without some regulatory license?",
            "Willingly shipping your financial data to OpenAI \ud83d\udc80",
            "Big time.",
            "Hoping for a llama-mix, laughed at trusting openai with personal data. Realized its not just openai, but also to a face hugger company and mongodb's cloud service and a text service. \n\nprivacy nightmare indeed.",
            "Exactly, OP - use an on-device model.",
            "\"You can save water cost by showering less. Don't call you parents, send an email instead. Bath water can be used to water house plants. You can save electricity by going to bed earlier.\"",
            "I shared a video. At the end of the video I showed the response and the message returned from successfully sending the SMSs. In case you missed it, I added a screenshot of the message sent. Still working on personalizing the response more",
            "Nono. He spammed his wife.\n\nI'd be so mad with him.",
            "Probably ends up giving out too much personal info \ud83e\udd37, idk why any sane person would want to connect that to their banks \u2620\ufe0f",
            "It makes his wife want to divorce him and he's been wanting her to break up with him for a while.",
            "Advice is a little generic, trying to figure out how to make it more useful by providing more actionable advice",
            "Even easier, use serverless for a cron lambda and it handles the whole stack with like 10 total lines in a yml.\n\n        functions:\n            transfer:\n            handler: handler.transfer\n            events:\n                - schedule: cron(15 3 ? * MON *)",
            "Some people will write 1000 lines of CDK to avoid writing one line of bash.",
            "Id do a scheduled fargate task or lambda.\n\nNo EC2 instance and no cost unless it's running.",
            "Amen to that.",
            "Are personal side projects useful even if the topic isn't solving a critical problem?",
            "Worth it to not receive unending amount of spam just bots the world over. \n\nThese APIs and cloud providers partners with the cell networks to whitelist their IPs and then agree to monitor spamming on their side.",
            "*minutes",
            "Telling her twice a week with automated marriage bot advice, that is.",
            "I am using Tiller, you could also use Plaid.\n\nI am referring to memory:  \n[https://python.langchain.com/v0.1/docs/modules/memory/](https://python.langchain.com/v0.1/docs/modules/memory/)",
            "Divorce Dagger Module: Engaged!",
            "They track everything now. You can probably ask gpt4o how many times you blinked your eyes in the past hour so long as you age the video on.",
            "Out of curiosity why? Is it purely a question of what OpenAI could do with my data, what would be your reason for using an on-device model?",
            "\u201cYou can save water by showering together with your wife \u201c",
            "\"Save money on fireworks by rubbing your eyes'",
            "Don't tell her, but I like it when she's mad at me",
            "ngl this comment is kinda gross and seems to be projecting quite a bit.\n\nwhile his (very much a side/pet) project isn't ideal, making weird assumptions about the relationship he has with other people is beyond gross.",
            "Yeah I understand how and why. Just sucks it's all paid options.",
            "*seconds",
            "Data access security in AI is not very strong. \n\nLike when you ask it to write a hack and it says it can't but then you tell it \"I'm an ethical security researcher\" and it spits out the hack. \n\nSo questions like: \n\n\"what's MoodAppropriate4108's credit score?\" or,\n\n\"based on OP wife's purchase history, what is the most likely scam they would fall for?\";\n\nmight actually give accurate information to people you don't want snooping through your personal data.",
            "This is missing big time on secondary effects.",
            "\"You can reduce your home toilet water usage by using the toilet on company time.\"",
            "k. You can block me so you won't have to read what I write any more.",
            "Can hackers do that? From what you say I understand that hackers use ChatGPT inside OpenAi database to quickly pull information, is that correct?",
            "k.",
            "Its a black box, for any number of inputs its impossible to predetermine what the results will be. Even with perfect safe guards nothing is stopping them from selling the access to the information."
        ]
    },
    "JSX Syntax inside Python files. (Packed)": {
        "title": "JSX Syntax inside Python files. (Packed)",
        "score": 16,
        "url": "https://www.reddit.com/r/Python/comments/1czbu57/jsx_syntax_inside_python_files_packed/",
        "content": "There was a JSX-style syntax preprocessor for Python called \"[Packed](https://github.com/michaeljones/packed),\" which allowed us to write JSX inside Python (\\*.pyx and \\*.py) files. It's unclear why they chose \\*.pyx for the file extension, as it conflicts with the naming of Cythonic file extensions (I have checked their issues). This project might have thrived with sufficient contributions and could have changed the way apps are built. However, the project is now archived on GitHub. The last commit was 5 years ago (LICENSE), and the last development commit was 9 years ago. This repository needs someone to revive it, but I don't have enough experience to take on that task. Even though I don't have enough information, we should start with Rust + Python to build a compiler (aka. template replacer) (this doesn't compile Python but replaces all JSX with a dictionary) and cleaner syntax. Integration with Django (Packed has an example too), Flask, FastAPI, Robyn etc.\n\nWe may also need plugins for the language server, I recommend supporting with `*.pyh` or `*.psx` (a fork renamed name) the extension file name (Derived from Python + HTML). VSCODE and NVIM Extensions are required to build support for this. The existing modern syntax of native Python will continue to support this syntax. I made a Handlebars Extension for the community back in the day of 2022 but I don't want to continue the development for it because later I disliked the syntax of handlebars (opinion, you're point of view may contrast with my thoughts). We can use emmet for writing easy HTML.\n\n    @packed\n    def tag(self):\n        share = get_share_link()\n        return <a href={share}>Share on internet</a>\n\nThe main point of view is that somehow make returnable components as \ud83d\udc46  \ninstead of doing this \ud83d\udc47\n\n    def app():\n        return div(div(p(\"Hello World\")),span(\"Not a Good Approach for someone (opinion)\"))",
        "num_comments": 10,
        "comments": [
            "Dropbox has a similar project but uses Python2 only and is too old (12 years):  \n[https://github.com/dropbox/pyxl](https://github.com/dropbox/pyxl)  \nThough, we need a modern alternative.",
            "There are tons of features:\n\n1. Ability to use emmet for writing HTML inside Python Code\n2. Syntax Highlighting like JSX\n3. Auto Rename Tag\n4. Auto-complete for tags\n5. This will make it easier to build web apps than using nodejs",
            "From what i have seen the only thing we would need to do is have that rust compiler you recommend add strings to the jsx return and then compile the file into a pyc file.  \nIf you see how the module generates html it litterally just returns html as a plain string so you dont need to do much but make that compiler and the extentions for it in vscode and nvim\nSo you can delete the to_html code and some other parts and get the same thing. It should provide much faster file generation",
            "Its funny you broght this up  [RevolutionaryPen4661](https://www.reddit.com/user/RevolutionaryPen4661/), with the recent hype around React Server Components (RSC) (and react 19), I had a similar thought.\n\nWhile I have not gotten very far (and web dev is a bit outside of my core expertise), I have started mocking up a simple library (if you can call what I have so far that) which uses:  \n - pydantic (state serialization/message protocol/html serialziation)  \n - react (for rendering the server sent components; I would have loved to use pyscript, but it seems pretty half baked ATM TBH)\n\n - A custom parser (using lark) to convert the \"html\" to pydantic models  \n - a websocket for passing the components and events\n\nIf you are interested on working on something like this, feel free to reach out (my name is Matt) and maybe we can combine our efforts to make web dev a reality in python.",
            "https://github.com/gvanrossum/pyxl3 https://github.com/pyxl4/pyxl4 https://github.com/twidi/mixt",
            "You can do that, but just like \"go\" has [templ](https://templ.guide/) (it enables Go developers to write direct HTML without strings or backticks inside the Go code) and the Python community needs one like this too. I believe that this may change how we develop apps nowadays. These are the pros of  having this idea (scraped from templ docs):  \nServer-side rendering: Deploy as a serverless function, Docker container, or standard Go program.\n\n* Static rendering: Create static HTML files to deploy however you choose.\n* Compiled code: Components are compiled into performant Go code.\n* Use Go: Call any Go code, and use standard\u00a0`if`,\u00a0`switch (match)`, and\u00a0`for`\u00a0statements.\n* No JavaScript: This does not require any client or server-side JavaScript.\n* Great developer experience: Ships with IDE autocompletion.",
            "You won't believe I'm 16 years old who just fixed age-old code to make it work and made some performance improvements. I don't think I have enough experience to handle this. Even, I know only half of Django. I thought it would be a better idea to fork it and make one. I deleted nutritious (my perfect working fork). Since the dependencies were GPL-licensed I had to delete the project from GitHub yesterday (cuz no one wanted to make a web framework on that) and decided to start from new. I planned to introduce XML writing in Python (basically JSX).\n\nhere's the fixed code:  \n[https://wastebin-1-f5614495.deta.app/doc/init%20file](https://wastebin-1-f5614495.deta.app/doc/init%20file)  \n[https://wastebin-1-f5614495.deta.app/doc/mjvjaykt](https://wastebin-1-f5614495.deta.app/doc/mjvjaykt)",
            "Sadly none of those have been touched this decade.",
            "Well in that case you could just use jinja2+html. It shouldnt be hard in this case at all",
            "I am familiar with Jinja2. However, this is a proof of concept to showcase how easy it can be to build web apps with Python using only Python and JSX. I have also come across Ludic, which has drawn inspiration from this repository.  \nI suggest you take a look at my second comment (a ton of features. See full discussion)"
        ]
    },
    "We built open-source SDK for adding custom code interpreters to AI apps": {
        "title": "We built open-source SDK for adding custom code interpreters to AI apps",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1czr85u/we_built_opensource_sdk_for_adding_custom_code/",
        "content": "**What My Project Does**\n\nHey everyone! I'm the CEO of the company that built an [SDK that makes it easy to build custom code interpreters for AI apps](https://github.com/e2b-dev/code-interpreter).\n\nWe're a company called E2B [0]. We're building and open-source [1] secure environments for running untrusted AI-generated code and AI agents. We call these environments sandboxes and they are built on top of micro VM called Firecracker [2]. We specifically decided to use Firecrackers instead of containers because of their security and ability to do snapshots.\n\nYou can think of us as giving small cloud computers to LLMs.\n\nWe recently created a dedicated SDK for building custom code interpreters in Python or JS/TS. We saw this need after a lot of our users have been adding code execution capabilities to their AI apps with our core SDK [3]. These use cases were often centered around AI data analysis so code interpreter-like behavior made sense\n\nThe way our code interpret SDK works is by spawning an E2B sandbox with Jupyter Server. We then communicate with this Jupyter server through Jupyter Kernel messaging protocol [4]. Here's our cookbook showing how to add code interpreter to different models [5].\n\nWe don't do any wrapping around LLM, any prompting, or any agent-like framework. We leave all of that to our users. We're really just a boring code execution layer that sits at the bottom. We're building for the future software that will be building another software.\n\nOur long-term plan is to build an automated AWS for AI apps and agents where AI can build and deploy its own software while giving developers powerful observability into what's happening inside our sandboxes. With everything being open-source.\n\nHappy to answer any questions and hear feedback!\n\n\n**Target Audience**\nYou can use it in production. We have companies using us in production already.\n\n\n**Comparison**\nAlternatives we usually see are serverless functions or Docker containers. Both have security issues. With serverless functions you can leak data between users and with containers you don't really have true isolation. Containers were made for packaging and portability, not security.\n\n\n**Links**\n\nhttps://github.com/e2b-dev/code-interpreter\n\n[0] https://e2b.dev/\n\n[1] https://github.com/e2b-dev\n\n[2] https://github.com/firecracker-microvm/firecracker\n\n[3] https://e2b.dev/docs\n\n[4] https://jupyter-client.readthedocs.io/en/latest/messaging.html\n\n[5] https://github.com/e2b-dev/e2b-cookbook",
        "num_comments": 1,
        "comments": [
            "man is into ai way too much"
        ]
    },
    "I made a small Python script that uses NASA'S APOD API to set cool backgrounds on a Windows machine": {
        "title": "I made a small Python script that uses NASA'S APOD API to set cool backgrounds on a Windows machine",
        "score": 48,
        "url": "https://www.reddit.com/r/Python/comments/1cz43o6/i_made_a_small_python_script_that_uses_nasas_apod/",
        "content": "[https://github.com/william7491681/APOD\\_Wallpaper\\_Script](https://github.com/william7491681/APOD_Wallpaper_Script)\n\n# What my project does\n\nNASA has a ton of accessible API's, one of which being the APOD (Astronomy Picture Of the Day) API. I made a script to get the last 9 pictures of the day and set them as my Windows 10 background, and then used task scheduler to have the script re-run every day at noon and whenever the computer boots up.\n\nIt's fairly hard coded for my setup (specific file paths, 1920x1080 monitor, etc), but it shouldn't be too hard to change if one wanted to.\n\n# Target audience\n\nAnyone who likes space backgrounds\n\n# Comparison\n\nIdk, automod made me put this section",
        "num_comments": 5,
        "comments": [
            "Haha, nice! I did the same thing, but with r/earthporn",
            "It could ne a good idea to leave each user specified his own path",
            "Nice! Great readme",
            "Sometimes I feel, APIs are real beneficial and super cool",
            "Yeah, I wasn't planning on doing anything of the sort at first, but it didn't take too long to add something like that in. I just made a quick update."
        ]
    },
    "DeepFusion: a highly modular Deep Learning Framework.": {
        "title": "DeepFusion: a highly modular Deep Learning Framework.",
        "score": 4,
        "url": "https://www.reddit.com/r/Python/comments/1czej7h/deepfusion_a_highly_modular_deep_learning/",
        "content": "**What My Project Does:**\n\nHello all, I am a student at Stanford University, I was on a gap year due to medical conditions and to utilitze my time I was studying deep learning.\n\nAnd Voila...\n\nI've developed a deep learning library, [**DeepFusion**](https://github.com/atharvaaalok/deepfusion)!\n\n**Details:**\n\nIt's customizable and has an easily accessible and highly intuitive codebase. One can just dive right in and effortlessly understand the source code.\n\nYou can download it from:\n- github at https://github.com/atharvaaalok/deepfusion\n- or install using `pip install deepfusion` (easy!)\n\nFor a series of examples explaining the usage and features refer [demo](https://github.com/atharvaaalok/deepfusion/tree/main/demo) or [tutorials](https://github.com/atharvaaalok/deepfusion-examples).\n\n**Target Audience:**\n\nMachine learning and python enthusiasts.\n\n**Comparison:**\n\nDeepFusion allows explicit access to all activations in a neural network, therefore, making applications such as neural style transfer much easier to perform. It also provides an easy user interface for forward and backward pass profiling, multiple loss functions, automated training, gpu training etc.",
        "num_comments": 3,
        "comments": [
            "It is amazing!",
            "This is the motivation I needed ![gif](emote|free_emotes_pack|sob)! Thanks!!!"
        ]
    },
    "TPC-H Cloud Benchmarks: Spark, Dask, DuckDB, Polars": {
        "title": "TPC-H Cloud Benchmarks: Spark, Dask, DuckDB, Polars",
        "score": 77,
        "url": "https://www.reddit.com/r/Python/comments/1cyqj6c/tpch_cloud_benchmarks_spark_dask_duckdb_polars/",
        "content": "I hit publish on\u00a0[a blogpost](https://docs.coiled.io/blog/tpch.html)\u00a0last week on running Spark, Dask, DuckDB, and Polars on the TPC-H benchmark across a variety of scales (10 GiB, 100 GiB, 1 TiB, 10 TiB), both locally on a Macbook Pro and on the cloud.\u00a0 It\u2019s a broad set of configurations.\u00a0 The results are interesting.\n\nNo project wins uniformly.\u00a0 They all perform differently at different scales:\u00a0\n\n* DuckDB and Polars are crazy fast on local machines\n* Dask and DuckDB seem to win on cloud and at scale\n* Dask ends up being most robust, especially at scale\n* DuckDB does shockingly well on large datasets on a single large machine\n* Spark performs oddly poorly, despite being the standard choice \ud83d\ude22\n\nTons of charts in this post to try to make sense of the data.\u00a0 If folks are curious, here\u2019s the post:\n\n[https://docs.coiled.io/blog/tpch.html](https://docs.coiled.io/blog/tpch.html)\n\nAnd here's\u00a0[the code.](https://github.com/coiled/benchmarks/tree/main/tests/tpch)\u00a0Performance isn\u2019t everything of course.\u00a0 Each project has its die-hard fans/critics for loads of different reasons. I'd be curious to hear if people want to defend/critique their project of choice.",
        "num_comments": 10,
        "comments": [
            "I'm excited to see benchmarks that don't use the polars streaming engine, or that show both!\n\nMy understanding was that Polars wins on performance nearly everywhere, short of clustering",
            "Oh, my colleague also recently wrote this post on how he and his team made Dask fast.https://docs.coiled.io/blog/dask-dataframe-is-fast.html",
            "\"Spark locally on a Macbook Pro\".\n\nInteresting.",
            "It would be interesting to see arrow ballista alongside those",
            "> Polars with a on performance  \n  \nWhat does this mean? Did you mean to say \u201cwiffs\u201d, i.e., performs poorly?",
            "Hey Matt, Are these numbers on Polars still the\\`polars-streaming\\` engine and not our default engine? \n\nFor context to readers. Our \\`streaming\\` engine is still in beta and not our default choice. The performance characteristics and correctness of our default engine are quite different. We see our \\`streaming\\` engine as being in beta. Currently, it is being completely redesigned to address known shortcomings.",
            "Wins on performance *\n\nMy bad haha",
            "Yes, they are still the polars-streaming engine.  There are disclaimers in the blogpost specifying this going out shortly.  My apologies on the delay here.\n\nOur plan is not to use the default engine because for the most part it doesn't complete queries in these hardware configurations (we can do this though if you prefer).  This is a case, I think, where different biases in hardware selection can cause dramatically different benchmark results.",
            "Thanks! That's what I figured as I've only heard positive things on the performance of Polars.",
            "> Our plan is not to use the default engine because for the most part it doesn't complete queries in these hardware configurations (we can do this though if you prefer).\n\nYes, I'd prefer that. We are designed to do well on the in-memory use case and our default engine is our best engine for that case.\n\nWe aren't happy with the streaming engine that's why we completely redesign it atm."
        ]
    },
    "MyTimer v1.3: A Geeky Timer for Terminal Enthusiasts": {
        "title": "MyTimer v1.3: A Geeky Timer for Terminal Enthusiasts",
        "score": 10,
        "url": "https://www.reddit.com/r/Python/comments/1cz2uyd/mytimer_v13_a_geeky_timer_for_terminal_enthusiasts/",
        "content": "GitHub Repo: [https://github.com/sepandhaghighi/mytimer](https://github.com/sepandhaghighi/mytimer)\n\n**What My Project Does:**\n\n**MyTimer** is a Python CLI project that provides a simple, efficient timer for terminal users, particularly targeting the geek community. It allows users to set timers directly from their command line interface, offering a distraction-free experience.\n\n    mytimer --hour=12 --minute=34 --second=56 --alarm --alarm-repeat=5\n    \n     ___    ______          ______   _     _         _______  _______   \n    (___)  (_____ \\        (_____ \\ | |   (_)       (_______)(_______)  \n       _     ____) )   _    _____) )| |_____    _    ______   ______    \n      | |   / ____/   (_)  (_____ ( |_____  |  (_)  (_____ \\ |  ___ \\   \n     _| |_ | (_____    _    _____) )      | |   _    _____) )| |___) )  \n    (_____)|_______)  (_)  (______/       |_|  (_)  (______/ |______/   \n\n**Target Audience:**\n\nDevelopers who spend a significant amount of time working in the terminal :)\n\n**Comparison:**\n\n1. **MyTimer** supports more features compared to [countdown](https://github.com/antonmedv/countdown)\n2. **MyTimer** offers a greater variety of faces and functions than [timer-cli](https://github.com/sobrinojulian/timer-cli)",
        "num_comments": 0,
        "comments": []
    },
    "Thank You PyConUS 2024 !!!": {
        "title": "Thank You PyConUS 2024 !!!",
        "score": 164,
        "url": "https://www.reddit.com/r/Python/comments/1cyceoq/thank_you_pyconus_2024/",
        "content": "First timer this year, currently at the airport leaving Pittsburgh after 6 days of PyCon... \n\nI've never seen such an intelligent, inclusive, humble, diverse, and inspiring group of human beings.  The Python community serves as a beautiful model of what tech culture should strive towards. I could go on and on about how much fun I had, but in short, thanks to all the volunteers, staff, and FOSS developers that have cultivated such an amazing culture.",
        "num_comments": 24,
        "comments": [
            "Yay!",
            "I\u2019m from pittsburgh and had no idea this was a thing \ud83d\ude2d\ud83d\ude2d\ud83d\ude2d. Glad you enjoyed yourself!!",
            "This was my first year, too! I had a blast, and I'm definitely gonna try to go again next year.\n\nThanks to everyone who helped organize =]",
            "I really really need to remember to go to this. I've wanted to go every year for years,",
            "PyconUS was also my first time and it was such a blast! As I'm still a student learning Python, the event was such an eye opener to all the things that can be done using python, libraries, etc. I honestly can wait for 2025 and hopefully I can bring more folks from my CS club to attend!",
            "I was there. PyCon rocked!",
            "So sad I was forced to miss it ... Can't wait till next year though!",
            "Are there going to be some records of the tutorials/talks somewhere?",
            "Cant wait to see all pycon talks on YT",
            "Did they still require masks ?",
            "Nice words. Feel inspired from these words.",
            "Won't attend again. Don't like politics in a tech conference.",
            "This guy has a cool lightning talk \u261d\ufe0f\ud83d\ude04",
            "It's in Pittsburgh again next year!",
            "Yes not everyone in Pittsburgh knew ...",
            "Yes, I'm not sure when they are released, but people said they get put up on YouTube eventually... There were so many good talks that I wasn't able to see all of them and am looking forward to the release.  \n\nA few notable talks I thought were interesting: \n\n* The design of everyday APIs\n* Pydantic Power Up\n* Geospatial Validations with FastAPI and PostGIS\n* Build in-browser 3d experiences with webGL and PyScript\n* How Python harnesses Rust through PyO3",
            "Yes - they required an N-95 or equivalent unless you were speaking or actively eating/drinking; same as last year.\n\nThat was the main reason why I decided to attend online rather than in-person.  I'm not an \"anti-masker\" -- I've had 5 or more COVID boosters, attended multiple N-95 requiring Python conferences in-person (including PyCon 2023 in SLC!), but at this point I'm just \"over it\" in terms of masking *in 2024*.   Outside of Python, there is basically no other tech conference that still requires masks.   I asked a friend who is a doctor and she said her medical conferences haven't required masks \\*in years\\*.\n\nHopefully 2025 (Pittsburgh) they will relax this.  I love PyCon (2024 was my 5th?).  I look forward to it every year!\n\nBTW: 2026-2027 will be in Long Beach, CA.",
            "\ud83d\ude01",
            "Heheheh. I have a video of it here: [a music video I created with terminal output from a Python program](https://www.youtube.com/watch?v=Sjk4UMpJqVs). It's \"scroll art\", a form of animated ascii art that doesn't require a lot of programming knowledge. I make most of them in Python but I've ported a few to JS for this website: https://scrollart.org",
            "I'll be there!",
            "Wow, yea I\u2019m also as far from an anti masker as it comes. I keep up on all my boosters, probably did the mask thing longer than needed. But it\u2019s really just not a thing anymore. We have vaccines, we have a very effective treatment. I\u2019ve been to several other conferences over the past few years that didn\u2019t require it either.",
            "That\u2019s\u2026total bullshit.\n\nThese people are delusional. I wouldn\u2019t go, either.",
            "It was still worth it but yeah I was sick of it too \ud83d\ude2d\ud83d\ude2d"
        ]
    },
    "Speed improvements in Polars over Pandas": {
        "title": "Speed improvements in Polars over Pandas",
        "score": 144,
        "url": "https://www.reddit.com/r/Python/comments/1cy9vpt/speed_improvements_in_polars_over_pandas/",
        "content": "I'm giving a talk on polars in July. It's been pretty fast for us, but I'm curious to hear some examples of improvements other people have seen. I got one process down from over three minutes to around 10 seconds.   \nAlso curious whether people have switched over to using polars instead of pandas or they reserve it for specific use cases. ",
        "num_comments": 80,
        "comments": [
            "I've been using polars for everything I do nowadays. Partially for the performance, but now that I've learned the syntax I would stick with polars even if there were no improvements at all on that front. Expressions are just *that good* for me: I can build huge lazy queries that can be optimized, rather than having to figure out all the pandas functions and do everything eagerly. \n\nI have got to the point that if I have to work with some codebase that does not support polars for some reason, I'll still do everything in polars and then convert the final result to pandas rather than doing anything in pandas. \n\nThe two things pandas does better than polars is styling tables and pivot tables. Pivot tables in particular are so much better with pandas, especially when I have to group by multiple variables rather than only one.",
            "Polars is the first thing i reach for nowadays. Once i got my head around the way that functions chain it made a lot more sense (really analogous to something like dplyr in some ways). I don't honestly care as much about the speedup as i do about it making more sense for how i manipulate data. I also find that my data are cleaner after working with them in polars, because of the enforced typing system it's been convenient at exposing issues with data (important for me because i work with a lot of really badly-formatted data). I treat the speedup more as an expansion of usability, meaning i don't have to reach for something different when i have a huge dataset, i just go to the lazy API and continue on as before",
            "It cut down a script that took nearly an hour to about 3 minutes. I've committed to polars so hard since January that I've more or less forgotten panda's syntax... which is kindof a problem when I have to go back to older projects :/",
            "So fast. I use pandas only in legacy code nowadays or with co-workers that don't know polars.\n\nI've also experienced better memory usage due to LazyFrame (which is even faster compared to standard polars DataFrame).\n\nBut the aspect I love the most is the API. Pandas is old, inconsistent and inefficient, even with years of experience I still have to rely on an ocasional Stack Overflow search to grab a mysterious snippet of code that somehow works. I learned full polars in about a week and only have to consult the docs because of updates and deprecations, given it's still in development.\n\nWith that in mind, pandas still has a lot of features that aren't present in polars, table styling being the one I use the most. Fortunately, conversion to/from polars is a breeze, so no problems there.\n\nOverall, I see no reason to learn pandas over polars nowadays. It's easier, newer, more intuitive and faster.",
            "I built a local web app in Dash that loaded data from a variety of systems and did an ETL for further analysis. The system was a behemoth (>1.2 GB in libraries) and underpinned by Pandas. Data loads would take roughly 5 minutes. Combine that with distribution issues, it never lived up to its potential.\n\nI rewrote the basic ETLs to run from an embeddable instance of Python with Polars (~175 MB) that I call from an Excel workbook via VBA Macro.\n\nThe Polars code feels exponentially faster. The \"batteries\" are smaller, and now my colleagues are actually using it! \n\nThe only trouble I've run into is date parsing. Pandas seems to do much better at automatically parsing the date regardless of the format, which unfortunately is one of the main things I need my code to do. I've built a UDF to coalesce a long list of potential formats, but it just feels a bit \"Mickey Mouse.\" Otherwise, I've got nothing but good things to say about Polars.",
            "Had a weird Polars issue using postgres when reading/writing from a database. Switched back to pandas and it solved the issue.\u00a0",
            "We're basically parsing [SLURM sacct job details](https://slurm.schedmd.com/sacct.html) (a shared university HPC cluster, so *tons* of activity), the original script was using pandas. I re-wrote this process to polars, and got the runtime of \\~30 minutes down to less than 3 minutes, while increasing time domain resolution from 5 minutes to 1 minute.\n\nLots of this gain came from using `scan_csv()` and `LazyFrame` while using... uh, I forget the term, but the expression syntax that uses the `|` pipe symbol?\n\nThe original script was pretty slap-dash, but my rewrite isn't that great either... exhibited by the fact I need to stay on `polars==0.16.9` - anything newer and it breaks in new and exciting ways that I can't be bothered to debug.",
            "Seems like a big hurdle is that it's still in development, with changes to the API, deprecations, etc. Do you know if the Polars team have a rough timeline for a 1.0 release?",
            "I think a big reason why it\u2019s so much faster (besides rust concurrency, lazy evaluation, etc) is that polars was built in rust and then bound to Python, whereas pandas was written in Python with C bindings for the tough spots. Polars is just a more cohesive approach, and the ecosystem is set up in a way that each rust crate has many dependencies, and if any one of them makes a speed improvement, all the downstream packages have the ability to benefit by just creating a new release, and PyO3 takes care of all the interfacing. I\u2019m writing a lot of rust for a library with Python bindings right now, it\u2019s so easy it\u2019s almost magical",
            "I remain loyal to Wes McKinney.",
            "I'm currently working on optimizing some code  at my job. I chose Polars and the transition has been smooth. With 10 lines of code was able to shave off ~10min on the runtime. Not even close to finished to. Trying to get the Quants to start writing new code in Polars instead of Pandas. I think once I'm done, they will be convinced by the results.",
            "I tried polars a few years ago when designing some qa software and duckdb was still faster so I stuck with that. I'll have to revisit it and see if it has indeed improved.\nPandas does have a lot of legacy support for data that isn't structured as expected, and it's reliable. I had backup functions written in it and expect to continue that until I see stability equalized.",
            "I had a script whose processing time went from 20min to 90 seconds,  i do use polars a lot nowadays but just to join or concat converted pandas dataframes and convert it back to pandas (my team mostly uses pandas).  Cant convert a lot of other scripts as most of them are multiprocessing based and polars doesn\u2019t love being inside multiprocessing, i get memory bugs which completely kills the entire program\n\nI\u2019m one of the weird people who likes pandas api especially like adding a column or a single static value to a column. But pandas lately has changed too much behaviour to be okay in production for me and trying to get everyone on polars.",
            "Read excel\u2019s calamine is like 30x speed up \n\nI am memory constrained on some of my VMs and the ability to scan the parquet/csv for the rows that I need instead of loading in a massive file in its entirety is awesome.",
            "Does it play nicely with sklearn? \n\nI\u2019ve always hear good things about polars but I know pandas so well and a lot of my custom modules uses pandas datafrmae that I never found the use case to move to polars.\n\nMy understanding is that polars don\u2019t do things in memory, but plenty of ML packages train in memory.  Any ideas how well polars play with ML packages?",
            "I primarily swapped from\npandas to Polars for remote execution of distributed dataframes in Ray. Pandas was causing out of memory errors (and incurs a copy of the arrow backed dataset) but Polars doesn\u2019t which makes handling TB sized datasets much easier.\u00a0\nAdditionally I had a custom apply function written in pandas which took 20min but takes 30sec in polars which is a significant improvement.",
            "I switched everything to polars except the things it is missing that I have to switch back to pandas for.  However, it wasn't really for speed, but for the syntax.",
            "Yes. Polar is great in terms of both performance and syntax.",
            "Basically null for me! But really, we get some huge and pretty gnarly (read=dirty) flat files from vendors and pandas handles them with zero issue. I\u2019ve attempted to get polars to handle them with no success thus far. There are a few implementations where I\u2019ll get the files read in and cleaned up with pandas, then send it over to polars, but even then, I don\u2019t really see a huge speed boost. \n\nAnd for what\u2019s it worth, I\u2019m not a hater, actually love rust and the ecosystem, but as a data engineer by day, my superiors would frown if I spent too much time tinkering with a library instead of just being productive. IYKYK!\n\nJust my anecdotal experience. Grace and peace mi amigos.",
            "When I read things about going from 3 mins pandas to 10 seconds polars; It makes me think that you did not really write good pandas code to begin with, its less of a advertisement for Polars. I am sure you could write bad slow code for polars as well.",
            "I tried it but didnt find much speed improvement compared to pandas with multithreading. Didnt try lazy dataframes though",
            "I loved Polars the couple of times I used it. But installing it in a way that works cross platform is enough of a pain in the ass that I've reverted to Pandas.\u00a0\n\n\nWith Polars, I can write my code on one machine, commit to git, then pull on another machine, and the entire thing breaks because of Polars. Most frequently, it happens in Jupyter notebooks, where simply importing Polars crashes the entire kernel.\u00a0\n\n\nI've tried installing the package meant for lower end devices, I don't remember the name off the top of my head, but that leads to the same issues.\u00a0\n\n\nI can't for the life of me find a way to reliably add Polars to my dependencies and have it \"just work\" the way that Pandas does.\u00a0\u00a0\n\n\nI'm also looking more at Ibis, but I just keep coming back to Pandas for the same reasons.. it's familiar, there are no surprises between machines when I try to pip install -r requirements.txt, and it's \"fast enough.\"\u00a0\u00a0\n\n\nIf I could get Polars to reliably install and run without error on any machine and inside notebooks the way I can with Pandas, I'd be using it for everything.\u00a0",
            "In one of my project, we were using pandas library, but then after knowing of polars, we switched to polars library.\n\nBut it wasn't as simple as changing the import statement. Lots of syntax had to be changed which caused us trouble and many equivalent functionalities weren't present for the same in polars.\n\nSo we just made the reading the file functionality to polars, and then changed the dataframe back to pandas df, this helped us reduction in our execution time.",
            "I use polars as my daily driver, and every code revision I'm actively replacing as much of my old pandas code as I can. \n\nI have a project that reads from two different tables, 6 csvs and two xlsx files and compiles everything into a single table that is then shaped and sent to accounting for vendor rebates and it takes around 15 seconds to run. It's only 5-10k rows at output but it's so much faster than when I tried the same thing in crystal reports with some of the joins taking place in pandas beforehand (10-15 minutes).\n\nI have a 5-7 minute pandas script I'm eying at replacing with polars as well but I went pretty deep into the features - it is going to take a while to unwind that one. It parses a heavily formatted xlsx and extracts out po data to be fed into several other reports. Row count is high enough that excel hangs for 10ish minutes before I can even open the file.\n\nOnly thing I struggle with for it is getting it to read complex json without a parser class or function helping it but I have a similar struggle with pandas.",
            "Originally I was writing all of my data processes in Pandas and I felt like I was wrestling with indexing, slow file reading (as our data sat on a network drive -- something out of my teams' control), and I also wasn't a big fan of the syntax.\n\nI had heard about Polars previously but chalked it up to hype. However, once I took the time to test Polars on a new project out of curiosity, I saw how much faster it was performing than Pandas -- so much so that I rewrote all of my existing Pandas processes into Polars and gained better performance across the board. I don't miss Pandas whatsoever.\n\nNow whenever there is a situation that comes up where I actually need to utilize a functionality available only to a Pandas DataFrame, I just do convert my Polars DataFrame to Pandas using to\\_pandas(). Beyond niche utility, there is basically no reason for me using Pandas over Polars. Realistically, unless Pandas was to be rewritten from scratch, it just cannot compete with the performance of Polars out-of-the-box. The only thing Pandas has going for it at this point is that it is a mature library that has a high adoption rate across the industry.",
            "you can pass multiple values to the \\`columns\\` argument - out of interest, do you have an example of an operation you found lacking?",
            "What are your thoughts on duckDB?",
            "You\u2019ll pick it up again pretty quickly!",
            "Have you checked out Great Tables for table styling? It supports Polars very well",
            "The more consistent api in polars does worlds for my brain.",
            "Any resources you used to learn polars?",
            "Just wondering, pandas 2.0 brings the Arrow backend to pandas (over numpy), so do you still see a significant difference? Are there other important factors that make polars faster?",
            "If you can send some details (ideally log an Issue?) I can look at that; database connectivity has been getting some love this year and I have more planned on that front, including some per-driver/backend type inference improvements: [https://github.com/pola-rs/polars/issues/new](https://github.com/pola-rs/polars/issues/new)",
            "Yeah it\u2019s not perfect. I\u2019ve had some trouble with typing where I\u2019ve had to switch back to pandas",
            "Do you have the memory corruption bug by any chance? I get that a couple of times on my cluster and i can\u2019t figure why?",
            "I'm confused by the \"pipe symbol\" bit. Doesn't that mean boolean `or` in polars? Or do you mean match/case statements?",
            "This makes me think how pandas became 1.0 only a couple of years ago",
            "Rust developers release 1.0 of their library impossible challenge",
            "I think Wes actually understands and appreciates what they are doing with Polars and would do the same if he could start over with Pandas",
            "When you say you're using duckdb you mean that you're writing SQL-like essentially for your use case?",
            "out of interest, which pandas behaviour changes have been most painful?",
            "Can't you do this in pandas with chunking?",
            "I actually added dedicated PyTorch and Jax integrations for Polars this month - take a look at the new \"to\\_torch\" and \"to\\_jax\" DataFrame methods and their respective docstrings, which have a few examples (including one loading from an sklearn dataset). Can export a DataFrame as a single 2D tensor/array, dict of individual 1D tensors/arrays or (for torch) a dedicated PolarsDataset object that is drop-in compatible with TensorDataset  ;)",
            "Polars does things in memory. It has a whole eager API.\n\n\nAnd yes, there scikit-learn support. Scikit-learn docs even have examples using Polars.",
            "Sklearn is leaning towards changing the default from pandas to polars in their docs. https://github.com/scikit-learn/scikit-learn/issues/28341\n\nAlso pandas team has a new triager that just seems intent on closing as many issues as possible without caring a world for UX. It's a huge turnoff for me to continue contributing anymore.",
            "Would you mind sharing this custom function? I would like to replicate your use case and compare between pandas and polars.",
            "i think many people write bad pandas and then complain about it, but polars is faster and harder to write slow code",
            "Disagree mainly because Polars has several performance features that are impossible to replicate in pandas such as lazy evaluation and the query optimizer (among several others). Thats a bit hand wavy of you imo. \n\nIve worked with pandas for several years and polars with like a month or two and already my exploratory rough draft Polars scripts dominates pandas scripts written with multiple peoples input and optimizations. \n\nEven if its a git gud issue why would I even care if I can write faster code as a beginner without even trying that takes domain experts in pandas to reach similiar performance",
            "Thanks for coming in with an insult. Very nice. I think doing a direct translation of pandas to polars and getting these results is a pretty good indication of what polars can do. I\u2019ve talked with past colleagues who have seen similar improvements as well.",
            "`pip install polars-lts-cpu`",
            "Yes, sure. Say I have an example like this.\n\n    df = pl.DataFrame(\n        {\n            \"sex\": [\"M\", \"M\", \"F\", \"F\", \"F\", \"F\"],\n            \"color\": [\"blue\", \"red\", \"blue\", \"blue\", \"red\", \"yellow\"],\n            \"case\": [\"1\", \"2\", \"1\", \"2\", \"1\", \"2\"],\n            \"value\": [1, 2, 3, 4, 5, 6],\n        }\n    ).with_row_index()\n    \n\nWith Polars I have to do this\n\n    df.pivot(values=\"value\", columns=[\"color\", \"sex\"], index=\"case\", aggregate_function=\"sum\")\n\n`index` is required, even if I don't care about providing one. The result is also quite unwieldy because having all the combinations of values on one row rather than stacked becomes really hard to parse really quick if there are too many combinations.\n\n    case\t{\"blue\",\"M\"}\t{\"red\",\"M\"}\t{\"blue\",\"F\"}\t{\"red\",\"F\"}\t{\"yellow\",\"F\"}\n    str\ti64\ti64\ti64\ti64\ti64\n    \"1\"\t1\tnull\t3\t5\tnull\n    \"2\"\tnull\t2\t4\tnull\t6\n\nWith Pandas I have\n\n    df.to_pandas().pivot_table(values=\"value\", columns=[\"color\", \"sex\"], index=\"case\")\n\nand I get\n\n    color\tblue\tred\tyellow\n    sex\tF\tM\tF\tM\tF\n    case\t\t\t\t\t\n    1\t3.0\t1.0\t5.0\tNaN\tNaN\n    2\t4.0\tNaN\tNaN\t2.0\t6.0\n\nwhere I can reorder the variables in `columns` to get different groupings, and the view is way more compact and easier to read. Pandas' version is also much closer to what I would build with a pivot table in Sheets, for example.\n\nI have been working with data that I had to organize across 4+ dimensions at a time over rows/columns, and there's no way of doing that while having a comprehensible representation using exclusively Polars pivots. I ended up doing all the preprocessing in Polars and then preparing the pivot in Pandas just for that.",
            "I have never heard about Great Tables. It looks great! Thanks for the shout out",
            "The docs",
            "The docs and there\u2019s a udemy lesson that can get you started.\n\nBut I feel like for most stuff the syntax flow really well so u rarely have to reach for support",
            "Yes. There is much more difference than the way we hold data in memory (arrow). Polars has much better performance. Here are the benchmarks against pandas with arrow support.\n\n\n\nhttps://pola.rs/posts/benchmarks/",
            "Apart from the benchmark, iirc pandas doesn't have a lazy API, which can both increase performance depending on the pipeline and make it possible to work with larger-than-memory datasets.",
            "Will do, I\u2019ll have to go back and check my logs. Thanks",
            "Sorry, I don't actually run the cluster - this is the first I'm hearing of something like this.",
            "Stuff like this:\n\n    df = df.filter(\n        ((pl.col(\"Account\") == \"REDACTED\") | (pl.col(\"Account\").str.starts_with(\"REDACTED-\")))\n        & ((pl.col(\"Partition\") == \"REDACTED02\") | (pl.col(\"Partition\").str.starts_with(\"REDACTED-\")))\n        & (pl.col(\"Start\") != \"Unknown\")\n        & (p",
            "[hot dang it's it only been 4 y](https://pandas.pydata.org/docs/whatsnew/v1.0.0.html)",
            "Exactly. It was a win win because SQL in general is much more accessible IMO for those getting started in programming and we are in the midst of a significant change to open source. We also have two fairly large SQL dbs in our org that service a few thousand employees, so all of that knowledge can be leveraged.\n I just went with it originally for pure performance, but then came to love the simplicity, especially with the pandas integration.",
            "Most painful is easily the string nan, changing it from np.nan to 'NaN' was one of the worst things they did for performance, ditching the numpy core pandas got popular with is a sure way to lose popularity for the future. Nans should be nans, or nulls. NOT 'NaN'",
            "That's the one, thank you :) unfortunately this also causes my notebooks to crash. Maybe it's because I'm opening the notebook within VSCode instead of the web UI, but just adding `import polars as pl` to a cell and running the notebook causes an immediate kernel crash.\u00a0",
            "Do you have any ideas for a better way to represent such information?\n\nMaybe something involving structs?\n\nJust an initial example that comes to mind:\n\n    pl.DataFrame({\n       \"sex\": [{\"0\":\"F\", \"1\": \"M\"}] * 2,\n       \"blue\": [{\"F\": 3, \"M\": 1}, {\"F\": 4}],\n       \"red\": [{\"F\": 5, \"M\": None}, {\"F\": None, \"M\": 2}],\n       \"yellow\": [{\"F\": None, \"M\": None}, {\"F\": 6, \"M\": None}]\n    })\n\n    # shape: (2, 4)\n    # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    # \u2502 sex       \u2506 blue      \u2506 red       \u2506 yellow      \u2502\n    # \u2502 ---       \u2506 ---       \u2506 ---       \u2506 ---         \u2502\n    # \u2502 struct[2] \u2506 struct[2] \u2506 struct[2] \u2506 struct[2]   \u2502\n    # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n    # \u2502 {\"F\",\"M\"} \u2506 {3,1}     \u2506 {5,null}  \u2506 {null,null} \u2502\n    # \u2502 {\"F\",\"M\"} \u2506 {4,null}  \u2506 {null,2}  \u2506 {6,null}    \u2502\n    # \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\nPerhaps others have some better ideas.",
            "This. The docs are great.",
            "I always get a variety of pyo3_runtime.PanicException, cant seem to get to the exact reason why it fails.",
            "That's just a boolean `or` on the expressions, it hasn't got a name beyond that. You could even call it using the `.or_` method. \n\nhttps://docs.pola.rs/py-polars/html/reference/expressions/api/polars.Expr.or_.html",
            "I could have sworn it wasn't more than 2",
            "What the chucklefuck is that abomination?",
            "thanks - I'm not sure I understand what you're referring to though, could you show an example please?",
            "They did what now?",
            "A struct in a dataframe? Seems overcomplicated, though I will readily admit I don't know the foggiest thing about polars",
            "Honestly I don't really know how to improve the representation while relying exclusively on the polars structs formatting. This might be the only case where I found pandas' multi-indexes useful. \n\nGiven that the issue is specifically with pivot tables, maybe it's possible to get around it by modifying how the table is displayed? Something like a \\`pivoted.compress()\\` method that changes the table display to something closer to pandas' version, including the multiple levels. Note that I have no idea how hard this might be to implement (though I think it'd be easier to do than having a full multi-index interface just for that use).",
            "Polars is written in rust which will never crash as long as the data going in is the type that it should be. Python is a language which will happily feed shit in that shouldn\u2019t be there.\n\n99% of the time you see that, it means that rust has tried to run code expecting one type, and you the user have presented it with another (e.g. scan_csv inferred that a u16 would do, and you actually need an i32).\n\nAt that point, there isn\u2019t an elegant off ramp, it panics in a way that rather frustratingly will kill a Jupyter kernel and all the hard earned intermediate variables you had with it.",
            "A panic isn't memory corruption. It is a failed assertion. If you encounter it, can you open an issue then we can fix it.",
            "The pandemic was a heck of a time warp",
            "A struct is what Polars calls it's \"mapping type\" (basically a dict)\n\n    df = pl.select(foo = pl.struct(x=1, y=2))\n\n    print(\n        df.with_columns(\n            pl.col(\"foo\").struct.field(\"*\"),\n            json = pl.col(\"foo\").struct.json_encode()\n         )\n    )\n\n    # shape: (1, 4)\n    # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u252c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\n    # \u2502 foo       \u2506 x   \u2506 y   \u2506 json          \u2502\n    # \u2502 ---       \u2506 --- \u2506 --- \u2506 ---           \u2502\n    # \u2502 struct[2] \u2506 i32 \u2506 i32 \u2506 str           \u2502\n    # \u255e\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u256a\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2550\u2561\n    # \u2502 {1,2}     \u2506 1   \u2506 2   \u2506 {\"x\":1,\"y\":2} \u2502\n    # \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n\n- https://docs.pola.rs/user-guide/expressions/structs/",
            "Yeah, maybe structs isn't the way to go - it was just an initial idea on how to get closer to the `.pivot_table` example.\n\nPerhaps /u/marcogorelli has some better ideas.\n\nI do recall there was a recent PR to remove the need for `index=` https://github.com/pola-rs/polars/pull/15855\n\nDiscussion here: https://github.com/pola-rs/polars/issues/11592#issuecomment-2093732433",
            "Heyo yes ill open an issue when i get to work, the reason i said memory issue was it gets worse kills the entire program.\nThe datasets are static schema so nothing has changed, but reading the thread i may have realised it might be inferring data"
        ]
    },
    "Interfacing Custom USB endpoints using Python!": {
        "title": "Interfacing Custom USB endpoints using Python!",
        "score": 4,
        "url": "https://www.reddit.com/r/Python/comments/1cyq6rb/interfacing_custom_usb_endpoints_using_python/",
        "content": "Hi everyone, I was building something that required me to communicate over USB to Raspberry Pi Pico using Pyusb Python. So I decided to make a blog post about it showing the concepts, process, and source code.   \nCheck out the blog post [here!](https://www.shekharverma.com/python-raspberrypi-pico-and-pyusb-unlocking-the-power-of-custom-usb-endpoints/)  \nCheck out the source code [here!](https://github.com/shekhuverma/Pyusb-RP-PICO)",
        "num_comments": 1,
        "comments": [
            "Sick as hell, checking this out soon. Thanks for sharing"
        ]
    },
    "Mystique: Sparse data matching for Python tests": {
        "title": "Mystique: Sparse data matching for Python tests",
        "score": 11,
        "url": "https://www.reddit.com/r/Python/comments/1cykaol/mystique_sparse_data_matching_for_python_tests/",
        "content": "**What My Project Does**\n\nI made this library to help assert test responses inline while directing the comparison to be as rigid or lax as it needs to be.\n\n**Motivation**\n\nI write a lot of tests that assert values in complex nested dictionaries. But really I only need to check some parts in the response, not all of it.\n\nI often find myself transforming the response or maliciously extracting the important parts I need - in order to satisfy the assertions. This gets messy and can make tests hard to follow.\n\n**Target Audience**\n\nAnyone who writes tests. This is particularly useful if you generate fake data in your tests with something like Faker, Factory Boy, or Model Bakery.\n\n**Comparison**\n\nI have not found a like-project. Searched high and low in PyPI. If such a library existed, I would not have written one myself.\n\nFeedback appreciated.\n\n[See PyPI project for basic use](https://pypi.org/project/mystique/) and [github tests for more complex examples](https://github.com/jonocodes/mystique/blob/main/tests/test_matcher.py).",
        "num_comments": 4,
        "comments": [
            "> I have not found a like-project. Searched high and low in PyPI. If such a library existed, I would not have written one myself.\n\nhttps://github.com/samuelcolvin/dirty-equals/ ?",
            "Awesome, thanks! Looks like a very similar approach.  \nI thought something like this should exist already but discoverability in PyPI is a nightmare.",
            "Try google instead of searching PyPi.",
            "What a dickhead thing to say."
        ]
    },
    "I made python audioplayer with FFmpeg and Qt6 ": {
        "title": "I made python audioplayer with FFmpeg and Qt6 ",
        "score": 2,
        "url": "https://www.reddit.com/r/Python/comments/1cyrhzk/i_made_python_audioplayer_with_ffmpeg_and_qt6/",
        "content": "Midnight Player - a simple python audiplayer for playing audio\n\n**What My Project Does:**\nMy project is just an audio player for playing music, it can play audio from folders, supports different audio formats like Flac, Mp3 and can show some information about the track.\n\nPlayer uses subprocess to access ffmpeg, then it decodes the audio file into pcm format, then plays this file using sounddevice library. the use of these libraries is to ensure that the audio file does not lose quality during processing.\n\n**Target Audience:**\nThis project was made to increase experience in python programming and to understand how the audio playback process works, but the project is also useful for people who are interested in learning the structure of the audio player as it is open source.\n\n**Comparison:**\nFirst of all you should understand that this player is not trying to compete with large-scale projects like AIMP because I developed this project alone and the project was written in a short period of time. But if you compare with other python audio players on github you will notice that many people use wrong libraries like qmediaplayer or pygame mixer to create their audio player, which are not designed for wide support of audio formats, my project is much more complex to operate audio file.\n\nPackages and source code can be found here:\nhttps://github.com/Niamorro/Midnight-Player\n\n\n\n\n",
        "num_comments": 4,
        "comments": [
            "Did you changed anything since last time? It's bit odd to have two copies of the same app for Linux and Windows with the difference of ffmpeg being either sources or Windows executable.\n\nYou should work on for example TrackInfoWidget where a lot of logic is hidden inside Qt code and it's a big conditional statement. App business logic should be extracted, easy to test and tested. Then you have some code repeats, settings/configuration data that repeats (like list of extension types).",
            "In the linux version of the application, unlike windows, there are no startup flags for ffmpeg creationflags=subprocess.CREATE\\_NO\\_WINDOW, because linux does not support it, and if you run in Windows without these flags, you will see the ffmpeg window.",
            "That can be build configuration and the build process should download ffmpeg as needed for Windows while have it as a classic system dependency for Linux."
        ]
    },
    "How to publish a Python package with GitHub Actions using Poetry": {
        "title": "How to publish a Python package with GitHub Actions using Poetry",
        "score": 6,
        "url": "https://www.reddit.com/r/Python/comments/1cyj6w6/how_to_publish_a_python_package_with_github/",
        "content": "Hi! I've been enjoying using [PyPI's trusted publishing](https://blog.pypi.org/posts/2023-04-20-introducing-trusted-publishers/) for the Python packages I maintain and I threw together a little post showing how I'm using that along with Poetry to publish a package from GitHub\n\n[https://johnfraney.ca/blog/how-to-publish-a-python-package-with-poetry-and-github-actions/](https://johnfraney.ca/blog/how-to-publish-a-python-package-with-poetry-and-github-actions/)\n\nIf you've got any tips for publishing a Python package, I'd be happy to hear those, too",
        "num_comments": 4,
        "comments": [
            "Hi buddy, is it possible to publish a package as private? With limited access, not for any one",
            "I took a quick look around and it looks like there are some private Python package repositories out there, but it doesn't look like GitHub has one.\n\n\nCheck out GitLab for one option: https://docs.gitlab.com/ee/user/packages/pypi_repository/",
            "Sounds good, thanks buddy"
        ]
    },
    "Reforger Whitelist Py": {
        "title": "Reforger Whitelist Py",
        "score": 7,
        "url": "https://www.reddit.com/r/Python/comments/1cyfsas/reforger_whitelist_py/",
        "content": "My project below, to put it simply, periodically checks the `console.log` for when a player join event occurs, when it does, it extracts the player's identifiers (`player_name` and `identity_id`). This is then checked against either, a JSON or, a database. I have incorporated standard logging, command-line arguments and threading to handle each player process individually. \n\nThe target audience for this is the Arma Reforger community, for which, the application is made for. \n\nCurrently, to my knowledge, there is no application like this available to the Arma Reforger community. \n\nI am very open to feedback, contributions and advice as want to expand this as much as possible!\n\n[https://github.com/BreathXV/ReforgerWhitelistPy](https://github.com/BreathXV/ReforgerWhitelistPy)",
        "num_comments": 3,
        "comments": [
            "You should add a git ignore file and drop your virtual environment from the repo. It's best practice to not save those files.\n\nCool practical project!",
            "Cool. Let me know if you'd like some help packaging to make it easier for folks to use",
            "Will do! Thank you for the feedback."
        ]
    },
    "I made a Traversible Tree in Python": {
        "title": "I made a Traversible Tree in Python",
        "score": 29,
        "url": "https://www.reddit.com/r/Python/comments/1cxfaph/i_made_a_traversible_tree_in_python/",
        "content": "**Comparison**  \nIt is inspired from the existing tree command on linux and windows too So basically it is just like the tree command, it shows you a tree of the current directory structure.\n\n**What My Project Does**  \nIt basically gives you a birds eye view of your dir structure and quickly navigate to the folder you want to without having to know its path or doing cd ../../.. many times.\n\nThere are a bunch of command line args such as setting the paths, flags to show dot directories, set head height (no. of parent dirs shown) and tail height (depth).\n\nYou can traverse around the tree using various key presses (inspired from vim keybindings) and based on the given argument (-o, -c or --copy) you can output the value (the node to which you traversed), cd into it and have it copied into your clipboard.J\n\nI had created this for my assignment and had a lot of fun with it. Tried to implement as much clean code and good design as I could but its still a mess and active work in progress tbh (added unit tests lol). And the rendering is still a little slow.\n\nDo check it out: [pranavpa8788/trav: A Traversible Tree command line program (github.com)](https://github.com/pranavpa8788/trav/tree/main) and let me know what you guys think. It is built with support for Windows and Linux, some installation stuff might be needed though, and I'll update those steps soon in the github page\n\n**Target Audience**\n\nFor anyone really, especially if you use a lot of terminal\n\n(Had to add the titles because my post was getting auto-deleted lol)\n\nLink to video demo: [https://streamable.com/ds911k](https://streamable.com/ds911k)",
        "num_comments": 5,
        "comments": [
            "Cool project. Some suggestions if you decide to take it further:\n\n* Add a script section to your pyproject so installing it gives you \"trav\" executable. [example](https://github.com/bitplane/uh-halp/blob/main/uh-halp/pyproject.toml#L48). (There's build pipelines for docs and for pypi in that repo that you can also use, so when you push a tag it publishes to pypi)\n* For recording command line apps, try asciinema. Just a convention, admittedly not as great as it could/should be.\n* Tab indent seems a bit severe by default!\n* Try to cut down the flickering by moving the cursor relatively.\n\nNot expecting you to do all this, but you took the trouble to post it so it's only fair that you get a code review from someone in the industry:\n\n* It's a bit verbose and java/c++, which is standard for people coming from C/C++/Java worlds. Takes a while to adjust to write pythonic code, but it's worth it.\n* The goal of writing a program (IMO) is to write a language that can talk about the problem space. This is why naming things is the hardest problem in software, and that in turn is why we make silly rules up about clean code and design patterns to act as guidance, and language features to give us concepts. But the real goal is communication, so prioritise concepts over rules. You've got the logic skills for sure, and some good and respected tricks to split logic up. A life of worrying about names comes next \ud83d\ude02\n* We prefer verbs (functions) rather than `ThingDoer`s in Python, which also makes the names of things more natural. [Famous rant on this](https://steve-yegge.blogspot.com/2006/03/execution-in-kingdom-of-nouns.html).\n* Namespaces are good, use them as context, like `lib.tree` vs `tree_lib`. You can put objects in your `__init__.py` so the imports don't get too long.\n* Consider `snake_case` method/function names and try to make them punchy. The location of the function, return types and parameters give you lots of info that you don't need to repeat. I focus on \"how would I use this phrase in a good python sentence?\", so `leftmostSiblingNodeInSameLevel` would be `self.parent.children[0]` or `first(self.siblings)`.\n* We let outsuders mess with our instance variables (prefix private ones with underscore). You can then use `@property` for computed/restricted attributes later. For example `tree.setRootNode(node)` becomes `tree.root = node`, and later on you can add a getter that returns `self._node` and a setter that sets it and does any checks and computations.\n* `curses` could replace your terminal lib, if you don't mind the dependencies. It'd mean you don't need to worry about the OS or terminal. You can save the terminal state and restore it afterwards by using `curses.wrapper(main)`, or just do relative movement.\n* Consider `argparse`, `click` or `typer` for parsing your command line args in future. It'll get rid of the need for logic and loops, which are a source of bugs.",
            "Sounds a lot like fzf. Up vote for rolling your own",
            "Thanks a lot for the kind words and all the great advice (especially asciinema, was looking for something like this), I really appreciate it brother. Had a few questions and clarifications\n\n\\* You're absolutely spot on about the verbosity thing, you got me there. I had started coding in python eventually but have been using Java at work for the past half a year and that's why you see me naming things like this XD  \n  \n\\* I had thought about using curses and click. The reason I had not went with it was because of my assignment limitations, didn't want to explain about curses to my teacher and thought it'd impress him more when he saw I implemented some stuff from scratch. But now that my assignment is out of the way I can go ahead and use curses that would be much better. Didn't even realize it would get rid of the flickering. Thanks for pointing out  \n  \n\\* What do you mean by severe indentation? Like, should it have been spaces instead of tabs instead?\n\n\\* I didn't the get part regarding namespaces, should I have put all \\_lib folders under a lib folder so the imports would be from lib.tree import xyz? And by putting them in \\_\\_init\\_\\_ you mean like all common objects from that package (folder), so I can just do from lib import tree?\n\n\\* I definitely agree with the long as traversal names I have used, very verbose indeed. I like the first(self.siblings). The entire reason I didn't do this is that I'll need to add logic for args in register events part which I wanted to avoid, maybe its worth it I guess, will need to think about this\n\n\\* \\`@property\\` definitely seems very useful. But I've always had this doubt, why do we use private variables and method. I see the advantage of using setters by having the advantage of being able to check stuff before assigning value, but is that all?",
            "Thanks, yeah I agree it is similar. Mine offers you a bird's eye view of the directory structure",
            "> What do you mean by severe indentation? Like, should it have been spaces instead of tabs instead?\n\nI meant in the video, I like my tmux 80 column 2x2 grid of terminals so 8 spaces seems like a lot of space.\n\n>  I didn't the get part regarding namespaces, should I have put all _lib folders under a lib folder so the imports would be from lib.tree import xyz? And by putting them in __init__ you mean like all common objects from that package (folder), so I can just do from lib import tree?\n\nYeah you can have `from lib import Tree` rather than `from lib.tree.tree import Tree`. You put `from .tree.tree import Tree` in `lib/__init__.py`, or something (I always get the module paths wrong! So I always install and use the full path). Or expose it as `lib.tree.Tree` or whatever makes sense.\n\nYou can discourage other people from using the submodules by renaming them to start with an underscore so they know it's private; `from lib._tree.tree import Tree` is possible but it looks bad. I don't think I'd use the `lib` thing in general though, not sure.\n\nI think if I were doing it, I'd use pytermgui and make a custom widget for the tree view. Have a Node hold things like open/closed status, last update time, cached target details, children list, children_loaded bool, parent node. Have the tree hold the selected node, write the nodes into the output line list, and set the scroll view area of the tree widget. The top level UI widget would do the mode switching, absorb inputs that it cares about etc. Depth parameters just say where to start and how deep to call \"open\" when it does.\n\n> `@property` definitely seems very useful. But I've always had this doubt, why do we use private variables and method. I see the advantage of using setters by having the advantage of being able to check stuff before assigning value, but is that all?\n\nYes, the main thing I like about it is it allows me to pick a simple name and just use an instance level variable. I assign it in my `__init__` and there's no code elsewhere. Later on, if I need to change it to something that's computed, I can switch to a property and the rest of the code doesn't change.\n\nSo the `obj.member` becomes a function that gets called rather than a value, and it code returns `obj._member` which holds the new value. Then the `@member.setter` function can raise errors or trigger changes that happen when the value is changed."
        ]
    },
    "Programmable Semantics (Eval, Semicolon, Assignment) for Python": {
        "title": "Programmable Semantics (Eval, Semicolon, Assignment) for Python",
        "score": 7,
        "url": "https://www.reddit.com/r/Python/comments/1cxp7qe/programmable_semantics_eval_semicolon_assignment/",
        "content": "I've seen programmable semantics (eval-hacking, macros) in LISPs and in Haskell-likes(Monads/Template Haskell), the overall techinque in OOP languages is called \"Aspect Oriented Programming\".  Has this kind of thing been discussed before, and is it Pythonic it could allow a lot of Python code to be shorter.  Python has sys.set\\_trace that sort of allows some form of programmable semantics but its mostly for debugging.\n\nProgrammable assignment(variables) are like setters/getters/properties, but instead of being run on o.x = 5, you could run them on \"all local assignments\" isnside a context manager or in a decorated function.  On every assignment you could do stuff like log the values, update dependencies, notify objects, do a database transaction, do persistance, calculate other values, without having to explicitly do so for every assignment statement.\n\nProgrammable semicolons (such as Haskell Monads, or reprogramming Lisp do/progn/let) could allow you to have the same code run either synchronous, async, get undo/history support, break on error, rollback, logging in between lines, changing local/global variables in between each line, database access in between lines, checking values for errors, ignoring certain statements, etc...  You can think of a semicolon like an \"unrolled for loop\"/iterator ran for each code line.  It would be like async but you can change a piece of code to be sync or async at run time by changing the context manager you are in.  Programmable \"call\" can change the default call operation in a context manager for all functions and be similar to semicolons.\n\nProgrammable eval would allow you to change the order of operations, choose to ignore certain functions, allow you replace certain expensive expressions with others, allow you to keep a trace of all evaluations taking place, you can turn an expression/program into an interator allowing you to pretty cool stuff.",
        "num_comments": 9,
        "comments": [
            "Python has some pretty powerful meta programming facilities, but nothing even close to lisp and Haskell in that regard. \n\nYou might be interested in https://github.com/Technologicat/unpythonic",
            "Python traditionally sacrifices power in the name of flexibility.  If Joe Random Programmer reads your code today, they understand what it does.  If you've reprogrammed assignment, semicolons, and variables in your corner of the project, changing the semantics of existing Python syntax, then Joe needs significantly more context to understand your code--and anybody else's code.\n\nYes, Python has some support for changing behavior, `__getattribute__` and `__add__` and so on.  I observe these are used sparingly and--generally--idiomatically.\n\n(Personally I was a little alarmed when I saw the pathlib `Path` object had overloaded `__div__` to really mean `os.path.join`.  But I can see how it would be irresistable.)",
            "Your title is misleading (or, alternatively, hard to understand). \"Semantics\" refers to the logic of your code (versus, say, syntax, that refers to the rules following its organization). All semantics is programmable, in every language.\n\nWhat you meant was \"operator overloading\", which is already implemented in Python through magic methods. Not everything can be overloaded, however; the semantics of `len` can, but that of `eval` cannot.",
            "I guess you can write an effects library that allows you to use different effect handlers with the same interface.",
            "That Path / thing really threw me when I first saw it, but now I am addicted to it",
            "rhythm grandfather rob distinct straight door disarm salt imminent wise\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
            "Python is pretty good at allowing you to change semantics, but not syntax. We have meta classes and \\_\\_new\\_\\_ that lets you do truly weird things. People don't generally go around using them in random projects. However, they are used in libraries to provide a better experience to the library users.  And there, it becomes part of the documentation of the rest of the semantics of that library.\n\n  \nIn general, there is no guarantee what the return value of any operator between unknown types is. And that is fine!",
            "Semantics is about the meaning of the code\u2014what the code does when it runs. This includes how expressions are evaluated, how statements control the flow of execution, how data structures are manipulated, and what the effect of different constructs is during execution. Semantics refers to the meaning and behavior of the code rather than the logic itself. The assertion \"Semantics refers to the logic of your code\" is extremely vague and not entirely accurate. Logic typically refers to the specific operations and control flow structures (like loops and conditionals) that you use to solve a problem, whereas semantics is about the underlying meaning and behavior of those constructs within the language.\n\n>\n\nWhile some languages allow users to define or override certain behaviors (like operator overloading in Python), the fundamental semantics of many language constructs are fixed and not changeable by the programmer.",
            "This [GitHub - orsinium-labs/eff: Python library to work with algebraic effects](https://github.com/orsinium-labs/eff?tab=readme-ov-file), looks interesting.  The Eff language and related F\\* language look like the  future of programming O\\_o."
        ]
    },
    "try... except... finally!": {
        "title": "try... except... finally!",
        "score": 82,
        "url": "https://www.reddit.com/r/Python/comments/1cx0dh4/try_except_finally/",
        "content": "Haven't seen this syntax used very often and was wondering why. During error handling, if you have something to run independent of the success, you can use finally.\n\n    from your_library import DataProcess\n    \n    \n    engine = DataProcess()\n    \n    try:\n        engine.io()\n        engine.process()\n        engine.some_more_io()\n    except Exception as e:\n        engine.revert()\n        raise e\n    finally:\n        engine.cleanup()\n\nVS\n\n    from your_library import DataProcess\n    \n    \n    engine = DataProcess()\n    \n    try:\n        engine.io()\n        engine.process()\n        engine.some_more_io()\n    except Exception as e:\n        engine.revert()\n        engine.cleanup()\n        raise e\n    engine.cleanup()\n\nVS\n\n    from your_library import DataProcess\n    from contextlib import contextmanager\n    \n    \n    @contextmanager\n    def process_data(engine: DataProcess):\n        try:\n            engine.io()\n            yield engine\n        except Exception as e:\n            engine.revert()\n            raise e\n        finally:\n            engine.cleanup()\n    \n    proc = DataProcess()\n    with process_data(proc) as engine:\n        engine.process()\n        engine.some_more_io()",
        "num_comments": 59,
        "comments": [
            "In your example, having finally is more proper. The other comment about using context manager is better. Context manager is largely why it's rare to need finally. There aren't many cases where you have a command that must run in BOTH try and except cases. A lot of the time, except is handled by raising another error or exiting early.\n\nIt's rare to see because most people don't know it. There's also try...except...else...finally.",
            "context managers and the `with` statement is used to separate the resource management from the exception handling. see also: https://docs.python.org/3/library/contextlib.html",
            "\\#2 is against DRY principle.\n\nIf engine.cleanup() must be called anyways, why repeat it in both the exception handler _and_ continuation code?\n\nWrapping in a @contextmanager is good, but sometimes that adds more mental load as the context manager is far away.\n\nSo it's either #1 or #3 for me, depending on how complex the .cleanup() procedure is.",
            "The `finally` block is executed when you leave the `try` and `except` blocks. So, if you or Python leaves those blocks by a `return` statement, an `exit` function call, or by any exception, whether caught or not, the code in the `finally` block will be executed. E.g.\n\n    f = None\n    try:\n        f = open(...)\n        # write to file\n    finally:\n        if f: \n            # finish writing to file\n            f.close()",
            "For anyone who sees this comment:\n\ntry: execute code\n\nexcept: handle error\n\nelse: no exceptions? Run this code\n\nfinally: always run this code",
            "Finally is always run, even before a return statement in the \"try\" or the \"except\" statement.\n\nThis has a totally different meaning and is meant for something that always need to run once you put a toe in the try block.\nThis is why the contextmanager actually work.\n\nExcept block is only for error handling.\n\nThings after these blocks are just the rest of the flow which might never be reached.\n\nI have personnaly seen \"finally\" too much instead of \"except\" for so many bad reasons.",
            "Fixing up code blocks from top post:\n\n\nOne:  \n\n    from your_library import DataProcess\n    engine = DataProcess()\n    try: \n        engine.io() \n        engine.process() \n        engine.some_more_io() \n    except Exception as e: \n        engine.revert() \n        raise e \n    finally: \n         engine.cleanup()\n\n\nTwo:\n\n    from your_library import DataProcess\n    engine = DataProcess()\n    try: \n        engine.io() \n        engine.process() \n        engine.some_more_io() \n    except Exception as e: \n        engine.revert() \n        engine.cleanup() \n        raise e \n    engine.cleanup()\n\n\nThree:\n\n    from your_library import DataProcess \n    from contextlib import contextmanager\n\n    @contextmanager \n    def process_data(engine: DataProcess): \n        try: \n            engine.io() \n            yield engine \n        except Exception as e: \n            engine.revert() \n            raise e \n        finally: \n             engine.cleanup()\n\n    proc = DataProcess() \n    with process_data(proc) as engine: \n         engine.process() \n         engine.some_more_io()",
            "`finally` is very handy in situations where you need it--but more often C-style `try: except: else:` is what you need",
            "Huge caveat with try-finally blocks - if you return inside of a finally block, then that value will be returned, *even if the finally block is triggered by the function returning a value elsewhere.*\n\n    \n    >>> def f():\n    ...    try:\n    ...        return True\n    ...    finally:\n    ...        return False\n    ...\n    >>> f()\n    False",
            "prefer context manager over try finally for resource management, also putting multiple lines that can go wrong in a try block is, IMHO, a code smell.",
            "Note: When you want to re-raise the latest caught exception all you need to do is have the statement \"raise\". No need to catch it the way you do and then \"raise e\".",
            "Personally i dont use it as i dont tend to need to use it.\n\nWith statements and context managers are easier to read for most use cases and remove the need for most close, disconnect, cleanup statements.\n\nMost of the time what i use try blocks for now is to stop a workflow and log appropriately. So they tend to log and rethrow as known types.  But i tend to write lambdas or scripts in python where top level errors are often preferred to keeping a system running.",
            "DataProcess should be a context manager and call cleanup in its __exit__ function.",
            "Please in the name of the old gods and the new, format your post.\n\n    like_this()",
            "Throw in the else block of the set (try, else, except, finally) and you have full control!",
            "Wait until you learn about for\u2026else, and while\u2026else.\n\nAlso, finally is useful for adding an exit message/log to a script/prompt/profess.",
            "I think it makes code more readable.",
            "Pp p",
            "  \nBased on the discussion here, this is probably what i would do in production.  \n  \n  \n`import types`  \n  \n`class DataEngine:`  \n\u00a0 \u00a0 `def revert(self): ...`  \n\u00a0 \u00a0 `def cleanup(self): ...`  \n\u00a0 \u00a0 `def io(self): ...`  \n\u00a0 \u00a0 `def some_more_io(self): ...`  \n  \n\u00a0 \u00a0 `def __enter__(self):`  \n\u00a0 \u00a0 \u00a0 \u00a0 `return self`  \n  \n\u00a0 \u00a0 `def __exit__(`  \n\u00a0 \u00a0 \u00a0 \u00a0 `self,`  \n\u00a0 \u00a0 \u00a0 \u00a0 `exc_type: type[BaseException] | None,`  \n\u00a0 \u00a0 \u00a0 \u00a0 `exc_val: BaseException | None,`  \n\u00a0 \u00a0 \u00a0 \u00a0 `exc_tb: types.TracebackType | None,`  \n\u00a0 \u00a0 `) -> bool:`  \n\u00a0 \u00a0 \u00a0 \u00a0 `if exc_val:`  \n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 `self.revert()`  \n\u00a0 \u00a0 \u00a0 \u00a0 `self.cleanup()`  \n\u00a0 \u00a0 \u00a0 \u00a0 `return False`  \n  \n  \n`class DataProcess:`  \n\u00a0 \u00a0 `def __init__(self, engine: DataEngine):`  \n\u00a0 \u00a0 \u00a0 \u00a0 `self._engine = engine`  \n  \n\u00a0 \u00a0 `def process(self):`  \n\u00a0 \u00a0 \u00a0 \u00a0 `with self._engine:`  \n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 `self._engine.io()`  \n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 `# process logic here`  \n\u00a0 \u00a0 \u00a0 \u00a0 \u00a0 \u00a0 `self._engine.some_more_io()`\n\n`Client Code`\n\n`from your_library import DataEngine, DataProcess`\n\n`def main():`  \n\u00a0 \u00a0 `proc = DataProcess(DataEngine())`  \n\u00a0 \u00a0 `proc.process()`\n\n  \nBenefits:\n\n1. Integrating the resource cleanup logic in DataEngine using context manager protocols, make the logic more cohesive\n2. Separating DataEngine from DataProcess, so that the DataEngine can focus on IO, and they can be tested and mocked independently.\n3. Designing a simple API for DataProcess, so that It can be used easily in client code.\n\nDepending on the complexity of DataProcess, such as how much state it has to carry, it might or might not be simpler to just use a function.\n\nQ: Why implementing DataEngine as a context manager instead of using try except finally?\n\nA. Separating error handling from resource management, by implementing context manager, clients of DataEngine can handle exceptions without worrying about resource management.",
            "Yeah, I feel like I\u2019m the only one that actually uses else for code blocks (for and while loops also support it). It\u2019s very useful when you want to do some operation on the last iteration of a loop while still having access to the context variables only accessible within the loop.",
            "And else is for when try didn't execute because of some condition that wasn't met, but not because of an error right?",
            "Tho this has the disadvantage of not making obvious what happens when exiting and having no control over it, e.g. multi threading Pool calls terminate instead of close() and join() which imo would be more common and intuitive.",
            "Added a context manager example for a quick comparison.",
            "That is my thought process as well.",
            "it gets better\n\n    try:\n        raise RuntimeError(\"...\")\n    finally:\n        return",
            "I guess it depends on the granularity of the error handling that you seek. Having a custom try.. except.. for every line is not always optimal either.",
            "Any line can go wrong, so IMO putting multiple lines in a try block is a code smell.\n\nCode smell doesn't mean that something is definitely wrong, it's just something you should look at with some suspicion. There are sometimes good reasons to do it, but in general you should avoid it.",
            "Prayers to the gods, but what exactly do you mean? The code blocks in the post seem well formatted.",
            "The else block is executed when the try block was successful.",
            "Else is run as basically continuation of the try.\n\nIt goes \"try doing A\", \"except if error X happens, do B\" (<- see the implicit \"if\" here), \"else do C\".\n\nTry part should only have the code that throws. Having too much code in the try could make you catch stuff you don't want or just make analysing the code hard (because someone would need to think which line can throw).\n\n\"Except\" statements catch errors, they don't need to break out of the thing. They may be used to try fetching a value in another way or something.\n\nBut then, the except that continues the thing may not need to do other stuff!\n\nSo without the \"else\" part, it would either be too much stuff in the \"try\" or setting and checking flags to see whether \"try\" was run fully without the \"except\".",
            "ok so my point was that you didn't see try except finally because for **separation of concerns** people would usually to one context manager with the try/finally and handle the errors outside the with block, something like this:\n\n    from your_library import DataProcess\n    from contextlib import contextmanager\n    \n    \n    @contextmanager\n    def process_data():\n        engine = DataProcess()    \n        try:\n            yield engine\n            engine.commit()\n        finally:\n            engine.rollback() # uncommitted\n            engine.cleanup()\n    \n    try:\n        proc = DataProcess()\n        with process_data() as engine:\n            engine.io()\n            engine.process()\n            engine.checkpoint() # maybe\n            engine.some_more_io()\n    \n    except SomethingBadException as e:\n        handle_exception(e)",
            "> Having a custom try.. except.. for every line is not always optimal either\n\nUnderstatement of the year.",
            "Looks like this on old.reddit.com\n\nhttps://imgur.com/a/48UqB32",
            "squeeze nine quickest reply far-flung reach snatch ancient aback sink\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
            "I see like putting the calculation/data manipulation part in the try part and the output i. e. on the screen in the else part.",
            "except should be for unexpected errors which is why it's most often used around I/O operations or tricky multithreaded nonsense.\n\nunexpected input should already be handled by your code normally elsewhere. And like, you shouldn't throw exceptions as like a GOTO statement to skip a ton of your own code.",
            "that's a chunky block, but I get your point",
            "ugh, that's ugly, will try to fix",
            "better now?",
            "*else* is for code you don't want the *except* block to run if it raises but do want to run only if *try* block does not raise.  It is a rare use case.",
            "IMO you should usually have only one line under `try` so you don't accidentally capture unrelated errors. Because of this I use `try...except...else` pretty frequently. There isn't a huge difference between this and just putting the code afterwards in most cases, but it does guarantee the code will only be run if there's no exception and not if there's an exception that's handled. This is often useful for stuff like `IndexError` and `AttributeError` where there's a default case that I can fall back to but I want to use the value I got if I got one.\n\n`finally` is important for cases where you have to close something on an error. If you just put the code afterwards, but you're raising or returning from the `except`, code afterwards won't be run. (And that includes if there's an error in your `raise` block code that you didn't notice, not just if you specifically are raising from the raise block.) `finally` will always be run no matter what.\n\nTL;DR `else` and `finally` are used because control flow in an exception-handling context can get finicky and you don't always know what to expect.",
            "     \n    try:\n        this_might_fail()\n    except:\n        this_might_also_fail()\n    cleanup()\n\nYou see the issue? `finally` guarantees that the cleanup will happen, even if any of the `try/except/else` block:\n\n* exits normally\n* `return`s\n* `break`/`continue`s\n* `raise`s\n\nThere's a bunch of control flow statments we otherwise need to worry about.",
            "No. Finally runs independent of success. Else only runs on success.",
            "Having inherited some python code from people who weren't really devs, I can partially understand what you mean. But think this: everything exists in the spec for a reason, and everything can be used for nice code and shitty code. Try/catch is part of flow control syntax, so it is to be used for flow control - used, not abused. I've seen it abused, that's why I partially get you, but it's not a reason to demonise it all. \n\nExcept should not be for \"unexpected\" errors, you literally have to know it can happen to mitigate it. Catch-all statements are discouraged by any stylistic guide, you're supposed to be as specific as possible - so you're supposed to catch an error you know! \n\n(I mentioned inherited code and abuse, but it matches catch-all as well - in one project, the author literally threw just Exception to jump - it was in an if! Should've been just continue to skip to next iteration of the loop - so yes, goto/abuse of the exceptions. But at the same time it was too broad except statement - the whole code doing stuff was in the try, and it was either bare except or `except Exception` hiding errors in the other parts of the code. Exactly catching \"unexpected errors\" and nobody ever saw them again... until I inherited the code and was made to reactor it to be more extensible. I fixed that abuse of try/except and discovered how much data it has hidden from the resulting document.)\n\nMy philosophy is that actual unexpected errors are supposed to be logged (tbh log all errors, also the expected ones), and to kill the script (or if not killing - let the maintainer know). Because if anything else runs the script, non-zero error code makes it not continue (and thus also having more points where the error gets noticed - from experience people don't read emails, even if they request the thing sends them email with the error :x). \n\nPython also loves the philosophy of \"better ask for forgiveness\". I help a lot of beginners so let's choose a simple example - user input that is supposed to be any integer. Newbies try to do ifs with str.isnum or str.isdecimal and other stuff, but then have to add other cases for negatives, etc... Just try converting and if it fails, loop the thing to repeat the input question! Simple! Not abuse of the syntax and actually shows how it can simplify the code when done properly, yay! \n\nExpected (and excepted - ie caught) errors would be basically anything like that that is easier checked by trying instead of doing many complicated ifs. Working with APIs that were inconsistent or otherwise badly made makes one appreciate the approach of just trying (eg. routers of same manufacturer but different versions, no api so ssh into each, where some had one version of the command and some had another - there were hundreds of them so keeping track in config which is which would be too tedious, the most reliable way was just to try the command and see if it outputs or errors - if error, try the other version of the command; this wasn't try/except but it used the same principle of \"just try\"). I love small functions and early returns (the \"done elsewhere\" in your code), but sometimes splitting it too much is a pain or require too much abstraction at that point - so you don't abstract it until needed later, because doing it at this point would be premature. \n\nFor reference, I've been coding for half my life, starting with c and cpp 15y ago, spent my recent years as python dev (and in free time - as educator), and in the meantime did some TA work for posix programming class in C at my uni - so working C and Python in parallel made the differences of approaches very apparent. Especially the checking everything everytime before and after running (because non-0 returns and errnos and stuff) vs \"just try and if it fails, catch it\".\n\nI could probably find more stories/examples of use vs abuse of python (and not only), but the message is long already. :)",
            "\\*chefs kiss*",
            "In OP's example, you might have something like `engine.commit()` in the `else` block, if the engine was transactional.",
            "amusing hard-to-find paint deliver pocket retire hat boast sink wasteful\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
            "cow somber rain intelligent mourn serious lush reply toothbrush toy\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
            "offer piquant price whistle brave market bedroom dolls snobbish dependent\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
            "Gotta be careful with those I think. Like it seems reasonable to have a catch all that logs some stuff out then does a bare raise. If you see it then it's a signpost that (like in your example) the code used to be buggy and was debugged with logs and real world data for a while.\n\nBut what ends up left is this stale log line that is really hard to unit test, so has a risk of blowing up and swallowing your stack trace in production. The more you have, the more likely it is to happen. Apply it all over the place and you'd better have a linter, pre-commit and not do anything clever in there.\n\nSo IMO a catch Exception block that doesn't have coverage and pleads it's case with a comment should be deleted. If someone wrote a test for it then it might be important enough to break the rules, but I'm still going to challenge it anyway. Reading code that looks dangerous has too much cognitive and emotional overhead, scrolling past it is a distraction.",
            "Here's one example that shows a potential use-case for of a `try..except..else`\n\n    try:\n        unsanitized_data = get_external_data()\n    except Exception:\n        # if get_external_data fails I don't care,\n        # I'll use some fallback safe method\n        clean_data = get_safe_fallback_data()\n    else:\n        # if get_external_data() didn't fail,\n        # I have to sanitized the output\n        # but I don't have to sanitize the output\n        # of get_safe_fallback_data()\n        clean_data = sanitize(unsanitized_data)\n\nIf something fails in `sanitize()`, I don't want it to go into the `except` block  \nBut also, I should only call `sanitize()` if the `try` block succeeds",
            "Here's an example I use all the time:\n\n\n    try:      \n        item = items[0]       \n    except IndexError:\n        logger.exception(\"list was empty\")\n    else:\n        do_stuff(item)\n\nIf I put `do_stuff` after, it would fail if there was a caught exception, since control flow goes there even if an exception was logged and there is no `item`.",
            "In my example, if both functions that might fail do in fact raise exceptions, `cleanup` will never be called.\n\nIf `cleanup` was in a `finally` block, it would always be called even if both raised.",
            "You misunderstand. The question is, that how is your code any different from this?\n\n    try:      \n        item = items[0]       \n        do_stuff(item)\n    except IndexError:\n        logger.exception(\"list was empty\")",
            "cats plants deranged enjoy deserted rainstorm scale fear live square\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
            "If there's an IndexError in do_stuff it'll be suppressed accidentally and logged incorrectly.",
            "If do\\_stuff raises an IndexError it would log an incorrect message.",
            "The `finally` block always runs, even if an Exception is raised inside the `except` block\n\nThere's not really any difference between\n\n```\ntry:\n   do_something_that_raises_an_exception()\nexcept Exception as ex:\n    logger.exception(ex)\n    do_something_that_raises_a_different_exception()\nfinally:\n    cleanup()\n```\n\nand \n\n```\ntry:\n    do_something_that_raises_an_exception()\nexcept Exception as ex:\n    logger.exception(ex)\n    raise ex\nfinally:\n    cleanup()\n```\n\nIt's a very common pattern to have an Exception get raised inside an `except` block and you still always want `finally` to run",
            "Finally runs no matter what, yes. That's the whole point. To be clear, the exception in the except block isn't *caught*, finally runs and the exception continues to get raised. \n\nI think you're overthinking the except part. Imagine you're in OG python with no `with` blocks, and you want to make sure your files are closed, no matter what happens. You'd write\n\n    try:\n        f = open(path)\n        return might_fail(f)\n    finally:\n        f.close()\n\nbecause you always want to make sure the file is closed. There are lots of resources like this where this is the case (locks, temporary files, etc). What if you didn't have finally? How would you write the above? Something like\n\n    try:\n        f = open(path)\n        result = might_fail(f)\n    except:\n        f.close()\n        raise\n    f.close()\n    return result\n\nIt's a lot of boilerplate, and you'd likely not do it properly every time you opened a file! Of course even that wasn't enough so we now have\n\n\n    with open(path) as f:\n        return might_fail(f)"
        ]
    },
    "Durable Python - Infrastructure failures should not stop the process ": {
        "title": "Durable Python - Infrastructure failures should not stop the process ",
        "score": 9,
        "url": "https://www.reddit.com/r/Python/comments/1cxbyf6/durable_python_infrastructure_failures_should_not/",
        "content": "Durable Python enables developers to write Python code while an underlying system ensures reliability and resilience.\n\nIt automatically handles state persistence, fault tolerance, and retry mechanisms, allowing developers to focus on business logic without worrying about infrastructure concerns.\n\nConsider the following code, in case the process terminates in the middle of execution, in case the process is killed or due to hardware failure, the process will not complete. \n\n\n```Python\nimport requests\nimport time\n\n\nSLEEP_SECONDS = 3\nURL = \"http://localhost:9980/webtools/api/msgs\"\n\ndef on_http_get(data):\n    for i in range(10):\n        print(\"Loop iteration: %d of 10\" % (i + 1))\n\n        # Send a POST request to the application\n        requests.post(URL, data = \"This is my \" + str(i) + \" iteration...\")\n        time.sleep(SLEEP_SECONDS)\n```\n\nBut actually, I would like the process to survive restarts and continue from the spot it terminated, especially if it's a long running process. For this we need Durable Python.\n\nI was wondering which use cases can take advantage of this technology.\n",
        "num_comments": 22,
        "comments": [
            "[deleted]",
            "You dont want durable code. \nSimple solution below:\n\n1, Store state outside the process, a file will do.\n2, update file after each post.\n3, run as service in the os with restarts.\n4, dont catch errors.\n\nThis way you can update the code, restart the service easy, restart/ replace the server.  Scale by moving the file to a db and run multiple instances.\n\nNo need for code level handling of this at all.",
            "It's an infra problem, not a python problem. Hell, the simplest solution is to create a bash script that runs your code, monitors the process id, and when it fails, restarts your code. \n\nThere's data you need to save? Use sqllite.",
            "This is what [Temporal](https://temporal.io/) is for",
            "This is the shittiest stealth advertising I've ever seen",
            "You want restart ability, no\tt durability. \n\nRestart ability means you checkpoint work and restart from the last checkpoint. To ensure replays are possible, make operations idempotent (same operation = same outcome).",
            "erlang/otp and elixir",
            "You mean like [Erlang and it\u2019s supervisor tree](https://en.wikipedia.org/wiki/Erlang_(programming_language))\n\n\n-Within a supervisor tree, all supervisor processes are responsible for managing the lifecycle of their child processes, and this includes handling situations in which those child processes crash.",
            "This is easily solved using a file for state storage in the simple case, and something like luigi in the more complex case.",
            "just use pm2 and logging.",
            "Sounds like a cool feature to work on, but I'm not sure I could ever trust partially compiled output from an app that departed normal operation based on my experience with various compilers over the years.",
            "Interesting, can you give me some pointers?",
            "I agree, for this simple use case. But saving state has many drawbacks once things get more complicated. Recovery can be very complicated. \nOf course this is how most distributed systems work today, with databases and states, but it can become really messy very fast and it's lrone to bugs once the state machine is not trivial.",
            "I think you missed, my point. I don't want to rerun the function from the beginning. I want it to run exactly 10 times even if the server crashes.  \nAs you mentioned, I can use a DB to save the state (the last completed iteration number). But then I need to add code at the beginning to read the last state and continue the iteration from it.   \nOf course, this is possible for this simple example, with more code, more potential errors, and a lot of testing. My whole point is that it would be great to have something that solves this problem out of the box without writing this code.",
            "Yep, Temporal is amazing, but using Temporal is not trivial or transparent to the user. You need to know what you're doing. \nFor a developer not familiar with Temporal, using Temporal is not trivial.",
            "For real, they didn't even bother to use two usernames that aren't associated with their typo-laden startup\n\nThe least somebody could do when trying to astroturf is not do so from an account named after the founder of the startup who is OP",
            "I agree; this is also a solution. The only thing is that it's sometimes complicated to implement. Depends on the use case.",
            "I work on ring-0 operating system components and if something that complex can utilise recoverable state then your project can too. People in this thread are all telling you the same thing.",
            "What you're calling \"very complicated\" is just what developers and software engineers and anyone else writing non-trivial code have to solve for. It's literally what they do.  And really not even that. The core use case of python is not \"10 line scripts written by people that are intimidated by the idea of saving state to a file or DB and checking it for existing state before beginning operation\".  Python IS accessible to those people, and there's nothing wrong with being that guy (most of us were to begin with), but if you need better than that then you build it.  And if you don't know how, you learn it (or the tools/libraries that do it already).    \n  \nIf learning new things is a big impediment for you, then maybe this isn't the field for you",
            "There are many ways to solve this problem out of the box without having to make python aware of the state of environment it is running within. You generally solve this problem through system design and not inside the python code. For your example you could address this by externalizing the for loop from your function and using a queue to contain the tasks to be processed. Most queue frameworks support an automatic task retry process that is abstracted away from the user.\n\nThere isn\u2019t a one-size-fits all solution, though. If there was then developers wouldn\u2019t have a job.",
            "You do realise if there's an exception and the code breaks, making it durable doesn't help. It'll break again. \n\nAlso instead of theory, show examples.",
            "Often things like youre suggesting require new coding paradigms. For all things X: \"For a developer not familiar with X, using X is not trivial.\" But part of being a developer is learning new things.",
            "Part of being human is"
        ]
    },
    "Dive into DevOps ebook Humble Bundle supporting the Python Software Foundation": {
        "title": "Dive into DevOps ebook Humble Bundle supporting the Python Software Foundation",
        "score": 53,
        "url": "https://www.reddit.com/r/Python/comments/1cwqkx7/dive_into_devops_ebook_humble_bundle_supporting/",
        "content": "https://www.humblebundle.com/books/dive-into-dev-ops-no-starch-books\n\nBe sure to click on \"Adjust Donation\" and \"Custom Amount\" and then max out the amount going to the Python Software Foundation. (From $1.75 to $24.50!)\n\nFor $30 you get the following ebooks from No Starch Press:\n\n* Automate the Boring Stuff with Python, 2nd Edition\n* DevOps for the Desperate\n* How Linux Works, 3rd Edition\n* The Book of Kubernetes\n* PowerShell for Sysadmins\n* Practical Vulnerability Management\n* Practical SQL, 2nd Edition\n* Practical Linux Forensics\n* Eloquent JavaScript, 3rd Edition\n* Cybersecurity for Small Networks\n* The Linux Command Line, 2nd Edition\n* Web Security for Developers\n* MySQL Crash Course\n* Designing Secure Software\n* Network Programming with Go\n* Practice of Network Security Monitoring\n* Network Flow Analysis\n* Absolute FreeBSD, 3rd Edition\n* Absolute OpenBSD, 2nd Edition\n* Linux Firewalls\n* Pentesting Azure Applications\n* The Book of PF, 3rd Edition",
        "num_comments": 7,
        "comments": [
            "Oh wow this is great. How long is the sale? I'm in an IT class tomorrow and my classmates might like this.",
            "Incredible bundle, always appreciate all that you do for the community, Al!",
            "Started reading automate the boring stuff with Python last week, fantastic book.  After several stops and starts with Python, this book and Thonny have super helpful to get a simple environment setup to learn in.",
            "Names do not match ISBN and dates, they are all mixed up :(",
            "> Offer ends in 20 days",
            "He copy pasted it from my post in r/humblebundles. I fixed it in my original post: [https://www.reddit.com/r/humblebundles/comments/1cwlyjb/comment/l4x8c7j/](https://www.reddit.com/r/humblebundles/comments/1cwlyjb/comment/l4x8c7j/)",
            "Here's a sneak peek of /r/humblebundles using the [top posts](https://np.reddit.com/r/humblebundles/top/?sort=top&t=year) of the year!\n\n\\#1: [April Bundle. Not Returnal or AC: Valhalla :(](https://i.redd.it/wjcoqghkk3sc1.png) | [625 comments](https://np.reddit.com/r/humblebundles/comments/1bu3uws/april_bundle_not_returnal_or_ac_valhalla/)  \n\\#2: [The leaks were true! Enjoy Nioh 2 :P](https://i.redd.it/f29rm0uy1kmc1.png) | [235 comments](https://np.reddit.com/r/humblebundles/comments/1b7bv9n/the_leaks_were_true_enjoy_nioh_2_p/)  \n\\#3: [Me since last week](https://i.redd.it/c7saxqocnglb1.jpg) | [70 comments](https://np.reddit.com/r/humblebundles/comments/166dj4m/me_since_last_week/)\n\n----\n^^I'm ^^a ^^bot, ^^beep ^^boop ^^| ^^Downvote ^^to ^^remove ^^| ^^[Contact](https://www.reddit.com/message/compose/?to=sneakpeekbot) ^^| ^^[Info](https://np.reddit.com/r/sneakpeekbot/) ^^| ^^[Opt-out](https://np.reddit.com/r/sneakpeekbot/comments/o8wk1r/blacklist_ix/) ^^| ^^[GitHub](https://github.com/ghnr/sneakpeekbot)"
        ]
    },
    "AioTx - crypto package": {
        "title": "AioTx - crypto package",
        "score": 1,
        "url": "https://www.reddit.com/r/Python/comments/1cx6w6k/aiotx_crypto_package/",
        "content": "# What my project Does:\n\nAioTx is the library for interacting with crypto nodes to get information about transaction or to broadcast your transactions,my package is now working with BTC, LTC, ETH, BSC and makes monitoring or interacting with crypto really easy. Now using my library you will be able to generate wallets, monitor new founds and send them, so you can build your payments system on top of it. It's working using public nodes.\n\nNode is the copy of blockchain what you can interact with, think about it like about crypto server instance, so you can send command to do something, it's working like API\n\nAs you know some blockchains are based on ideas of others because of that I have created some parent classes for them, now it's EVM (ETH, BSC) and UTXO (BTC, LTC) clients. Examples will be only about some of them, but the same logic will work for all.\n\nLet me show you some usage examples now:\n\n    from aiotx.clients import AioTxETHClient\n    import asyncio\n    \n    eth_client = AioTxETHClient(\n        node_url=\"https://ethereum-sepolia-rpc.publicnode.com\", \n        chain_id=11155111)\n    \n    u/eth_client.monitor.on_block\n    async def handle_block(block):\n        print(\"eth_client: block\", block)\n    \n    @eth_client.monitor.on_transaction\n    async def handle_transaction(transaction):\n        print(\"eth_client: transaction\", transaction)\n    \n    async def main():\n        await eth_client.start_monitoring()\n        while True:\n            await asyncio.sleep(1)\n    \n    if __name__ == \"__main__\":\n        asyncio.run(main())\n\nIn that example you can see how you can monitor the ETH blockchain you can create handlers for block and transactions for know about top-ups for example.\n\nTransaction includes custom field named *aiotx\\_decoded\\_input* it's because by default for contract interactions you will get only transaction input encoded and you will not be able to understand what so AioTx will decode that for you if the method was from eth20\\_abi methods.\n\nLet's now look at the transaction sending example:\n\n    from aiotx.clients import AioTxETHClient\n    import asyncio\n    \n    eth_client = AioTxETHClient(\n        node_url=\"https://ethereum-sepolia-rpc.publicnode.com\", \n        chain_id=11155111)\n    \n    private_key = \"231d9a16df21402be2b2b50343c489129f1d42dcbaa18b553e6c99057e699df6\"\n    USDC_contract = \"0x13fA158A117b93C27c55b8216806294a0aE88b6D\"\n    USDT_contract = \"0x419Fe9f14Ff3aA22e46ff1d03a73EdF3b70A62ED\"\n    to_address = \"0xf9E35E4e1CbcF08E99B84d3f6FF662Ba4c306b5a\"\n    \n    eth_in_wei = eth_client.to_wei(0.00001, \"ether\")\n    tokens_in_mwei = eth_client.to_wei(1, \"mwei\")\n    \n    async def main():\n        nonce = await eth_client.get_transactions_count(to_address)\n        tx_id = await eth_client.send(private_key, to_address, eth_in_wei)\n        print(tx_id)\n        tx_id = await eth_client.send_token(private_key, to_address, USDT_contract, tokens_in_mwei, nonce=nonce+1)\n        print(tx_id)\n        tx_id = await eth_client.send_token(private_key, to_address, USDT_contract, tokens_in_mwei, nonce=nonce+2)\n        print(tx_id)\n    \n    asyncio.run(main())\n\nHere you can see the example of sending native ETH token and some contracts, we are using nonce here is that way because we are pushing transactions one by one too fast and nonce will be not managed fast enough by node.\n\nNonce - the current number of transactions on your wallet.\n\nUXTO based clients (BTC, LTC)\n\nFor UTXO based clients we will need a database because we should store the unspent transactions for creating new ones from it, by default AioTx will create SQLite database on first client run and will put all the data into it but you can specify the url for your MySQL database and AioTx will use it\n\nFor working with LTC/BTC you always should have monitoring running, because you should get fresh data about your unspent transactions. Logic for run the monitoring are same as for ETH client:\n\n    from aiotx.clients import AioTxLTCClient\n    import asyncio\n    \n    ltc_client = AioTxLTCClient(node_url=\"https://api.tatum.io/v3/blockchain/node/litecoin-core-testnet\", testnet=True)\n    \n    @ltc_client.monitor.on_block\n    async def handle_block(block):\n        print(\"ltc_client: block\", block)\n    \n    @ltc_client.monitor.on_transaction\n    async def handle_transaction(transaction):\n        print(\"ltc_client: transaction\", transaction)\n    \n    async def main():\n        await ltc_client.start_monitoring()\n        while True:\n            await asyncio.sleep(1)\n    \n    if __name__ == \"__main__\":\n        private_key, address = asyncio.run(ltc_client.generate_address())\n        print(\"address\", address)\n        print(\"private_key\", private_key)\n        asyncio.run(main())\n\nAfter you will get the top-up you will see the UTXO transaction in your database ( I can't add photo here because of rules)\n\nNow we are ready to spend it :)\n\n    from aiotx.clients import AioTxLTCClient\n    import asyncio\n    \n    LTC_TEST_NODE_URL = \"http://localhost:19332/wallet/main2\"\n    ltc_client = AioTxLTCClient(LTC_TEST_NODE_URL, testnet=True, node_username=\"litecoinrpc\", node_password=\"7aON+t6CMysoGC7U7dOwCipjpzE=\")\n    \n    private_key = \"18553b3eb4c5f905d7b023e1736b55ffcbf47657d2cb27f398526ddc9d1764e7\"\n    address = \"tltc1qekukv0c9frj3zz8jyag863p8gvv7m3gy2np88d\"\n    to_address = \"tltc1qswa8y94sd0njs0atf7h2rmr638nuksw0p2m03v\"\n    \n    async def main():\n        balance = await ltc_client.get_balance(\"tltc1qekukv0c9frj3zz8jyag863p8gvv7m3gy2np88d\")\n        print(\"balance is:\", balance)\n        amount_in_satoshi = ltc_client.to_satoshi(0.0005)\n        # Without any additional params\n        tx_id = await ltc_client.send(private_key, to_address, amount_in_satoshi)\n        print(tx_id)\n        # Deduct fee from client\n        tx_id = await ltc_client.send(private_key, to_address, amount_in_satoshi, deduct_fee=True)\n        print(tx_id)\n        tx_id = await ltc_client.send_bulk(private_key, {to_address: amount_in_satoshi,\n                                                         \"tltc1qswslzcdulvlk62gdrg8wa0sw36f938h2cvtaf7\": amount_in_satoshi})\n        print(tx_id)\n        balance = await ltc_client.get_balance(\"tltc1qekukv0c9frj3zz8jyag863p8gvv7m3gy2np88d\")\n        print(\"balance is:\", balance)\n    \n    asyncio.run(main())\n\nAs you can see we have a logic for default send and bulk send as well, so you can include a lot of addresses for mass payments and it will be cheaper for you.\n\nTransaction fee estimations is automated but if you want to - you can set total commission in LTC or fee per bytes and you also can deduct commission from your receivers for single or bulk send.\n\n# Target Audience\n\nPeople who want to build crypto apps/payments systems in easy and fast way.\n\n# Comparison\n\nYou can find the code from that examples here if you need it:  \n[https://github.com/Grommash9/aiotx\\_test\\_examples](https://github.com/Grommash9/aiotx_test_examples)\n\nThe source code and package is available at:  \n[https://github.com/Grommash9/aiotx](https://github.com/Grommash9/aiotx)\n\nThe documentation is available at:  \n[https://grommash9.github.io/aiotx/](https://grommash9.github.io/aiotx/)\n\nAnd you can install it from pypi using your python package manager\n\n    pip install aiotx\n\nThanks for reading! I hope my package can be useful for you!",
        "num_comments": 0,
        "comments": []
    },
    "A Beginner's Guide to Unit Testing with Pytest": {
        "title": "A Beginner's Guide to Unit Testing with Pytest",
        "score": 17,
        "url": "https://www.reddit.com/r/Python/comments/1cwm734/a_beginners_guide_to_unit_testing_with_pytest/",
        "content": "Hey r/python!\n\nI wrote a guide on how to use Pytest, covering a bunch of important features like designing tests, filtering tests, parameterizing tests, fixtures, and more. Check it out [on this link](https://betterstack.com/community/guides/testing/pytest-guide/).",
        "num_comments": 3,
        "comments": [
            "so, you re-wrote the docs?",
            "You know that tutorials are different kinds of documentation then say, a manual, right?\n\n\nI mean why even have schools if we have books, right?"
        ]
    },
    "Reactive programming for Python with live-cells-py": {
        "title": "Reactive programming for Python with live-cells-py",
        "score": 31,
        "url": "https://www.reddit.com/r/Python/comments/1cwcm7f/reactive_programming_for_python_with_livecellspy/",
        "content": "live-cells-py (Live Cells Python) is a reactive programming library which I ported from [Live Cells](https://livecells.viditrack.com/) for Dart.\n\n# What my project Does:\n\nYou can declare *cells* which are observable containers for data:\n\n    import live_cells as lc\n    \n    a = lc.mutable(0)\n\nCells can be defined as a function of other cells:\n\n    a = lc.mutable(0)\n    b = lc.mutable(1)\n    \n    c = lc.computed(lambda: a() + b())\n\n`c` is defined as the sum of the values of cells `a` and `b`. The value of `c` is automatically recomputed when the value of either `a` or `b` changes.\n\nThe definition of `c` can be simplified to the following:\n\n    c = a + b\n\nWhich reads like an ordinary variable definition\n\nYou can define a *watch* function which runs whenever the value of a cell changes:\n\n    lc.watch(lambda: print(f'The sum is {c()}'))\n\nThis watch function, which prints the value of `c` to standard output, is run automatically whenever the value of `c` changes.\n\nMore complex computed cells and watch functions can be defined using decorators:\n\n    n = lc.mutable(5)\n    \n    @lc.computed\n    def n_factorial():\n        result = 1\n        m = n()\n    \n        while m > 0:\n            result *= m\n            m -= 1\n    \n        return m\n    \n    @lc.watch\n    def watch_factorial():\n       print(f'{n()}! = {n_factorial()}')\n\nI've found this paradigm to be very useful for handling events and keeping the state of an application, be it a GUI desktop application, systems software or a server, in sync between its various components, which is why I ported this library to Python so I can use the same paradigm, with a similar API, on the backend as well.\n\n# Target Audience\n\nThis project is intended for those who are looking for a declarative solution to handling and reacting to events in Python applications that is simple and intuitive to use and doesn't require excessive boilerplate. Particularly if you're used to working with signals in JavaScript, you will quickly pick up this library.\n\n# Comparison\n\nThe de-facto standard for reactive programming is the ReactiveX (RX) series of libraries available for various programming languages. The main difference between RxPy and Live Cells is in the design of the API, with the main difference being that cells are self-subscribing. Referring to the examples shown in the previous sections, you do not have to explicitly \"connect\", \"subscribe\" to cells nor do you need a \"map\" or \"zip\" construct to build more complicated reactive pipelines. Instead you simply reference whatever you need and the subscription to the dependencies is handled automatically by the library.\n\nThe source code and package is available at:\n\n[https://github.com/alex-gutev/live\\_cells\\_py](https://github.com/alex-gutev/live_cells_py) [https://pypi.org/project/live-cells-py/](https://pypi.org/project/live-cells-py/)\n\nThe documentation is available at:\n\n[https://alex-gutev.github.io/live\\_cells\\_py/basics/cells.html](https://alex-gutev.github.io/live_cells_py/basics/cells.html)",
        "num_comments": 4,
        "comments": [
            "Nice project! Is it thread safe? How do you handle concurrency?",
            "Thanks for the interest. It's not thread safe. Currently it supports limited concurrency with green threads: [https://alex-gutev.github.io/live\\_cells\\_py/basics/pitfalls.html](https://alex-gutev.github.io/live_cells_py/basics/pitfalls.html). The Dart library has facilities for defining asynchronous cells (you can read more about it here <https://livecells.viditrack.com/docs/basics/async-cells>), which integrate with Dart's Futures. I plan on porting this part of the library next, and provide facilities for integrating cells with asyncio.",
            "Asyncio integration would be awesome!",
            "It's a priority for the next version."
        ]
    },
    "The possibility to build Android apps with python professionally is here and needs your support.": {
        "title": "The possibility to build Android apps with python professionally is here and needs your support.",
        "score": 51,
        "url": "https://www.reddit.com/r/Python/comments/1cvvy36/the_possibility_to_build_android_apps_with_python/",
        "content": "You guys really need to check this. I believe new comers to python would love to tinker with the android ecosystem from the safety of python :-)\n\nImgur: https://imgur.com/gallery/DtfwOVi\n\nhttps://www.kickstarter.com/projects/kivyschool/the-pain-free-python-on-android-essentials-course\n\nEdit: added imgur link.",
        "num_comments": 28,
        "comments": [
            "Nice that's it's growing. Still it needs stronger commerciall recognition/maturity. When I was using it internally for a POC app it was easy to use but then debugging on actual Android devices was so annoying ;)",
            "I\u2019ve built a little tool using Flet. Works great. It\u2019s like Python over Flutter",
            "https://beeware.org/\n\nMet the maintainer of this project at Pycon this weekend, it seems to have great potential",
            "> kivy\n\nNo thanks, I'd rather chew on broken glass than use kivy again.",
            "Is \"kivyschool\" a part of the kivy project, or a separate entity? In other words, does sponsoring kivyschool directly benefit kivy software or just the person(s) behind kivyschool?",
            "I ve built many professional Android apps with Kivy. Some extremely complex using communicating with BLE device, GPS , geofencing, using camera and reading QRCode.\n\nIt s a real alternative",
            "Take a look a /r/kivy",
            "is it really python or just some code conver to android",
            "Is this cross-plattform? If not, it will probably have a hard time because native app development is getting more and more obsolete",
            "Things since last updates have gone way better especially for performance, also for debugging you can the check the hot reload function created by kivy school team.",
            "Flet looks nice, but as I understand it only allows you to deploy on android as a PWA, which I read \"Limited access to native device features: Progressive web apps may be unable to access all of the features available on a user's device, including push notifications, a camera, and an accelerometer\"",
            "Does your hate for kivy go so far that you'd rather chew broken glass than at least explain your pain points with kivy?",
            "I was planning to use Kivy for a small project, what particularly did you dislike?\n\nChanged autocorrect Kirby to Kivy",
            "Agreed.",
            "Kivy school team works closely and contribute to kivy libraries, for example they implemented hot reload for kivy.\n\n Sponsoring kivy school will surely help the community of kivy with better tools, documentation and recognition.",
            "And it has grown even better recently.",
            "It s a python interpreter built for android, launched by a small java launcher.",
            "It's really pure python",
            "Yes similar to Flutter you can write apps for android, iOS, windows and Linux.",
            "Fair enough, my app was a very basic form, kind of thing. I mean, whoever comes up with something like flutter, but you think python, is going to change the game. I know we have kivy but I feel like they could be a better implementation.",
            "Oh I do love Kirby. Played so much in my DS",
            "Why recently ? Did i miss something new in last release ?\n\nKivy grow slowly, but it s a great, and stable FW.",
            "Oh nice, I might take a look at it",
            "I do hate autocorrect :'(.",
            "I believe it's getting more attention recently, probably because of python libraries and how easy to start with.",
            "But I do love Kirby :(",
            "I actually had the opposite feeling; we hear less and less about it compared to Flutter.",
            "We have feelings yes, but the reality shows there is some forward movement, for example on flutter sub you see posts about flutter being deprecated which is far far away from happening, kivy on the other hand isn't a dead project despite it's older than flutter."
        ]
    },
    "You should only use licensed version of python": {
        "title": "You should only use licensed version of python",
        "score": 490,
        "url": "https://www.reddit.com/r/Python/comments/1cvhi1m/you_should_only_use_licensed_version_of_python/",
        "content": "I\u2019m an intern in a company and I automated some processes using python. My company\u2019s IT wing said that as long as it is a licensed software you can use it in our company.\n\nIn my mind I was like where the f I\u2019m going to get a license for an open source software. \n\nNote : They mention that another team has been using licensed python. I thought either IT is so stupid or that team is so smart that they brought license for pycharm or anaconda (claim that it is a Python license) and fooled IT.\n\nIf I am wrong then tell me where I can get that license.\n\nAnd I am also looking for job in data analyst.",
        "num_comments": 234,
        "comments": [
            "You don\u2019t have to purchase a license to have a license. If they ask for the license send them here: https://docs.python.org/3/license.html#psf-license",
            "Python is Open Source software, it comes with a free license already. There is a files `LICENSE` in the [source code distribution](https://www.python.org/downloads/source/) if you need details.",
            "Amazing. I think Anaconda fits this description mostly though.\n\nYou can get an enterprise support licenses for lots of major open source tools like DBeaver, Polars, etc. They're a great way to get a company onboard, and also help give back to the dev teams that made the awesome tools in the first place.",
            "ActiveState and Anaconda offer commercially supported Python distributions, I guess that is what the IT department has in mind. By paying those companies for providing the interpreter and packages, the obligation to check for security or foss license issues is outsourced and there is someone to sue if something goes wrong.",
            "Ask your IT department. They're the only ones who can answer what they accept.\n\n\nInclude suggestions (such as Anaconda) and let them say which ones are acceptable.\u00a0",
            "I must ask, and it's an even more tricky one than Python itself. \n\nHow do your company handle each external library, from pip as one example? Every package is a licensed software.",
            "What OS are you using? If Linux and something like RHEL it comes bundled as part of the system so is part of the subscription.",
            "> I thought either IT is so stupid or that team is so smart that ...\n\nAsk the other team what they did.",
            "You're right that either IT is wrong or you are, but frankly it's probably you. It's fun to dunk on IT departments but I find it really unlikely that they haven't heard of Python. It's much more likely that you aren't understanding their instructions. Reddit isn't going to be able to help you here, communicating with some humans is what's going to resolve your conundrum.",
            "Python comes with free for commercial use License. Maybe they don't know the difference between Python and PyCharm",
            "https://docs.python.org/3/license.html#psf-license",
            "Maybe they mean libraries, not all libraries are open source or free for commercial use. There's also development environments e.g. Visual Studio Code is free for commericial use, other options may not be.",
            "Python is licensed\u2026 [here you go](https://docs.python.org/3/license.html#psf-license)",
            "Package it in a Red Hat Enterprise Linux Universal Base Image container, then the IT department can have a support contract and license and they\u2019ll have a route to getting security updates. \n\nRed Hat Developer license is free and lets you use all their software, your company would likely have to purchase a support package and a supported runtime\n\nhttps://catalog.redhat.com/software/containers/rhel8/python-311/6278e0f006a32ea64d5d6c2c?architecture=amd64&image=66187fc7eee51afdaa1fe352&container-tabs=gti",
            "My company has pretty strict policies about which open source licenses we can use in our software. This is to protect the company from devs who don't understand licensing from using some code that then requires the company release code of our derivative works to customers. For some licenses there is a specific process to request to use it.\n\nI feel like there must be some miscommunication here between you, IT, and legal.",
            "You should find a new job",
            "Free license is also license.",
            "It already has an Open Source License so it's technically already licensed.",
            "Since it's open source, that means that ANYONE can create something that can be downloaded. All they want is something that shows that you got it from a trusted source. Docker has stuff like that, but all those random python modules? Some can be questionable, but as long as you provide good documentation that proves that they're trusted sources, then that's all that's needed. That's how my company functions.",
            "That's not how any of this works.",
            "Good news you have a license it can be found right [here](https://docs.python.org/3/license.html#psf-license)",
            ">You should only use licensed version of python\n\nYou know it's the case, right? \"Licensed\" does not mean \"proprietary\", it does not even mean \"paid\".\n\nThe only three cases where a software is unlicensed are:\n\n* software without a license (even random codes/binaries from Github where there is no license in the repository)\n* pirated software (anything running without a valid key)\n* freemium whose trial period expired (e.g. WinRAR)\n\nDo not get this the wrong way, but you're an intern, you should start to know what you're talking about, especially if your supervisors don't. You'll likely be the one blamed should something happen.",
            "https://github.com/python/cpython/blob/main/LICENSE",
            "I'd get reconfirmation that is what they said and if so, what they mean.\n\n\nI'm assuming they mean \"as long as the licence is valid\". Using open source would be valid as the license allows you to use it\u00a0\n\n\nPirated software or software that is free for personal use would not be\u00a0",
            "For us it was the same thing so we had to procure anaconda",
            "There _are_ paid versions of python like this one https://www.activestate.com/products/python/. I have no affiliation with the company other than using their Perl product many years ago.",
            "The reason they want the license is to see if it\u2019s free to use or not. \n\nFor example, MIT license is open source and can be used in any project, for profit or not, without disclosure. \n\nFor an AGPL license on the other hand, if you use a function from an AGPL library, then all of your code connected to it must become open source. This is one of the strictest licenses, and if you do not make your code open source and you get audited, likely legal troubles or potential to force your code base to become open source.\n\nOther licenses say that the code is for academic, or non-commercial applications, and any commercial applications would not be allowed.",
            "Hey! I'll sell python to you! Only a hundred bucks I'll dm my paypal. \n\nUpgrade to 3.13 will only be 50.",
            "Get the standard anaconda distribution. It is free for public, but they charge a license fee from companies. Tell your billing department to pay for it",
            "Isn't the Anaconda Distribution licensed? That would include python, along with a large portfolio of Data Science related stuff. Also, I think you might be able to make a case for a Visual Studio enterprise license, which would enable you to access Python.",
            "Commercial licenses do exist for some software\u2026\u2026 anaconda for example charges large entities for use of their software\u2026. It\u2019s not free. They also can monitor the use of the software coming from these entities because it causes network traffic.",
            "There are probably proprietary implementations of Python, you can look for those and ask them to buy it. There are legitimate concerns with using FOSS versions of software, namely lack of paid support. \n\nAs an example ActivePython or something similar, there are some mentioned here: https://www.python.org/download/alternatives\n\nI'd ask that other team what they're using (your company probably has a license already).",
            "All you need to do is to include LICENSE.md in your Github repo. [Details](https://docs.github.com/en/communities/setting-up-your-project-for-healthy-contributions/adding-a-license-to-a-repository)\n\nYou can copy MIT license, which will make it licensed software, free for commercial use:\n\nhttps://license.md/licenses/mit-license/",
            "It is open source. That is the license.",
            "Python is open source licensed. Anaconda's private repository is privately licensed.",
            "What OS is your computer running?  Windows 10 or 11?\n\nPython is available in the Windows App Store.  This should meet IT's requirement for \"licensing\". You can [Get started using Python on Windows for scripting and automation](https://learn.microsoft.com/en-us/windows/python/scripting).\n\nWindows Subsystem for Linux (WSL) also is an option.  Learn [How to install Linux on Windows with WSL](https://learn.microsoft.com/en-us/windows/wsl/install).  The Linux distro (Ubuntu, OpenSUSE, Kali, Debian, Arch Linux, etc) installed by WSL should include Python.  Then you can [Get started using Python for web development on Windows](https://learn.microsoft.com/en-us/windows/python/web-frameworks).",
            "Open source itself means that you have the license to use it for free. So you actually do have the license to use it.",
            "Go above IT to legal. They should understand licensing better.",
            "License like MIT is placed on the free and open source license.\n\nProbably the issue was that there is no license at a so you can't tell if you are allowed to use it or not.",
            "Obviously they are just making sure that unlicenced software is not being used, so nothing to worry about.",
            "I would buy a product I want to have, like pycharm pro or something and send the python open source license with it. While you are at it you could also buy monthly OpenAI subscription and tell it is like copilot.",
            "Go see if the intel python distribution has a way to get support. It\u2019s both fast and has most of the data science libraries you would want.",
            "Licensed python lol",
            "For packages we watch licensing carefully",
            "Maybe the projects they are using that were written in python have their own licenses.",
            "Register an LLC, write a license agreement for your script, and send the company and invoice for the license. Problem solved!\n\nlol, Python is a programming language, not a for-profit product/library",
            "It is licensed, it\u2019s an open source license. Your company have rules against some open source licenses. Like we don\u2019t allow gplv3 without an explicit approval. But all other open source license is fine. \n\nI assume they just want to make sure there\u2019s a license and its usage is clearly spelled out. It\u2019s a legal thing.",
            "Did they mean: ***anaconda***",
            "So I guess they can't run Ubuntu servers? Since it cones with python already lol.",
            "When I worked as a license manager in configuration management, I dealt with people who had some pretty bad assumptions. Just because something worked the way it did one place, doesn\u2019t mean it\u2019s universal. \n\nBest guess, whoever said they need a Python license and invoice probably once paid for a licensed IDE or framework.",
            "This might have already been mentioned but can't they look at best practices from other companies? There are so many fortune 500 companies using Python with no cost and they all follow their companies audit and risk controls to use it.\n\nThe only thing I ever ran into was having a company run R packages through Black Duck to ensure the package source did not have any malicious code.",
            "\"sell\" them cpython source code and become a millionaire \n\n\n/s dont do this",
            "They could mean paid support. We have a similar policy for some enterprise software.",
            "Just make sure if you use conda you use miniforge/conda forge. Otherwise using conda to pull from the Anaconda hosted libraries need a license for orgs over 100 people. If you're using conda that's been pre-installed on a cloud machine, it likely already has conda forge set.\n\nConda forge/miniforge are free to pull from, Anaconda default is not when org is large",
            "Finish your internship. Take whatever they give. Then don't work there. Some companies insist on having somebody to take the blame for all security and bug fixes. These companies are infuriating to work for. Anything in healthcare is especially prone to this behavior. Good luck, young developer!",
            "At least consider dumping Anaconda.  \nSo much troubles it's questionable if to stop using it.\n\n* Classical we start as free and gradually demand an online account (damn cheers to Qt)\n* Still does not allow to protect basic env which frequently damages everything and requres reinstalls\n\nAnd some unconfirmed opinions that situation changed nowadays and it's simply less requred. I'm still using it but had some surprising troubles with Qt via conda vs Qt via pip just yet",
            "What OS are you running on? All Linux distros come with Python built-in so if you bought one with paid support it would be included in the license.",
            "That IT dept is dumb AF.",
            ">  I thought either IT is so stupid \n\n:nodding Nicholson yes meme:",
            "I can sell them an enterprise Python license. Also an enterprise Linux license. Enterprise licenses for all open source software is available.",
            "They could pay someone like Divio for infrastructure, who will also provide their own pypi server.",
            "Fork it, and sell your fork to them. Paycheck hacks",
            "There\u2019s really no conversation to be had here. Just use it and if they ask link then the license on python\u2019s website. \n\nLiterally most of the recent ai companies are built entirely on python. If your IT department doesn\u2019t understand what python is, they need to be fired.",
            "Same with my org. I thought it was just government being government.",
            "i had this happen to me this week. it was my second weekend interning. over my first 8 days i made a simple online app with python and js. then i asked the it department what i need to do for the hosting and this guy shut down everything i told him i was doing. then he said he would have to get legal involved since i used python even though its only in my local files\u2026. Turns out another department is secretly using python so im working on find the work around they used.",
            "A company with this mindset is a HUGE red flag.",
            "I know the IT guys in my company all want us to use Anaconda and install modules using the corporate Anaconda channel \u2014 that is how paranoid they (righly) are. Cant install Python any other way w/o running into compliance issues.",
            "corporations are full of stupid people. Sadly they pay no taxes so they can afford all these nonsense.",
            "You sound really arrogant and dismissive of both your colleagues, and your company\u2019s approach to good governance. That attitude will very negatively affect your future unless you recognise it and adjust it.",
            "I know but they want a paid version \ud83d\ude02\ud83d\ude02\ud83d\ude02",
            "Open source is a huge red flag in many companies because of anti-FOSS FUD. They are afraid of having to open up their own code if they accidentally serve AGPL or link against GPL or LGPL. Even my senior team lead has trouble understanding the difference.",
            "It's open source, but not GPL-compliant. I was Guido's boss at BeOpen in the early 2000's, and I wrote the license for version 2.0. I intentionally left out the word \"irrevocable\" because I wanted the right to do so if there was a good reason. Subsequent (derivative) versions of Python are subject to that license as well.\n\nWhen BeOpen.com collapsed, employees got to pick various things in lieu of pay. Some chose laptops or other hardware. I chose the Python copyright itself (2000). It's a weird quirk of history.",
            "What bigger companies want is enterprise support because everyone knows you need it and can\u2019t provide it yourself. Better buy and get to call some experts than getting stuck endless.\nMongoDB, RedHat, Jetbrains\u2026\nFor python itself idk, but frameworks or such could offer it.",
            "Yeah",
            "Great idea",
            "Yep, we stopped using conda at our company because they removed commercial support from their free tier. If your company wants to pay for something, that would work. Whether using conda is better than sticking with pip and virtualenv is another debate.",
            "Hey I want to second Anaconda. My firm (~5000 employees) was super hesitant about using a free distribution of software for client work, even with the free distribution license others have mentioned. Getting an enterprise subscription to Anaconda/Spyder lets the business/IT folks feel safe for a fee that is negligible to a large company. \n\nI still think it\u2019s silly, but your post just sounds exactly like my experience, and this is how my firm got on board with production in python.",
            "We use this at work. They help with custom requirements.\u00a0\n\n\nIt's seemingly a CYA thing for the company, but working with Anacondas TAMs/engineers is pretty nice. I could definitely implement similar solutions with PyPI or Anaconda, but then it's one guys' solution on every team in the company vs a uniform service.",
            "Yes, but if OP's supervisor read \"support license\" they might not be happy given how stupid they are.",
            "That will work",
            "Each as a separate software and wants a license for each",
            "No we use windows(windows 10)",
            "This is the solution.",
            "I have every version of Python on my workstation, 3.3 -> 3.13. I also have all the alternative implementations like mircorpython, circuitpython, pyjion, pypy, pyston, cinder, mojo, etc. Some have a jit, some have weird build arguments, some have weird memory allocators, some only work on ARM, etc. This isn't the flex OP thinks it is. All IT wants is an *official version* e.g. from python.org/Windows Store and not some fly-by-night build that promises the world.\n\nIf they want enterprise support they can buy Anaconda. \n\nThey can also buy an Intel optimized compiler + Python interpreter.",
            "I agree. If OP was an intern at my company, I\u2019d chuck him out",
            "^This is the right answer. It's still technically using a license but it's a different kind than Companies are use to. If you provide Legal and compliance (or it's equivalent) with the license you should be in the clear",
            "I know that, but he is the COO of company so can\u2019t argue with him",
            "They told us that another team uses a paid version of python",
            "PERL, writ once, read never",
            "Some time ago, they aggresively engaged our company, so we tried to clean everything conda from all corners. But it's not easy. The conda binaries are spread everywhere in legacy systems since 2012 on the basis that it was free.\n\nOur folks are mixing Anaconda inc, anaconda distro, conda command, miniconda, miniforge, conda-forge, default [repo.anaconda.com](https://repo.anaconda.com) channel. That ToS switch created a whole lot of confusion between our IT, Legal, Procurement departments. Not worth the mess.  \nWe had a somewhat complex setup with Jupyterhub, and we switched every \"conda install\" with \"pip install\" and it was not only way faster, it's now more stable.  \nForget about mamba, it's the same snake behind (never trust a snake).",
            "*Hands you a mirror*",
            "Sell it to them \ud83e\udd37\u200d\u2642\ufe0f",
            "https://www.anaconda.com/blog/anaconda-commercial-edition-faq\n\nMaybe the other dept is using this.",
            "Yes. There are legal departments that are this dumb. They don't want to risk fighting in court over legalese they didn't personally sign.",
            "If your main use is data science consider Anaconda. Since it comes with all the (data) science stuff you\u2019re also covered for *those* libraries.",
            "Use the anaconda package and tell them that by paying for the sub,  you get access to the \"verified\" packages. Not lying and you get to go about your day.",
            "\"This is a paid version that costs 0.00$\"",
            "Anaconda has a paid tier with enterprise support and vetted packages, i think",
            "For a open source software",
            "Hey! Free PyCharm",
            "Give them my bank account info, you\u2019re welcome!",
            "How much are they willing to pay. I can sell a licensed version /s",
            "Do you buy any chance work for a financial institution?\n\nI work for a local CU and our Information Security guys are very much like that. \"Doesn't matter the cost as long as we have paid support, for compliance.\"\n\nThey do a good job but it can be super inconvenient  \ud83d\ude05",
            "I'll gladly sell it to you for $100 cash.",
            "Send the donation link.",
            "Your technologists can't be so stupid that they don't even know about open source software? If they indeed are then call them out and educate what it is. This is 2024 and even space companies like NASA and SpaceX use open source and also contribute to it.",
            "> I know but they want a paid version\n\nBullshit. No employee in their right mind is going to write a policy that says: *We must give our money away else it's not real*.\n\nI suspect that you caused confusion by saying \"we don't need a license\" and now the person that you were talking to doesn't trust what you say.\n\nAs others have said, Python *is* licenced. To anyone. For free.",
            "Genuine question: why?",
            "But it from me",
            "Sounds dumb.",
            "I have heard this many times and I'm just give a little shake of my head whenever I hear it again. I'm a freelancer and I worked with many of the largest companies in my country (and some of our neighbors), banks, critical infrastructures, others. None of them had an anti FOSS policy. Most of them had clear rules when you can use FOSS and when not. Just to name a common \"DON'T\": A(G)PL. Often there was even a specialist, an Open Source officer, who gave support and was assisting with the release process.\n\nBut I have to admit that there were FOSS skeptics in smaller and middle sized companies, but it was quite some time since I met the last of them. Coincidentally most of them have left the market by now.",
            "My former IT Director had the belief FOSS is less secure and not safe. She, also, thought Windows is the most secure OS in existence compared to any other. Pointing out that is not true with how OS's are designed to close source/opensource pros/cons to \"I have been pwn\" competition results she would scoff claiming \"That does not prove anything...\" because she got a MS cert on how to be a system admin and knows nothing about engineering or true cybersecurity practices (writing software or locking down systems). She even thought ChromeOS was the least secure OS, yet every cyber attack we had it was the only systems safe along with ipads!",
            ">They are afraid of having to open up their own code if they accidentally serve AGPL or link against GPL or LGPL\n\nThis is a legitimate concern in regards to GPL. ln a good company, legal should have clear guidelines for what code under which licenses can be shipped in production code release and what software under which licenses can be used in the development of productions code",
            "It\u2019s pretty easy to check if it\u2019s AGPL by looking at the GitHub of the project.",
            "At Amazon they had a \"blessed\" list of open source licenses for software that we were allowed to use. No idea if this is still the case though as this was years back.",
            "There are also the big audits for risk like SOX and the like that are likely anti-FOSS. Let's say ACME builds a big internal workflow using python. Compliance later says all OS have to be upgraded to version X. Something goes sideways and now the workflow isn't flowing. Who do you call to fix it?\n\nA risk audit will point out that you have no vendor with an SLA to lean on in this event. The question becomes: do we spend time and money making workflow flow on X or do we rewrite workflow using a vendor backed product. Either way, these are unexpected expenses and now ACME needs to figure which bonus pool to dock.",
            "I have worked for Fortune 100 companies in my career. While I have used Linux and various OS systems since the nineties (Was cheaper than a Sparcstation when I wanted to work at home) this has not been the case in companies with capable IT staff for the past twenty years. Even Microsoft shops will almost invariably have some file / web / data / print serving by open source systems. \n\nMy current company (A fully owned subsidiary of a large fortune 100 company) manages networks in Sports arenas, hotels and airports. Our whole back end is Open Source based. BTW: the licenses were never an issue since we are a service and do not distribute products or software. But all the other big shops I know understand the issues the way they didn't twenty years ago.",
            "Huh? Can't you just fork it, host it on your own internal repo if you are really that paranoid?",
            "You can just buy anaconda and never use it. Will come in handy when your company decides to stop paying for anaconda.",
            "I\u2019ve transitioned over to mamba simply because it\u2019s much faster and does a better job of resolving dependencies. It seems to be maintained by a different team, and doesn\u2019t appear to restricted by conda licensing, does it?",
            "Heh, my company just sent a notice out last week saying to STOP using anaconda immediately because they were charging exorbitantly for the licenses and they weren't going to pay for it. It's going to be forcefully removed from all systems in a couple of weeks.\n\nCompany has >100k employees",
            "Tough to say. My company's biggest fear with a lot of these tools is that they don't fit into the \"it just works\" ecosystem Microsoft has going for it. We're more than happy to pay for fast support for those rare cases where the tools aren't working great and are wasting time.",
            "Oh to build anything meaningful you\u2019re going to want a different approach.\n\nYou\u2019ll need:\n- pip, venv, pandas, \n\u2026 no wait, this is stupid of me, just look at articles like this\u2026\n[20 Python libraries](https://builtin.com/data-science/python-libraries-data-science)\n\nIn short you will need lots of libraries and have this problem regularly.\n\nIf you\u2019re serious about data science in this company find another developer in the company and ask how they obtained these tools.  Good luck.",
            "We do keep track of licenses and what external libraries we are using, but we are fine as long we know each license is compatible with our product.",
            "So my IT department put us through this (a new CIO came in and decided he needed to lock everything down). He had to get a commercial license from Anaconda and they helped him set up a repo for the packages inside our network. So Anaconda keeps it updated and he can run his virus checking and everything else on it. We can still use pip or conda, but we point them to the repo. It was a hassle to set up and now he has to manage all the Anaconda users. But once it\u2019s set up and you have the license, it works just fine. No complaints.",
            "Microsoft store has a version of Python. Do they let you use the store?\n\nI\u2019ve never used it, but I\u2019ve heard of it being used.\n\nI\u2019m not sure how that other team is using it, but you could reach out to them. Chances are the other team is using python.exe and they won\u2019t block it on just your computer it would be blocked across the company.",
            "I am sorry for you.",
            "install WSL and use that :-) I've had to deal with a few corporate IT issues like this before major PITA. Not much you can do really.",
            "You\u2019d chuck anyone out, even your most talented guy for looking at you wrong",
            "LOL Sounds like that COO doesn't understand what a License is then. Good luck haha",
            "And you then asked them to explain what they meant by that...?",
            "Ask which team then ask them?",
            "So use whatever this other team is using? They've obviously gone through whatever process IT is OK with. \n\nIf you don't know what they mean by this, **ask**. Instead of posting on Reddit and guessing.",
            "And you asked for an explanation then? Because it's not, it does not justify anything, and, now you're happy wasting everyone's time.\n\nWe're not in your shoes, pal.",
            "Quite a story!  \nIt there some exceptions which are still easiest only via conda?",
            "Many years ago (before open source was what it is today) I had a similar experience.  I wrote a bunch of code for interpreting the outputs of some scientific equipment.  It was my fault for asking, but the IT department told me that I needed a license and receipt to use it.  I crafted a receipt for $100 for it, licensed in perpetuity.  I\u2019ll be darned if they didn\u2019t pay me the $100.  Since I already did it on their time, I bought pizza for the lab and invited the IT guys.  ($100 used to buy a lot of pizza). We all decided that we had done \u201cthe responsible thing\u201d and set in motion a recurring \u201cproduct release\u201d schedule.",
            "This is the right response",
            "Even better set up a company that they would make payments too. Now profit with them whether you stay there or dont",
            "\ud83d\ude02 They can\u2019t digest an intern has done what they can\u2019t",
            "Ask for a raise and tell them they can expense it as \u201clicensing fees\u201d",
            "Yooooooo... this idea ^ actually isn't half bad OP... make up an invoice, tell them you found where to get the license, profit???",
            "Hi we're only ever going to use the free plan features but we'd like to pay for it please. No we don't want one of your other advertised plans because they are per-user and the administration involved in tracking that would be way too much.",
            "This is the kind of company that this page addresses: https://sqlite.org/purchase/license",
            "Somehow Government even here in r/Philippines which are known for \"FREE FOR ALL\" SoftPaq",
            "If your company is larger than 200 people then you need to pay for Anaconda.",
            "We need you to go ahead and find us a better deal \ud83e\udd1d",
            "Python software foundation could always do with more funding, $50k should do the trick",
            "Not all opensource licenses are the same. When you get to a certain level you need to know the exact license of every dependency (python package) you have. You could easily make a misstep and use a license that has linking implications. Boom. You just created a whole lot of paperwork and a resume generating event.",
            "Maybe their motivation is \"if it's not paid we can't sue if anything happens\"",
            "Hey, where I work we are migrating from a single user app (backed by squlite) to multi user, which means we need a \"proper\" DB backend. We have customers from small labs to multinationals, and we asked the big ones for feedback about preferences (MySQL, postgres, MS SQL server, IBM DB...). We of course expected something along the lines \"whatever\" except here or there somebody already paying for, for example, Oracle and trying to simplify by having it all in the same.\n\nWhat we got, was, indeed, whatever, except it should not be open source, so for example postgres is out. WTF...",
            "I know that and I didn\u2019t tell them about the license \n\nThey just don\u2019t want an open source license they want some developer license.",
            ">A(G)PL\n\nThat parenthesis got me confused. Did you put it on the wrong letter, or were you actually referencing the [Adaptive Public License](https://en.wikipedia.org/wiki/Adaptive_Public_License)?",
            "> thought Windows is the most secure OS in existence\n\nTurns out the whole internet runs on an open source Unix instead",
            "The issue is that there is a good number of OSS licenses (MIT, BSD, Apache, CC, ...) in addition to the GNU ones, yet GPL is almost always quoted as being the reason for not allowing open source.",
            "There might be a single AGPL licensed .c file in there that makes the whole thing AGPL :D\n\nSome projects put \"MIT\" but then edit the license so it's not MIT and not even free software at all.",
            "I would say to the risk audit person they need to educate themself and do the task again.\n\nMost open source works on newer systems or just requires a recompile or just telling it to work on a older runtime stack. Not a big deal or hard to do. Far cheaper than paying some vender some big cost.  Along with so many other reasons FOSS is the better way.",
            "Who is going to do it? What if they can\u2019t fix it? Where will you find a contractor that can fix it? How long will it take to find and hire them, not to mention fix the problem? If the company\u2019s person can fix it, how long will it take? Are you okay with losing money (thousands of dollars a minute?) and potentially customers while someone works on it?        \nMaybe just don\u2019t upgrade? What about security vulnerabilities in the old software?       \nEtc.       \nMany things aren\u2019t so simple as \u201cfork it yourself.\u201d",
            "The at-rest location of GPL/LGPL/AGPL source code does not limit who is legally entitled to it.",
            "The official version of conda uses libmamba for dependency resolution now, so should be just as fast.",
            "I think ActiveState sells support for the libraries included \u00a0in their python distribution. That would probably fit the bill.\u00a0\n\nEnterprise IT likes commercial software because they have somewhere to go for support if things go wrong, not just because they like spending money.",
            "It's an internship - it's a good to see how the company works, and make sure you don't go back for an actual job later. Avoid at all costs - company seems to not be aware of anything and is run by morons. I've never seen a situation like that get better with time",
            ">Do they let you use the store?\n\nIf \"the talk\" was had I have serious doubts that _any_ instalation is allowed.",
            "> Do they let you use the store?\n\nI've worked a couple places that were way more open that OP's company. Free software was 100% allowed, as long as it had a standard license*. Products from the apple/ms store were forbidden without explicit permission.\n\n*I'm sure that a list of allowable licenses was provided, but its almost always GPL, Apache or BSD. Since this was all devops/tooling/etc GPL redistribution was a non-issue.",
            "Yeah we are having a meeting with them on Monday",
            "Conda used to be good for isolating environments, exporting them (conda-pack) and using them over Spark. But you can very well isolate with virtualenv or even docker. Stress free from their licensing\n\nI don't miss the \"Resolving environment...\" message when I just want to add a simple lib to my env. Very sluggish compared to pip. For sizeable env, it seems to be stuck in a loop for an hour until it times out.. \n\nTo make matter worse: I even caught Miniforge trying to d/l packages from [repo.anaconda.com](http://repo.anaconda.com), even when disabled, most likely a bug.\n\nAnyway glad we moved away.",
            "This reads like embezzlement",
            "You forgot the part in which everyone clapped",
            "[deleted]",
            "Use of software can be a significant business risk if the way the software has been deployed creates a liability for the company.\n\nThe sorts of things this policy might be meant to address include audit rights, obligations to pay for commercial use, and metrics for consumption.\n\nYour company may also have a Software Asset Management tool or person who has to track all this stuff.\n\nI doubt the IT folk care about what you've achieved except in as much it has the potential to cause a headache down the line if it isn't tracked.",
            "Rise above \u201cgood coder\u201d and use this as a chance to influence their software licensing policy. Put together a proposal for the relevant decision-makers on the merits of including the license python uses (and/or other FOSS licenses as appropriate) to augment their paid licenses. Show them the benefit by demonstrating the *\u201dnon-production prototype\u201d* (emphasize that it is non-production and just experimental) and be clear about the business impact of what you\u2019ve built. Cost savings, manual effort reduction, error rate reduction, process scalability improvement, etc. (try to quantify these as best you can, even using estimations). \n\nMake your recommendation that the company\u2019s IT and legal departments review the license terms and consider adjusting their policies. \n\nWhether or not they agree, this exercise and the experience you will gain from it will be useful 100 times in your career, maybe more. And you\u2019ll get better each time you do it. \n\nAnyone can code. Hell, we may not even need to before too awful long here. But not everyone can see the value in certain decisions, and then effectively influence others, without authority over them, to make those decisions. *That* is the real skill to develop in yourself in this situation. \n\nThey might come back and say no, and if so, do your best to *respectfully* understand why, and use that feedback to hone your strategy for future instances where you find yourself in a similar situation. \n\nDeveloping your *influence* is what moves you from \u201ccoder\u201d to lead developer to technical advisor to architect to principal, or to any number of other positions of leadership.",
            "Speaking from personal experience, Anaconda will take your money based on an estimate of upper bound of users in your company who would ever use Anaconda.\n\nAnd they will have no problem if you don't use any of the enterprise features and just grab your own copy of the individual installer and distribute that internally.",
            "This is a really interesting topic. Can anyone confirm that [this PDF](https://marketplace-res-cbc-cn.obs.myhwclouds.com/app_temp/attachment/20200410/50f04249-4157-4238-a5fe-4e9f14081fa5/2004100739324205.pdf) that I found with a cursory Google search is a valid example of their license? Not sure if I'll ever need to draw something like this up (and if I do, I'll ask a pro), but having a general idea would be nice",
            "That\u2019s the point. according to OP. His employer doesn\u2019t want \u201cfree,\u201d they want a product that\u2019s paid for because those are better (or so they think)",
            "Maybe this is how we can get more funding for open source software, software and IT people need to get their stories straight and tell the bean counters python costs money, extra if you want numpy.",
            "I suspect that the person that replied to you either misunderstood their own policy or didn't express it properly. Generally, a commercial organization does not want to have any open-source *source-code* saved anywhere on their premises because there's a danger that it will \"contaminate\" their proprietary code if it's not properly ring-fenced, so there's usually a strong \"no open source code\" policy. The *application* compiled from that source code is a whole different matter. The licence restrictions on open-source *applications* are very similar to purchased proprietary applications in that you need to look carefully at what the licence allows if you wish to bundle the application or its run-time library with your own code for distribution to others outside your organization.",
            "Is that how they actually worded it? Because the PSF Licence *is* the  developer's licence. The Python Software Foundation license.",
            "https://fossa.com/blog/open-source-software-licenses-101-agpl-license/\n\n\nNo AGPL is a license that requires any code that uses the license to become open source. \n\nAny code that calls an AGPL function becomes AGPL and must be visible to all users of the software. If the code is connected to the public internet then it must be open sourced. If it is available on a VPC to specific clients then you at minimum need to tell your customer \u201cif you want access to the source code, we can provide it to you\u201d or make it open source.",
            "I know. She did not believe that either thinking most is all windows servers even network gear and super computers. Thank goodness she resigned.",
            "Well because MIT, BSD,Apache all allow you to take open source code and use it in commercial code (close source it), but GPL does not",
            "Normally if you are using a reputable open source library, they put the license info in the GitHub and as long as you are not using a library that has very little contributions, you can feel relatively safe.\n\nAlthough there is always a risk.",
            "You used a weasel word though, \u201cmost.\u201d What if it doesn\u2019t work and shuts down your business?",
            "We had a product that the licensing cost was so insane, that we decided we could save money by just writing the program ourselves. We didn't need all the features that the company offered, only a subset of them. We took open source solutions and built on them. Saving hundreds of thousands of dollars, and we pay a contractor to support the software when needed.\n\nI've had companies where we have paid tens of thousands of dollars to admit there is a bug and refuse to fix it. Fuck that, will never have that issue with opensource. I can ALWAYS find someone to fix it.",
            "I agree - but doesn\u2019t hurt to test it. IT teams are weird and can be inconsistent when it comes to licenses and security in my experience.\n\nBut you are likely correct sadly",
            "Again, rather interesting insights, I never touched env packing that professionally, and wish ever had a need for docker. VMware was enough so far,   \nthough the whole subject intersects interestingly with safety and I often recall very casual isolation attempt of Comodo Sandbox which apparently was made even before docker for Windows.\n\nThough was interested about bit different subject - is there still some packages around which are hard to install with pip, but easy with conda?   \n  \nFor non-corporate casual users, that was main reason to use conda - I definitely remember multiple such packages, but can't recall which ones (solve and forget). Seems OpenCV?  \nOr it's safe to consider nowadays all these cases are solved?",
            "Is it embezzlement when you say \"I did this for free using free things\"\n\nI want to pay\n\n\"You don't have to\"\n\nWell someone has to take out money or you can't use it\n\n\"...\"",
            "I mean, they embezzled it back into the company \ud83e\udd37\ud83c\udffe\u200d\u2640\ufe0f",
            "None of it was hidden.",
            "This is an under appreciated reply. I'm sure I'm not the only one who remembers the software environment of the 80's and 90's - folks would pirate commercial software, bring it to work, create a tool (or even a product) with it - and then discover a bug or, worse, that the version they'd stolen was incompatible with the next operating system update. The organization would be left holding the bag for whatever remediation was required . Given the relative conservatism of risk managers, and (I'm generalizing here) their lack of understanding of more modern software environments the attitude OP describes is understandable, if not reasonable. In addition to licenses we used to have to buy support and subscriptions for updates for anything we used on company computers.",
            "If a rollout of a little python script to the whole company of say 1000 users is going to cost $180k/year that's going to need some budgetry consideration before being signed off. And large companies will use management software to track the numbers to make sure they don't exceed the license, whether Anaconda cares or not. They might think it simpler to ask someone to try and do it in powershell instead. \n\nPerhaps Anaconda should just sell a license to their free install for a one off fee, just to make those who need a paid licence happy.",
            "I was actually trying to find where it said on their website that there is an option to pay $4000 for a license. And then spend too long, but I don\u2019t see it anymore.",
            "And the win is that the bean counters will do it and pat themselves on the back on what a great deal they got.",
            "I hear matplotlib is thrown in for free when you pay for numpy.",
            "I\u2019m trying to push for this at my work (a University) as we widely use python and numpy. Unfortunately they get a bit funny about donating public funds (grant money) to organisations :/",
            "\ud83d\ude02 They are thinking even if they want to pay me $100 pm as stipend. Do you will they pay 50k??",
            "Yes \u201cThe other team got a developer license. So if you get a developer licence then it is ok to use python.\u201c",
            "But what about the APL? Or did you mean to write (A)GPL?",
            "Yeah some folks in this thread clearly don't understand that there are pitfalls with opensource. Easy to avoid if you know. But they are still there. I had to rework a project with ansible due to the linking. Was able to achieve the same result in a legal licensed way. But was more cumbersome without linking.",
            "Often in KDE projects the translations for ukrainian and catalan have a separate license than the rest of the project. And you won't know that until you go and open the translation file.\n\nReally, don't expect big projects to not have files licensed with something different.",
            "I prefer to only use public domain software, so not worried.",
            "Right, and good on you for that.      \nMy intention (perhaps not well executed) was to show that there is a lot more to this than \u201cjust fork it\u201d and other superficial answers people are posting.        \nThere also isn\u2019t a one size fits all answer.",
            "Rebezzlement?",
            "It's all good.  They unbezzled.\n\nFo' shizzle...",
            "That mentality can be explained to start with, but sticking with it in the face of facts showing that mentality is outdated or does not apply at all is worth critiquing as asinine and stupid.",
            "I can't speak to companies in general, but the issue we had was it was difficult to determine \"active\" users, compared to a product like IntelliJ which you open the same application every time and it has a license server that can be allowed.\n\nIt was determined the effort to give and support regular active count to Anaconda would cost more than just paying for a fixed total amount based on requests and installs and company size (your number is a little high but in the right ball park).",
            "If you sign up for a three year subscription, we\u2019ll throw in scipy for free too.",
            "How much for pandas, though, may as well get both",
            "I'd suggest asking that team about it. If it's Anaconda, say, then they're paying for access to Anaconda's repository and their proprietary tools \u2014 rather than Python for which Anaconda has no right to ask payment.",
            "Yes AGPL is a license type that is very restrictive.\n\nNot sure what the parenthesis that the other guy put are for either.",
            "Let\u2019s say a single .c file that is AGPL made it into a big library like Numpy, and the license agreement for Numpy did not say AGPL\n\nYes, the project should be AGPL, but if the project does not advertise it\u2019s license agreement, then is it really enforceable?\n\nI really don\u2019t know but I would assume the hypothetical liability would be on the hypothetical Numpy for not licensing their software properly. \n\nHas anyone gotten in trouble for using a library that was not properly licensed as AGPL?",
            ">  the translations for ukrainian and catalan have a separate license\n\nDo you have example of that?",
            "I\u2019m curious what you use for an operating system and software? There isn\u2019t much public domain software around.",
            "inbezzlement",
            "I think in the west powerful phones and tablets have replaced a lot of consumer desktop use cases, so piracy isn't as big of a thing. In turn the risk of pirate software being used by employees has been massively reduced. So it's easier for us to get free software installed because we're not a liability.\n\nIn developing countries the employee risk is higher because desktop software is still a huge thing, they haven't been forced to move to mobile apps or web offerings. And desktop software is still marketed and the norm, ads and tracking have less profit so no big push. With big box software and piracy as a free option, employees bringing that attitude to the office are a business risk. So getting a business to sign off on \"it's free\" hits the sort of controls we used to have 15+ years ago.",
            "Yeah I think that's common. And will scare off companies who just want to use python for a little thing and want to pay a negligible amount for a license.",
            "Hear me out.\nIf you buy this software called linux, you get all these for free and even more!",
            "What a bargain! Where do I sign?",
            "hahahaha",
            "Ever imagine that being free would be a problem?",
            "Okay \ud83d\udc4d\ud83c\udffb",
            "Oh lol it wasn't you. Yeah, I think the confusion is just the brackets imply they meant the AGPL and the APL, so we're just wondering if they meant AGPL and GPL.",
            "> then is it really enforceable?\n\nyes.\n\n> the hypothetical liability would be on the hypothetical Numpy\n\nYes, you can ask them damages for 100x of what you paid them :D\n\n> Has anyone gotten in trouble for using a library that was not properly licensed as AGPL?\n\nNo idea. But software gets rejected from debian all the time because of license problems (that are not apparent reading the license field on github).",
            "https://invent.kde.org/network/alligator/-/blob/master/po/ca/alligator.po?ref_type=heads\n\nhttps://invent.kde.org/network/alligator/-/blob/master/po/fi/alligator.po?ref_type=heads\n\nAs you see catalan file has its own license, while finnish file just follows the project's license.",
            "Actually ... Not a bad idea for OP. Pay for Red Hat or Ubuntu license with support and then all the FOSS packages are \"included for free\".",
            "Do you think that it may be possible for a rogue actor to purposefully inject AGPL in popular open source libraries, resulting in thousands of projects unknowingly becoming AGPL? \n\nIn that case what would happen? Seems like a crazy situation.",
            "Interesting, thanks.",
            "Yeah I\u2019d try this route too.",
            "rogue actor?\n\nI think it's much more likely for people to copy paste from the wrong project.\n\nI am ready to bet that most proprietary code violates some license."
        ]
    },
    "Dash Pip Components": {
        "title": "Dash Pip Components",
        "score": 12,
        "url": "https://www.reddit.com/r/Python/comments/1cw486p/dash_pip_components/",
        "content": "  \n**What My Project Does**  \nHey everyone, just released 8 new pip components for plotly and dash including:\n\n* `Full Calendar Component`\u00a0- A Full Calendar Component for Dash\n* `Dash Summernote`\u00a0- A rich text WYSIWYG Editor for Dash\n* `Dash Emoji Mart`\u00a0- A Slack-like Emoji Picker for Dash\n* `Dash Charty`\u00a0- A Charting Library for Dash\n* `Dash Image Gallery`\u00a0- A Image Gallery Component for Dash\n* `Dash Swiper`\u00a0- A Swiper Component for Dash\n* `Dash Insta Stories`\u00a0- An Instagram Stories Component for Dash\n* `Dash Credit Cards`\u00a0- A Credit Card Component for Dash\n\nDocumentation can be found here:\n\n[https://pip-docs.onrender.com/](https://pip-docs.onrender.com/)\n\nThe repo for the github can be found here:\n\n[https://github.com/pip-install-python/pip-docs](https://github.com/pip-install-python/pip-docs)\n\n**Target Audience**\n\nPlotly dash and Python developers.\n\n**Comparison**\u00a0\n\nAll these are new components for the dash framework, but based on javascript or react projects which were forked and edited to work specifically for dash.\n\n",
        "num_comments": 0,
        "comments": []
    },
    "HS-transform, python package for hyperbolic S-transform in signal processing": {
        "title": "HS-transform, python package for hyperbolic S-transform in signal processing",
        "score": 4,
        "url": "https://www.reddit.com/r/Python/comments/1cvzidl/hstransform_python_package_for_hyperbolic/",
        "content": "I made a python package for [S-transform](https://en.wikipedia.org/wiki/S_transform) with Hyperbolic window (Hyperbolic S-transform or HSTransform package). This is my first time publishing a python package, so the project is still far from stable and still under beta release.\n\n* What my project does: This transformation is applied to signal processing, analyzing transient changes of a signal during very short-time. Some special use case can be in power system signal, or Geophysical signal analysis, or MRI ...\n* Target audience: anyone who is interested in signal processing or power system analysis or geographical analysis.\n* Comparison: The comparison with Wavelet Transform has been shown. (which shows more potential in detecting transient changes)\n\nI would highly appreciate some feedback, before progressing further.\n\nHSTransform\u00a0is available on\u00a0[pypi](https://pypi.org/project/HSTransform/).\n\n[Link to source code in github](https://github.com/nvlinhvn/HSTransform)\n\n# Quick Usage\n\n    import numpy as np\n    from hstransform import HSTransform\n    \n    # Create input signal (for example: Voltage signal)\n    t = np.linspace(0, 10, 100) # timeseries\n    V_m = 220*np.sqrt(2)  # peak voltage\n    f_V = 50  # frequency\n    phi_V = 0  # phase\n    \n    V_clean = V_m * np.sin(2 * np.pi * f_V * t + phi_V)\n    # Create voltage sag/dip (80% of the nominal voltage for 0.15 second)\n    V_sag = np.where((t >= 2) & (t <= 3.5), 0.5 * V_clean, V_clean)\n    \n    # Create an instance of HSTransform\n    \n    hs = HSTransform()\n    \n    # Perform the transform\n    signal = V_sag\n    S_transformed = hs.fit_transform(t, signal)",
        "num_comments": 1,
        "comments": [
            "Looks good to me \ud83d\udc4d\ud83c\udffb"
        ]
    },
    "I made a cheatsheet for pydash": {
        "title": "I made a cheatsheet for pydash",
        "score": 7,
        "url": "https://www.reddit.com/r/Python/comments/1cvu4wb/i_made_a_cheatsheet_for_pydash/",
        "content": "[https://brunodantas.github.io/pydash-cheatsheet/en/](https://brunodantas.github.io/pydash-cheatsheet/en/)\n\n* What my project does: pydash is a library with great potential to make you code more Functional and simple. I made this cheatsheet a while ago to highlight some of the most useful functions of the library, since there are so many. I hope it's useful.\n* Target audience: anyone who is interested in pydash, functional programming, not reinventing the wheel.\n* Comparison: on Google you can find cheatsheets for Lodash, which is the original Javascript library which pydash is inspired by, but no cheatsheets for pydash itself. Note that many pydash functions are already implemented in modern Python, so I did not include those in the cheatsheet.\n\nI made this programatically using\u00a0[Material for Mkdocs](https://squidfunk.github.io/mkdocs-material/), which I also recommend.\n\n[https://github.com/brunodantas/pydash-cheatsheet](https://github.com/brunodantas/pydash-cheatsheet)",
        "num_comments": 14,
        "comments": [
            "Can someone explain to me why you would used a lib like pydash (adding a dependancy) rather than doing it \"by hand\"? Seems like a left pad risk to me",
            "I had never heard of this library. Ignoring that the name sounds too much like it\u2019s related to plotly dash, I really don\u2019t understand the point. It seems like it\u2019s just some very generic/basic operations that are easy enough to implement by the user without much hassle. Having to import a whole other library just to do some basic filtering or data structure mangling seems like a really bad idea.",
            "I guess this is a mistake: \"Variants: drop\\_right\\_while, drop\\_while, drop\\_right\\_while\" and the first one should be \"take\\_right\\_while\"",
            "Nice. That Mkdocs site is pretty cool too. I'm a fan of using lodash, and was looking for something similar with Python.",
            "I'm confused what I'm supposed to be looking at in your repo. You should make a pdf or something to look at.",
            "Some of these functions are useless, I agree. Some are kinda nice though (eg flatten, case conversions, etc). I may use this one!",
            "How to post my lib? All my messages are banned by spam filter, but my post looks pre same. Can somebody please help me",
            "It's a matter of not reinvent the wheel. And as far as I know you can always have the source code of the lib downloaded locally.",
            "I mean, it's basically the same reason people use requests instead of urllib, isn't it?",
            "You should look at the first link at the top for the docs. I included the repo below as well because of the rules of the sub.",
            "I get the not reinventing the wheel part, but In my opinion this is too extreme. If you don't know how to flatten a list or chain them, this is definitely something you should learn to do by yourself (also, most of Pydash functionnality are in the standard library anyway)",
            "No, not at all. Both of those libraries would be difficult for a user to implement themselves.\n\nHave you actually looked at the source for pydash? Almost every function is a one liner that is directly returned. \n\nIt would be like if someone made an \u201carray\u201d library where every function was called something like \u201cto_array\u201d and all it did was return np.array(x).",
            "A lot of the one liners is just to have parity with Lodash.\n\n\nDon't strawman, it can be useful even if you dislike it.",
            "It\u2019s not a strawman. It\u2019s genuinely silly to create a library that is lots of basic one liners that anybody can write and then asking people to make that a dependency on the code they are writing."
        ]
    },
    "IconMatch - find icons and letters positions from images!   ": {
        "title": "IconMatch - find icons and letters positions from images!   ",
        "score": 6,
        "url": "https://www.reddit.com/r/Python/comments/1cvp53v/iconmatch_find_icons_and_letters_positions_from/",
        "content": "Hey all,\n\nI am not the original creator, but found that 4yo project, and decided to revive it!\n\n**What my project does:** IconMatch is library allowing you to extract icons and letter positions from image or from display! There is also realtime demo on repo showcasing how it works!\n\n**Target Audience**: For all detecting objects from display! \n\n**Comparison**: I did not find other project like that - but it was my first find too! It is also not OCR!\n\n[https://github.com/NativeSensors/IconMatch](https://github.com/NativeSensors/IconMatch)\n\nHave fun!",
        "num_comments": 1,
        "comments": [
            "Subscribe to us for free (me) on polar to get more info about our projects: [https://polar.sh/feed](https://polar.sh/feed)"
        ]
    },
    "Tutorial: Simple Pretty Maps That Will Improve Your Python Streamlit Skills": {
        "title": "Tutorial: Simple Pretty Maps That Will Improve Your Python Streamlit Skills",
        "score": 67,
        "url": "https://www.reddit.com/r/Python/comments/1cuyivc/tutorial_simple_pretty_maps_that_will_improve/",
        "content": "Interactive web applications for data visualization improve user engagement and understanding.\n\nThese days,\u00a0***Streamlit***\u00a0is a very popular framework used to provide web applications for data science.\n\nIt is a terrific programming tool to have in you Python knowledge toolbox.\n\nHere\u2019s a fun and practical tutorial on how to create a simple interactive and dynamic\u00a0***Streamlit***\u00a0application.\n\nThis application generates a beautiful and original map using the\u00a0***prettymaps***\u00a0library.\n\nFree article: [HERE](https://johnloewen.substack.com/p/simple-pretty-maps-that-will-better) \n\n",
        "num_comments": 15,
        "comments": [
            "How can streamlit apps be used commercially? Has anyone had any experience at implementing them? Are there other ways to host other than via streamlit / what about from a  cybersecurity perspective?",
            "I work a lot in streamlit. Wish the sub was more active. I'm hoping that they will enable more interactive graphs with plotly soon.",
            "This is an exceptionally simple and easy way to build a python application. Just the interactive graphs alone are enticing enough for me. Just a note, its best for rapid prototyping but gives up customizability. Its very noob friendly and the website offers a interactive way to learn its uses, [website](https://streamlit.io/), [github](https://github.com/streamlit/streamlit).",
            "Thanks, I\u2019m going to go through this .",
            "[deleted]",
            "This framework is best for personal projects or rapid prototyping. The corporate world is slow to pick up new technologies.",
            "I think it's becoming more active. And yes, more Plotly would be great. I really enjoy working with the plotly library as well.",
            "And thank you for the comment - much appreciated!",
            "Thanks for the props!\n\nAnd it's just fun to get visual results like this from an inclusive programming tutorial.",
            "Let me know how it goes!",
            "ha ha, Thanks for the props - and for the editing. I did mean way to go - didn't even notice that until now - so thank you.",
            "The corporate world is only slow when it's not useful for generating actual value",
            "Yeah, that's what I thought, but then https://streamlit.io/ says:\n\n> Trusted by\u00a0over 80% of Fortune 50\u00a0companies",
            "and thank you for the comments - very much appreciated!",
            "And thank you for the comment - much appreciated!",
            "We use it for small internal applications, would never use it for anything client facing. I presume it's the same story for those F50 companies\u00a0"
        ]
    },
    "Interactive 8-Puzzle Game ": {
        "title": "Interactive 8-Puzzle Game ",
        "score": 2,
        "url": "https://www.reddit.com/r/Python/comments/1cvk87v/interactive_8puzzle_game/",
        "content": "# What does my project do\n\nHi everyone \n\nI\u2019m excited to share a project I\u2019ve been working on: an interactive 8-puzzle game built using Python and Pygame. This project also includes several solvers based on classic search algorithms.\n\n## Technical details:\n\n- Python: the primary language in the project.\n- Pygame: for rendering and handling user interaction.\n- Search algorithms: implement depth first search (dfs) and A star search for solving the puzzle. By default A star search is used because it finds the solution faster than dfs\n\n# Target Audience \n\nThis is a toy project I did for fun. You can find the project in GitHub: [link](https://github.com/mohammedElfatihSalah/8-Puzzle-Solver)\n\nI would love to get your feedback, contributions, and if you find it interesting or helpful, please give it a star on GitHub. Your support and feedback will help me improve and add more features!Thank you for checking out my project!",
        "num_comments": 3,
        "comments": [
            "hi, thanks for your project, i was trying to run your code on Visual Studio but i met this error problem:\n\n Exception has occurred: ImportError\n\n\n\n&#8203;\n\n    cannot import name 'solver_lib' from 'eight_puzzle' (unknown location)\n    \n\nwould u mind to help to solve it, i would appreciated alot",
            "Sure, I looked into the code and I actually found a bug and some issues with the README, so thanks so much for raising this.  I resolved those issues and updated the repo,  so please clone the code again and this time when you are executing main.py use the following command:\n\npython -m eight_puzzle.main\n\nPlease let me know how it goes"
        ]
    },
    "Mastering Python: 7 Strategies for Writing Clear, Organized, and Efficient Code": {
        "title": "Mastering Python: 7 Strategies for Writing Clear, Organized, and Efficient Code",
        "score": 38,
        "url": "https://www.reddit.com/r/Python/comments/1cuqmmh/mastering_python_7_strategies_for_writing_clear/",
        "content": "Optimize Your Python Workflow: Proven Techniques for Crafting Production-Ready Code\n\n[Link](https://www.kdnuggets.com/mastering-python-7-strategies-for-writing-clear-organized-and-efficient-code)",
        "num_comments": 28,
        "comments": [
            "Rather than using `typing.Union`, [the documentation](https://docs.python.org/3/library/typing.html#special-forms) recommends using the shorthand form `X | Y`.",
            "1. use meaningful variable names, not \"a\" and \"b\" ;)\n2. it's not \"calculate\\_interest\" function responsibility to validate data. That should be a separate layer and used as needed. If you want a very strict interface then use data classes and accept only matching objects.\n3. strategies, dictionaries, moving conditionals up the code.\n4. environment variables would likely be used.",
            "For your config it would be better to use Pydantic settings or even a dataclass rather than writing a class. And with pydantic settings it\u2019ll load your yaml, parse and validate all in one.",
            "Not a fan of 2., it really clutters the code. Either use a generic decorator to validate types of parameters if you need to do it at runtime, or do strict typechecking with mypy and prevent a commit containing type violations with git pre-commit or your build system.\n\nAnd for 7 you should probably consider pydantic.",
            "This has an error:\n\n    def make_point_3d(pt):\n        match pt:\n            case (x, y):\n                return Point3d(x, y, 0)\n            case (x, y, z):\n                return Point3d(x, y, z)\n            case Point2d(x, y):\n                return Point3d(x, y, 0)\n            case Point3d(_, _, _):\n                return pt\n            case _:\n                raise TypeError(\"not a point we support\")\n\nShould be:\n\n    def make_point_3d(pt):\n        match pt:\n            case (x, y):\n                return Point3d(x, y, 0)\n            case (x, y, z):\n                return Point3d(x, y, z)\n            case Point2d(x=x, y=y):\n                return Point3d(x, y, 0)\n            case Point3d(_, _, _):\n                return pt\n            case _:\n                raise TypeError(\"not a point we support\")\n\n\nThe first version will raise a TypeError.",
            "This can be safely ignored as incomplete and in so.e cases in error.",
            "The likes on this show how much of an absolute useless pit this sub is.",
            "That's true, but `X | Y` is only available from Python version 3.10. If you are writing anything that may be shared (e.g published on github) then you have an obligation to support at least version 3.8.",
            "I kind of hate that.  I'm a mid-level dev on a team with a bunch of kids and I've been trying to get them to use typing.  I'd rather make it very very clear what's going on.  Besides:\n\n`Explicit is better than implicit`",
            "If you want very strict interfaces, don't use Python.",
            "I am a heavy FastAPI user so I completely agree with this. Pydantic is a lifesaver especially for config files/validation.",
            "Yeah unfortunately I disagreed so much with this point, that it dissuaded me from reading the rest of the article.",
            "Yep. \u00a0 \u201cNote, that we use conditional statements for input validation.\u201d (Six, inline; so, 12+ LOC.)\n\nAlso note that the 2-line `calculate_interest` function has become freakin\u2019 hideous. It\u2019s no way to greet a reader, making them come in through the boiler room.\u00a0",
            "This doesn't have an error, it *is* an error.  The whole article.",
            "> If you are writing anything that may be shared (e.g published on github) then you have an obligation to support at least version 3.8.\n\nThat seems rather extreme, as it would prevent anyone publishing on GitHub from using any new Python features added since 2020 (Python 3.9 release date).",
            "The shorthand version is just as explicit as the longhand version. Both mean exactly the same.\n\nThe `Union` type hint was introduced in Python 3.5, and the shorthand version was added in Python 3.10. Since the introduction of the pipe syntax, it is the recommended form, though the older syntax remain valid for legacy compatibility.",
            "I'm going to disagree with you.  The pipe as an \"or\" is very common across languages.  str | none reads clearly as \"string or none\".  Doing the typing.Union is longer to read, longer to write, somewhat implies \"str *and* none\" if you're unfamiliar with the syntax, and in Python PEP fashion, has been superseded by a new community standard.",
            "It\u2019s pretty explicit. I always read \u2018int | str\u2019 as \u201cint or string\u201d since it\u2019s just the bitwise or.",
            "In my mind, Union is actually more confusing. The goal of this kind of type hint is to convey to users that the variable/return/etc is X or Y. Telling users that it's a union between X and Y could easily be interpreted as having any of the other many meanings of \"union\" in computer science/mathematics.\n\nIn fact, I recall the first time seeing it thinking that the \"Union of X and Y\" would have meant something more like \"and\" instead of \"or\".",
            "If you are publishing a package (e.g. on Github or PyPi) that you intend other users may want to install, then yes that is how it is. You may be surprised but that is what all reasonable Python package authors all do. Python 3.8 is the oldest version currently [officially supported](https://devguide.python.org/versions/) so any respectable package should support at least that.",
            "I also prefer \u201cstr | None\u201d over Optional because it explicitly states what types to expect",
            "Not all Python repositories on GitHub are intended for general 'end user' use.\n\nIf I am writing a cutting-edge, state-of-the-art library for use by proficient researchers, then I will use whatever I need to accomplish the task, _and will document the project's requirements_. If you decide to ignore my documentation, then I am under no obligation to change my code or even offer you any support (though I would actually refer you to the documentation because I'm a nice guy ;)\n\nAt work, we use Python 10 and Python 11. When I write open source code for work, I write it for Python >= 10, and document it as such. I do not believe that I am under any obligation to use older versions of Python for these projects. Imo the obligation is on you to read the docs.",
            "Agreed.  If I'm publishing a package, I'm likely using it for my use case first and foremost.  Anyone else benefiting from the package is welcome to contribute, extend, or manipulate, but that does not constitute a requirement for me to support a version that is *years* out of date*.*  I see this same mentality all the time on the Excel side of things (the other 2/3rds of my job...).  How dare we use features that aren't supported in version... 2013?  2016?  2021?  If you can't stay *reasonably up to date*, that's not an emergency on my end.\n\nHow's 2.7 treating people these days?",
            "Note the first sentence in my comment you are replying to and note the first sentence in your reply. I.e your reply is not relevant to what I was saying. Of course I know much software on github is not intended for general use - but I am not talking about those!"
        ]
    },
    "Enhanced EPUB Version of \"An Understated Dominance\" Available for Fans!": {
        "title": "Enhanced EPUB Version of \"An Understated Dominance\" Available for Fans!",
        "score": 2,
        "url": "https://www.reddit.com/r/Python/comments/1cv041z/enhanced_epub_version_of_an_understated_dominance/",
        "content": "Hey everyone!\n\nI recently completed a fun project that I think fans of \"An Understated Dominance\" will appreciate, especially those who have struggled with reading the novel online due to website clutter and distractions.\n\nI've created a clean, distraction-free EPUB version of the novel that you can download and read on your preferred device. You can get it here: [EPUB Download](https://drive.google.com/file/d/142IZ2lmqqJn0z6yEv3WD_-tpisLVCMeI/view?usp=sharing).\n\n**Why I did this:** The original website hosting the novel has a lot of distractions that can take away from the reading experience. My goal was to provide a seamless reading experience that allows you to fully immerse yourself in the story without unnecessary interruptions.\n\n**Project Details:** For those interested in the technical side, here's a brief overview of how I created the EPUB:\n\n* **Web Scraping:** I used Python with libraries like `requests` and `BeautifulSoup` to scrape all 2240 chapters of the novel.\n* **Concurrency:** Leveraged `concurrent.futures` to speed up the scraping process.\n* **Retries:** Implemented retry logic with `tenacity` to handle any request failures.\n* **EPUB Creation:** Used `ebooklib` to compile the scraped content into an EPUB file, complete with chapter headers and a cover image.\n\nYou can check out the full code for this project on my GitHub: [GitHub Repository](https://github.com/saturnthehustler/chapterverse-scraper.git).\n\n**Feedback & Collaboration:** I\u2019d love to hear your thoughts on the EPUB. Feel free to download, read, and let me know if you encounter any issues or have suggestions for improvements. If you're interested in collaborating on similar projects or have any ideas, I'm all ears!\n\nEnjoy the novel, and happy reading!",
        "num_comments": 1,
        "comments": []
    },
    "Picodi - Simplifying Dependency Injection in Python": {
        "title": "Picodi - Simplifying Dependency Injection in Python",
        "score": 1,
        "url": "https://www.reddit.com/r/Python/comments/1cuz4kw/picodi_simplifying_dependency_injection_in_python/",
        "content": "# What My Project Does\n\n[Picodi](https://github.com/yakimka/picodi) is a lightweight and easy-to-use Dependency Injection ([DI](https://en.wikipedia.org/wiki/Dependency_injection)) library for Python. Picodi supports both synchronous and asynchronous contexts and offers features like resource lifecycle management. Think about Picodi as a decorator that helps you manage your dependencies without the need for a full-blown DI container.\n\n# Key Features\n\n* \ud83c\udf1f Simple and lightweight\n* \ud83d\udce6 Zero dependencies\n* \u23f1\ufe0f Supports both sync and async contexts\n* \ud83d\udd04 Resource lifecycle management\n* \ud83d\udd0d Type hints support\n* \ud83d\udc0d Python & PyPy 3.10+ support\n\n# Quick Start\n\nHere\u2019s a quick example of how Picodi works:\n\n    import asyncio\n    from collections.abc import Callable\n    from datetime import date\n    from typing import Any\n    import httpx\n    from picodi import Provide, init_resources, inject, resource, shutdown_resources\n    from picodi.helpers import get_value\n    \n    \n    def get_settings() -> dict:\n        return {\n            \"nasa_api\": {\n                \"api_key\": \"DEMO_KEY\",\n                \"base_url\": \"https://api.nasa.gov\",\n                \"timeout\": 10,\n            }\n        }\n    \n    @inject\n    def get_setting(path: str, settings: dict = Provide(get_settings)) -> Callable[[], Any]:\n        value = get_value(path, settings)\n        return lambda: value\n    \n    @resource\n    @inject\n    async def get_nasa_client(\n        api_key: str = Provide(get_setting(\"nasa_api.api_key\")),\n        base_url: str = Provide(get_setting(\"nasa_api.base_url\")),\n        timeout: int = Provide(get_setting(\"nasa_api.timeout\")),\n    ) -> httpx.AsyncClient:\n        async with httpx.AsyncClient(\n            base_url=base_url, params={\"api_key\": api_key}, timeout=timeout\n        ) as client:\n            yield client\n    \n    @inject\n    async def get_apod(\n        date: date, client: httpx.AsyncClient = Provide(get_nasa_client)\n    ) -> dict[str, Any]:\n        response = await client.get(\"/planetary/apod\", params={\"date\": date.isoformat()})\n        response.raise_for_status()\n        return response.json()\n    \n    async def main():\n        await init_resources()\n        apod_data = await get_apod(date(2011, 7, 19))\n        print(\"Title:\", apod_data[\"title\"])\n        await shutdown_resources()\n    \n    if __name__ == \"__main__\":\n        asyncio.run(main())\n\nThis example demonstrates how Picodi handles dependency injection for both synchronous and asynchronous functions, manages resource lifecycles, and provides a clean and efficient way to structure your code.\n\nFor more examples and detailed documentation, check out the [GitHub repository](https://github.com/yakimka/picodi)\n\n# Target Audience\n\nPicodi is perfect for developers who want to simplify dependency management in their Python applications, but don't want to deal with the complexity of larger DI frameworks. Picodi can help you write cleaner and more maintainable code.\n\n# Comparison\n\nUnlike other DI libraries, Picodi does not have wiring, a large set of different types of providers, or the concept of a container.\n\nPicodi prioritizes simplicity, so it includes only the most essential features: dependency injection, resource lifecycle management, and dependency overriding.\n\n# Get Involved\n\nPicodi is still in the experimental stage, and I'm looking for feedback from the community. If you have any suggestions, encounter any issues, or want to contribute, please check out the [GitHub repository](https://github.com/yakimka/picodi) and let me know.",
        "num_comments": 21,
        "comments": [
            "That's like [FastDepends](https://github.com/Lancetnik/FastDepends) with extra steps.",
            "FastDepends is not compatible with FastAPI, and it also lacks the concept of a \"resource\". Additionally, it handles parameter validation (assert main(\"1\", 2) == 4.0 - [https://github.com/Lancetnik/FastDepends?tab=readme-ov-file#sync-code](https://github.com/Lancetnik/FastDepends?tab=readme-ov-file#sync-code) ), which is not a primary functionality for a DI library.",
            ">FastDepends is not compatible with FastAPI\n\nYou don't need it to. FastDepends is literally FastAPI's DI that has been extracted.\n\nFastAPI's DI system is really great out of the box (which is why someone extracted it). I am not sure why anyone would add another DI framework on top of it.\n\n>it also lacks the concept of a \"resource\".\n\nA simple LRU cache decorator will give you the same effect as what you call a resource in your project.",
            "> You don't need it to.\n\nI need this if my application is slightly larger than just a few API endpoints, and I want to use DI in workers, commands, or somewhere else where FastAPI cannot inject dependencies.",
            ">FastAPI cannot inject dependencies.\n\nYou can inject anything anywhere in FastAPI. If you have a custom class, you just create a function that will instantiate that class with its parameters and this is what your routers will use. You can also use that pattern to chain dependencies very gracefully.\n\nSee: https://fastapi.tiangolo.com/tutorial/dependencies/#declare-the-dependency-in-the-dependant\n\nWhere the dict returned would be replaced by your custom class.\n\nEveryone that I've seen who thought they needed an extra DI framework on top of FastAPI simply misunderstood how FastAPI's DI worked. This post is no exception to that.",
            ">and this is what your routers will use.\n\nA web application can consist of more than just routes.\n\n>and I want to use DI in workers, commands",
            "Right, then back to my first reply.\n\nWhy would anyone use yours instead of FastDepends, which is simpler and a lot more battle tested?",
            "I already addressed this in my first reply.\n\nRegarding lru\\_cache - it cannot perform teardown on app shutdown.\n\nAdditionally, lru\\_cache cannot initialize resources at application startup to inject even asynchronous resources into synchronous functions.",
            ">Regarding lru\\_cache - it cannot perform teardown on app shutdown.\n\nAdd yield and voil\u00e0, FastAPI or FastDepends will pick it up.\n\n>Additionally, lru\\_cache cannot initialize resources at application startup to inject even asynchronous resources into synchronous functions.\n\nOf course. It's just a cache decorator. You just use it if you need a dependency to be reused.",
            "> Add yield and voil\u00e0, FastAPI or FastDepends will pick it up.\n\nI think you don't understand what you're talking about; you can try it yourself:\n\n    import random\n    from functools import lru_cache\n    \n    from fastapi import Depends, FastAPI\n    \n    app = FastAPI()\n    \n    \n    @lru_cache\n    def get_random_int():\n        print(\"get_random_int setup\")\n        yield random.randint(1, 100)\n        # this will be called only once on first request\n        print(\"get_random_int teardown\")\n    \n    \n    @app.get(\"/\")\n    # On first request we will see \"get_random_int setup\" and \"get_random_int teardown\"\n    # but random int is not integer - it is generator, so FastAPI will consume it\n    # and return [random_int] as response\n    # on second request we will get [], because generators can be consumed only once - voil\u00e0\n    async def read_root(random_int: int = Depends(get_random_int)):\n        return random_int\n    \n    \n    # uvicorn just_fastapi_di:app --reload\n    \n\nAnd even if it worked, teardown on app shutdown would still not be executed."
        ]
    },
    "Homoiconic Python Code": {
        "title": "Homoiconic Python Code",
        "score": 150,
        "url": "https://www.reddit.com/r/Python/comments/1cu2bpv/homoiconic_python_code/",
        "content": "Homoiconic, what does it mean? In simple terms, homoiconic code is when code is treated as data and can be manipulated as you would data. This means the code can be changed, new functions and variables added, the code can generate new code or even examine and modify its own structure and behavior all while it is running. That\u2019s why homoiconic languages like Lisp are so powerful. But what if we can make a homoiconic python code, where the code and the data are one and the same and can be modified in the same way?  \n  \nThis [guide](https://aljamal.substack.com/p/homoiconic-python) does a good job in trying to explain how you would create a python version of the \u201cLisp in Lisp\u201d code which would give you access to all those homoiconic features that Lisp brags of like the macro systems, the expressiveness and flexibility, the metaprogramming etc. while still using python. What do you guys think of this?",
        "num_comments": 50,
        "comments": [
            "Expose API that runs `exec()` on anything sent by client.\n\n- Ultimate flexibility.\n- No releases. Clients need to update their code.",
            "Sounds like a security nightmare",
            "I can somewhat follow what is going on, but I don't understand *why* anyone would want to do this or what the benefit of this is.",
            "Did you write this guide?",
            "It is absolutely no problem to create dynamic Python code or treat Python code as data and data as code.\u00a0\n\n\nBut in most cases this is neither required (Python is dynamic enough without modifying code) nor desirable (it gives you a couple of larger security challenges you really don't want to have).",
            "Doesn't this have the power to essentially make each new project look and feel like a completely different programming language?  Things you can take for granted about the language would only become common conventions.  Seems like it would make it very difficult to transfer knowledge and experience from project to project.\n\nI can see some applications for this, for example, any time you feel inclined to switch to a different language within another project (sql or regex or exec or shell commands inside of python) those could instead be native python code instead of being confined to string literals. \n\nThis also seems like it would be hell for linters, formatters, completers, and any other static code analysis, making the task of properly linting/formatting the code in a fully correct way impossible without actually running the code, right?  I'm not sure I see the advantage of freeing things from string literals if I don't get linting/formating with it.  And, in fact, my editor does format/lint sql code and other embedded languages in my python code already.\n\nI've never used lisp, so I would love to be corrected on any misconceptions in the above about where the power of lisp comes in handy or the limitations to static code analysis.",
            "The folks involved in designing the language took a very deliberate decision not to support macros. The Zen of Python says there should be one, and ideally only one, easy way to do things, and every macro is a new way to do things. You gain the ability to write certain kinds of code more easily, at the expense of potentially making code harder to read.\u00a0\n\n\nIf you want these things, you'll probably be happiest in a language that isn't Python.",
            "> homoiconic features that Lisp brags of like the macro systems, the expressiveness and flexibility, the metaprogramming\n\nIMO, python does not need macros to achieve any of that.\n\nUsually people use macros to implement DSL, it was done in python without macros with [pyxl3](https://github.com/gvanrossum/pyxl3?tab=readme-ov-file) and you can do meta programming with inspect + ast.parse + ast.NodeTransformer.",
            "Just use Lisp. Honestly, it's great.",
            "Seems at odds with the zen of python\u2026",
            "[removed]",
            "I think you'll like [Hy](https://hylang.org/).",
            "Phoscript: the SIMPLEST (challenge?) clone of FORTH and related stack machine (metaprogramming) languages, (theoretically and practically) portable to ANY KNOW TARGET PROGRAMMING LANGUAGE\n\nhttps://github.com/udexon/PyPhos",
            "Oh, so this post isn\u2019t about Rue Paul writing Python? I\u2019m a lot less interested now.",
            "When code and data love each other very much, macros are born.\u00a0",
            "From a practicality standpoint this may not have much use, but from a computer science standpoint I find this interesting. The ability of Python to create and run its own code on the fly was always something I wanted to experiment with. It's like a train that lays tracks in front of itself as it moves forward. It seems combining this ability with ML could lead to some form of actual AI.\n\nIt was also a bit surprising to see just how easy it was to implement a core subset of Lisp in Python.",
            "Are you familiar with Hy? It's a Lisp syntax for Python.\n\nhttps://hylang.org",
            "Actually saw this as the standard pattern in a web project with more than 4 man-years of development put into it.",
            "Yea, there's no way that could go horribly wrong, from a security standpoint.",
            "this would only work optimally if the process running that code had root privileges",
            "When I was just getting started in programming I impressed a friend by creating a web form that accepted live PHP code from the client to execute on the server. Took me a good solid minute to realize how dumb that was.\u00a0",
            "Yeah always understood this to be \u201cbig no-no\u201d territory.",
            "I\u2019m still relatively new to python so I\u2019m curious in how this would be a security nightmare",
            "Buzzword scalability to the GPT blockchain",
            "It can be useful for building tools that are used interactively. R uses this feature for data analysis, and it generally lets the user type less code than the equivalent operation in Python.  \n\nFor example, if you want to subset a pandas dataFrame by a condition, you have to repeatedly type the name of the dataframe:\n\n    above_35 = titanic[titanic[\"Age\"] > 35]\n\nR can distinguish between a function\u2019s argument  and its value. That lets the language infer scoping to write less verbose (but less precise) code:\n\n    above_35 = subset(titanic, Age >= 4)",
            "They were just paid to promote it.",
            "~~easy~~ obvious",
            "Why is this getting downvoted? This is hilariously juvenile",
            "Hi there, from the /r/Python mods.\n\nThis comment has been removed for violating one or more of our community rules, including engaging in rude behavior or trolling. Please ensure to adhere to the r/Python guidelines in future discussions.\n\nThanks, and happy Pythoneering!\n\nr/Python moderation team",
            "Lmao",
            "?  Any language that has an equivalent of the exec() function can do this.",
            "\"There is absolutely no way an attacker can gain any access denied to a normal user\"\nSeems perfectly secure to me!",
            "The first and most glaring concern I would have is malicious code injection.",
            "with AI quantum synergy",
            "In Pandas, you can of course do `above_35 = titanic.query(\"Age > 35\")` - the argument to `.query` ends up being `exec`d.",
            "What is malicious code injection?",
            "Google AI passant",
            "Yes, but that illustrates the benefits of homoiconic languages. In Python you have to pass a string to \u2018query\u2019 which is used to indirectly compute on the languages R can operate directly on the expression you pass to \u2018subset\u2019. In R, you can use code completion to help you specify columns, and you can\u2019t in Python+pandas. \n\nI\u2019m not saying one language is superior to the other. I\u2019m just pointing out differences and the advantages of  operating on the programming language.",
            "https://xkcd.com/327/ (this is actually SQL injection but I guess that counts)",
            "It\u2019s when you give the user the ability to enter data, say a name or something, and they find something to send that lets them run arbitrary code",
            "Oh so for business related data this could cause issues with users editing the data"
        ]
    },
    "The best Python CLI library, arguably.": {
        "title": "The best Python CLI library, arguably.",
        "score": 35,
        "url": "https://www.reddit.com/r/Python/comments/1cu6toc/the_best_python_cli_library_arguably/",
        "content": "**What My Project Does**\n\nhttps://github.com/treykeown/arguably\n\n`arguably` makes it super simple to define complex CLIs. It uses your function signatures and docstrings to set everything up. Here's how it works:\n\n* Adding the `@arguably.command` decorator to a function makes it appear on the CLI.\n* If multiple functions are decorated, they'll all be set up as subcommands. You can even set up multiple levels of subcommands.\n* The function name, signature, and docstring are used to automatically set up the CLI\n* Call `arguably.run()` to parse the arguments and invoke the appropriate command\n\nA small example:\n\n    #!/usr/bin/env python3\n    import arguably\n\n    @arguably.command\n    def some_function(required, not_required=2, *others: int, option: float = 3.14):\n        \"\"\"\n        this function is on the command line!\n\n        Args:\n            required: a required argument\n            not_required: this one isn't required, since it has a default value\n            *others: all the other positional arguments go here\n            option: [-x] keyword-only args are options, short name is in brackets\n        \"\"\"\n        print(f\"{required=}, {not_required=}, {others=}, {option=}\")\n\n    if __name__ == \"__main__\":\n        arguably.run()\n\nbecomes\n\n    user@machine:~$ ./readme-1.py -h\n    usage: readme-1.py [-h] [-x OPTION] required [not-required] [others ...]\n    \n    this function is on the command line!\n    \n    positional arguments:\n      required             a required parameter (type: str)\n      not-required         this one isn't required, since it has a default (type: int, default: 2)\n      others               all the other positional arguments go here (type: int)\n    \n    options:\n      -h, --help           show this help message and exit\n      -x, --option OPTION  an option, short name is in brackets (type: float, default: 3.14)\n\nIt can easily hand some very complex cases, like passing in QEMU-style arguments to automatically instantiated different types of classes:\n\n    user@machine:~$ ./readme-2.py --nic tap,model=e1000 --nic user,hostfwd=tcp::10022-:22\n    nic=[TapNic(model='e1000'), UserNic(hostfwd='tcp::10022-:22')]\n\nYou can also auto-generate a CLI for your script through `python3 -m arguably your_script.py`, more on that [here](https://github.com/treykeown/arguably?tab=readme-ov-file#no-integration-required).\n\n**Target Audience**\n\nIf you're writing a script or tool, and you need a quick and effective way to run it from the command line, `arguably` was made for you. It's great for things where a CLI is essential, but doesn't need tons of customization. `arguably` makes some opinionated decisions that keep things simple for you, but doesn't expose ways of handling things like error messages.\n\nI put in the work to create GitHub workflows, documentation, and proper tests for `arguably`. I want this to be useful for the community at large, and a tool that you can rely on. Let me know if you're having trouble with your use case!\n\n**Comparison**\n\nThere are plenty of other tools for making CLIs out there. My goal was to build one that's unobtrusive and easy to integrate. I wrote a whole page on the project goals here: https://treykeown.github.io/arguably/why/\n\nA quick comparison:\n\n* `argparse` - this is what `arguably` uses under the hood. The end user experience should be similar - `arguably` just aims to make it easy to set up.\n* `click` - a powerhouse with all the tools you'd ever want. Use this if you need extensive customization and don't mind some verbosity.\n* `typer` - also a great option, and some aspects are similar design-wise. It also uses functions with a decorator to set up commands, and also uses the function signature. A bit more verbose, though like `click`, has more customization options.\n* `fire` - super easy to generate CLIs. `arguably` tries to improve on this by utilizing type hints for argument conversion, and being a little more of a middle ground between this and the more traditional ways of writing CLIs in Python.\n\nThis project has been a labor of love to make CLI generation as easy as it should be. Thanks for checking it out!",
        "num_comments": 14,
        "comments": [
            "No comparison to fire?",
            "Awesome!",
            "cool lib! reminds me of click",
            "i love arguably.",
            "Does it play well with gooey?",
            "`def some_function(required, not_required=2, *others: int, option: float = 3.14):`\n\nThat syntax looks strange, given that positional arguments cannot be passed after a keyword argument.",
            "I thought this looked familiar: https://www.reddit.com/r/madeinpython/comments/14b2kf2/the_best_python_cli_library_arguably/\n\nSame title and everything.",
            "This looks really good! I think this is the first CLI tool that extracts the parameter descriptions from the docstring, which is super nice.",
            "Sure! `fire` is great, super flexible. That's where `arguably` drew inspiration for automatically creating a CLI from a script without any setup.\n\nOne key difference is that `arguably` utilizes type hints for the function signature, automatically converting the command line arguments to the correct types.\n\nAnother is that `arguably` lets you specify what should be positional arguments, vs what should be options. Arguments to the CLI look just like calling the Python function. Using the function defined in the OP:\n\n    >>> from intro import some_function\n    >>> some_function(\"asdf\", 0, 7, 8, 9, option=2.71)\n    required='asdf', not_required=0, others=(7, 8, 9), option=2.71\n\nOn the command line:\n\n    user@machine:~$ ./intro.py asdf 0 7 8 9 --option 2.71\n    required='asdf', not_required=0, others=(7, 8, 9), option=2.71\n\nFor easy CLIs where the inputs can all have default values (or you're comfortable with it guessing the type), `fire` is the better choice. Otherwise, `arguably` is a good option if you'd like extra features through type hints and want more control over how your CLI behaves.",
            "I didn't know this was a thing! Just tried it, and it seems to work just fine, which is really cool.\n\nI'm tempted to make this a supported feature, would be super cool to auto-generate a GUI from a script using the `python3 -m arguably your_script.py` syntax.",
            "Hey, I understand what you're saying. The thing about Python arguments is that they can all be passed in as both positional or keyword arguments by default.\n\n    >>> def foo(a, b):\n    ...   print(f\"{a=} {b=}\")\n    ...\n    >>> foo(1,2)\n    a=1 b=2\n    >>> foo(a=1,b=2)\n    a=1 b=2\n\nThe thing that makes an argument keyword-only is if it comes after a `*args` parameter. In fact, you can even have *required keyword-only arguments*, which aren't useful IMHO, but are an interesting part of how Python was designed:\n\n    >>> def bar(a, *, b):\n    ...   print(f\"{a=} {b=}\")\n    ...\n    >>> bar(1, b=2)\n    a=1 b=2\n    >>> bar(1)\n    Traceback (most recent call last):\n      File \"<stdin>\", line 1, in <module>\n    TypeError: bar() missing 1 required keyword-only argument: 'b'\n\nSee more here: https://docs.python.org/3/tutorial/controlflow.html#special-parameters",
            "If you use type hints,  I believe fire does all of that",
            "The thing that looks strange to me is that, unless I am mistaken, it is not possible to pass `others` arguments without also passing the `not_required` argument as a positional argument.\n\nOn the other hand, that limitation would not apply to:\n\n`def some_function(required, *others: int, not_required=2, option: float = 3.14):`",
            "Hm, I haven't seen it utilize my type hints in the past. Though it does take a guess at the type based off its value: https://github.com/google/python-fire/blob/master/docs/guide.md#argument-parsing"
        ]
    },
    "LinkedIn-Learning-Downloader v1.1": {
        "title": "LinkedIn-Learning-Downloader v1.1",
        "score": 6,
        "url": "https://www.reddit.com/r/Python/comments/1culpl3/linkedinlearningdownloader_v11/",
        "content": "With Python i created a tool that enables users to download LinkedIn Learning courses, including the often overlooked but incredibly valuable exercise files. This feature sets our project apart, offering a complete learning experience by providing both the course videos and the materials needed for practical application.  \nWhat great about it and beyond other tools in the same genre concerned LinkedIn Learning Downloaders, now you can download the whole courses from a path link. this is was never possible without Python.\n\n\u00a0For more detailed information, visit the repo : [https://github.com/M0r0cc4nGh0st/LinkedIn-Learning-Downloader](https://github.com/M0r0cc4nGh0st/LinkedIn-Learning-Downloader)\n\n",
        "num_comments": 1,
        "comments": []
    },
    "FastAPI Backend Template for SaaS products": {
        "title": "FastAPI Backend Template for SaaS products",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1cuxatg/fastapi_backend_template_for_saas_products/",
        "content": "Hello there, I just created a template for creating a backend for your SaaS products.\n\n**What my project does:**\u00a0It is a FastAPI project/template for creating SaaS backends and admin dashboards.\n\n**Comparison:**\u00a0  \nOut of the box, it supports\n\n1. Licence key generation and validation.\n2. OAuth 2 authentication with scopes.\n3. Endpoints with pagination and filters to easily integrate with an admin dashboard.\n4. Passwords are securely stored using hashing.\n5. used PostgreSQL for database\n\n**Target Audience:** Production\n\n[Check it here!](https://github.com/shekhuverma/FastAPI-SaaS-Template)\n\n**Update 1**: Added pre-commit hooks, tox for testing and linting.",
        "num_comments": 13,
        "comments": [
            "Hi there, from the /r/Python mods.\n\nWe want to emphasize that while security-centric programs are fun project spaces to explore we do not recommend that they be treated as a \nsecurity solution unless they\u2019ve been audited by a third party, security professional and the audit is visible for review.\n\nSecurity is not easy. And making project to learn how to manage it is a great idea to learn about the complexity of this world. That said, there\u2019s a difference \nbetween exploring and learning about a topic space, and trusting that a product is secure for sensitive materials in the face of adversaries. \n\nWe hope you enjoy projects like these from a safety conscious perspective. \n\nWarm regards and all the best for your future Pythoneering,\n\n/r/Python moderator team\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Python) if you have any questions or concerns.*",
            "You didn't list anything about billing. I think that's probably more key than any license key feature that is presumably interchangeable with a binary flag in a controlled environment. Not sure I understand the concept of licensing keys on a SaaS vs on-prem option.",
            "Nicely done, your missing a license file",
            "Yes, it's for on-prem software which requires license keys to work.",
            "Thanks for pointing out, I will add it :D",
            "So how are you protecting the source code for that? I've been on the hunt for a while for a solution in Python similar to PHP's Ioncube, Zend, etc...\n\nI'm not entirely sure on this, but I don't think on-prem exactly meets the definition of SaaS.",
            "Since  the op has decided to just not respond to your question. It's a problem I have faced recently and I've decided against the route of a license key in that context. There is no way to protect the mechanism with the key so it's just easier to remove the issue entirely and look at from a different angle IMO.\n\nSpecifically, I took it to:\n\n1. ensuring the agreement signed with the customer was rather clear with the context in which the software can be used. This allows to set the rules governing how we would respond in case of breach\n2. Contant communication with my custoemrs to understand how their success with the product. If you start hearing other teams want to try it (or are already doing it's, it's a cue to get the sales hat on again :p\n\nFrom my perspective, the success is measured if they want to use it more :)",
            "Let me explain.\nI created a VBA based plugin for Ms-excel and to distribute that, i created a similar backend which can generate and email the licence keys to the users, a react based dashboard to manage users (edit their details, revoke licences,etc).\nThis project is the skeleton structure which i open sourced so that other people can take help, i removed all the application specific code to make it general purpose.\nI hope you got some clarity now",
            "No I understand. I'm just not sure I understand the purpose of license key validation with source code that isn't protected. What stops the end user from just stripping out the license verification, without that? It's kind of like putting a padlock on a door, with three simple wood screws facing out.",
            "This entire code runs on AWS, that's why I have created endpoints for licence key validation.",
            "Your responses make no sense. You previously said it was on-prem, now you say it's for the cloud. Either you're highly confused about what very common terms in this industry mean, or you're dancing around very direct questions. \n\nGood luck to you, I'm out with this.",
            "Bro!, The licence validation and the entire backend runs on AWS, the actual on-prem software (THE EXCEL PLUGIN I MENTIONED ABOVE) runs on end user's computer.  \nI don't know why it's s hard to understand",
            "Perhaps because you aren't delivering that nearly as clearly as you seem to think you are? So if you had laid it out a little more like that from the beginning, it would have made a little more sense. Now I understand what you are trying to elevate."
        ]
    },
    "this.s and this.d ": {
        "title": "this.s and this.d ",
        "score": 37,
        "url": "https://www.reddit.com/r/Python/comments/1cu26mq/thiss_and_thisd/",
        "content": "Recently, I found out about the ```this``` \"Easter egg\" in python3. Adding ```import this``` into a py file will print \"The Zen of Python\" by Tim Peters. Also, ```this``` has two attributes: ```this.s``` and ```this.d```, which I guess form the actual Easter egg. ```this.s``` returns an encrypted version of \"The Zen\" and ```this.d``` well, see for yourself, maybe you'll solve the puzzle.",
        "num_comments": 7,
        "comments": [
            "There are also `this.i` and `this.c`.\n\nThe 4 attributes `i, c, s, d` are just implementation details to slightly obfuscate the code with ROT13 encoding.",
            "`result = []`  \n`for char in this.s:`  \n`result.append(this.d.get(char,char))`  \n`print(\"\".join(result))`\n\nNot sure what `this.c` and `this.i` are for, `this.c==97, this.i==25`.\n\n(Oh, I think I see it now, thx u/markmuetz)",
            "Hint:\n\n>!`import inspect`!<\n\n>!`print(inspect.getsource(this))`!<",
            "    result = [this.d.get(char, char) for char in this.s]\n\nSurely?",
            "You don't need inspect magic. Just open `this.py`. It's a regular file.",
            "We were all new to list/dick comprehensions once.",
            "or try to figure it out without cheating"
        ]
    },
    "I made a Mandelbrot Zoom using Python": {
        "title": "I made a Mandelbrot Zoom using Python",
        "score": 12,
        "url": "https://www.reddit.com/r/Python/comments/1cu9jz1/i_made_a_mandelbrot_zoom_using_python/",
        "content": "I made a YouTube video which previews the zoom and explains the code, which you can find here: [https://youtu.be/HtNUFdh2sjg](https://youtu.be/HtNUFdh2sjg)\n\n**What my project does:** it creates a Mandelbrot Zoom. \n\n**Comparison:** it uses Pillow and consists of just 2 main blocks of code: one is the main function that finds which points are in the Mandelbrot Set and the other is the main loop that applies appropriate colors to each image. It gives the option of being black and white OR in color. \n\nIt works fairly well but can definitely be faster if parallelized. I'd love to hear any suggestions on how it can be improved.\n\n**Target Audience:** fun/toy project\n\nSource code is here: [https://github.com/AbideByReason/Python\\_Notebooks/tree/main](https://github.com/AbideByReason/Python_Notebooks/tree/main)",
        "num_comments": 6,
        "comments": [
            "One quick suggestion. Instead of doing two for loops to go through the pixels, build a numpy 2d array with complex numbers for coordinates. Then you apply np.square to the whole thing and add coordinates. You can also create a mask for abs>2 before squaring. A third 2d array to store the number of steps before reaching abs>2, for coloring. \nIn numpy you can ser the datatype to NPY_COMPLEX128 to have more precision.\nAlso, keeping the pixels at places with \"nice\" binary representation will enhance visualization and calculation.\n\nGreat job.",
            "There are also some modifications to the algorithm that involve fewer multiplications fyi",
            "Numpy is so much faster than a loop.",
            "Thanks for the really helpful comment. This will make it a lot more efficient. I'll definitely implement these changes.",
            "Numpy is coded in C, with bridges to Fortran libs like LAPACK, ATLAS, etc. These libs, coded in the 90s are extremely fast. But you have to write in numpy, like np.add(np.square(Z),Z0), np.where(np.linalg.abs(Z)<2,Z,2). This allows numpy to ignore python level code as much as possible and delve into lower level protocols to run faster."
        ]
    },
    "sjvisualizer: a python package to animate time-series data": {
        "title": "sjvisualizer: a python package to animate time-series data",
        "score": 20,
        "url": "https://www.reddit.com/r/Python/comments/1cu4epm/sjvisualizer_a_python_package_to_animate/",
        "content": "What the project does: data animation library for time-series data. Currently it supports the following chart types:\n\n* Bar races\n* Animated Pie Charts\n* Animated Line Charts\n* Animated Stacked Area Charts\n* Animated (World) Maps\n\nYou can find some simple example charts here:\u00a0[https://www.sjdataviz.com/software](https://www.sjdataviz.com/software)\n\nIt is on pypi, you can install it using:\n\n`pip install sjvisualizer`\n\nIt is fully based on TkInter to draw the graph shapes to the screen, which gives a lot of flexibility. You can also mix and match the different chart types in a single animation.\n\nTarget audience: people interested in data animation for presentations or social media content creation\n\nAlternatives: I only know one alternative which is bar-chart-race, the ways sjvisualizer is better:\n\n* Smoother animation, bar-chart-race isn't the quite choppy I would say\n* Load custom icons for each data category (flag icons for countries for example)\n* Number of supported chart types\n* Mix and match different chart types in a single animation, have a bar race to show the ranking, and a smaller pie chart showing the percentages of the whole\n* Based on TkInter, easy to add custom elements through the standard python GUI library\n\nTopics to improve (contributions welcome):\n\n* Documentation\n* Improve built in screen recorder, performance takes a hit when using the built in screen recorder\n* Additional chart types: bubble charts, lollipop charts, etc\n* Improve the way data can be loaded into the library (currently only supports reading into a dataframe from Excel)\n\nSorry for the long post, you can find it here on GitHub:\u00a0[https://github.com/SjoerdTilmans/sjvisualizer](https://github.com/SjoerdTilmans/sjvisualizer)",
        "num_comments": 1,
        "comments": [
            "As another alternative let me cite manim (btw so far I know there are only few contributors if anyone is seeking any cool projects to contribute).\n\nOther than that: nice project!"
        ]
    },
    "Auto Data Analysis python packages to know ": {
        "title": "Auto Data Analysis python packages to know ",
        "score": 4,
        "url": "https://www.reddit.com/r/Python/comments/1cu5476/auto_data_analysis_python_packages_to_know/",
        "content": "Check this video tutorial to explore different AutoEDA python packages like pandas-profiling, sweetviz, dataprep,etc which can enable automatic data analysis within minutes without any effort : https://youtu.be/Z7RgmM4cI2I?si=8GGM50qqlN0lGzry",
        "num_comments": 0,
        "comments": []
    },
    "Folks who know the internals: Where does operator precedence \"happen\"?": {
        "title": "Folks who know the internals: Where does operator precedence \"happen\"?",
        "score": 20,
        "url": "https://www.reddit.com/r/Python/comments/1ctwi8z/folks_who_know_the_internals_where_does_operator/",
        "content": "Hey! Messing around with instaviz, cool library, highly recommend. You can visualize a function's bytecode as well as AST and some other stuff. \n\ni entered this:\n\n    def f():\n      x = 1 + 2 - 10**2\n      return x\n\n  \nI was expecting the AST nodes for `1 + 2 - 10**2` to be rearranged somehow, with 10\\*\\*2 being moved to the left hand of the expression, because exponents get evaluated before addition/subtraction. but no! just looks like this:\n\n  \n... (more tree up here)\n\nBinOp\n\n|                    \\\\                 \\\\\n\nBinOp          Sub             BinOp  \n|    \\\\      \\\\                           /    |    \\\\\n\n1  ADD  2                       10 POW 2\n\n  \nI was assuming operator precedence was implemented as the AST level. Seems no - I would assume that the tree would've had the 10 POW 2 on the left. Does it happen at the control flow graph phase? I can imagine the interpreter itself handles it.\n\ndanke danke danke danke ",
        "num_comments": 10,
        "comments": [
            "ASTs aren't evaluated from left to right, they're evaluated from leaf to root, and you can see that the hierarchy is correct here.",
            "Operator precedence is determined during parsing, and is usually implemented by defining the grammar rules in a certain way.  For example, a grammar like\n\n    expr ::= number\n               | expr '+' number\n               | expr '-' number\n               | expr '*' number\n               | expr '/' number\n               | expr '**' number\n\nhas no precedence, so the operations will be performed in the order they're encountered.  Meanwhile\n\n    expr ::= term\n               | expr '+' term\n               | expr '-' term\n    term ::= factor\n               | term '*' factor\n               | term '/' factor\n    factor ::= number\n               | factor '**' number\n\ndefines the typical precedence for addition/subtraction, multiplication/division, and exponentiation.",
            "Precedence is about the grouping of the expressions, not about the order of evaluation!\n\nIf you write `a() + b() ** c()`, the functions are called in left-to-right order of evaluation: a, b, c.\nBut the values from those three call expressions will be combined according to the operator precedence: `a() + (b() ** c())`.",
            "Just to emphasize the point of the other comments in a different way - your images show that precedence has already \u201chappened\u201d. There are many different orders of operation that respect operator precedence, the compiler doesn\u2019t have to pick the same one you would if you did the computation by hand.",
            "This is exactly it. I made [my own \"programming language\"](https://github.com/schibsted/jslt/), and I implemented precedence this way. It's also specified this way in [the XPath spec](https://www.w3.org/TR/1999/REC-xpath-19991116/#section-Expressions). Click on `OrExpr` and you'll see.",
            "Wouldn't you grammar prevent parsing 2*3+4 ?",
            "Yes,  I think this is OP's central point of confusion.  Precedence isn't done by looking through an expression and doing all the exponents, then doing all the multiiplications and divisions, then doing all the additions and subtractions and so on.  The operations are only reordered enough that the order is correct.\n\nThere's a discussion to be had about reverse Polish notation here but I haven't the time.",
            "bingo. amazing answers from everybody, huge thanks, but this was what i was missing.",
            "Dunno, I think you go \n\n    expr ->    (applying expr ::= expr + term)\n     expr + term ->   (applying expr ::= term)\n     term + term ->   (applying term ::= term * factor)\n     term * factor + term ->   (applying term ::= factor in two places)\n     factor * factor + factor ->   (applying factor ::= number in three places)\n     number * number + number\n\nand it works out?  But in general this is not a good example of a grammar.   (I have vague memories of left-recursive productions being problematic in some way, but my days of writing parsers are long over.)",
            "I think you're right. Thanks."
        ]
    },
    "pip time machine ": {
        "title": "pip time machine ",
        "score": 75,
        "url": "https://www.reddit.com/r/Python/comments/1cte019/pip_time_machine/",
        "content": "[https://github.com/nevakrien/time\\_machine\\_pip](https://github.com/nevakrien/time_machine_pip)\n\nthis is a fairly simple project barely anything to it but I think its promising   \nthe idea is to put pip in a time machine so it can not use package versions that were made after the project is made. \n\nI am doing this by proxiying pypi and cutting out the newer versions. \n\ninitial tests show that pip respects the proxy and works like you would expect",
        "num_comments": 44,
        "comments": [
            "What's the difference between that and https://github.com/astrofrog/pypi-timemachine",
            "The uv project has something like this: \nhttps://pypi.org/project/uv/\n\ne.g.\n\nuv pip install --exclude-newer 2020-01-01 -r requirements.txt",
            "isn't this a reason to freeze versions, or am i misunderstanding",
            "I feel silly, but why not just specify the versions of your dependencies?",
            "Well, this might be interesting for some packages that do not lock their dependencies and installing the same package years later breaks things...\n\nBut for a daily basis I prefer to use a lock-file.",
            "Cool project!\n\nAt our org, most of us use [poetry](https://python-poetry.org/) to get a frozen state (i.e., every package at a specific version) of all dependencies (and all sub-deps, etc). The complete set of all dependencies are stored in the poetry.lock file, which we version control as part of a project.\n\nPoetry is its own thing though (with own learning curve), so I can see why other solutions might be handy, but this is a pretty good solution for those already using poetry for dependency mgmt?",
            "Thanks for this, I use https://github.com/astrofrog/pypi-timemachine to debug and reproduce issues and this will be an interesting alternative.\n\nRather than using PyPI's JSON API could you look at using the PEP 700 upload time field: https://peps.python.org/pep-0700/#specification. \n\nThe big advantage of using a specification based approach is it means that private indexes that implement the Simple API 1.1 specification or higher can also be proxied. Which brings the second issue, can you add a config to support private indexes rather than just `pypi.org`?\n\nAlso it appears you are currently only proxying the HTML page, can you also consider supporting the PEP 691 JSON-based Simple API: https://peps.python.org/pep-0691/. Pip actually uses the JSON based Simple API first if it is available.",
            "That's a cool idea",
            "Is there something about \"pip freeze > requirements.txt\" that doesn't already do that, based on your description of the functionality?\n\nIt lists the packages like so: \"pandas==x.x.x\".",
            "Why would you do that? You could just use [poetry](https://python-poetry.org/) and set a ceiling to the package versions.",
            "I didn't know this existed but we also have a different interface. \n\nMine let's u specify specific times for specific packages so u can theoretically use an older version of something like tensorflow with a new version of transformers because tf breaks way more.\n\nThey both use the same idea tho I am defiantly staring that project",
            "Idk I am not familiar with them. Do they have full pip compatibility?",
            "UV big hype",
            "No for a few reasons. \n\n1. Freeze is OS and architecture specific in some cases \n2. If u want to add a package to a freeze it will get a new version",
            "I'd u go through ur second order dependencies and stuff it gets somewhat usble (good luck following the 1000+ dependencies) \n\nBut a new package would break all of this. \nThis also breaks when u switch os or architecture.",
            "Ya I looked at it very intresting.\n\nI am considering learning it maybe if I get back into doing serious python work I put I'm the time.",
            "Poetry and Pipenv both accomplish this, and are a significantly better workflow than pip with a requirements.txt file.  I'm more familiar with Pipenv, but either one is a fairly easy learning curve.  If someone is familiar with npm the learning curve is near zero.",
            "A short look on pypi time machine shows their code is almost identical to mine and its less than 100 lines.\n\nI am not super familiar with pypi but if u would genuinely use the features u r asking i would read up on it and try implementing them.\n\nVery new to this space so idk what existing solutions have I used pip for everything I did because I didn't care for stability (reaserch needs u to just write a working prototype for a month so its f9nr if after 3 months everything breaks)",
            "Yes u can't freeze in the future.\n\nSo I am making this because I m so f done with projects from papers I am trying to reproduce having a broken enviorment. Like that's most of them. \n\nI wana just go \"hey do that thing u did for them 6 months ago\" and have that work the same.",
            "I think adding a section in the readme with a comparison of features would be a nice add. It wasn't immediately obvious what the capabilities were from a quick glance at the readme.",
            "Almost, but they replace pip with some faster concepts. Same group making ruff, hopefully it becomes the cargo of python someday",
            "if you want to add a package, that invalidates freezing anyway as it is purely based on previous dependencies and not the new combination... even if you did freeze there is no guarantee it won't break if ranges differ...",
            "What if I specify the version when I add it?",
            "How would it break when you switch OS? They were released on the same day. I have an open source project with 20+ releases now. I\u2019m not going to go back years later and add support for Mac or whatever. Use the recent version that is supported if you want that feature.\u00a0\n\n\u00a0There is value in supporting extremely old versions for customers (I was supporting python 2.4 just 2 years ago), but what you\u2019re describing isn\u2019t a problem.",
            "> Very new to this space so idk what existing solutions \n\nAhh, well it's very impressive for a newcomer! And thanks for sharing your work.\n\nIf your just sharing this as a tool write for yourself that you find useful that's great. The risk of open source is always people start using, depending on it, and start asking for a lot more ;)!",
            "Ya I may just end up adding the change I did (which is specific times on the index) onto that original package because its a very small code base (and there is a feature request for it) \n\nBut I can't really comment on a package I haven't used seriously so I can't put a comperison.\n\nIt's clear we both want around the same thing. So I won't say mine is better.",
            "So its a diffrent thing then. For me, I like having full pip compatibility. Because everything is tested for pip. \n\nI been burned by c++abi things in python too many times to like switching. But I think it'd very depends on what u do. Trying deeplearning with intel GPU is definitely one of the hardest things to package manage and that's what I remeber doing in python. \n\nIk web devs I talked to r much less paranoid I think having pure python (more or less) with fewer packages makes it easier.",
            "Yap which is why this is a better solution apparently someone came up with this 3 years ago they made pretty much exacly what i did",
            "Won't work because of the defences of ur decency. Unless every single script is specifying exact versions u can have things break on u and in ml they often do",
            "I beg to differ the official docs for torch ccl had a 2 line script for installing it. 3 months after it was made on the same machine these 2 dependences (exact versions) broke on the same hardware. \n\nFixing it took over an hour... I thinknit segfualted on me to as I did it because if the one api version \n\nThis is something u see in ML a lot",
            "Look into something like pytorch it depends on mpi which is an os specific binary. \n\nWindows and Linux threading apis r so diffrent that u really can't write the same c code. The same goes with something like select if u look at the code on Linux it's epoll on mac it's poll and on windows it's their new fancy IO thing.",
            "I think I would be happy having an open source tool ppl actually use. \n\nLike I been looking for something like that to do. Allways thought it would be a c lib or something to do with llms since that's what I specialise in. \n\nI think this is the closest I ever came to it which makes me very happy",
            "Well uv uses the same pipeline as pip under the hood, and you can install pip using uv if you really want, but uv is also just faster because it uses a lot of symlinks rather than copying all the python stuff around every time you make a new venv. It also has some features beyond the standard pip",
            "You mean defences of existing dependencies? I can still pip install with a semver expression though.\n\n    pip install super_ml~=3.0.0",
            "Report a bug or see if the dependencies changed. Most projects don\u2019t support a huge range of versions. I generally do, but if it\u2019s too difficult of a bug, I limit the version. Also, there are just buggy versions of say numpy. That\u2019s what happens with software.\n\nFor my work, I don\u2019t run on the latest greatest for that reason. My first instinct is to downgrade.",
            "You can do optional dependencies by platform. Look at the dependencies of your dependencies. It\u2019s all specified in setup.py/requirements.txt/poetry.lock/pyproject.toml",
            "Ya but do u know them? Because at least for me if I am giving a repo with a paper from a month ago that has 1000 packages and won't build I have no clue.\n\nI would really like to have a \"build it like it should be\" button that just does the same thing they did a month ago",
            "Oh good luck doing that with a repo someone made for a paper... they r not maintained at all. \n\nEven some of the official stuff r just broken its so common and it drives me insane. \nAround half the time I spend doing work for papers is package managment.",
            "Personally, I'd just go with pipenv or poetry to do that. But more power to you for making something that works for you!",
            "So you\u2019re fixing shitty programmers code dependencies declarations. That isn\u2019t very intuitive imo. I know why you\u2019re doing it but isn\u2019t this the wrong direction?",
            "I\u2019ve worked with research codes too, but why are you expecting them to be more than they are? Welcome to non-software developer software development.\n\nI expect those to mostly work on one example. There are probably a few bugs, but the concept is there.",
            "Depends what ur doing if the project only jeed to work for like a few months and then we throw the code in the garbage (this is half of papers out there) then no thos is a perfectly valid direction. \n\nIf u need it for a production server god no I would never trust that",
            "I don't hence why I made a tool to try fix the dependency problem. \n\nIn my old job my boss sometimes wanted me to make THAT repo work he wouldn't hear anything about code quality or decency managment he'll. \n\nThis tool coild save me hours in those projects.",
            "This is why these posts are supposed to be formatted though, great idea if it works for you. Others have mentioned poetry which is the comparable package and this is where that clarification should have been. It\u2019s pedantic sure but it does go a LONG way for anyone that comes across this."
        ]
    },
    "Building an LLM chat application using RAG Agent": {
        "title": "Building an LLM chat application using RAG Agent",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1cu3xl7/building_an_llm_chat_application_using_rag_agent/",
        "content": "# Motivation\n\nChatbots are among the most popular applications of large language models (LLMs). Often, an LLM's internal knowledge base is adequate for answering users questions. However, in those cases, the model may generate outdated, incorrect, or too generic responses when specificity is expected. These challenges can be partially addressed by supplementing the LLM with an external knowledge base and employing the retrieval-augmented generation (RAG) technique.\n\nHowever, if user queries are complex, it may be necessary to break the task into several sub-parts. In such cases, relying solely on the RAG technique may not be sufficient, and the use of agents may be required.\n\nThe fundamental concept of agents involves using a language model to determine a sequence of actions (including the usage of external tools) and their order. One possible action could be retrieving data from an external knowledge base in response to a user's query. In this tutorial, we will develop a simple Agent that accesses multiple data sources and invokes data retrieval when needed. We will use a\u00a0[Dingo framework](https://github.com/BeastByteAI/agent_dingo)\u00a0that allows the development of LLM pipelines and autonomous agents.\n\n# RAG Agent Architecture and Technical Stack\n\nThe application will consist of the following components:\n\n1. `Streamlit`: provides a frontend interface for users to interact with a chatbot.\n2. `FastAPI`: facilitates communication between the frontend and backend.\n3. [Dingo Agent](https://github.com/BeastByteAI/agent_dingo):\u00a0agent powered by GPT-4 Turbo model from OpenAI that has access to provided knowledge bases and invokes data retrieval from them if needed.\n4. LLMs docs: a vector store containing documentation about the\u00a0**recently released**[\u00a0Phi-3 (from Microsoft) ](https://azure.microsoft.com/en-us/blog/introducing-phi-3-redefining-whats-possible-with-slms/)and [Llama 3 (from Meta) ](https://ai.meta.com/blog/meta-llama-3/)models.\n5. Audio gen docs: a vector store containing documentation about the\u00a0**recently released**\u00a0[OpenVoice model from MyShell](https://research.myshell.ai/open-voice).\n6. `Embedding V3 small`\u00a0model from OpenAI: computes text embeddings.\n7. `QDrant`: vector database that stores embedded chunks of text.\n\n# Implementation\n\n# Step 0:\n\nInstall the Dingo framework:\n\n    pip install agent-dingo\n\nSet the\u00a0`OPENAI_API_KEY`\u00a0environment variable to your OpenAI API key:\n\n    export OPENAI_API_KEY=your-api-key\n\n# Step 1:\n\nCreate a [`component.py`](http://component.py)\u00a0file, and initialize an embedding model, a chat model, and two vector stores: one for storing documentation of Llama 3 and Phi-3, and another for storing documentation of OpenVoice.\n\n    # component.py\n    from agent_dingo.rag.embedders.openai import OpenAIEmbedder\n    from agent_dingo.rag.vector_stores.qdrant import Qdrant\n    from agent_dingo.llm.openai import OpenAI\n    \n    # Initialize an embedding model\n    embedder = OpenAIEmbedder(model=\"text-embedding-3-small\")\n    \n    # Initialize a vector store with information about Phi-3 and Llama 3 models\n    llm_vector_store = Qdrant(collection_name=\"llm\", embedding_size=1536, path=\"./qdrant_db_llm\")\n    \n    # Initialize a vector store with information about OpenVoice model\n    audio_gen_vector_store = Qdrant(collection_name=\"audio_gen\", embedding_size=1536, path=\"./qdrant_db_audio_gen\")\n    \n    # Initialize an LLM\n    llm = OpenAI(model = \"gpt-3.5-turbo\")\n\n# Step 2:\n\nCreate a\u00a0[build.py](http://build.py) file. Parse, chunk into smaller pieces, and embed websites containing documentation of the above-mentioned models. The embedded chunks are used to populate the corresponding vector stores.\n\n    # build.py\n    from components import llm_vector_store, audio_gen_vector_store, embedder\n    from agent_dingo.rag.readers.web import WebpageReader\n    from agent_dingo.rag.chunkers.recursive import RecursiveChunker\n    \n    # Read the content of the websites\n    reader = WebpageReader()\n    phi_3_docs = reader.read(\"https://azure.microsoft.com/en-us/blog/introducing-phi-3-redefining-whats-possible-with-slms/\")\n    llama_3_docs = reader.read(\"https://ai.meta.com/blog/meta-llama-3/\")\n    openvoice_docs = reader.read(\"https://research.myshell.ai/open-voice\")\n    \n    # Chunk the documents\n    chunker = RecursiveChunker(chunk_size=512)\n    phi_3_chunks = chunker.chunk(phi_3_docs)\n    llama_3_chunks = chunker.chunk(llama_3_docs)\n    openvoice_chunks = chunker.chunk(openvoice_docs)\n    \n    # Embed the chunks\n    for doc in [phi_3_chunks, llama_3_chunks, openvoice_chunks]:\n        embedder.embed_chunks(doc)\n    \n    # Populate LLM vector store with embedded chunks about Phi-3 and Llama 3\n    for chunk in [phi_3_chunks, llama_3_chunks]:\n        llm_vector_store.upsert_chunks(chunk)\n    \n    # Populate audio gen vector store with embedded chunks about OpenVoice\n    audio_gen_vector_store.upsert_chunks(openvoice_chunks)\n\nRun the script:\n\n    python build.py\n\nAt this step, we have successfully created vector stores.\n\n# Step 3:\n\nCreate\u00a0[`serve.py`](http://serve.py)\u00a0file, and build a RAG pipeline. To access the pipeline from the Streamlit application, we can serve it using the\u00a0`serve_pipeline`\u00a0function, which provides a REST API compatible with the OpenAI API.\n\n    # serve.py\n    from agent_dingo.agent import Agent\n    from agent_dingo.serve import serve_pipeline\n    from components import llm_vector_store, audio_gen_vector_store, embedder, llm\n    \n    agent = Agent(llm, max_function_calls=3)\n    \n    # Define a function that an agent can call if needed\n    u/agent.function\n    def retrieve(topic: str, query: str) -> str:\n        \"\"\"Retrieves the documents from the vector store based on the similarity to the query.\n        This function is to be used to retrieve the additional information in order to answer users' queries.\n    \n        Parameters\n        ----------\n        topic : str\n            The topic, can be either \"large_language_models\" or \"audio_generation_models\".\n            \"large_language_models\" covers the documentation of Phi-3 family of models from Microsoft and Llama 3 model from Meta.\n            \"audio_generation_models\" covers the documentation of OpenVoice voice cloning model from MyShell.\n            Enum: [\"large_language_models\", \"audio_generation_models\"]\n        query : str\n            A string that is used for similarity search of document chunks.\n    \n        Returns\n        -------\n        str\n            JSON-formatted string with retrieved chunks.\n        \"\"\"\n        print(f'called retrieve with topic {topic} and query {query}')\n        if topic == \"large_language_models\":\n            vs = llm_vector_store\n        elif topic == \"audio_generation_models\":\n            vs = audio_gen_vector_store\n        else:\n            return \"Unknown topic. The topic must be one of `large_language_models` or `audio_generation_models`\"\n        query_embedding = embedder.embed(query)[0]\n        retrieved_chunks = vs.retrieve(k=5, query=query_embedding)\n        print(f'retrieved data: {retrieved_chunks}')\n        return str([chunk.content for chunk in retrieved_chunks])\n    \n    # Create a pipeline\n    pipeline = agent.as_pipeline()\n    \n    # Serve the pipeline\n    serve_pipeline(\n        {\"gpt-agent\": pipeline},\n        host=\"127.0.0.1\",\n        port=8000,\n        is_async=False,\n    )\n\nRun the script:\n\n    python serve.py\n\nAt this stage, we have an openai-compatible backend with a model named\u00a0`gpt-agent`, running on\u00a0`http://127.0.0.1:8000/`. The Streamlit application will send requests to this backend.\n\n# Step 4:\n\nCreate\u00a0`app.py`\u00a0file, and build a chatbot UI:\n\n    # app.py\n    import streamlit as st\n    from openai import OpenAI\n    \n    st.title(\"\ud83e\udd8a Agent\")\n    \n    # provide any string as an api_key parameter\n    client = OpenAI(base_url=\"http://127.0.0.1:8000\", api_key=\"123\")\n    \n    if \"openai_model\" not in st.session_state:\n        st.session_state[\"openai_model\"] = \"gpt-agent\"\n    if \"messages\" not in st.session_state:\n        st.session_state.messages = []\n    \n    for message in st.session_state.messages:\n        avatar = \"\ud83e\udd8a\" if message[\"role\"] == \"assistant\" else \"\ud83d\udc64\"\n        with st.chat_message(message[\"role\"], avatar=avatar):\n            st.markdown(message[\"content\"])\n    \n    if prompt := st.chat_input(\"How can I assist you today?\"):\n        st.session_state.messages.append({\"role\": \"user\", \"content\": prompt})\n        with st.chat_message(\"user\", avatar=\"\ud83d\udc64\"):\n            st.markdown(prompt)\n    \n        with st.chat_message(\"assistant\", avatar=\"\ud83e\udd8a\"):\n            stream = client.chat.completions.create(\n                model=st.session_state[\"openai_model\"],\n                messages=[\n                    {\"role\": m[\"role\"], \"content\": m[\"content\"]}\n                    for m in st.session_state.messages\n                ],\n                stream=False,\n            )\n            response = st.write_stream((i for i in stream.choices[0].message.content))\n        st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n\nRun the application:\n\n    streamlit run app.py\n\n\ud83c\udf89\u00a0We have successfully built an Agent that is augmented with the technical documentation of several newly released generative models and can retrieve information from these documents if necessary.\u00a0Let\u2019s ask some technical questions, and check the generated output:\n\n# Conclusion\n\nIn this tutorial, we have developed a RAG agent that can access external knowledge bases, selectively decide whether to access the external data, which data source to use (and how many times), and how to rewrite the user's query before retrieving the data.\n\nIt can be seen that the Dingo framework enhances the development of LLM-based applications by allowing developers to quickly and easily create application prototypes.",
        "num_comments": 2,
        "comments": [
            "    Hi! Has anyone resolved this problem?\n    \n    python build.py\n    Traceback (most recent call last):\n      File \"C:\\LLM\\RAG\\build.py\", line 3, in <module>\n        from components import llm_vector_store, audio_gen_vector_store, embedder\n    ModuleNotFoundError: No module named 'components'"
        ]
    },
    "What changes needs to be done when I change the version of Wergzeug from 2.3.8 to 3.0.0 ?": {
        "title": "What changes needs to be done when I change the version of Wergzeug from 2.3.8 to 3.0.0 ?",
        "score": 1,
        "url": "https://www.reddit.com/r/Python/comments/1ctxzhj/what_changes_needs_to_be_done_when_i_change_the/",
        "content": "What are all the changes needs to be done when I change the version of Wergzeug from 2.3.8 to 3.0.0 ?\n\n\nThere are some CVE fixes available in the latest 3.x version of werkzueg. To take the fixes as part of my code, we want to upgrade the version. When I do so, I\u2019ve faced lot of breakages. I found some on documents and release notes. But it would be easier if someone already did some changes regarding this. \n",
        "num_comments": 4,
        "comments": [
            "You likely have to upgrade versions of packages that use it directly like flask and work out from there.",
            "Have you tried updating locally and seeing which tests fail? That is a good starting point..",
            "/r/learnpython",
            "I\u2019ve tried upgrading it. It broke plenty of other things. When I updated those packages, my functionality broke \ud83d\ude2c\ud83d\ude2c. Need to spend a lot time with it to get it working."
        ]
    },
    "Langchain using llama3 to build recommendation system": {
        "title": "Langchain using llama3 to build recommendation system",
        "score": 5,
        "url": "https://www.reddit.com/r/Python/comments/1ctnxa4/langchain_using_llama3_to_build_recommendation/",
        "content": "Hi,\n\nRecently I played a bit with LLMs, specifcally exploring ways of running the models locally and building prompts using LangChain. As a result ended up coding a small recommendation system, powered with Llama3-7b model, which suggests topics to read on HackerNews.\n\nWanted to share my experiences, so I wrote a small article where I described all my findings.  \nHope you'll like it:\u00a0[https://lukaszksiezak.github.io/ScrapyToLLM/](https://lukaszksiezak.github.io/ScrapyToLLM/)\n\nGithub repo:\u00a0[https://github.com/lukaszksiezak/ScrapyToLLM](https://github.com/lukaszksiezak/ScrapyToLLM)\n\n**What the project does:**\n\nIt's a Python application which uses scrapy to scrape HackerNews page. Scraped articles are pipelined to redis, which is then feeding Llama3 using langchain. Prompter is configured to serve a user articles which are matching his request.\n\n**Target Audience**:\n\nI think it suits the best all the people who are looking for a Hello World projects using LLMs. I think it also reveals some difficulties related to LLM tech, what potential problems could be found in production systems.\n\n**Comparison:**\n\nRecommendation systems are widely used and known, however LLMs are the ones which may work out of the box when appropriate prompt is given. It's kind of interesting to explore various usages of the technology and take part in fast grow of that stack.\n\nCheers.",
        "num_comments": 1,
        "comments": [
            "Great work!"
        ]
    },
    "PyCon US 2024 is here!": {
        "title": "PyCon US 2024 is here!",
        "score": 52,
        "url": "https://www.reddit.com/r/Python/comments/1ct1tnh/pycon_us_2024_is_here/",
        "content": "It\u2019s that time of year again, this time in Pittsburgh, Pennsylvania!\n\nYou can chat with others in the Python Discord (discord.gg/python) in the #pycon-us channel or in this thread. \n\nIf you\u2019re going, leave a comment below. Maybe include a talk you\u2019re excited to hear or summit your excited to attend.\n\nIt\u2019d be really great to meet some of you as well! I\u2019ve got stickers ;)",
        "num_comments": 6,
        "comments": [
            "I'm stoked, getting there tomorrow night as a first timer! \ud83e\udd13",
            "do we have discord or telegram group ?  or any other social app where guys are sharing the event snaps etc etc?",
            "Online attendance crowd, checking in. o7",
            "Ahhhhhh I wannna go",
            "Excited for you! This was supposed to be my first year as well but took a financial hit and had to back out of the trip. Already planning for next year though.",
            "Really only the pycon-us channel on the Python discord."
        ]
    },
    "Blat AI generates Python code to do web-scraping (code based on Scrapy framework)": {
        "title": "Blat AI generates Python code to do web-scraping (code based on Scrapy framework)",
        "score": 1,
        "url": "https://www.reddit.com/r/Python/comments/1ct9cqu/blat_ai_generates_python_code_to_do_webscraping/",
        "content": "[Miguel Algorri](https://www.linkedin.com/in/ACoAABsQysMBHUMg-KGkmYwYry-xIjUsCd0mthw)\u00a0and\u00a0[Arnau Pont V\u00edlchez](https://www.linkedin.com/in/ACoAAAucVMgB0cfv21gGto5FWMC_q8iLymtlOSI)\u00a0here,\u00a0[blat](https://www.blat.ai/)\u00a0co-founders!\n\n**Target Audience**  \nPeople who need to collect public data from the web (pricing, articles, reviews, leads etc).\n\n**What does our Project Do?**  \nAt\u00a0[blat](https://www.blat.ai/)\u00a0we aim to deliver production-ready web scraping code in minutes (written in Python, Scrapy framework).  \nThis is feasible thanks to our Web Scraping AI Agent \ud83e\udde0.\u00a0[Here our CLI to interact with the Web Scraping AI Agent (github)](https://github.com/blat-ai/blat-cli). Too good to be true?\u00a0[Check our video](https://www.blat.ai/)\n\n**Comparison**  \nThere are lots of other tools in the market, like [Zyte](https://www.zyte.com/), [Apify](https://apify.com/), [Kadoa](https://www.kadoa.com/). All those are great tools for web scraping purposes. The main difference with our competitors is that we give you the Python code that's ready to use (you host it, you run it). Also, once created, the code does not use AI for parsing HTMLs, so it's more efficient and deterministic.\n\n**What are we looking for?**  \nWe encourage you to[\u00a0register as a alpha testers](https://www.blat.ai/)\u00a0\ud83d\udcaa\u00a0if you are willing to have a better and more automated web scraping experience.\u00a0\n\n[Here our CLI to interact with the Web Scraping AI Agent (github)](https://github.com/blat-ai/blat-cli)",
        "num_comments": 1,
        "comments": []
    },
    "Apple Health data exploration with Atlas, Clickhouse, Vega-Altair, Quarto": {
        "title": "Apple Health data exploration with Atlas, Clickhouse, Vega-Altair, Quarto",
        "score": 13,
        "url": "https://www.reddit.com/r/Python/comments/1css42g/apple_health_data_exploration_with_atlas/",
        "content": "**What My Project Does**\n\nA few days ago I wrote a simple python script (\"[Atlas](https://github.com/atlaslib/atlas)\") that turns the Apple Health export.xml file (which is about 1 GB in my case, with about 10 years of data) into a very simple parquet file (a bit like a compressed CSV) that is also way smaller (40 MB).\n\nThe parquet file has 5 columns:\n\n* type (e.g. \"CyclingDistance\")\n* value (e.g. \"12.100\")\n\nand 3 datetime timestamps:\n\n* start\n* end\n* created\n\nThis makes it way easier to do data exploration. Here are a few example charts I generated using Clickhouse (chDB) and Vega-Altair in a Quarto notebook.\n\nStep Count:\n\n[https://x.com/\\_\\_tosh/status/1785397655784337684](https://x.com/__tosh/status/1785397655784337684)\n\nEnvironmental Noise:\n\n[https://x.com/\\_\\_tosh/status/1787530483208786029](https://x.com/__tosh/status/1787530483208786029)\n\nSleep Duration & States:\n\n[https://x.com/\\_\\_tosh/status/1786505867438768254](https://x.com/__tosh/status/1786505867438768254)\n\nCoffee Consumption:\n\n[https://x.com/\\_\\_tosh/status/1783906333911076996](https://x.com/__tosh/status/1783906333911076996)\n\nCoffee after 17:00:\n\n[https://twitter.com/\\_\\_tosh/status/1789304034442043421/photo/1](https://twitter.com/__tosh/status/1789304034442043421/photo/1)\n\n**Target Audience**\n\nFor everyone who would like to explore their own Apple Health data or see how to work with a simple .parquet file using Clickhouse (chDB), Vega-Altair and Quarto.\n\nQuarto notebook:\u00a0[https://github.com/atlaslib/atlas/blob/main/examples/apple-health-exploration-clickhouse-chdb-altair-quarto/index.qmd](https://github.com/atlaslib/atlas/blob/main/examples/apple-health-exploration-clickhouse-chdb-altair-quarto/index.qmd)\n\nIn the repo on Github I've added also added instructions for how to get your export.xml file from Apple Health and how to install the python script via pip to use it as a command line tool:\n\n[https://github.com/atlaslib/atlas](https://github.com/atlaslib/atlas)\n\n(\u2b50\ufe0f star to stay tuned for updates)\n\nCurious if you have charts that you would be interested in. Happy to add more examples over the next days!\n\n**Comparison**\n\nThis is me playing around with the data and wrapping the script up in a pip package to make it easier for others to install and use.\n\nYou can also explore the data in the Apple Health app but why would you if you can also explore it with your favorite programming language?",
        "num_comments": 0,
        "comments": []
    },
    "I made a python bot that plays minesweeper": {
        "title": "I made a python bot that plays minesweeper",
        "score": 85,
        "url": "https://www.reddit.com/r/Python/comments/1csd77f/i_made_a_python_bot_that_plays_minesweeper/",
        "content": "Hello,\n\nI made [this](https://github.com/ffhy/minesweeper) Minesweeper bot that I wanted to share with you all.\n\n**What My Project Does** -\n\nThe bot takes a screenshot of the board and runs a classification algorithm to extract the contents of the board. It then analyzes the board, finds as many mines as it can, and sends clicks. If it cannot find any mines then it guesses the most probable position of a mine.\n\n**Target Audience** -\n\nIt's a toy project for anyone interested in algorithms or problem-solving.\n\n**Comparison** -\n\nThis is just my attempt at making a minesweeper bot. I'm sure there are many bots out there that are much more efficient than this.\n\ndo let me know, if you feel anything can be done better :)",
        "num_comments": 10,
        "comments": [
            "Someone on r/learnpython made minesweeper yesterday!    \nhttps://www.reddit.com/r/learnpython/comments/1crao8e/i_wrote_a_fullyfledged_minesweeper_for_command/\n\nThis is cool, well done!",
            "Sorry OP, you solved a cool problem and did a great job accomplishing it.\n\nBut honestly - this code is quite unpythonic, and can be easily simplified and be like 10 times shorter. Full of magic numbers, wall of ifs, etc...\n\ne.g. so so much code can be refactored if you add a simple neighbours helper (writing in browser, without IDE, so might have some typos/errors):\n\n    def neigbours(self, i, j):\n        for delta_i in (-1, 0, 1):\n            for delta_j in (-1, 0, 1):\n                if 0 <= i+delta_i < self.rows and 0 <= j+delta_j < self.cols and not (delta_i==delta_j==0):\n                    yield i+delta_i,  j+delta_j\n      \n\nthen your dfs code becomes something like\n\n    flag = any(arr[ni][nj]==-1 for ni, nj in self.neighbours(i,j))  # Although I would suggest a better name than flag\n    if flag:\n        border.append([i,j])\n    visited[i][j] = True\n    for ni, nj in self.neighbours(i, j):\n        if(not visited[ni][nj] and 0<=arr[ni][nj]<=8):\n            self.dfs(arr,ni, nj ,visited,border)\n\nand it looks like all the other functions would also benefit from the same helper",
            "That's a cool project and very pleasing visually.\n\nBut that wall of `if`s asks for a refactoring. Try thinking what parts of your code look repetitive and how to extract them into functions that can be reused.",
            "If only I knew how to play minesweeper. \ud83d\ude2d\ud83d\ude2d\ud83d\ude2d",
            "Love this!",
            "Cool. Also, oof, this is a reminder that people actually use PyAutoGUI and I need to maintain it.",
            "nice job, enjoyable to read through this code.",
            "Good job.",
            "Thank you!\nRemoved most of the if walls using this.",
            "Wait, you made pyautogui?\n\nGreat work man!"
        ]
    },
    "Production grade AI Web apps, just using python ?": {
        "title": "Production grade AI Web apps, just using python ?",
        "score": 32,
        "url": "https://www.reddit.com/r/Python/comments/1csfimo/production_grade_ai_web_apps_just_using_python/",
        "content": "Hey guys, I have worked on building multiple ai/ml usecases and their specific backends. But now I want build interfaces for easy and quick integration. I saw a blog which used FastUI which looks quick decent but when I tried it just showed me a Json of elements on the page. Are there any other libraries I should use? \ud83e\udd14",
        "num_comments": 50,
        "comments": [
            "I use FastAPI for backend, with jinja templates and htmx for front. It feels pretty straightforward.",
            "Fast UI is good too",
            "If it\u2019s going to production then you better use a front end framework like react, otherwise at some point there might be a feature you can\u2019t build using streamlit or other python libs.",
            "Depends on your usecase, but if it's for internal use i can recommend you Rio. I've deployed 6 ML usecases (mostly FC including CRUD stuff) in the last 3 months. It works well for me, it serves \\~50 dayli users per application. As a DB I use MongoDB and it is deployed on Kubernetes.\n\nI'm one of Rio's developer. We announced Rio to the public last week. Maybe you can give it a try and give us feedback.\n\n[Website](https://rio.dev)  \n[GitHub](https://github.com/rio-labs/rio)",
            "Have you looked at Shiny for Python? Reactive coding so easier to manage if your app grows in complexity. I use both streamlit and Shiny.",
            "[**FastAPI**](https://fastapi.tiangolo.com/) with a React frontend is quality setup.\n\nThey also actively maintain a full stack example template. [ Github here: [**Full-Stack FastAPI Template**](https://github.com/tiangolo/full-stack-fastapi-template) ]",
            "I think you already discovered there is no such thing - customizable and in only python.\n\n\n\nJust use flask and some frontend, htmlx for example if you want to avoid JS. You will spend one or two days learning it and will have all the flexibility you can imagine.",
            "My team used only streamlit for about a year. *If* it does what you need, I\u2019ve yet to find anyone able to tell me a concrete reason why streamlit is generically \u201cbad\u201d for production. \u00a0\n\nBUT, we\u2019re now migrating to FastAPI for our AI apps and handing off UI to a web development team. What ultimately made streamlit stop working for us was an app that needed multiple conditional user interactions. We went down a deep rabbit hole on streamlit statefulness before realizing we were essentially fighting streamlit to get what we wanted.\u00a0",
            "streamlit",
            "A good source of information: https://www.fullstackpython.com/",
            "Want to share our library burr (GitHub.com/dagworks-inc/burr) \u2014 it excels at building applications that manage state (storing memory, etc\u2026), abstracting away persistence/telemetry. Works with other UIs (gradio, streamlit, custom, etc\u2026). \n\nAt a high level streamlit/gradio are pretty good for internal tools, you\u2019ll want something more custom for a user-facing tool most likely (I use tailwind + react,  but thats low level). \n\nHere\u2019s a write up about building an interactive AI server from scratch https://towardsdatascience.com/building-an-email-assistant-application-with-burr-324bc34c547d",
            "There's also HoloViz Panel.",
            "Surprised no one has mentioned Panel by Holoviz, it's fully in Python for front and backend (ala compiler) and doesn't share the drawbacks of Streamlit.",
            "See this presentation \"Full Stack Python\" from 2023 PyTexas conference. Front-end and backend in Python. [DAY 2 Keynote - \"Full-Stack Python\" (Andy \"Pandy\" Knight) - PyTexas 2023 (youtube.com)](https://www.youtube.com/watch?v=ka5KRLUn47s)",
            "Plotly Dash + Django Dash + Dash Bootstrap Components",
            "Start with gradio",
            "Got a GitHub?\n\nCurious how u use htmx",
            "I am building a streamlit-based RAG chat ui. What kind of app are you building where this stack is nescessary?",
            "Yeah, I saw the examples and demo call components on their page. I am not able to run it, shows json on the page??how have you done it!!",
            "Like what kind of feature? Everything seems to be pretty straightforward with streamlit, but I have no exp. with JS frameworks",
            "> at some point there might be a feature you can\u2019t build using streamlit or other python libs.\n\nOn the other hand, a quick and simple front end may be perfectly suitable for 5+ years, after which time technology may have moved on and brought new and better options. While it is true that design should consider future requirement, that needs to be balanced against the [YAGNI](https://en.wikipedia.org/wiki/You_aren't_gonna_need_it) principle.",
            "Project looks cool! How does the issue w/ state get handled? A lot of these Python UI web front ends have such a terrible time w state it makes me think twice",
            "Thanks, will try out \ud83d\udc4d",
            "The Panel framework from the Holoviz ecosystem actually does come closest and can be done fully in Python.",
            "Streamlit is slow and filled with redundant calls due to its execution mechanism every time an input is changed in my experience. It's fine if your Web app is using a few variable inputs, but otherwise the Panel framework is just as easy to use (syntax like Streamlit) and more versatile I'd argue.",
            "Good starting point, but not really 'production grade'. \n\nDepends on how much 'production grade' you need, I guess!",
            "People want it so simple that it starts to be too complex.\n\n\nJust use streamlit for POC and than flask with htmlx if you want to avoid JS.\n\n\nBuilding the whole web apps in only python is something we have been failing at for the last 15 years. If one wants customization there will be unneeded complexity. Just use appropriate tools.",
            "Yeah man, just saw the documentation, looks neat and customisable. Will try, Thanks \ud83d\udc4d",
            "Gradio and streamlit as good till POC part, want something that can be customised as well.",
            "Repo is private, sorry.\n\nHere's the site [www.wasfire.com](http://www.wasfire.com)\n\nQuick run through:   \nIn essence, I have folder for the jinja templates with the .html files, where I use tailwinui components + htmx\n\n    src/templates/home\n    base.html\n    brands.html\n    contact.html\n    cta.html\n    faqs.html\n    footer.html\n    ...\n\nThen a FastApi router.py, where you indicate where your templates are and upon request you return the html, it this case just a GET, we inject the translations too.\n\n    router = APIRouter()\n    \n    templates = Jinja2Templates(directory=\"src/templates/home\")\n    \n    @router.get(\"/\", response\\_class=HTMLResponse)\n    \n    async def get_home(request: Request, translations: dict = Depends(get_translations)):\n    \n    return templates.TemplateResponse(\"home.html\", {\"request\": request, \\*\\*translations})\n\nAnd as for HTMX, I use it for basic stuff, don't do anything fancy, for instance post a form, and plug the response in a div to show a message to the user.\n\n     <form\n        hx-post=\"notifications/send-email\"\n        hx-target=\"#response\"\n        hx-swap=\"innerHTML\"\n        hx-on::after-request=\"if(event.detail.successful) this.reset()\"\n        class=\"mx-auto mt-16 max-w-xl sm:mt-20\"\n      >\n    \n    ...\n    \n    <div id=\"response\" class=\"mt-10 text-center text-slate-500\"></div>",
            "It's a engine that scrapes deals from top brands and post them to whatsapp channels. The front part it's just for the landing page. Everything else is backend.",
            "We don't use it, our stack is mostly fastapi & next",
            "What exactly do you mean by \"run it\"? JSON sounds correct to me?\n\nAh nevermind, sorry, I confused FastAPI and fast UI",
            "Like an interactive table where you can add columns, rows, sort them in place etc.",
            "it\u2019s not really a \u201con the other hand\u201d, since developing in professional front end frameworks does not contradict building a quick and simple front end.",
            "Rio has per-component state (rather than global state). Rio continuously watches your attributes for changes and updates the UI as necessary.\n\nMaybe it gets clearer with an simple example:\n\n    class MyComponent(rio.Component):\n        clicks: int = 0\n\n        def _on_press(self) -> None:\n            self.clicks += 1\n\n        def build(self) -> rio.Component:\n            return rio.Column(\n                rio.Button('Click me', on_press=self._on_press),\n                rio.Text(f'You clicked the button {self.clicks} time(s)'),\n            )\n\n    app = rio.App(build=MyComponent)\n    app.run_in_browser()\n\nIf you have any questions feel free to ask. :)",
            "The redundant execution is what made us start exploring statefulness and ultimately led us to abandon streamlit. We may eventually make very simple streamlit pages to interact with our APIs that now handle the heavy lifting.\u00a0",
            "I found that streamlit is more highly customizable than gradio  \ncan you define production grade in your terms and an alternative tool?",
            "As someone who only has experience with streamlit: what makes it not really production grade?",
            "well said.\n\n(you meant htmX)",
            "You can customize them.",
            "Let me put it another way: A \"front end framework like react\" may be appropriate for some jobs, but I don't believe that it is always the best \"professional\" solution. Imo the choice of front end technologies is highly nuanced and depends on many factors.",
            "Yeah simple pages that you don't need to customize a lot/are fairly cookie cutter is convenient with Streamlit",
            "React is the standard production grade web frontend tool. Postgres is the standard database backend probably. Not sure about the standard language to build backend in, probably C# or Java or something, maybe Go as a modern alternative",
            "It's designed to simplify web development, rather than *be* web development. I'm not a web developer, but I know the basics.\n\nSuggest you take a look at r/webdev, they will have better answers than me.",
            "Yeah it\u2019s not 100%, I can\u2019t negate the possibility that such case exists,  although I haven\u2019t seen one yet.",
            "Right but for building chat UIs it should suffice? Seems overkill to use a webdev stack",
            "Well, like I said, depends on how 'production grade' you need it to be? Is it internal only or customer facing? How long is it expected to operate for?",
            "Good points. How does the last point about duration of the app operating affect which stack is used?",
            "Well, if it is going to be around for 10 years other people will need to come and maintain it, add new features etc. So it need to be well tested with unit/integration tests (to ensure maintenance doesn't break it.\n\nAlso it needs good code with a stronger type system that is more durable"
        ]
    },
    "Optimizing Poetry & VS Code Integration: Current Best Practices?": {
        "title": "Optimizing Poetry & VS Code Integration: Current Best Practices?",
        "score": 1,
        "url": "https://www.reddit.com/r/Python/comments/1cstr3w/optimizing_poetry_vs_code_integration_current/",
        "content": "Hi r/Python, I'm a structural engineer using Python, VS Code, and Poetry for my work. I'm frustrated with the way VS Code handles Poetry's virtual environments and am looking for current best practices.\n\nVS Code doesn't automatically recognize virtual environments when they are stored in Poetry's default location. To work around this, I've tried:\n\n1. **Local** `.venv`: Configuring Poetry to create the venv within each project directory. This is my current approach. Still there are some issues with VS Code (or me) getting confused about whether the correct venv is in use. There's some terminal restarting required and it just doesn't seem optimal.\n2. **Manual Configuration**: Explicitly setting the VS Code interpreter for environments stored in the default location. This annoying, having to add a new file path every time to a new venv.\n3. **Automated Workspace Settings**: Using `.vscode/settings.json` to pre-define the interpreter path for local `.venv` setups. This was my first solution that never ended up working correctly for me.\n\nEverything else about Poetry is excellent. This is my one fist clencher. I know it's not that big of a deal.\n\nThis topic has been discussed before, but I'm wondering if there are any new tools, scripts, or strategies that have emerged since. How do you integrate Poetry-managed environments with VS Code in your workflow? \n\nLooking for tips to streamline this setup. I know there's a better way to do this.",
        "num_comments": 3,
        "comments": [
            "I create the venv manually ie; `python -m venv venv;source venv/bin/activate` and go on my merry way.",
            "Thanks, that's a quick no nonsense route."
        ]
    },
    "Is PyGame still alive?": {
        "title": "Is PyGame still alive?",
        "score": 232,
        "url": "https://www.reddit.com/r/Python/comments/1crsktg/is_pygame_still_alive/",
        "content": "So it was a long time ago in the good old Python 2.x days (circa 2010 probably) that I had learned PyGame with some tutorials at my former work place. But nowadays since I mostly freelance with business apps, I never felt the need for it.\n\nBut since such a game development project is on the horizon after all these years, I was wondering if PyGame can still be up for the task with Python 3.x? Or is there a better Python library available these days?\n\nI don't need any advanced gaming features of modern day VFX or anything, all I need is some basic Mario/Luigi style graphics, that's all!",
        "num_comments": 62,
        "comments": [
            "You probably dont know about this but pygame team separated. There's now 2 versions of pygame.\n\n* `pygame-ce`  actively developed\n* `pygame` the OG one but this is a one man show these days. \n\n\n\n As for can games be made with `pygame`, checkout  [dafluffypotato](https://www.youtube.com/@DaFluffyPotato), he made games in `pygame` that won against games made in `godot`/`unity`.",
            "It might be worth checking out arcade https://pypi.org/project/arcade/",
            "I think you can now use pygame for a medium/heavy complexity 2D game.  I've seen a lot of videos on YouTube from clear code and thefluffypotato and today pygame is fantastic, of course with the community edition which offers tons of new features that make this library a great start for Python game development",
            "For the kind of tasks you mentioned I think it will be fine, personally I will recommend investing time in a more actively developed framework, even if that means changing the programming language.",
            "pygame-ce is active, and it's up to the task of implementing most of the sprite based games that older people know from the arcades or consoles like the sega saturn/megadrive.  \n  \nGet the new one from [pyga.me](http://pyga.me) (or pip install pygame-ce).  It's a drop-in replacement from the known pygame, with pretty much all core devs moved to that new project.  If you chose to try it, you need to uninstall the normal pygame before installing, since both use the same namespace (that's the drawback of a dropin replacement)",
            "You might want to check out [Arcade](https://pypi.org/project/arcade/).",
            "Yes. Pygame still works as well as it ever did. They aren't adding new features, but if you just need a basic game framework, it's good for that.",
            "Use pygame-ce. It's very much alive and thriving",
            "[Pygame has a new commit 2 weeks ago.](https://github.com/pygame/pygame)\n\n[Pygame-ce has a new commit yesterday.](https://github.com/pygame-community/pygame-ce)",
            "I use pygame quite a bit. Recently, I started integrating esper with it, and I\u2019ve experimented with Imgui (pyimgui) which has an integration for pygame. I didn\u2019t know pygame split, so I\u2019ll have to check out -ce version and see what it offers.\u00a0",
            "Yes",
            "Have a look at Godot. It has a scripting language that's basically multi-threaded Python.",
            "You can go look at their github or pypi repo. You don't need us to answer this for you.",
            "Github pygame has some cool games",
            "You can actually use [steamdb.info](https://steamdb.info) to search for games with pygame:\n\n[https://steamdb.info/instantsearch/?refinementList%5Btechnologies%5D%5B0%5D=Engine.PyGame](https://steamdb.info/instantsearch/?refinementList%5Btechnologies%5D%5B0%5D=Engine.PyGame)\n\nAlthough it detects RenPy engine as pygame also, so if you filter it out, there are still some games that use only pygame:\n\n[https://steamdb.info/instantsearch/?refinementList%5Btechnologies%5D%5B0%5D=Engine.PyGame&refinementList%5Btechnologies%5D%5B1%5D=-Engine.RenPy](https://steamdb.info/instantsearch/?refinementList%5Btechnologies%5D%5B0%5D=Engine.PyGame&refinementList%5Btechnologies%5D%5B1%5D=-Engine.RenPy)",
            "Hey, look at this [https://www.geeks3d.com/geexlab/](https://www.geeks3d.com/geexlab/)\n\nGame examples:\n\n[https://www.geeks3d.com/hacklab/20200415/snake-the-classic-snake-game-revisited/](https://www.geeks3d.com/hacklab/20200415/snake-the-classic-snake-game-revisited/)\n\n[https://www.geeks3d.com/hacklab/20200720/tetris-0-2-1-the-classic-tetris-game-revisited/](https://www.geeks3d.com/hacklab/20200720/tetris-0-2-1-the-classic-tetris-game-revisited/)\n\n[https://www.geeks3d.com/hacklab/20220821/video-game-qb-rubiks-cube-simulator-2x2x2-and-3x3x3/](https://www.geeks3d.com/hacklab/20220821/video-game-qb-rubiks-cube-simulator-2x2x2-and-3x3x3/)\n\n[https://www.geeks3d.com/geexlab/games/tirobulles/](https://www.geeks3d.com/geexlab/games/tirobulles/)",
            "I guess did a little project myself with it a few months back",
            "This reminds me of the current situation with fast api. Seems like the owners won\u2019t accept PRs from anyone",
            "I use pygame to detect a controller for a auto chat macro script I wrote.",
            "no             \nyou want pygame-ce\n\nhttps://pyga.me/\n\nthe main person in charge of pygame got snotty with taking updates and fixes so most of the main contributors left and started pygame-ce (pygame community edition)                   \n\nits a drop in replacement for pygame, but has lots of fixes and updates",
            "It still exists, but if you're planning to make a game I'd recommend using some other framework/game engine, as it'll be much easier to actually get something finished in a reasonable length of time. Godot could work well if you only know Python (GDScript's syntax is similar-ish to Python's)\n\n\nThat being said, I don't really use python much (I don't know why this subreddit was recommended to me, honestly), and I'd personally not use Python anyway because there are other languages I prefer using. But do whatever makes you happy",
            "From what I understood pygame is still a great library for game development and I don't see why it wouldn't be in wide use today still. I know the YouTube [Tech with Tim](https://www.youtube.com/@TechWithTim) also had done some work with Pygame and got really good with it. I don't think dafluffypotato level, but he covers it form time to time on his channel.",
            "\\[EDIT\\]: ignore this, Pygame Zero is dead, thanks u/DickerDackel\n\n# Pygame Zero\n\nIt's a Pygame \\*subset\\*, so it's much easier to learn. When/if you outgrow it you can move to standard Pygame.\n\n[https://pygame-zero.readthedocs.io/en/stable/](https://pygame-zero.readthedocs.io/en/stable/)",
            "Haha",
            "[Dayum, didn't know that had happened](https://www.youtube.com/watch?v=pYq9edSUaOw)",
            "Hey thanks for the tips. I didn't know that there was a split in the team myself and while I had visited dafluffypotato a while ago, I had forgotten about him. So go back and see his stuff again was refreshing. :)",
            "Didn't know about that. Why was the split made? Original author gatekeeping progress in the original repository?",
            "There seems to be a lot of game devs under this comment.  There are games I've always wanted to make that would be very enjoyable, but I have 0 artistic talent at all and that's always been the thing I let keep me from getting anywhere near game design.   I can handle the game logic just fine, but at some point, you need avatars, drawings, icons, etc...  is there a solution to this that I'm unaware of?",
            "I m not yet a programmer but want to learn python. Can I make games like clash of clans with python for android and ios? What language I should learn if not python?",
            "DRAMA!!!",
            "+1 for arcade especially if you're an OOP inclined pythonista. No shade against pygame, it is a valid option personally I found the approach of arcade more aligned with my default approach. Additionally the project docs have great documentation demonstrating how to use it for a variety of use cases",
            "That depends. Commercially it isn't really used and in terms of support it's also way behind Godot/Unreal or even Unity. Mobile/Console support may also play a role.",
            "pygame-ce is being actively developed. i think even pygame itself is.",
            "[deleted]",
            "or use it via a venv ! then you don't have the hassle to uninstall and install the other",
            "\\`pygame-ce\\` is being continuously worked on and improved and new features keep getting added to it. It's all the same pygame still.",
            "Wait, you wrote \"Automate the Boring Stuff?\" Holy shit!  I've probably purchased 50 copies of that book to give to junior IT staff over the years!  My 11 year old uses my copy from time to time.  That book really helped enhance my skill set as an IT professional, and made my son's request to make a video game together possible.  Thank you!",
            "I picked up your book from a garage sale a few weeks ago.\u00a0",
            "In contrast to pygame-ce, pygame-zero is pretty much dead.  Last commit 2 years ago.",
            "Same! I started out a project using pygame just recently, I'll have to switch.",
            "I guess it's time to run an rgrep against my repos for requirements files with that old name in it, and start replacing ... thanks for the info!",
            "According to their github \n\n\"It is a fork of the upstream pygame project by its former core developers, and was created after impossible challenges prevented them from continuing development upstream. \"\n\n[Found this reddit thread as well](https://www.reddit.com/r/pygame/comments/18xy7nf/what_was_the_disagreement_that_led_to_pygamece/)",
            "You can get cheap or free high quality assets for prototyping https://kenney.nl/",
            "Not really, because Python doesn't have a great support for android and ios \n\n\nBut you can start learning some Python and then search about Godot. \nIs a game engine that works on mobile and it has the GDScript language that is a lot similar to Python",
            "> Can I make games like clash of clans with python for android and ios?\n\nYes you can. But making a game in python is a bit challenging. If you are upto the task, the reward will be fundamental knowledge on how things work.\n\n> What language I should learn if not python? \n\nThis is entirely upto you, you can pick C# (unity+godot), C++(unreal), GdScript(godot)\n\nGive all of these a shot and see which one sticks with your taste :)",
            "of course, you're right, if you want to use pygame it's for indie development use or you want to know how a game works without using ready-made code. Now I would never recommend pygame if you want to do game development seriously",
            "Godot, easier\nUnreal, fully fledged",
            "L\u00f6ve2d is my preference. I dislike using anything other than a text editor.",
            "If you use them, you'll already know.  But the amount of people plainly refusing to make use of them got frustrating, so I stopped mentioning this option.",
            ":D",
            "Why\u00a0",
            "What a shitstorm... And\u00a0the\u00a0guy that\u00a0did that with all the collaborators just\u00a0for unjustified political move and ideas.\u00a0Pretty sad.\n\n\nBut I'm glad to see that people responsible for pygame-ce is doing the right things, keeping technical and supporting the community around.\n\n\nI already used pygame for very simple toy projects and I liked it, that was ten years ago.\u00a0\n\n\nCool to see that is not dead.",
            "Thank you",
            "Thank you",
            "I use arch btw",
            "- I prefer the version that's in active development.\n\n\n- I was looking for an answer to why I couldn't create a surface in indexed color mode (pygame 2), and the developer answer was \"you don't need to.\"\u00a0 (Pygame 1 allowed it.) Great, but my emulator is getting its raw pixel data in indexed color mode, so it'd sure be convenient to not have to 1) create an Image in indexed color mode 2) assign it the palette 3) blit that image to another image in the destination surface's mode, 4) blit _that_ to the surface\u00a0_every frame_. I'm working on other parts of the code right now and haven't circled back to trying to asking the community for a fix for this. I'm starting to think the answer would be \"use pygame-ce.\""
        ]
    },
    "Track the size of your PyInstaller packages in CI": {
        "title": "Track the size of your PyInstaller packages in CI",
        "score": 2,
        "url": "https://www.reddit.com/r/Python/comments/1csmx2q/track_the_size_of_your_pyinstaller_packages_in_ci/",
        "content": "If you have ever wanted to track the size of your PyInstaller packages in CI, Bencher now supports tracking your package size: [https://bencher.dev/docs/how-to/track-file-size/](https://bencher.dev/docs/how-to/track-file-size/)",
        "num_comments": 0,
        "comments": []
    },
    "I created a Python script that makes it easier to track how your baby's sleep is improving": {
        "title": "I created a Python script that makes it easier to track how your baby's sleep is improving",
        "score": 21,
        "url": "https://www.reddit.com/r/Python/comments/1csa6j0/i_created_a_python_script_that_makes_it_easier_to/",
        "content": "My wife and I use the Huckleberry app to track our baby's sleep periods. Although the free version of the app allows you to view a number of sleep-related metrics, I also wanted to see whether his longest nightly sleep stretches were getting longer over time. Therefore, I created\u00a0[a Python project](https://github.com/kburchfiel/baby_sleep_analysis/)\u00a0to help me answer this and other questions I had about my baby's sleep.\n\n# What My Project Does\n\nThis project reads in data from a Huckleberry .csv export (or a separate custom .csv file); analyzes its sleep information; and then produces\u00a0[a number of visualizations](https://github.com/kburchfiel/baby_sleep_analysis/tree/main/Visualizations).\n\nPersonally, I've found that running the code and viewing its output helps reassure me that our baby\u00a0*is*\u00a0making progress with sleep, even if he seems to have some setbacks now and then! I hope you'll find it useful as well in evaluating the effectiveness of your sleep training approach.\n\n# Target Audience\n\nThis project can be useful for any parent who wishes to see how his or her baby's sleep is improving over time. (It could be used for other age ranges as well, but the code and visualizations are geared towards infant sleep data.)\n\n[The project's readme](https://github.com/kburchfiel/baby_sleep_analysis/)\u00a0has instructions on using the code to track your own baby's sleep data. \n\n# Comparison\n\nThis project is released under the open-source MIT license, so you are welcome to use and modify it for free. (I imagine that this is not the case for many sleep analysis tools.)\n\nAs noted earlier, the project allows you to see how your baby's longest daily sleep stretch has improved over time. (The longer your baby sleeps at any given point, the longer *you* get to sleep, so I think this metric is of great interest to most parents!) I don't think the free version of Huckleberry includes this data in line chart form, though you can get a sense of this improvement by scrolling through your daily sleep data.\n\nThis script also separates individaul sleep entries into their respective daytime and nighttime components. For instance, if your baby slept from 6 AM to 9 AM, and you've specified the nighttime period to end at 7 AM (the default setting), the script will treat this entry as one hour of nighttime sleep and 2 hours of daytime sleep. I don't think Huckleberry offers this same functionality, though I could be wrong.\n\n  \n(Note: The sample data shown within the project is completely made up using\u00a0[another Python script](https://github.com/kburchfiel/baby_sleep_analysis/blob/main/Sleep%20Dataset%20Generator.ipynb), and is not meant to reflect normal sleep patterns in infants.)",
        "num_comments": 5,
        "comments": [
            "You have a newborn and you have time to develop stuff?",
            "\nI see you've posted a GitHub link to a Jupyter Notebook! GitHub doesn't \nrender large Jupyter Notebooks, so just in case, here is an \n[nbviewer](https://nbviewer.jupyter.org/) link to the notebook:\n\nhttps://nbviewer.jupyter.org/url/github.com/kburchfiel/baby_sleep_analysis/blob/main/Sleep%20Dataset%20Generator.ipynb\n\nWant to run the code yourself? Here is a [binder](https://mybinder.org/) \nlink to start your own Jupyter server and try it out!\n\nhttps://mybinder.org/v2/gh/kburchfiel/baby_sleep_analysis/main?filepath=Sleep%20Dataset%20Generator.ipynb\n\n\n\n------\n\n^(I am a bot.) \n[^(Feedback)](https://www.reddit.com/message/compose/?to=jd_paton) ^(|) \n[^(GitHub)](https://github.com/JohnPaton/nbviewerbot) ^(|) \n[^(Author)](https://johnpaton.net/)",
            "It's funny, but for me, projects like this are a big part of my self-care strategy as a new dad. I love seeing the code and visualizations come together. With regard to logistics: much of this project was created when he was asleep on my chest in a baby carrier--or when he was in his crib at night. I'm also fortunate to have a very supportive wife who tolerates these projects!",
            "I also had that same question but also like baby sleep is improving? Outside the first couple months it\u2019s been nightly wake up 3-5 times \ud83d\ude15"
        ]
    },
    "ChatGPT can talk with all my Python notebooks": {
        "title": "ChatGPT can talk with all my Python notebooks",
        "score": 1,
        "url": "https://www.reddit.com/r/Python/comments/1csjhge/chatgpt_can_talk_with_all_my_python_notebooks/",
        "content": "I'm working on an open-source framework for converting Python notebooks into web applications, it is called [Mercury](https://github.com/mljar/mercury). Recently, I have added an option to execute notebooks with REST API. You can pass paramters in POST request body to the notebook, execute all cells and return JSON as response. I'm also running a SaaS service, [Mercury Cloud](https://runmercury.com) where you can deploy notebooks with one-click with unique website domain.\n\n## What My Project Does\n\nIt makes Python notebooks extermely easy to integrate with custom ChatGPT, so GPT can execute Python notebooks and get response. It is 3-steps process:\n\n1. Create Python notebook, with Mercury widgets to accept parameters and return JSON response.\n2. Deploy notebook online - it can be done in 1 minute with [Mercury Cloud](https://runmercury.com)\n3. Configure ChatGPT Actions - it is quick, because Mercury automatically generates OpenAPI schema based on your notebooks.\n\nYou can read more in article [how ChatGPT is talking with all my Python notebooks](https://mljar.com/blog/python-notebook-chatgpt-builder-actions/).\n\n## Target Audience\n\nThis solution is perfect for people:\n- that would like to quickly create custom API for ChatGPT with Python,\n- that don't want to manage server by themself.\n\n## Comparison \n\nI think that building API with Python notebooks is alternative for full REST API development with Django, Flask or FastAPI, if you **quickly need few endpoints** that will expose your Python code. \n\n## Examples\n\nI have created example notebooks that are used by ChatGPT:\n\n* [notebook to send email directly from ChatGPT](https://runmercury.com/use/gpt-builder-action-send-email/)\n* [notebook to query Postgres database with SQL from ChatGPT](https://runmercury.com/use/gpt-action-query-database/)\n* [notebook to access Google Sheets in custom ChatGPT](https://runmercury.com/use/gpt-builder-sheets/)",
        "num_comments": 1,
        "comments": [
            "I\u2019m new to python but I wanna help lol"
        ]
    },
    "Framework to use for backend": {
        "title": "Framework to use for backend",
        "score": 69,
        "url": "https://www.reddit.com/r/Python/comments/1croj1r/framework_to_use_for_backend/",
        "content": "Hello guys\n\nI recently decided to move from nodejs(expressjs) to python for general purposes but mostly for backend. \nI have couple of questions. \n\n1. Will i regret my migration to python? :) \n\n2. Which framework you suggest for backend solo dev? \n\nAnd what tips are you suggesting me in general to get used to python. \n",
        "num_comments": 112,
        "comments": [
            "There is Django for more classical websites (and it can do APIs), then Flask and FastAPI. Each unique/specific in style. Python overall is popular on the job market, often used to make APIs for JS SPAs, mobile apps and alike.",
            "I would really recommend Django for a first time. It provides a lot of structure out of the gate. It's a really useful tool to learn at what places you should have your abstractions. Where should you put your config, your views, your ETL jobs, your db migrations, etc.\n\nWhile not every framework is prescriptive, you still need to follow design patterns. Django is a great way to start to learn those (healthy) design patterns.",
            "I'm really surprised by the number of people recommending async frameworks to somebody with a Node background without providing context. They are not the same thing and are really closer to being opposite things. \n\nI think that async programming in python is hard or at least not beginner friendly, because there isn't a language-level event loop, which is one of the standout features of Node. And unlike JS, which is by comparison is quite forgiving about the function color problem, python is not.\n\nThe folks who are recommending Django and Flask are on target, especially since those frameworks have lots of tutorial content and large communities. They can grow with your project without getting in the way.\n\nIf somebody approached me to ask \"what language should I use on the backend\" I would want to know what kind of app they're building and if there's reason that any one language might offer an advantage. In the absence of this information, I think Node is usually the best choice.",
            "Take a look at fastapi for the framework (if you are looking to do apis), and also look into ruff for lint/style/formatting paired with pre-commit to keep everything tidy (your own sanity, and future people looking at the code)",
            "If you decided to move without a reason - yes, you will regret. What pushes you to migrate to completely other environment?  \n\nAs for the frameworks - I's stick with FastAPI or Django. Depending on use case and the things you want to build on you own or have ready OOTB.",
            "Another take:\n\n1. You should never regret learning new things, but as for any change in technologies, you'll miss some things. Python's async story is mostly worse than node's, but the rest of the language is designed more sane for the most part.\n\n2. People mentioned the current big 3 frameworks already, but let me map them to the NodeJS ecosystem:\n\n- Express.js -> Flask: minimalist, big plugin ecosystem, simple and unopionated\n\n- Fastify -> FastAPI: opinionated on the tools to use (like logging), focus on async performance, great documentation, fast to learn\n\n- Nest.js -> Django: \\*very\\* opinionated, basically specifies your application architecture; has everything built-in you need for 90% of all apps; takes some time to learn, but once you know it well you can be very productive",
            "i would do FastAPI",
            "Flask rocks, very stable.",
            "1. I don't know. Only you will and when that happens, it's too late :) . But I doubt that you will regret it.\n\n2. FastAPI, Flask (+ Connexion), Django, depending on your needs.",
            "[Flask](https://flask.palletsprojects.com) is a great choice, with lots of great documentation e.g. https://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-i-hello-world.\n\nIf you need to use async libraries use [Quart](https://quart.palletsprojects.com) as everything you've learnt about Flask will still apply.",
            "Hey bro,\n13 year tech lead here, writing Nodejs (typescript) apps for 5-6 years before migrating to Python 3 years ago.\n\nMy take: \nPython ecosystem is very frustrating, let me explain:\nThe python language has async support for a few years ago, but Django still has issues with translating sync-to-async code in their ORM.\n\nIf you want async you can\u2019t use Django Rest Framework because it does not support async out of the box. There are people explaining that if you are going to ever use async in Django you would need all middleware to be async for it to be efficient, you pay a price for converting sync code to async (this will take years, and I personally don\u2019t think it will ever happen).\n\nI tried making a graphql api in Django, and the used \u201clibrary\u201d is Django Graphene, but they migrated to version 3 without completing everything, so dataloaders do not work, you need an async server for it to work.\n\nBut you can\u2019t use async because then you have ORM problems in Django.\n\nSo you see there is no good alternative to graphql api in Django. Dataloders are one of the most important concept in graphql apis.\n\nWhy didn\u2019t the Django team develop their own Graphql integration ? Good question, maybe you can ask them on their forum, see what answers you get :)\n\nYou can use Fastapi(which is async) but here you either use their ORM or SQLAlchemy and strawberry.\n\nComing from the javascript ecosystem I felt that at work and in personal projects I had to use \u201cweird libraries made by a dude that is not really adding support\u201d every now and then.\n\nYou will feel the pain, that doesn\u2019t exist in the Js ecosystem where normally libraries give you full support for everything.\n\nYou will not have anything close to Nestjs in the Python ecosystem. \n\nFastapi, Django are magnitude slower than any Python framework. \n\nLet me tell you how to read techempower benchmarks.\n\nGo to techempower select javascript, typescript and python , select the frameworks like Django, Fastapi and Nestjs, express.\n\nIn the database filter under ORM select \u201cFull\u201d this means you will get benchmarks with ORM full fledge frameworks like sqlalchemy and Django ORM, compared to Nestjs which uses typeORM.\n\nYou will see how the javascript frameworks are 3 to 4 times faster in single query, multiple query, etc benchmarks.\n\nFastapi and puthonistas like to brag saying Fastapi is as fast as Nodejs, and yes, it\u2019s fast if you use \u201craw sql queries\u201d, but at the moment you start using an ORM and actual code production ready, Python frameworks are 3-4 times slower.\n\nPeople will say caching, yes. But the throughput of the server is 3-4 times faster in nodejs so if I use caching for the same app, I still need 3 times less resources to have the same performance in Nodejs compared to Python. That is significant cost reduction for my startup.\n\nAlso in Javascript you have Promise.all() to run queries in parallel, truly async code. In Python you ned to create tasks in Sqalchemy because it\u2019s transactions based and each query needs to run on its own session - it\u2019s not nice and error prone.\n\nIn Django, well, you have no async support (I guess you have some, but then you need to wrap your code in ugly sync_to_async() functions) and other stuff.\n\nIf you have 3 operations that each takes 2 seconds you finish in 6 seconds if you run it sync.\n\nIn nodejs with promise.all you run them in parallel in takes only 2 seconds (or the time of the longest running query), do you know how hard it is to achieve this in Python ?  - and no, Asyncio.gather() does not work again because you need separate session for SQLAlchemy.\n\nGood luck. If you don\u2019t want to use weird library that solves a problem done by \u201cone guy\u201d that is not maintaining it anymore, or do weird workarounds, or if you want high performance, I say learn typescript and stick to express and nestjs. \n\nIf you want to try something new, learning a language that is slow, go for it.\n\nAnd btw, the typings of python are nowhere near close the quality of what typescript gives you.\n\nDay to day work for me still feels hackish many times, sadly. I work with both Django and Fastapi to build fast, scalable, production ready apps.\n\nIf you do a hello world app, or a basic crud restapi any framework is good, but when things get complicated, you start feeling the Python ecosystem pain.\n\nGood luck.\n\nPythonjstas will tell you I say bullshit, but actually probably many of them don\u2019t know the production ready ecosystem of Javascript and Typescript and they believe what they have is really great\u2026 it is, but you can\u2019t compare it to the Js ecosystem. You will know what I mean once you start feeling the pains, especially if you are used to the js ecosystem where everything just works flawlessly together.\n\nPeople will tell you that in python you get shit done faster and that development time costs money and servers are cheap. I can guarantee you that using typescript and Nestjs you will have the same productivity speed as using Django or Fastapi in delivering any project.",
            "FastAPI for sure.",
            "I rewrote an app from Express to Litestar and I've been quite happy with it.  Key things I liked vs Express were Pydantic doing real checks on all the inputs and outputs, and the built-in OpenAPI generation, making it easy to hook up a frontend without having to write types for all the models again.",
            "Quick question : why are you moving away from nodejs ?\n\nSecondly, to answer your questions : python is very useful for backend work, lots of companies recruiting with that skill in mind. That being said, python is clearly not very fast, so your express servers answering queries in less than 100ms will turn into a backend answering at 300ms or more with python, depending on the framework of choice.\n\nFor frameworks, you have a lot of choice in the python ecosystem:\n\n- Django : it's the juggernaut of backend dev. Also the slowest option of them all, but it's batteries included (admin site, ORM, views, templating language)\n\n- Flask : very simple WSGI framework, it's good for APIs. Bring your own ORM.\n\n- FastAPI : one of the better choices for API dev in python, it's an ASGI framework, so you'll need an ASGI compatible worker (gunicorn or uvicorn usually), based on the Starlette framework (which is seldom used on its own)\n\n- litestar : The rising star of python ASGI frameworks, used to be based on Starlette (hence the name), but has since moved away. Seems to be one of the fastest frameworks around.\n\n- blacksheep : I don't know if it's still maintained, but it was a very very fast ASGI framework, crushing all kinds of benchmarks. Was not very dev friendly though.\n\nI don't think you'll regret learning backend with python, as it's still a useful skill to have, but you'll have tradeoffs, namely speed / response time / async handling.",
            "Go for [FastAPI](https://fastapi.tiangolo.com/). The documentation is great and the framework is very well written. You will quickly get up and running and will save yourself from ever having to know what Django is.",
            "I'm a big fan of Flask, so I always recommend it. It still is one of the most popular python frameworks for backend (around 70k stars on GH, 1.9M people using it on GH, and still one of the top frameworks in the StackOverflow survey). If you want to go for more complex applications you might use Django, again one if not the most popular framework.\n\nRegarding pure ASGI frameworks, there is Litestar (my favorite), Quart (Flask ASGI implementation) and FastAPI (the most popular one I'd guess). But I'd say they are all \"quite\" similar and i wouldn't stick to only one of these.",
            "Flask 100%",
            "1) Definitely not.\n2) Django.",
            "In my projects, I often use Django. Though I also use FastAPI sometimes, Django is still preferred in projects with many data, because Django has built-in admin pages which help a lot in the early stages, to manage data.\nDjango is used both in SPA and non-SPA projects.",
            "drf",
            "1. absolutely not\n2. Django web framework, more of a \"all-in-one / batteries included\" framework, definitely would recommend with django rest framework. Other lightweight libraries would be Flask and Fast API, meant to be more modular with your architecture, pretty similar to expressJS. If you'd like to have more strict modeling and validation look into Pydantic, for anything other than django would also recommend SQLAlchemy as a relational ORM, django has its own ORM included.\n\nI've used a number of each for notable companies, with proper infrastructure it can scale very well to handle thousands of requests / sec with no problem. Can't go wrong with any of those and what most others I see are commenting.",
            "Django/DRF if you want to build things fast. Fastapi for the rest",
            "One backend framework I often find nice for API design and development is Flask. Super simple to get started with and build things with. I am even experimenting with an assist agent which will interface with the flask backend to pull in custom plugin style services I am creating. The hope is that I can build in everything from LLM style libraries to text to voice to weather info and to-do task creation to help assist me on day to day life. Maybe my own personal 'JARVIS' one day.",
            "Django all the way",
            "1. No; 2. Django",
            "I am not a python dev but I loved the time I spent working with FastApi. I followed the template https://github.com/tiangolo/full-stack-fastapi-template",
            "I would suggest you have an AI chatbot help you write a fast api (or flask) backend. Fast api is great because it\u2019s asynchronous and you get a nice test screen for free to let you try out your API",
            "1. Maybe? Consider Laravel before you go too far.\n\n2. Flask is pretty easy to get started with. A lot of people like FastAPI.",
            "If you\u2019re just building an API service to be consumed by a front end or other kinds of remote users FastAPI is great. If you want an entire batteries-included web development framework Django is king in python.",
            "if u care for load preformance js is king because the browser nativly supports it.   \nthat being said python is super nice to work with and I think for most sites that's a worth while trade. \n\nfor some interactive things u may want HTMX or even some js on the page but lets be real how many times do u actually care for the extra second on load vs the annoying js quirks u gotta deal with",
            "for any mid to large site/app - go w django, it takes more time to pick up but has everything you need, including extensions, async, ORM, etc\n\nif you cant put in the time to learn it, go with fastapi or quart (async version of flask)\n\nboth are used widely and stable \"microframeworks\"",
            "the main reason i want to move to other environment is because every few weeks there is new \u201ctech\u201d in JavaScript new library new framework hype etc. Iam a bit frustrated with the ecosystem , and i want more stable environment. Not to mention that you are forced to learn Typescript",
            "If you\u2019re looking for a micro framework, I\u2019d recommend Litestar. They are quite active and responsive. \n\nFor something more comprehensive, either Django or Reflex could work, but I have very little experience on both so \ud83e\udd37\n\nMicro frameworks:\nLitestar\nBlacksheep\nMicrodot\nEmmett\nRobyn\nFlask\nQuart\nFastAPI\n\nFull frameworks:\nDjango\nReflex",
            "I\u2019ve never met anyone who regretted moving away from JS except one crotchety SVP who was a trash programmer back in the day anyway, so you should be good. Like others have said, Flask, FastAPI, and Django should get you going. If you\u2019re doing microservices and building everything from scratch, there are tons of smaller resources that feel like proper OOP you can use.",
            "For adding a REST API to Django, I'd recommend Django-Ninja over Django REST Framework; particularly if you like Pydantic/FastAPI/Litestar.",
            "Also if you started with Django and find it to your liking, read Two Scoops of Django. It's not really \"Here's how to start using Django\", but \"Here's how to use Django well\"",
            "Agree:\n\n- Django's migrations framework (how to apply/rollback database changes) is second to none\n\n- the ORM (high-level query language) is quite good\n\n- template language is solid\n\n- just enormous numbers of high-quality useful plugins: [https://djangopackages.org/](https://djangopackages.org/)\n\nIt's not 100% unicorns and rainbows: there's a learning curve, and it can be over-opinionated. It's still my go-to for anything.",
            "Seconded. I've been using Django professionally for a decade now, and it's wonderful. As mentioned in another comment, the Object-Relational Model and the migrations are top notch, there are a ton of packages developed for it, and it's got a built-in admin panel.\n\nIf a REST API is what's being called for, Django Rest Framework is my favorite, it's quick to set up, and it handles most of the heavy lifting for you. I did a volunteer project in which I'm in charge of the backend, and I used Django and DRF, and most of my code is models and serializers.",
            "I didn't understand most of that, but I saved your comment for someday when I figure it out.",
            "and for dependency and env management i'd recommend poetry",
            "oh and 1. no you won't :p totally unbiased opinion",
            "Thank you for your answers. Which code editor you use?",
            "What is your opinion of litestar? And sanic?",
            "The main reason i want to move to other environment is because every few weeks there is new \u201ctech\u201d in JavaScript new library new framework hype etc. Iam a bit frustrated with the ecosystem , and i want more stable environment. Not to mention that you are forced to learn Typescript",
            "What is your opinion of litestar? And sanic?",
            "Thank you really informative.",
            "Why don't people just use quart then?",
            "Flask really isn't a good option nowadays.",
            "I am going to tell you one more thing. You believe there are many jobs in the market but actually many of them are data science, ml, ai jobs.\n\nYou are a web dev you have none of this skills, search your job market for web development and skills that you actually own and you will see that actually in python you have much less opportunities than in js/ts for what you actually know.",
            "wow, i was looking forward to hearing from an experience programmer and complete answer. You made me think it twice now and i think i will not make the transition but instead i will focus on TS instead :) . Thank you for your analysis and time.",
            "the DB speed is relevant if youre doing millions of transactions, and if youre doing that, why even use JS or Py when you run something via a compiled framework that will be 1000x faster, ie Crystal, Go, etc which have their own frameworks\n\n  \nfor 99% of people who need  a web FW, this wont be a factor, unless theyre quering with bad logic, django has a debug toolbar that roots out bad queries and shows query time for each request. \n\nsame case for async. \n\nif you need that level of performance, then a scripted language isnt the right choice for a web FW",
            "I actually dislike doing OpenAPI yaml file generation.\nYou\u2019re not truly API first, and many times, engineers get lazy with the spec itself.\n\nGoing the other way around, where I define the API via OpenAPI spec, has just been more enjoyable.\n\nEspecially when I can plug it into a framework and it does all the validation and json shape for me without a single decorator needed as part of the API.\n\nMaking product development super fast, as you only define the language and agree upon it and FE and BE can independently develop from the get go.\n\nAnd how many lines of code do I need to write outside of a yaml file to do all this?\n\n5 or less.  Have to register the yaml and you\u2019re off to the races (Connexion package).",
            "I like Flask, but don't see what the advantage is over FastAPI nowadays to be honest.",
            "It has defaults that most people wouldn't want in 2024.",
            "Just because there is something new doesnt mean you need to switch.",
            ">Not to mention that you are forced to learn Typescript\n\nIt's no *\\*annoying coincidence\\** every project and company has shifted their JavaScript to TypeScript. TypeScript is just JavaScript with types. Having types not only allows you to debug/resolve issues faster, but an important benefit is it allows the Intellisense features of your code editor to give you much better suggestions and nowadays also allows code-generation AI to better understand your code intent and make better forward code suggestions.\n\nAs you're in webdev, you'll still need to do JS/TS unless you're 100% backend, which it doesn't sound like your case. Don't be the goof still pushing type-less JavaScript (unless there's a very strong use case for doing so such as some underlying library with strict needs for maximum performance speed).",
            "I have a question - is moving from nodejs to python for API Dev considered as an upgrade? Because in my eyes you're moving from a slow language to another slow language.",
            "I've not used Django-Ninja, but I'm a DRF advocate. What makes you recommend Ninja over DRF?",
            "Seconded, it has lots of practical advice.",
            "The [wiki article on event loops](https://en.wikipedia.org/wiki/Event_loop) is a good introduction. Bottom line, event loops have lots of uses but are critical in scenarios where you have to wait for input of some kind. This means they're a key abstraction behind most GUIs, games and network-facing applications like, for example, a webserver. They are notably not particularly common in procedural, scripting /\"glue\" and scientific computing contexts, which is one of the use cases where the python language shines. Conversely, this is a thing that Node is good at, especially for new developers. Go and Elixir/Erlang are other popular languages that have event loops and (in particular Erlang) trying to solve problems around concurrent inputs by using an event loop.\n\nThe comment about \"closer to being opposite things\" is my opinion about what the await keyword does in each language relative to how they normally run. This discussion ends up full of technical gotchas and valid personal interpretations of what API \"feels\" right to you. I really like [this article](https://medium.com/@interfacer/intro-to-async-concurrency-in-python-and-node-js-69315b1e3e36) that gives you some sense of the difference in flavor between the two languages. It also gives a pretty good example (scraping) of when you might want to do some async programming.\n\n[What Color is Your Function](https://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/) is a classic.",
            "what is the benefit of using poetry instead of venv with pip?",
            "I\u2019ve used Pycharm for 3 years and after getting used to its tools I can\u2019t imagine why I would ever use anything else for Python development.",
            "The ones i like best is PyCharm and VS Code.",
            "I believe this type of question is likely to start \"religious\" type wars, but am willing to fan those flames - PyCharm is my clear preference.  \n\nVS Code is tolerable for small changes, but configuring hot keys and using multiple monitors just doesn't work as well or even exist (I work with die hard VS Code, MS tool fanboys and they don't think this is important).  The default PyCharm behavior of running files as a module and managing relative imports makes testing and development of dependent scripts much easier.",
            "I'm not a good example here, I use vim + plugins and no real IDE :)",
            "VS Code",
            "pycharm is good because it holds your hand setting up the environment, testing, etc.  it's generally smoother.\n\ni use vs code though because i'm used to it and it's fantastic as well.",
            "Ive not touched them, they weren't mature when i started with fastapi (or at least i hadn't heard of sanic) , and I've not run into any thing in fastapi to make me look elsewhere essentially.",
            "Litestar is certainly an option, though it's a bit newer than Fastapi.\n\nSanic is really old and doesn't use typing information afaik, not sure if it's worth recommending.",
            "Wait.. are we talking about an existing project of yours? How would \"new tech\" matter than? Just because there's a new JS/TS framework in town, you don't need to change anything about your code. \n\nAlso, TypeScript is awesome, I think it's a very good idea to become at least a bit familiar with it.\n\nPS: not wanting to bash on Python for backend here, just sayin that JS/TS for backend is absolutely fine if you're already working with it)",
            "My opinion about frameworks is irrelevant here. Those 2 mentioned by me are the most popular now and OP would get the best support.   \nIf it's about testing other opportunities - go ahead, play with others. But if it's about delivering a product - just go with the tool you know the best.",
            "Flask has a wider ecosystem of extensions, in addition if you mostly use sync libraries Flask is a better choice.",
            "Can you explain why you think this?",
            "By all means explore Python, but do take a correct look at the techempower benchmarks (with ORM filtered to full).\n\nAnd please look at the job market and when you search for python jobs read the description and see how many are actual web dev jobs compared to ml/ai, data science jobs that you are not qualified for.\n\nIt\u2019s a fun language, but I personally believe typescript is better. I would not write pure javascript backend these days. \n\nI would go for Nestjs, typeORM, typescript, resist Postgres, or of such.\n\nBut again, exploring Python is not a bad thing and knowing a new language might be beneficial for your career.\n\nI for example worked with Nodejs, C#, php, Java and now Python.\n\nBut i dont know in what phase of yout career are you currently in. If you have 2\u20134 years, I would definitely say focus on typescript and specializing to the job market needs in your area.\n\nIf you have a stable job and don\u2019t need/want to play the market, you can do some python mini projects and play with it. But at that point no one will employ you on a python job above junior.\n\nSo you want to be mid/senior in typescript/node or junior in python ? If there are less jobs in python for web dev than in typescript/javascript in your area, it doesn\u2019t make any sense to make the switch to Python career wise.\n\nPython jobs are not better paying than Nodejs jobs.\n\nIf you want corporate career then learn c# or Java which are strongly typed.\n\nYou already know javascript for a dynamic language, why learn another dynamic language (python)?\n\nGolang and Rust don\u2019t have a too big market penetration for me to be able to recommend them.\n\nYou always need to play your regional market and ensure good employment prospects for yourself by also keeping in mind your career progression.",
            "Whatever works for you - this is a solo project and I find the OpenAPI yaml syntax a lot less pleasant to read and write than the Pydantic model Python code.",
            "Such as? Just curious. I like and use flask. Just wondering what defaults may not be desirable?",
            "yeah i understand this, but am looking for more stable environment in general it might seems stupid. Force to learn typescript seems stupid",
            "For API work, there are a lot of considerations. Neither are truly \u201cslow\u201d anymore, they\u2019re just comparatively somewhat slower than C. It all depends on the best implementation for your particular framework, although I would always default to Python. Python has fewer headaches and was actually built for this sort of work whereas JS was originally a formatting language that people have bastardized so much over the years to do things it shouldn\u2019t.",
            "It uses Pydantic models natively and replicates the bulk of the FastAPI/Litestar structure and behaviour. If you run multiple projects in both Django and these other APIs, it makes switch mental context between them a breeze.",
            "And a lot of that advice also can be carried into other frameworks too. Great book",
            "Thank you so much.  The world needs more of you. \ud83d\udc51",
            "Lockfiles and idempotent dependencies.",
            "poetry essentially does that under the hood while also ensuring a valid python version in the venv, as well as locking dependencies, ability to build/publish to pypi etc.\n\nI hope to one day recommend uv like ruff, but that is still early days and limited in scope, so poetry will continue to be my recommendation for now.",
            "The only thing that pycharm can do that is unmatched is refactoring. And debugger is quite good",
            "Omg\ud83d\ude05",
            "That's the best example.",
            "Agreed not good ex",
            "I use vim in pycharm",
            "It's frustrating how just when you feel comfortable with vanilla JS, the next thing you know, it's \"YOU MUST learn TypeScript\" (and I agree, it's important). It feels like there's always another \"you must\" when it comes to JS.",
            "10 years of experience in all full stack frameworks. If you have to scale go for fastapi, pydantic, sql_alchemy because of the extensive asynchronous support. \n\nYou can\u2019t compare nodejs to fastapi, nodejs is a language - fastapi is a framework. When you start using nodejs with framework like nest, you will start seeing the performance. There is actually a benchmark which says fastapi is faster than most of nodejs framework.\n\nIf you are using nodejs with express, it will be faster but these days no one uses express.",
            "Just because there is something new in the ecosystem doesn\u2019t mean you have to adopt it. \n\nHowever, there is a lot of marketing around frameworks and tools in the JS community that makes it difficult. \n\nI have noticed that fewer blog posts talk about best practices when using browser APIs or patterns for building certain features",
            "I am a data engineer and I too lean towards Python APIs. But the thing is that I have to calculate things on the fly and for that I need to use something like Pandas or Numpy. I do not have any issues with Numpy, but when I am forced to use to Pandas, I hate making any APIs.\n\n  \nI am convinced that we should not use Pandas for any API related tasks. And this is when I wonder if I do things in any other language like Golang or Rust, will the performance be the same or will there be any performance improvement? I know that Pandas is written in C or something and it is highly optimized. But still, how will Rust/Golang fare in this situation?",
            "Okay, that's fair enough. I only have to maintain one project in FastAPI and several in Django, so the switch to pydantic and sqlalchemy when I have to change is a bear, but I love Django's ORM and migrations. Plus, I've been using DRF since like 2016 or so, so I'm an old hand at it",
            "For those of us willing to suffer for their art while learning :D I hopped on the vim wagon 15+ years ago, the pain has eased.",
            "Here I did it for you:\n\nhttps://www.techempower.com/benchmarks/#hw=ph&test=db&section=data-r22&l=zijzen-cn1&o=e&f=zik0zj-zik0zj-zik0zj-zik0zj-zik0zj-zik0zj-zik0zj-ziimf3-zih7un-zik0zj-zik0zj-zik0zj-zik0zj-zik0zj-1ekf&d=e3\n\nLook at single query, multiple query, fortune and updates benchmarks etc - it\u2019s 3 times faster than fastapi. \n\nIt uses the same db (postgres)\n\nAnd it\u2019s using an ORM and all the \u201cbatteries\u201d, actually nestjs has much more batteries than fastapi with 3x more performance.\n\nThese days everyone uses typescript with Nestjs.\n\nYou can put all the Nodejs frameworks with ORM and Postgres and all of them will be 3x faster than Fastapi.\n\nFastapi is faster when doing raw queries (but who does raw queries these days? Everyone uses an ORM). So not really relevant if you ask me. \n\nI guess you can agree techempower are a trustworthy independent, capable benchmarked.\n\nWhat Python needs is SQLAlchemy to get its game together and come up with a very fast ORM that is on par with TypeORM. Or maybe that is not possible and actually the limiting factor here is actually the language (python vs JavaScript)",
            "Nodejs is a runtime not a framework. \nI read techempower benchmarks since they are the industry standard (even linked on fastapi site).\n\nSo this exercise (I already mentioned it):\nGo to tech empowered go to the latest tests go to filters and filter for language: Python, Typescript .\n\nGo to databases and filter: Full (for ORM benchmarks not raw queries).\n\nYou will have results from Nestjs using Fastify with typeORM, and fastapi-Gunicorn-ORM (using SQLAlchemy) \n\nSee the results, fastapi with full ORM will be 3 times slower than nestjs-Fastify with ORM.",
            "Try Polars instead of Pandas. It\u2019s built on Rust and is similar to Pandas but SO much more performant. I love it. It\u2019s similar to PySpark in performance without the required startup time or cluster, but you interact with it like Pandas.",
            "I personally prefer to keep my api models separate from database models as their structures are typically vastly different.",
            "Thank you these amazing content, l was always rooting for fastify numbers, I think your claim make lot of sense. \n\nWhat would be the best resource to learn these?",
            "See, mine aren't. My api models are my database models, and there are serializer classes that adjust how the models are displayed or input through the endpoints, so why bother with multiple models?\n\nI'm not saying your way is wrong and mine is right, mind you, I just want to have a discussion on different patterns. I might give Ninja a try on my next project, though, just to try it out",
            "For typescript there is a use my instructor called Maximilian Schwarzmuller, he is the best when talking about js and typescript. So you can learn typescript, react, enhance your JavaScript skills if you want using all the identity courses created by him. (Btw he has Django and other courses as well), he is highly recommended. \n\nHe talks in great detail about each subject and not only that, but he also talks about corner cases and such, giving you almost always the complete full picture around any concept.\n\nSo for typescript go with him: https://www.udemy.com/course/understanding-typescript/?couponCode=LEADERSALE24A\n\nThen once you are familiar, make a identity course on nestjs :\n\nhttps://www.udemy.com/course/nestjs-zero-to-hero/?couponCode=LEADERSALE24A\n\nNestjs + Fastify is the way.\n\nhttps://docs.nestjs.com/techniques/performance",
            "Used DRF for a decade and recently moved away from it. Its fine when your api corelates directly to your database models, once you move away from that and have api models that don't match your db models (for example data that might come from redis, from calculations, or any other that does not closely match to the ORM models) then my serializers start to become complicated.",
            "One more question, did you use synchronus SQLAlchemy or AsyncSQLAlchemy for your implementation?",
            "For the benchmarks ? You can see the code sources here:\n\nhttps://github.com/TechEmpower/FrameworkBenchmarks/tree/master/frameworks/Python/fastapi\n\nThe one for the ORM test can be found here:\n\nhttps://github.com/TechEmpower/FrameworkBenchmarks/blob/master/frameworks/Python/fastapi/app_orm.py\n\nAnd as you can see, it is using the async Postgres engine and all the routes having db requests are async.\n\nThis is done again, by TechEmpowered which are experts in benchmarking web frameworks.",
            "I see, it's leveraging asyncio for Sqlalchemy. No I am questioning myself why did't I do enough research on fastapi to build my app."
        ]
    },
    "New Python-only abstractions for extracting data from apis": {
        "title": "New Python-only abstractions for extracting data from apis",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1csox31/new_pythononly_abstractions_for_extracting_data/",
        "content": "Hey there, you are probably familiar with REST APIs.    \nWe at dlt library added a new way to get data from apis (and dlt can already load it with best practice to db or parquet). We already did some internal hackathons but we would appreciate your feedback so we can improve it further  \n\\- Our new REST API Source is a short, declarative configuration driven way of creating sources.    \n\\- Our new REST API Client is a collection of Python helpers used by the above source, which you can also use as a standalone, config-free, imperative high-level abstraction for building pipelines.  \nYou can read more about the source here or go to our docs for the REST APIClient info  \nhttps://github.com/dlt-hub/verified-sources/tree/master/sources/rest\\_api  \nPS: see you at Pycon Pittsburgh!",
        "num_comments": 0,
        "comments": []
    },
    "Interactive Data Visualization with Python: A Showcase of Plotly Dash": {
        "title": "Interactive Data Visualization with Python: A Showcase of Plotly Dash",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1csjh1d/interactive_data_visualization_with_python_a/",
        "content": "**What My Project Does:**  \nI'm excited to introduce my latest project built with Python \u2013 an interactive data visualization application using Plotly Dash. This project aims to empower users to explore and analyze datasets dynamically through interactive visualizations. By leveraging Plotly Dash's capabilities, users can interact with data in real-time, customize visualizations on the fly, and gain deeper insights with just a few clicks.\n\n**Target Audience:**  \nThis project caters to a wide range of users, from data enthusiasts and analysts to professionals seeking to communicate insights effectively. Whether you're a data scientist exploring patterns in large datasets or a business analyst presenting findings to stakeholders, this tool is designed to streamline your workflow and enhance your data storytelling capabilities. It's suitable for both production-grade applications and educational purposes, offering a versatile platform for data visualization tasks of varying complexity.\n\n**Comparison:**  \nUnlike traditional static charts or cumbersome data exploration tools, this Plotly Dash application stands out for its interactivity and flexibility. While existing alternatives may offer basic charting functionalities, they often lack the dynamic capabilities required for in-depth data exploration. With Plotly Dash, users can manipulate charts in real-time, zoom in on specific data points, filter datasets dynamically, and even integrate interactive components like dropdowns and sliders for a more immersive experience. This project takes data visualization to the next level by providing a user-friendly interface coupled with powerful interactivity, setting it apart as a top choice for visualizing and analyzing datasets.\n\n**Source Code:**  \nYou can access the source code for this project on GitHub: [Interactive Data Visualization with Plotly Dash](https://github.com/yourusername/plotly-dash-interactive-viz)\n\n**Website:**  \nFor more information and to see the project in action, visit : [https://www.aspiresoftserv.com/](https://www.aspiresoftserv.com/)",
        "num_comments": 3,
        "comments": [
            "https://github.com/yourusername/plotly-dash-interactive-viz\n\n404.",
            "GitHub link not working"
        ]
    },
    "Declarative GUI Slint v1.6 released with Design Mode (WYSIWYG) Improvements": {
        "title": "Declarative GUI Slint v1.6 released with Design Mode (WYSIWYG) Improvements",
        "score": 9,
        "url": "https://www.reddit.com/r/Python/comments/1crsmbe/declarative_gui_slint_v16_released_with_design/",
        "content": "[https://slint.dev/blog/slint-1.6-released](https://slint.dev/blog/slint-1.6-released)\n\nSlint is a declarative GUI toolkit to build native user interfaces for desktop and embedded applications. Find more information at\u00a0[https://slint.dev/](https://slint.dev/)\u00a0or check out the source code at\u00a0[https://github.com/slint-ui/slint](https://github.com/slint-ui/slint/).\n\nEDIT: The Python APIs are currently in alpha. More info -- [https://github.com/slint-ui/slint/tree/master/api/python](https://github.com/slint-ui/slint/tree/master/api/python)",
        "num_comments": 2,
        "comments": [
            "This doesn\u2019t have Python bindings it would seem. Why is this here?",
            "The Python APIs are currently in alpha\n\nhttps://github.com/slint-ui/slint/tree/master/api/python"
        ]
    },
    "Implementing your own pypi clone": {
        "title": "Implementing your own pypi clone",
        "score": 31,
        "url": "https://www.reddit.com/r/Python/comments/1crksf7/implementing_your_own_pypi_clone/",
        "content": "Hi,\n\nJust want to know how difficult is it to manage your own pypi clone and how do you recommend to create a seperation between dev and prod systems.",
        "num_comments": 21,
        "comments": [
            "I mean. You can just deploy your own. The PyPI Warehouse is open source and has a readily-deployable docker image: [https://github.com/pypi/warehouse](https://github.com/pypi/warehouse)",
            "I use sonatype nexus oss for artifact storage. It operates as a python package repo for local things and a pull-through cache for pypi.org\n\nyou could create a separate repository for dev package deployment and prod package deployment if you wanted to.",
            "https://devpi.net/",
            "I am not sure whether this is what the OP wants, but I think he might be interested in hosting a local mirror of PyPi but including only the packages used by his or her apps, say in a VM or LXC in his or her cluster, or similar.\n\nShould this be the case, what would the options be? [DevPi](https://www.devpi.net/)?",
            "It can range from something very simple to very complicated and DevOps intensive. It really depends on the scale and expected usage.  \nYou can read more about the options here: https://packaging.python.org/en/latest/guides/hosting-your-own-index/ \n \nI'll note that from my personal experience setting up a private server for a medium company, having a general artifactory that supports pip protocol is a better way to go.  \n \nRegarding dev and prod, it's considered good practice to separate but there are multiple ways to do it and really depends on how you plan to build the CI/CD around it.  \nI don't use separate repositories rather rely on the package semver to indicate dev packages at various stages.",
            "If you don't mind public clouds, Google Cloud has [managed Pypi support](https://cloud.google.com/artifact-registry/docs/python/manage-packages) and it works well. The only downside is that it's a bit of a pain to associate your DNS to their internal ones. So it's essentially better for private repositories.",
            "I'd use packages from the distribution, so they are tied to the version of the distribution and that's it.",
            "Or you use Nexus containers. It you use Gitlab containers.",
            "Would nexus work for an offline pypi repo? I saw that it was caching and I thought like how do I make sure all packages are pulled as it's not obvious what I'd need before hand.",
            "Yup kind of but want to have a easily managed pypi server with separation for dev and prod environment scripts.",
            "Cool seems this might work for me let me come back once i dig deep.",
            "GitLab also has package manager support, we're using pypi and npm.",
            "AWS CodeArtifact has pypi compatibility, too.",
            "Can you elaborate on this",
            "Yes, it would work fine. Nexus has 3 types of pypi repos: locally hosted, remote (that can cache), and repo group.\n\nEach repo you create has their own url to access that repo.\n\n* locally hosted, as expected, just serves the packages there.\n* remote pulls packages from an upstream repository like pypi or whatever\n* group repo, allows you to add multiple repos and pull from them in order--first to resolve succeeds.\n\nYou may create as many repos of any kind as you like.\n\nSonatype nexus allows you to host other artifactories as well and supports some pretty advanced configurations with a relatively easy to use UI. The open source version lacks a few features but nothing that stops me. You don't have to use it but giving it a try is pretty easy to see if it works for your situation.",
            "Thanks my project uses a lot of aws so this might fit right.",
            "I did spin it up in a docker container but at least for apt I didn't see an easy way to just pull all packages from inside Nexus. I ended up having to use apt-mirror instead and I didn't get around to mirroring pypi at all. I even tried a script that would try to \"pull\" all the packages on the repo as well. After talking with someone from a different company about it I'm glad I didn't attempt to mirror all of pypi, they told me the tensorflow stuff comes in at around 20 TB *alone*. Also I wanted to ensure it was a \"drop in replacement\" (by using DNS/DHCP to fake out the domains) and Nexus didn't preserve the Release file for apt, so you'd have to provision a different key on these systems in order for them to accept the repo (which would be very unideal, time was not a luxury we had). Also I know that pypi delivers things with SSL so I guess that wouldn't have worked for that either.",
            "nexus can work as a pull-through cache that will keep the last version of whatever you pulled...but you shouldn't try to mirror all of pypi... I'm not entirely sure what you are trying to achieve so I can't really offer good advice unless you give me some more details.\n\nIf you want to mirror apt... I recommend debmirror package. It works well--you serve the mirror simply with an http server, supports rsync.",
            "I need (mostly) full mirrors for offline isolated development, we don't have access to the Internet on these systems and need to bring everything in one way essentially. So being as self sufficient as possible is a big plus for this, it helps prevent time wasted burning more CDs just to bring in a few deb files.",
            "you can make a full mirror of debian apt which is like 270 gigabytes for amd64, that's not too bad with the price of storage these days. very easy to serve and use.\n\nas for pypi? create an artifactory with a tool like pypi or sonatype nexus then get the packages you need for development on them, then survive with that.\n\nIf you truly have no internet and need to sneakernet your data in, that can be a pain--but if you're worried about intermittent outages, a pull-through cache would be really good",
            ">If you truly have no internet and need to sneakernet your data in, that can be a pain\n\n\nThat's exactly the scenario, hence why I chose this route\u00a0"
        ]
    },
    "Manage Your Squid Proxy Server Efficiently with This Python Script": {
        "title": "Manage Your Squid Proxy Server Efficiently with This Python Script",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1crzgrr/manage_your_squid_proxy_server_efficiently_with/",
        "content": "### \ud83e\udd91 Squid Proxy Manager Script\n\nHello fellow Python enthusiasts!\n\nI've created a Python script that makes managing your Squid Proxy Server a breeze. If you're looking for an efficient and straightforward way to interact with your Squid server remotely, this script is for you. \ud83c\udf89\n\n---\n\n### What My Project Does\n\nThe Squid Proxy Manager script allows you to manage your Squid Proxy Server remotely using a simple command-line interface. Here are some of the key features:\n\n- **Check Squid Service Status**: Quickly check if your Squid service is running or not.\n- **Start/Stop/Restart Service**: Easily control the Squid service remotely.\n- **View Logs**: Access the latest entries in your Squid access logs.\n- **View Configuration**: Display the current Squid configuration file.\n- **Update Configuration**: Replace the existing Squid configuration with a new one.\n- **Reload Service**: Reload the Squid service to apply changes without restarting.\n\n---\n\n### Target Audience\n\nThis script is designed for anyone who manages a Squid Proxy Server and prefers a command-line tool for remote management. If you are comfortable using Python and SSH, this tool will streamline your workflow and enhance your productivity.\n\n---\n\n### Differences\n\nHere are some aspects that make this Squid Proxy Manager script stand out:\n\n- **Remote Management**: Manage your Squid server without needing physical access, thanks to SSH connectivity.\n- **Ease of Use**: The script provides a simple and intuitive command-line interface, making it easy to perform various tasks.\n- **Comprehensive Features**: From checking service status to updating configurations and viewing logs, this script covers all essential Squid management tasks.\n- **Error Handling and Logging**: Detailed logging and error handling ensure you know exactly what's happening and can troubleshoot issues effectively.\n\n---\n\n### \ud83d\ude80 Usage\n\n1. **Installation**:\n   - Ensure you have the required libraries installed:\n     ```bash\n     pip install paramiko termcolor\n     ```\n\n2. **Running the Script**:\n   - Use the script with appropriate arguments to manage your Squid Proxy Server. Here's an example command to check the Squid service status:\n     ```bash\n     ./squid_proxy_manager.py 192.168.2.111 22 username password --check-status\n     ```\n\n3. **Updating Configuration**:\n   - Create a new configuration file (e.g., `new_squid.conf`) with your desired settings.\n   - Run the script to update the Squid configuration:\n     ```bash\n     ./squid_proxy_manager.py 192.168.2.111 22 username password --update-config new_squid.conf\n     ```\n\n---\n\n### \ud83d\udcbb Script Example\n\nHere's a snippet of the script to give you an idea of its simplicity and functionality:\n\n```python\n#!/usr/bin/env python3\n\nimport paramiko\nimport argparse\nimport logging\nimport sys\nimport os\nfrom termcolor import colored\n\nclass SquidProxyManager:\n    def __init__(self, hostname, port, username, password):\n        self.hostname = hostname\n        self.port = port\n        self.username = username\n        self.password = password\n        self.client = paramiko.SSHClient()\n        self.client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n\n    def connect(self):\n        try:\n            logging.info(colored(\"Attempting to connect to {}:{}\".format(self.hostname, self.port), 'cyan'))\n            self.client.connect(self.hostname, port=self.port, username=self.username, password=self.password)\n            logging.info(colored(f\"Connected to {self.hostname} on port {self.port}\", 'green'))\n        except Exception as e:\n            logging.error(colored(f\"Failed to connect: {e}\", 'red'))\n            sys.exit(1)\n\n    def disconnect(self):\n        self.client.close()\n        logging.info(colored(\"Disconnected from the server\", 'green'))\n\n    def execute_command(self, command):\n        logging.info(colored(\"Executing command: {}\".format(command), 'cyan'))\n        try:\n            stdin, stdout, stderr = self.client.exec_command(command)\n            stdout.channel.recv_exit_status()\n            out = stdout.read().decode()\n            err = stderr.read().decode()\n            if err:\n                logging.error(colored(f\"Error executing command '{command}': {err}\", 'red'))\n            else:\n                logging.info(colored(f\"Successfully executed command '{command}'\", 'green'))\n            return out, err\n        except Exception as e:\n            logging.error(colored(f\"Exception during command execution '{command}': {e}\", 'red'))\n            return \"\", str(e)\n\n    # More functions here...\n\ndef parse_args():\n    parser = argparse.ArgumentParser(description=\"Squid Proxy Manager\")\n    parser.add_argument('hostname', help=\"IP address of the Squid proxy server\")\n    parser.add_argument('port', type=int, help=\"Port number for SSH connection\")\n    parser.add_argument('username', help=\"SSH username\")\n    parser.add_argument('password', help=\"SSH password\")\n    parser.add_argument('--check-status', action='store_true', help=\"Check Squid service status\")\n    parser.add.add_argument('--start', action='store_true', help=\"Start Squid service\")\n    parser.add.add_argument('--stop', action='store_true', help=\"Stop Squid service\")\n    parser.add.add_argument('--restart', action='store_true', help=\"Restart Squid service\")\n    parser.add.add_argument('--view-logs', action='store_true', help=\"View Squid logs\")\n    parser.add.add_argument('--view-config', action='store_true', help=\"View Squid configuration\")\n    parser.add.add_argument('--update-config', help=\"Update Squid configuration with provided data\")\n    parser.add.add_argument('--reload', action='store_true', help=\"Reload Squid service\")\n    return parser.parse_args()\n\ndef main():\n    logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n    args = parse_args()\n    logging.info(colored(\"Initializing Squid Proxy Manager script\", 'cyan'))\n\n    manager = SquidProxyManager(args.hostname, args.port, args.username, args.password)\n    manager.connect()\n\n    try:\n        if args.check_status:\n            manager.check_squid_status()\n        if args.start:\n            manager.start_squid()\n        if args.stop:\n            manager.stop_squid()\n        if args.restart:\n            manager.restart_squid()\n        if args.view_logs:\n            manager.view_squid_logs()\n        if args.view_config:\n            manager.view_squid_config()\n        if args.update_config:\n            if not args.update_config.endswith('.conf'):\n                logging.error(colored(\"The provided file must have a .conf extension\", 'red'))\n            elif not os.path.isfile(args.update_config):\n                logging.error(colored(f\"Configuration file {args.update_config} not found\", 'red'))\n            else:\n                try:\n                    with open(args.update_config, 'r') as config_file:\n                        config_data = config_file.read()\n                    manager.update_squid_config(config_data)\n                except Exception as e:\n                    logging.error(colored(f\"Error reading configuration file {args.update_config}: {e}\", 'red'))\n        if args.reload:\n            manager.reload_squid()\n    finally:\n        manager.disconnect()\n        logging.info(colored(\"Squid Proxy Manager operations completed\", 'green'))\n\nif __name__ == \"__main__\":\n    main()\n```\n\n---\n\n### \ud83c\udf1f Benefits\n\n- **Remote Management**: No need to be physically present to manage your Squid server.\n- **Ease of Use**: Simple command-line interface for quick operations.\n- **Versatility**: Supports various Squid management tasks, from checking status to updating configurations and viewing logs.\n\n---\n\n### \ud83d\udce2 Get Involved!\n\nIf you find this script useful, feel free to give it a try and share your feedback. Contributions and suggestions are always welcome! Comments however, that are unhelpful and serve no purpose to better the script or the author in their python scripting abilities are not welcome! Keep the nasty to yourself.\n\n### Access the script\n\nYou can find the script [here](https://github.com/slyfox1186/script-repo/blob/main/Python3/Networking/squid_proxy_manager.py) on GitHub.\n\nHappy coding! \ud83d\ude80",
        "num_comments": 0,
        "comments": []
    },
    "modern_colorthief - Modified Median Cut Quantization algorithm in rust + python": {
        "title": "modern_colorthief - Modified Median Cut Quantization algorithm in rust + python",
        "score": 5,
        "url": "https://www.reddit.com/r/Python/comments/1crouri/modern_colorthief_modified_median_cut/",
        "content": "* [github](https://github.com/baseplate-admin/modern_colorthief)\n* [documentation](https://modern-colorthief.readthedocs.io/en/latest/)\n\n## What my project does :\n\nIt gets the dominant color/color palette from given image.\n\n\n## Target Audience:\n\nAnyone\n\n## Usage\n\nmodern_colorthief exposes two functions get_color and get_palette\n\nHere is how to use get_color:\n\n```python\nfrom modern_colorthief import get_color\n\n# Path to any image\npath = ...\n\nprint(get_color(path)) # returns tuple[int,int,int]\n```\n\n\nHere is how to use get_palette:\n\n```python\nfrom modern_colorthief import get_color\n\n# Path to any image\npath = ...\n\nprint(get_palette(path)) # returns list[tuple[int,int,int]]\n```\n\n\n\n# Goals:\n\n- Bring [color-thief-rs](https://github.com/RazrFalcon/color-thief-rs/) to python\n\n# Benchmarks:\n\n[Written in deatils](https://modern-colorthief.readthedocs.io/en/latest/benchmarks.html)\n\nGist:\n\n```python\nPython Took:            0.09976800000004005\nCPP Took:               0.008461299999908078\nRUST Took:              0.008549499994842336\n\n\nPython Took:            0.0960583999985829\nCPP Took:               0.008564600000681821\nRUST Took:              0.007692700004554354\n```\n\n\n\n# Differences\n\n## With fast-colorthief\n\n-   Supports more architectures. ( pybind11 vs pyo3 )\n-   Doesn't have a hard dependency on numpy\n-   Code is simple compared to fast-colorthief's CPP codebase\n-   Automated tooling powered by maturin and github-actions\n-   The size of fast-colorthief is 52kb-60kb.\n\n## With color-thief-py\n\n-   Superior execution time (nearly 100x)\n-   Doesn't have a hard dependency on pillow\n-   color-thief's codebase is not in par with modern python versions\n\n\nIf you like this project please star this [repository](https://github.com/baseplate-admin/modern_colorthief)",
        "num_comments": 5,
        "comments": [
            "What architectures are supported in pybind11 that aren\u2019t in pyo3? Genuinely curious, as I\u2019m working on a (very different) project using pyo3",
            "great job! what does the quality parameter do?",
            "I apologise for the confusion. I meant the other way around. PyO3 supports more architectures(for example powerpc).",
            "Hi thanks for checking it out. Quoting ColorThief's [documentation](https://lokeshdhakar.com/projects/color-thief/#api)\n\n\n> quality is an optional argument that must be an Integer of value 1 or greater, and defaults to 10. The number determines how many pixels are skipped before the next one is sampled. We rarely need to sample every single pixel in the image to get good results. The bigger the number, the faster a value will be returned.",
            "Oh okay that\u2019s what I thought!"
        ]
    },
    "Frame - a new language for programming state machines in Python": {
        "title": "Frame - a new language for programming state machines in Python",
        "score": 92,
        "url": "https://www.reddit.com/r/Python/comments/1cqoyuq/frame_a_new_language_for_programming_state/",
        "content": "Hey,\n\nI am (re)releasing a project called Frame that I've been working on to create a language and transpiler to easily create state machines/automata in Python. It also is able to generate UML documentation as well.\n\nThis project is for people who are interested in programming state machines for a wide range of purposes such as game programming, workflows, MBSE modeling as well as school projects for comp sci theory. It is also useful simply for generating flow documentation. \n\nThe Framepiler (Frame transpiler) is in beta at this time. It would be great to get feedback from the Python community on any gaps in key functionality or bugs. \n\nLow-code/no-code workflow tools are often problematic for creating state machine like flows. Frame is intended to give a textual way to accomplish the same thing, but without having to \"draw\" your software and with the ability to use all the standard devops tooling and processes for \"normal\" development processes. \n\nThere is also a [VSCode extension](https://marketplace.visualstudio.com/items?itemName=frame-lang-org.frame-machine-maker) and a [playground environment](https://playground.frame-lang.org/) to experiment in. \n\nVery much hoping to connect with people who might find this interesting and useful. If that is you, please take a look at the\u00a0[Overview](https://docs.frame-lang.org/en/latest/)\u00a0and the\u00a0[Getting Started](https://docs.frame-lang.org/en/latest/about/introduction.html)\u00a0articles. Here is a link to the\u00a0[GitHub Framepiler Project](https://github.com/frame-lang/frame_transpiler)\u00a0as well.\n\nPlease LMK if you have any questions or interest in the project.\n\nThanks!\n\nMark",
        "num_comments": 34,
        "comments": [
            "I think this project could do with a serious think about the [strangeness budget](https://steveklabnik.com/writing/the-language-strangeness-budget) of the language.\n\nEverything you do that is unlike anything else people know will make it harder to learn and less likely for people to adopt. You should only change things when they provide a clear benefit. I think you've fallen down the trap of \"short sigils for special things are better than keywords\". Rust did this too originally, but then it got rid of them (`~T` became `Box<T>`/`Vec<T>`/`String` and `@T` became `Rc<T>/Arc<T>`) and it made the language easier to learn. Generally people will be able to parse what looks like English much faster.\n\nThere are just too many example of weird sigils and strange syntax:\n\n* Using `|>|`/`|<|` for enter/exit and `^` for return are bad ideas, it makes the language unreadable for beginners. I'd use keywords `enter, exit, return`. \n* The boolean expressions... why not just use the tried and tested `if/else if/else`? `x ?! f[] :> g[] : h[] :|` wut?\n* Using `-block-`. This is very strange to me, I'd use something like `block:` from c++ or `impl block { ... }` from rust . Do you even need these blocks?\n* In the `machine` block, how are the event handlers delimited? whitespace? Tokens? It's not clear at all. \n* `var x:# = #MySystem()` rather than `var x: Frame = #MySystem()`. On this subject, IMO it's much easier to parse `var x: t` rather than `var x:T`.\n* Using backticks in your language pretty much always sucks because people will be writing about it in markdown and you'll accidentally escape things. I'm not sure what you could replace it with, my first thought is what other template languages use `{ ... }` or `{{ ... }}`.\n* `[...]` for parameter specs and subroutine calls. Why? Pretty much every other language use `f(x, y, z)` or `f x y z`.\n* Using # and ## to delimit systems... Why not `system #MySystem { ... }`?\n* Allowing target language expressions outside of template blocks (\"superstrings\") seems like a really bad idea.\n* Using `~/.../` and `#/.../` sigils to mark match expressions for strings and numbers respectively. Why? Again keywords are clearer.\n* Basically everything to do with the [state parameters](https://docs.frame-lang.org/en/latest/intermediate_frame/states.html#state-parameters) is confusing and messy and full of strange sigils.\n\nTLDR you've blown through your strangeness budget very quickly and I don't think you need to! The use of N different syntaxes in the N blocks (including main) is inherently confusing. I'd try and unify them in some way. Currently it looks like you're writing N different languages mushed together.\n\nMy other complaint is one generally leveraged at go: why have you ignored all programming language design from the last half century?\n\n* `loop var x = 0; x < 5; x = x + 1`. Come on guys, don't go back to C. `loop x in list` is so much more powerful. Provide `range` and iterator combinators.\n* `enum`s (noticed how you decided to at least use a keyword to define these) don't hold any data. Sum types / ADTs have been a feature of every major language (minus go) for the last 15 years. I'd especially expect a DSL for state machines of all things to support them.\n* Uninitialized variables as null. Do we need to persiste the [billion dollar mistake](https://www.infoq.com/presentations/Null-References-The-Billion-Dollar-Mistake-Tony-Hoare/)? You should be forced to explicitly initialize everything, and if they are typed, they cannot be null. Introduce an `Option` sum type for that.\n* Why do you support lists but no other common data types like maps and sets? I'm not sure what the point is to be honest since you just hand off processing to the target language anyway.",
            "I think your overview page would massively benefit from some code snippets - I like the sound of the project but I was hoping for some quick examples of what it looks like. DSLs can be complicated so it'd be nice to get a quick feel for how hard it'll be to learn!",
            "I've spent a lot of time with UML, SysML, Python, and JavaScript. I went through the Georgia tech masters in systems engineering program, with a big focus on MBSE.\n\nI get the desire to manage state machines in code, but I think early on, it is useful to start visually first and translate that to code to get started with. A great example of this on the JavaScript side is [xstate](https://xstate.js.org/docs/).\n\nThe other aspect I noticed when looking at your playground is the language used to define the state machines is so different than python, that I'd worry about whether you are gaining much by managing it this way.\n\nOverall, really neat concept and I think state machines are super useful, but if working in Python I'd want something more aligned with the language I'm working in.",
            "I would love to see real use cases/examples where it can be used.    \nThanks.",
            "Looks interesting but I don\u2019t understand it enough to see where it would be useful. Anyone want to give an example of where state machines shine compared to traditional paradigms?",
            "I've used state machines a good bit (for DTD validation in the xmlproc parser, for example), but I don't really know what I'd use this for.\n\nYou may want to change \"Alan Turning\" to \"Alan Turing\". Also, please don't link to that movie for information. It's not very informative and not very accurate. [Andrew Hodges's biography](https://www.turing.org.uk/book/) is much better. (Turing didn't invent state automata, which came later, but I'm sure you know that. Since he did the first automata I guess the claim is fair enough.)",
            "This is some great work. I don't really some great applications here, but still will compliment this great piece of work.",
            "What does this offer that the transitions package doesn't?",
            "Have you ever looked into [Amazon States Language](https://states-language.net/spec.html)?\n\nIt is a JSON-based language used to describe state machines declaratively.",
            "You have a typo on the docs page, it says progarmming language",
            "Looks really interesting. I\u2019m going to follow you.\n\nI found the syntax for the state machines themselves to be intuitive and great way of visualising what a state machine is. The other syntax (functions, control flow, variables) didn\u2019t seem like it would be too hard to get the hang of but it doesn\u2019t look as beautifully organic as the state machine syntax, especially coming from Python where I\u2019m a bit grossed out by the use of braces as function deljmters and by C-style for loops.",
            ">feedback\n\nI know what a state machine is, but I am too stupid for what you have created. Idk if that helps?",
            "Hello and thank you for your thoughtful feedback - very much appreciated! Frame's major goal is to find a way to make creating automata based systems easy to create and use in any project. In the past I supported other language targets than Python and hope to again in the nearish future. \n\nAs for the details of the syntax, I am not very wedded to any of my particular choices at this point. Overall I tried to make it compact and easy to understand but recognize it is novel in many ways and runs risks in that regard. Feedback like yours I consider very valuable so thank you.\n\nAs this is only the beginning and I am only one person working nights and weekends to put this out there am trying to focus on the differentiators from all the other languages first to add value there initially. I certainly hope to improve on all the things Frame doesn't yet do over time.   \n\n  \nBest,\n\nMark",
            "And also some examples of how you can use the output. Hard to see where the benefit is otherwise.",
            "Thanks for the feedback. xState is definitely an interesting project and in the spirit of Frame. As for visually designing software, I completely agree in its utility - I just don't like actually creating the drawings as I found I spent a lot of time trying to lay them out rather than code. In contrast Frame generates the UML from the system design, so I'm hoping people view that as easier. \n\nAlso I do intend to expand the number of generated languages in the future. \n\nThanks.",
            "Please have a look at the linked articles and the repo for some ideas about utility: https://docs.frame-lang.org/en/latest/about/introduction.html.",
            "regex and other pattern matching engines are implemented using a state machine",
            "Gaming AI heavily uses state machines.",
            "Industrial automation (like PLC) and such often use states and next state transitions, not always fully a state machine but related. Could probably be used to replicate or simulate automation tasks in python for testing or visualisation",
            "We used state machines in a previous job to control a physical workflow (like turn on machine, operate machine, display results, eject cartridge, etc.). This could all be programmed manually without a state machine, but it would be less flexible and would need to be carefully managed to avoid unknown or undefined states/transitions.",
            "Thanks for taking a look! I've added some content to my documentation under the \"Solution Depot\" and \"Articles\" section that might give some ideas. I'm continuing to build that out so very open to any suggestions about what domains might be of interest to add an article or example about. \n\n[https://docs.frame-lang.org/en/latest/about/introduction.html](https://docs.frame-lang.org/en/latest/about/introduction.html)",
            "Back in the days when I worked on process control systems (i.e. automated soft drink bottling plants, dairies - anything that had lots of liquid moving through a maze of pipes) we used state machines to model the system. This turned 1000s of lines of code to 100s.",
            "non-blocking I/O",
            "OMG. Thanks for the spelling correction. I can't imagine why autocorrect didn't catch that lol!",
            "Thank you!",
            "I'm also interested in a comparison with what I'm most familiar with, pytransitions. \n\nWhat does Frame do differently that sets it apart from pytransitions?\n\nFor example, I don't think they support any UML diagramming, just visual state machine generation.",
            "Hello,\n\nI have, but not to a great depth. Frame was actually inspired by my own attempt to build a statechart drawing tool. In the process of writing the serialization code I realized that all the value was in the xml I was generating and not in the visual editing of the software. While the diagrams are extremely useful, they aren't an easy way to actually create software.\n\nThe States Langauge, xState and Google Workflows languages all use a data language to express state machines which was something I didn't like about the xml I created. So I decided to create a language that hopefully was more syntactically elegant than xml, yaml or json. \n\nWe'll see if anyone else agrees I succeeded :) \n\nThanks for your interest!",
            "Oh man - thanks! Fixed lol.",
            "Thanks for the interest! This is really alpha software so I'm very open to finding syntax that people like - its not that hard to change at this point. Please send any suggestions - I'm logging them: https://github.com/frame-lang/frame\\_transpiler/issues/238.",
            "I know Frame is a very different kind of language and probably pretty specialized for right now. You might take a look at this article for a step-by-step example of how to create a running model using Frame: https://medium.com/p/4ae605f9a040. \n\nThanks",
            "Yeah I get what you're trying to do. Hopefully it didn't come across as too harsh. Programming Language design is a passion of mine so I like to see it done well \ud83d\ude42\n\nSyntax may not be important from your perspective and seem trivial (and plus you will inherently understand it!), but it really does matter. In fact I'd argue it's the most important thing to start with because you can always add features but changing syntax is nightmare. Just look at python 2 to 3. And what is a language if not syntax?\n\nRead the article I linked, hopefully it will be persuasive and informative.",
            "Thanks for the feedback. I'll see what I can do to make that more prominent. For the moment here is an intro article I wrote that might help: [https://mark-truluck.medium.com/modeling-a-lamp-finite-state-machine-in-frame-4ae605f9a040](https://mark-truluck.medium.com/modeling-a-lamp-finite-state-machine-in-frame-4ae605f9a040)\n\nFor a rather eclectic assortment of examples please check out this repo: [https://github.com/frame-lang/frame\\_solution\\_depot](https://github.com/frame-lang/frame_solution_depot)",
            "Unfortunately I am not familiar with that library. I took a quick look and can give a couple of assessments.\n\nWhile it looks pretty powerful, it is, I believe, strictly for Python. Frame is intended (and had been in the past) to generate other languages as well. Not sure if there is a port of this library but if not that would be a key difference.\n\nAs you mentioned, the UML generation is a key differentiator. Using the VSCode extension or playground you can visually code while not having to mess around with layout issues. \n\nI have also added the ability to pass parameters to states directly as well as through the transitions themselves. Not sure if that is part of the library but I'll take a closer look. It seems they may have some interesting ideas about transitions that might be useful. \n\nI would lastly say it looks like the package uses data structures to model the state machines. Frame's syntax hopefully feels like a more natural expression of the concepts involved with automata. Not sure if that has been successful, but certainly it is one of the goals.\n\nThanks for the question and the tip about transitions."
        ]
    },
    "SQLPage - a Python library to add string token based pagination easily": {
        "title": "SQLPage - a Python library to add string token based pagination easily",
        "score": 11,
        "url": "https://www.reddit.com/r/Python/comments/1cqzf6o/sqlpage_a_python_library_to_add_string_token/",
        "content": "**What My Project Does  -** This is a Python package to easily add string token based pagination. Currently it supports SQLModel and SQLAlchemy ORMs.\n\nRecently I wanted to add pagination in one of my Python projects and in the API response, I had to return a string next page token. Now I could not find a straight-forward way of doing this in Python. All of the tutorials or blog posts I saw, there in the response the server always returned a `page_number`, `page_size`, and `total_elements` and then the onus was on the calling service to adjust this accordingly.\u00a0\n\n**Comparison -** The current packages and methods requires some changes in the app layer as well. I tried using a few but those did not satisfy the use case and were also a bit harder to implement. I could not find a easy to use option. The present ones returned integers instead of a string token\n\nI wanted it to be simpler, just like OpenSearch - you call its search API and it returns 10 elements and a `next_page_token` and then for the next 10 (or you configure this using the `size` parameter) you use the `next_page_token` in the subsequent request to get to the new page.\n\nI ended up doing a lot of if-else checks and encoding and decoding, so I decided to create this library.\n\n**Target Audience -** This is production ready, have been using it in one of my projects. Hope some of you folks find it useful :)\n\nHere is the link to the [PyPi repository](https://pypi.org/project/sqlpage/) and here is the [GitHub repo](https://github.com/prabhupant/sqlpage)",
        "num_comments": 3,
        "comments": [
            "If you know total and page size you can generate start to end pagination. With only next page you can't so it's somewhat different.\n\nIf the endpoint uses some more complex query then the count function could be expensive and \"next page\" only approach would be faster but IMHO that would be done on endpoint layer when returning different metadata.\n\nIn your code you are hiding the count behind a proxy model and not exposing all the metadata? That's bit weird as it would combine disadvantages of both solutions. Also your tests need some work - you should use assertions, proper test cases, probably also FactoryBoy to create require data in the database.",
            "Thanks for the feedback, appreciate it! Yes, I got to work on the test. Right now the \"test\" is just a script to test if the code was working.\n\nI am planning to add other details like totalElements, currentPage in the PageData object shortly.\n\nAlso, if the count query is expensive, is there any other way to optimise this? Because, I think, without knowing the total elements, we might not be able to do the calculation needed for pagination. And I was looking at Spring Boot's JPA and it also does a count operation",
            "If the pagination can't or doesn't want to do the count then only \"local\" navigation is possible where if given offset still returns the results limit you assume there is a next page.\n\nalso for Python no camel case for attributes on a pagination object."
        ]
    },
    "UXsim 1.3.0 released with vehicle tracking and improved vehicle routing": {
        "title": "UXsim 1.3.0 released with vehicle tracking and improved vehicle routing",
        "score": 19,
        "url": "https://www.reddit.com/r/Python/comments/1cqstyd/uxsim_130_released_with_vehicle_tracking_and/",
        "content": "**Main Changes**\n\n* Add GUI functions\n   * Vehicle tracking: You can now track a specific vehicle to see their route\n   * Dataframe viewer: Stats can be confirmed\n* Improve vehicle routing functions\n   * Add\u00a0[example of routing optimization](https://github.com/toruseo/UXsim/blob/main/demos_and_examples/demo_notebook_07en_optimal_routing.ipynb)\n* Change\u00a0[documentation](https://toruseo.jp/UXsim/docs/_autosummary/uxsim.analyzer.Analyzer.html#uxsim.analyzer.Analyzer.link_cumulative_to_pandas)'s theme for better indexing\n\n**UXsim**\n\n[UXsim](https://github.com/toruseo/UXsim)\u00a0is a free, open-source macroscopic and mesoscopic network traffic flow simulator written in Python. It simulates the movements of car travelers and traffic congestion in road networks. It is suitable for simulating large-scale (e.g., city-scale) traffic phenomena. UXsim is especially useful for scientific and educational purposes because of its simple, lightweight, and customizable features, but users are free to use UXsim for any purpose.",
        "num_comments": 0,
        "comments": []
    },
    "Resume Screening Chatbot using RAG Fusion": {
        "title": "Resume Screening Chatbot using RAG Fusion",
        "score": 5,
        "url": "https://www.reddit.com/r/Python/comments/1cqwcap/resume_screening_chatbot_using_rag_fusion/",
        "content": "Hi everyone!\n\nI recently finished a small side project for my graduating thesis, which is about experimenting with RAG-based frameworks in improving resume screening.\n\n**What my project does:**\n\nThe project for the thesis is a GPT-4 Chatbot with RAG Fusion retrieval. Given a job description as input, the system retrieves the most relevant candidate profiles to perform follow-up tasks such as analysis, summarization, and decision-making, which can assist the screening process better.\n\nThe revolving idea is that the similarity-based retrieval process can effectively narrow the initial large pool of applicants down to the most relevant resumes. However, this simple similarity ranking should not be used to evaluate a candidate's actual ability. Therefore, the top resumes are used to augment the GPT-4 Chatbot so it can be conditioned on these profiles and perform further downstream tasks.\n\n**Target audience:**\n\nThe repo contains the link to my paper and the notebooks that were used to design the prototype program and conduct some experiments. For the newcomers to RAG/RAG Fusion, or people who are just interested in building a RAG-based chatbots, this can be especially helpful. Feel free to check them out too!\n\n**Comparison:**\n\nI'm not sure if there's any similar project out there, but the program is sort of designed to move the resume screening process away from existing keyword-based methods. It's much more versatile in use cases and also more effective in handling resumes.\n\nThe project is very far from being perfect. Because of that, I share this with the hope to receive suggestions and feedback from you. If you have time, please give the project a visit here: [GitHub](https://github.com/Hungreeee/Resume-Screening-RAG-Pipeline)",
        "num_comments": 2,
        "comments": [
            "Cool. I had a similar idea, but from the perspective of a job seeker. I made a RAG app that used the set of all the resumes I had created (I was making adjustments to my resume to tailor it to specific jobs), and I fed it job postings to rank the jobs based on my skill set.\n\nI found I got better results when I supplied smaller sections of job descriptions, which got me thinking about how to split up the text. I decided to try training a topic model on the collection of job ads I\u2019d scraped, and then split up new job ads based on the dominant topic of each sentence in the ad.\n\nThis led to better results but I abandoned the project when I realized that in reality, resumes are a terrible thing to optimize as it has always been my professional network that has been the source of any new job.",
            "What\u2019s RAG Fusion?"
        ]
    },
    "Giving New Life to JModelica: Bringing Powerful Modelica Simulations to Python": {
        "title": "Giving New Life to JModelica: Bringing Powerful Modelica Simulations to Python",
        "score": 3,
        "url": "https://www.reddit.com/r/Python/comments/1cqvyyf/giving_new_life_to_jmodelica_bringing_powerful/",
        "content": "Five years ago, I [posted](https://www.reddit.com/r/Python/comments/dcj6fy/jmodelica_combining_the_power_of_python_and/?utm_source=share&utm_medium=web3x&utm_name=web3xcss&utm_term=1&utm_content=share_button) about JModelica, a fantastic open-source tool for simulating complex systems that combined the ease of Python with the strength of Modelica. \n\nSadly, the project went quiet, but I'm thrilled to share that, thanks to the dedication of a few folks (myself included!), JModelica is back! You can find the revived project on GitHub: https://github.com/JModelica/JModelica.\n\n## What JModelica Does:\n\nJModelica provides a way to write complex simulations using the Modelica language, which is known for its ability to handle differential equations and model physical systems beautifully. The magic of JModelica lies in its Python integration\u2014you can solve your Modelica models and access the results directly in Python for in-depth analysis, visualization, and even optimization using libraries you already love!\n\n## Target Audience:\n\nThis project is geared toward anyone interested in modeling and simulating complex systems, particularly those with a background in engineering, physics, or related fields. If you've struggled with Python's ODE solvers or wish for a more elegant way to model physical interactions, JModelica offers a compelling solution. It's ready for research, educational projects, and even more ambitious endeavors!\n\n## Comparison:\n\nJModelica stands alongside OpenModelica as a champion of open-source Modelica tools. While OpenModelica is known for its user-friendly graphical interface, JModelica shines in its seamless integration with Python, giving you the best of both worlds! It's a powerful alternative to proprietary software like Simulink, providing transparency, flexibility, and a thriving community.\n\nWe're actively working on squashing bugs, adding features, and making JModelica more accessible across different platforms (Windows and macOS support are on the horizon!).\n\nAnyone interested in contributing is welcome! Whether you're a Modelica expert or a curious newcomer, this project has a place for you. Check out the [GitHub repository](https://github.com/JModelica/JModelica) to explore the code, open issues, or submit pull requests.",
        "num_comments": 2,
        "comments": [
            "Look forward to hearing good news"
        ]
    },
    "CLI to embed code snippets in your README, from actual (testable) code": {
        "title": "CLI to embed code snippets in your README, from actual (testable) code",
        "score": 10,
        "url": "https://www.reddit.com/r/Python/comments/1cqlvgt/cli_to_embed_code_snippets_in_your_readme_from/",
        "content": "## What My Project Does\n\n**What My Project Does:** **[snipinator](https://github.com/realazthat/snipinator)** is a CLI to embed (testable) snippets from your codebase into your README, using Jinja2 and functions provided by snipinator to assist with embedding code, shell output, etc.\n\nPlease provide any feedback in the comments or GH issues.\n\n## Target Audience\n\n**Target Audience:** Developers of {GitHub,other} projects that have a README. It works for me, it might work for you.\n\n## Comparison\n\n**Features:**\n\n* Supports anything [**Jinja2**](https://github.com/pallets/jinja) supports.\n* First-class support for **python** source code.\n  * Can include python function signatures, docstrings, entire function source code, classes.\n* Snip from **any source code language**.\n  * Put delimiter markers into the code (e.g `# START_SNIPPET`, `# END_TEMPLATE`), and use [snippet()](https://github.com/realazthat/snipinator#snippet).\n* First-class support for **Markdown** templates (with `backtickify`, `decomentify`).\n* Can include [**shell**](https://github.com/realazthat/snipinator#shell) **output**.\n  * Supports ANSI colors with SVG output.\n* More robust **references/links** to local files using [path()](https://github.com/realazthat/snipinator#path).\n\nI keep a table of similar projects in my README at [realazthat/snipinator: Related Projects](https://github.com/realazthat/snipinator/#-related-projects).\n\nNot complete, and not necessarily up to date. Make a PR\nto [README.md.jinja](https://github.com/realazthat/snipinator/blob/develop/README.md.jinja2), (see [realazthat/snipinator/Contributions](https://github.com/realazthat/snipinator#commit-process)) to insert/modify the table.\n\n| Project                                                           | Stars     | Last Update  | Language   | Platform         | Similarity X Obviousness |\n| ----------------------------------------------------------------- | --------- | ------------ | ---------- | ---------------- | ------------------------ |\n| [mdx-js/mdx][24]                                                  | 16.8k     | `2024/04/17` | JS         | N/A              | \u2b50\u2b50\u2b50\u2b50\u2b50               |\n| [zakhenry/embedme][25]                                            | 222       | `2023/11/08` | JS         | N/A              | \u2b50\u2b50\u2b50\u2b50\u2b50               |\n| [cmacmackin/markdown-include][26]                                 | 95        | `2023/02/07` | Python     | N/A              | \u2b50\u2b50\u2b50\u2b50\u2b50               |\n| [BurdetteLamar/markdown_helper][27]                               | 38        | `2020/03/16` | Ruby       | N/A              | \u2b50\u2b50\u2b50\u2b50\u2b50               |\n| [SimonCropp/MarkdownSnippets][28]                                 | 23        | `2024/04/23` | .NET       | N/A              | \u2b50\u2b50\u2b50\u2b50\u2b50               |\n| [endocode/snippetextractor][29]                                   | 4         | `2014/08/16` | C++        | N/A              | \u2b50\u2b50\u2b50\u2b50\u2b50               |\n| [polywrap/doc-snippets][30]                                       | 3         | `2023/09/26` | JS         | N/A              | \u2b50\u2b50\u2b50\u2b50\u2b50               |\n| [JulianCataldo/remark-embed][31]                                  | 2         | `2022/09/22` | JS         | N/A              | \u2b50\u2b50\u2b50\u2b50\u2b50               |\n| [xrd/oreilly-snippets][32]                                        | 2         | `2015/10/15` | Ruby       | N/A              | \u2b50\u2b50\u2b50\u2b50\u2b50               |\n| [DamonOehlman/injectcode][33]                                     | 1         | `2021/08/01` | JS         | N/A              | \u2b50\u2b50\u2b50\u2b50\u2b50               |\n| [electrovir/markdown-code-example-inserter][34]                   | 1         | `2024/02/19` | JS         | N/A              | \u2b50\u2b50\u2b50\u2b50\u2b50               |\n| [andersfischernielsen/Simple-Embedded-Markdown-Code-Snippets][35] | 1         | `2021/02/12` | JS         | N/A              | \u2b50\u2b50\u2b50\u2b50\u2b50               |\n| [ildar-shaimordanov/git-markdown-snippet][36]                     | 0         | `2021/09/14` | Perl       | N/A              | \u2b50\u2b50\u2b50\u2b50\u2b50               |\n| [teyc/markdown-snippet][37]                                       | 0         | `2024/01/22` | Powershell | N/A              | \u2b50\u2b50\u2b50\u2b50\u2b50               |\n| [marc-bouvier-graveyard/baldir_markdown][38]                      | 0         | `2020/06/15` | Python     | N/A              | \u2b50\u2b50\u2b50\u2b50\u2b50               |\n| [dineshsonachalam/markdown-autodocs][39]                          | 176       | `2022/09/19` | JS         | GH Action        | \u2b50\u2b50\u2b50\u2b50                 |\n| [tokusumi/markdown-embed-code][40]                                | 28        | `2022/01/05` | Python     | GH Action        | \u2b50\u2b50\u2b50\u2b50                 |\n| [sammndhr/gridsome-remark-embed-snippet][41]                      | 2         | `2021/06/14` | JS         | [Gridsome][42]   | \u2b50\u2b50\u2b50\u2b50                 |\n| [NativeScript/markdown-snippet-injector][43]                      | 4         | `2019/01/24` | JS         | N/A              | \u2b50\u2b50\u2b50\u2b50                 |\n| [fuxingloh/remark-code-import-replace][44]                        | 0         | `2022/12/21` | JS         | Remark?          | \u2b50\u2b50\u2b50\u2b50                 |\n| [szkiba/mdcode][45]                                               | 15        | `2014/02/12` | Go         | N/A              | \u2b50\u2b50\u2b50                   |\n| [devincornell/pymddoc][46]                                        | 0         | `2023/12/01` | Python     | Python           | \u2b50\u2b50\u2b50                   |\n| [shiftkey/scribble][47] ([docs][48])                              | 40        | `2013/08/08` | .NET       | N/A              | \u2b50\u2b50                     |\n| [calebpeterson/jest-transformer-test-md][49]                      | 2         | `2020/08/21` | JS         | Jest Tests       | \u2b50\u2b50                     |\n| [tjstankus/commitate][50]                                         | 0         | `2014/05/29` | Ruby       | N/A              | \u2b50                       |\n| [GitHub Docs: Creating a permanent link to a code snippet][51]    | N/A       | N/A          | N/A        | N/A              | \u2b50                       |\n| [javierfernandes/markdown-exercises][52]                          | 1         | `2017/05/01` | JS         | N/A              | \u2b50                       |\n| [gatsby-remark-embed-snippet][53]                                 | N/A (55k) | `2024/01/23` | JS         | [Gatsby][54]     | \u2b50                       |\n| [ARMmbed/snippet][55]                                             | 6         | `2021/08/05` | Python     | N/A              | ?                        |\n| [drewavis/markdowninclude][56]                                    | 1         | `2024/04/06` | JS         | VSCode Extension | ?                        |\n| [romnn/embedme][57]                                               | 0         | `2024/04/18` | Go         | N/A              | ?                        |\n\n[24]: https://github.com/mdx-js/mdx\n[25]: https://github.com/zakhenry/embedme\n[26]: https://github.com/cmacmackin/markdown-include\n[27]: https://github.com/BurdetteLamar/markdown_helper\n[28]: https://github.com/SimonCropp/MarkdownSnippets\n[29]: https://github.com/endocode/snippetextractor\n[30]: https://github.com/polywrap/doc-snippets\n[31]: https://github.com/JulianCataldo/remark-embed\n[32]: https://github.com/xrd/oreilly-snippets\n[33]: https://github.com/DamonOehlman/injectcode\n[34]: https://github.com/electrovir/markdown-code-example-inserter\n[35]:\n  https://github.com/andersfischernielsen/Simple-Embedded-Markdown-Code-Snippets\n[36]: https://github.com/ildar-shaimordanov/git-markdown-snippet\n[37]: https://github.com/teyc/markdown-snippet\n[38]: https://github.com/marc-bouvier-graveyard/baldir_markdown\n[39]: https://github.com/dineshsonachalam/markdown-autodocs\n[40]: https://github.com/tokusumi/markdown-embed-code\n[41]: https://github.com/sammndhr/gridsome-remark-embed-snippet\n[42]: https://gridsome.org/\n[43]: https://github.com/NativeScript/markdown-snippet-injector\n[44]: https://github.com/fuxingloh/remark-code-import-replace\n[45]:\n  https://github.com/szkiba/mdcode\n  \"Extracts code blocks from README and produces tests; a similar approach, but quite different\"\n[46]: https://github.com/devincornell/pymddoc\n[47]: https://github.com/shiftkey/scribble\n[48]:\n  https://github.com/shiftkey/scribble/blob/master/docs/features/code-snippets.md\n[49]: https://github.com/calebpeterson/jest-transformer-test-md\n[50]: https://github.com/tjstankus/commitate\n[51]:\n  https://docs.github.com/en/get-started/writing-on-github/working-with-advanced-formatting/creating-a-permanent-link-to-a-code-snippet\n[52]: https://github.com/javierfernandes/markdown-exercises\n[53]:\n  https://github.com/gatsbyjs/gatsby/tree/master/packages/gatsby-remark-embed-snippet\n[54]: https://github.com/gatsbyjs/gatsby\n[55]: https://github.com/ARMmbed/snippet\n[56]: https://github.com/drewavis/markdowninclude\n[57]: https://github.com/romnn/embedme\n\nThe 5 star projects have the bare minimum of being able to embed a file, and run via CLI.\n\n* Snipinator does have other features (such as `shell()`), implemented as I needed them (and listed below) which I do not think any of these have in combination.\n* Some of these projects are not CLIs.\n* [mdx-js/mdx][24] is the closest in terms of flexibility, but it is JS + components, which may not be everyone's cup of tea.\n\n---\n\n**Usage:**\n\nExample template README: (./snipinator/examples/EXAMPLE.md.jinja2):\n\n    # A README\n    \n    Here is a code snippet:\n    \n    <!--{{ pysnippet(path='snipinator/examples/code.py', symbol='MyClass', backtickify='py', decomentify='nl') }}-->\n    \n    Note that `code.py` has a test:\n    {{path('./snipinator/examples/code_test.py', link='md')}}.\n\nGenerating the README:\n\n    $ python -m snipinator.cli -t snipinator/examples/EXAMPLE.md.jinja2\n    <!--\n    \n    WARNING: This file is auto-generated by snipinator. Do not edit directly.\n    SOURCE: `snipinator/examples/EXAMPLE.md.jinja2`.\n    \n    -->\n    # A README\n    \n    Here is a code snippet:\n    \n    <!---->\n    ```py\n    class MyClass:\n      \"\"\"This is a global class\"\"\"\n    \n      def __init__(self, name):\n        self.name = name\n    \n      def MyClassMethod(self):\n        \"\"\"This is a method of MyClass\"\"\"\n        print(self.name)\n    ```\n    <!---->\n    \n    Note that `code.py` has a test:\n    [./snipinator/examples/code_test.py](./snipinator/examples/code_test.py).\n",
        "num_comments": 0,
        "comments": []
    },
    "map_plotter - abstracts complexity of creating intensity plots overlaid onto global map": {
        "title": "map_plotter - abstracts complexity of creating intensity plots overlaid onto global map",
        "score": 6,
        "url": "https://www.reddit.com/r/Python/comments/1cqjpft/map_plotter_abstracts_complexity_of_creating/",
        "content": "# What My Project Does\n\nOverlaying intensity plots onto a geographical map using cartopy/matplotlib can be complex. So we created this [map\\_plotter](https://github.com/amentumspace/map_plotter) package to abstract away that complexity for a common use case.\n\n**Installation**\n\n(opinionated use of conda to avoid cartopy dependency hell and install precompiled binaries)\n\n    conda install cartopy\n    git clone git@github.com:amentumspace/map_plotter.git\n    cd map_plotter\n    pip install .\n\n**Usage**\n\n    import map_plotter\n    map_plotter.plot(lons_g, lats_g, variable, units=\"m/s\", img_name=\"image.png\",\n        save=True, plot=True, title=\"something\", zlims=[0,10])\n\nWhereby:\n\n* `lons_g` and `lats_g` represent 2D matrices / grids of longitudes and latitudes.\n* `values` is the matrix of values to be plotted (same grid dimensions).\n* `units` and `img_name` (self explanatory).\n* `save` & `plot` boolean flags to save the file and plot to screen, respectively.\n* `zlims` define the color scale minimum and maximum.\n\n# Target Audience\n\nPython developers or data scientists or scientists or any Pythonista wanting a simple way to quickly plot an intensity map onto a geographical map.\n\n# Comparison\n\nDiffers from using cartopy and matplotlib in its ease-of-use, but it is less customisable (can't change projections, colors). Regardless, it's convenient and at least provides a starting point for customisation. Similar functionality can be had from geopandas or folium (although cartopy/matplotlib suited our needs better).",
        "num_comments": 0,
        "comments": []
    },
    "2,000 lines of Python code to make this scrolling ASCII art animation: \"The Forbidden Zone\"": {
        "title": "2,000 lines of Python code to make this scrolling ASCII art animation: \"The Forbidden Zone\"",
        "score": 235,
        "url": "https://www.reddit.com/r/Python/comments/1cpq2d9/2000_lines_of_python_code_to_make_this_scrolling/",
        "content": "* What My Project Does\n\nThis is a music video of the output of a Python program: https://www.youtube.com/watch?v=Sjk4UMpJqVs\n\nI'm the author of Automate the Boring Stuff with Python and I teach people to code. As part of that, I created something I call \"scroll art\". Scroll art is a program that prints text from a loop, eventually filling the screen and causing the text to scroll up. (Something like those BASIC programs that are 10 PRINT \"HELLO\"; 20 GOTO 10)\n\nOnce printed, text cannot be erased, it can only be scrolled up. It's an easy and artistic way for beginners to get into coding, but it's surprising how sophisticated they can become.\n\nThe source code for this animation is here: https://github.com/asweigart/scrollart/blob/main/python/forbiddenzone.py (read the comments at the top to figure out how to run it with the forbiddenzonecontrol.py program which is also in that repo)\n\nThe output text is procedurally generated from random numbers, so like a lava lamp, it is unpredictable and never exactly the same twice.\n\nThis video is a collection of scroll art to the music of \"The Forbidden Zone,\" which was released in 1980 by the band Oingo Boingo, led by Danny Elfman (known for composing the theme song to The Simpsons.) It was used in a cult classic movie of the same name, but also the intro for the short-run Dilbert animated series.\n\n* Target Audience\n\nAnyone (including beginners) who wants ideas for creating generative art without needing to know a ton of math or graphics concepts. You can make scroll art with print() and loops and random numbers. But there's a surprising amount of sophistication you can put into these programs as well.\n\n* Comparison\n\nBecause it's just text, scroll art doesn't have such a high barrier to entry compared with many computer graphics and generative artwork. The constraints lower expectations and encourage creativity within a simple context.\n\nI've produced scroll art examples on https://scrollart.org\n\nI also gave a talk on scroll art at PyTexas 2024: https://www.youtube.com/watch?v=SyKUBXJLL50",
        "num_comments": 32,
        "comments": [
            "This is AWESOME.  Those of us that program as a day job can be very quick to forget that programming is a creative activity just as much as writing, drawing, sculpting, etc.  Projects like this really serve to remind us that what we do is an art form.\n\nProjects like this need to exist, and I'm extremely glad that this one does.\n\nAlso, in regards to your book: thank you!  I picked it up as part of a humble bundle years ago and as a result it's what I point people to immediately when I get asked about learning to code.",
            "This reminds me of a side project I did recently: [https://github.com/isaac-j-miller/particle-simulation](https://github.com/isaac-j-miller/particle-simulation). Basically it just models gravity and elastic collisions, and I use it to make art",
            "Big fan of terminal art here. If you like this sort of thing, I\u2019ve been working on a project called TerminalTextEffects. It\u2019s basically a character based terminal animation engine with a bunch of bundled effects.\n\nhttps://github.com/ChrisBuilds/terminaltexteffects",
            "So retro. I was helping someone with their asciii scroll road and making art with it just the other day. Where's that code now...",
            "This is seriously cool. Thanks for sharing!",
            "I love it, I was at PyTexas and have been hacking away at little scrollart demos over since.  I really enjoyed the talk!",
            "Love how it contains both an ending fade out and and ending quine.",
            "I absolutely love this, thank you for sharing.",
            "This is cool, art of this kind qualifies as being part of the demo scene subculture.\n\nJust put demoscene into youtube and you'll find this amazing world of coding and creativity.",
            "Most excellent choice of art.  Do *Dr. Caligari* (1989) next.",
            "Very nice.\n\nP.S. Figlet sighting!",
            "I love u",
            "This rules.\n\nEDIT: to remove some unnecessary but congratulatory profanity, this is a really great and creative project, love it.",
            "Hiya. From the opening comment:\n\n> (I've started looking at YouTube videos to figure out what DJs actually do, and it turns out I could have made all this a lot simpler if I had known basic DJing stuff from the start, LOL. Ah well, never to late to learn for the future.)\n\nCould you expand on this comment? What could be made simpler?",
            "Where is the Mona Lisa and Scream ASCII art from?",
            "[deleted]",
            "Yeah! I like how scroll art makes you stick to the basics and the standard library. There's no extra libraries you need to install, which means you can code it in browser-based REPLs with no need to install Python even. And every programming language has print() and loops, so it's not limited to Python or any particular OS.\n\nAnd it is text but it doesn't require the user to know English; you can understand it in any human language.\n\nI'm collecting a bunch of examples at https://scrollart.org and I'm hoping this style of program becomes a common way for beginners to get into coding since it has such a low barrier to entry.",
            "Wow I love this. If the transition times were fast enough I wonder if you could use it when opening/breaking out of full screen apps like htop or less, or inside tmux? Alias `reset` maybe?",
            "I always found the demoscene to be a bit intimidating: needing to know so much about math and assembly and what not. What I like about scroll art is that, for the simpler pieces anyway, you can look at the output and kind of figure out how to make print() and loops create it. I want something that has a low barrier to entry but cooler than making fizz buzz or compound interest calculation.",
            "Haha, yeah. For those who don't know, Figlet is a tool used to create large banner text using ASCII art. For example, I used it for:\n\n     __ __|  |                ____|              |     _)      |      |                  __  /                     \n        |    __ \\    _ \\      |      _ \\    __|  __ \\   |   _` |   _` |   _ \\  __ \\         /    _ \\   __ \\    _ \\ \n        |    | | |   __/      __|   (   |  |     |   |  |  (   |  (   |   __/  |   |       /    (   |  |   |   __/ \n       _|   _| |_| \\___|     _|    \\___/  _|    _.__/  _| \\__,_| \\__,_| \\___| _|  _|     ____| \\___/  _|  _| \\___| \n\n\nThere's an online figlet generator here: https://doodlenerd.com/web-tool/figlet-generator",
            "Thank you, internet stranger! :D",
            ":D",
            "Some ways I could refactor the code:\n\n* Turn the functions into generators that produce the next line of output.\n* Use async features to make it easier to control when to start/stop the animations. (Right now I just have them poll a text file which gets updated from a program in another terminal window. It's a hack but it works well enough.)\n* Make the timing set by FPS instead of just whatever `time.sleep()` call I have, and make it adjustable in real time.\n* Make these animations more standardized as plugins so they can be mixed together (e.g. half the terminal window with one animation and half the other, etc.)\n\nMy guess is that DJs and sound mixers do a lot of stuff that could translate well to making scroll art. But for now, I'm mainly interested in scroll art as example programs for beginners than using it to create live shows.",
            "I used an online ASCII art generator to convert images. I think it was this one (there's a ton you can google): https://www.ascii-art-generator.org/\n\nBy tilting the images a few degrees before converting, I made them look at bit more interesting.",
            "With modern art you have to read the little placard next to it so that you can understand the context of when it was made and what else was going on in the art world and how it relates/is a response to other modern art or how it subverts expectations of some sub-sub-genre, etc. etc.. Without being aware of all that, it can just look like a bunch of random nonsense.\n\nSo, modern art is kind of like anime.",
            "It's also a base to build upon too.  A great next project would be to build a generic audio visualizer, like they used to have in Windows Media Player, but with ASCII art.",
            "I\u2019d have to check it out. The biggest challenge there is those tools will likely use a bunch of terminal sequences which will not mix well with the sequences in the effects. Worth testing, though.",
            "Okay, I guess I just have to say it:\n\nAnd I wrote it. Also designed the \"shadow\" font you're using.",
            "I  bought and made use of your book \"Automate the Boring Stuff with Python\"  and put it to very effective use as a Supply chain analyst .  As you would naturally expect I'm now on a PIP.  :-(",
            "This is awesome, thanks for the detailed response and all the work you do for the community!",
            "Very cool, thanks!",
            "Yeah that'd be awesome. It'd also be great to turn some of the music generation AI on its head and use it to extract themes, and use that to direct the visuals. Like each musical theme becomes a kind of character or effect, and it visits with the audio and acts like it feels.",
            "Ha ha ha! Nice!\n\nI checked the Figlet Wikipedia entry (and the history to make sure you weren't some random person making a last second edit). Thanks for helping to make Figlet! It's such a useful thing."
        ]
    },
    "Reviewing Dataframe Changes? Looking for Your Preferred Methods!": {
        "title": "Reviewing Dataframe Changes? Looking for Your Preferred Methods!",
        "score": 12,
        "url": "https://www.reddit.com/r/Python/comments/1cpyem9/reviewing_dataframe_changes_looking_for_your/",
        "content": "After playing around with a dataframe\u2014applying filters or other transformations\u2014I'm curious about your methods for reviewing the changes. \n\nIn VS Code, the variable explorer is quite handy for a quick look at the modified dataframe. Alternatively, when working in a Jupyter notebook within VS Code, exporting the data to an Excel file provides a detailed view and allows for an easy deep dive into the results. What are your preferred practices for ensuring your data adjustments are precisely what you intended?",
        "num_comments": 6,
        "comments": [
            "Excel file \ud83e\udd2e\n\nThere is pandas.compare, which does what you say.\n\nThat said, basically it sounds like you want to start unit testing: feeding example datasets through your data pipelines and seeing if they perform as you expect them to do. Suggest you look at a basic pytest and unit testing guide.",
            "Should check out the data Wrangler extension for vs code and Jupiter notebooks. Allows you to view the data quickly and easily and gives you stats about the table and columns to help narrow down issues. I find it annoying to filter and sort it on this but saves having to kick a file out.",
            "Libraries like Pandera, Great Expectations or Hypothesis are worth looking into. \n\nThey all provide means of automating the process of data validation. I haven\u2019t used them extensively myself, but even if you\u2019re in a situation where you\u2019re doing ad-hoc work, it might be worth looking into these tools as they may provide a nice concise framework for expressing the kind of checks you wish to perform on your data that would make the process more efficient than manual inspection.\n\nAlso means that if ad-hoc work suddenly becomes  required on a regular interval, you\u2019ve already got the test cases written ready for integration into a CI/CD process.",
            "i am with you on the excel for quick analysis\n\ni copy data frame to clipboard then paste into excel/google sheets\n\neasy to add check columns.\n\nobviously you have programmatic methods in python, but its often easier when you see the dataframe first",
            "Also, pandas has a unit testing component with assert statements. It feels a bit clunky at first but it's VERY helpful in debugging *why* your assert statement failed. Additionally you can grade the level of exact ess down. E.g. if a column is in a different order and you don't care you can turn it off.",
            "Hey! Yea I gotta do some inspections to make sure that hopefully I have the correct python code to do as desired. It\u2019s hard to blindly trust myself :).  If I ever come up with a better solution to keep it all inside of vs code I\u2019ll try to remember to hit you with a reply."
        ]
    },
    "Library for automatic Cython 3.0 code annotations generation.": {
        "title": "Library for automatic Cython 3.0 code annotations generation.",
        "score": 5,
        "url": "https://www.reddit.com/r/Python/comments/1cpqh34/library_for_automatic_cython_30_code_annotations/",
        "content": "Hi everybody,\n\nover the last year I've been developing a library that adds some Cython 3.0 annotations to existing python code.\n\n**What My Project Does:**\n\nFor example if it sees a `for i in range():` in a function it recognizes `i` as an integer and adds a `i = cython.declare(cython.int)`line at the beginning of the function.\n\nIt actually uses the built-in `ast` module under the hood for parsing, I found it a super useful library!\n\n**Target Audience:**\n\nIt is a side project I made mainly for fun. I don't know if it can be of interest to anybody, or if it could have some potential utility.\n\n**Comparison:**\n\nI did not find anything similar. There are a lot of very cool projects like `mypyc` for example, but nothing that does this tiny little code generation specific to Cython.\n\nThe link to the repository is here:\n\n[https://github.com/nucccc/markarth](https://github.com/nucccc/markarth)",
        "num_comments": 6,
        "comments": [
            "Curious why you used cython declare rather than type annotation syntax.",
            "So this is a python compiler?",
            "Sincerely I don't of any factual difference between the two expressions. I just picked one :). If I was aware of any significant advantage then I would evaluate a change",
            "Not at all.\n\nThere are programs (Cython, mypyc) which tranpile python code directly into C/C++ to obtain a C Extension, which can then be imported into python.\n\nMy idea was just to add some annotation that could benefit a Cython transpilation in terms of execution performance of the generated C Extension.\n\nI'll try to explain up to my knowledge:\nWhat Cython does is basically taking python code, transpiling it into C/C++ and then obtain an extension out of it. It enables the possibility to add types among the original python codelines, so as to obtain better performances. For example, if I was to write: `for i in range(9000):` in the generated C code the `i` variable would be treated as a Py_Object, with all the related overhead.\n\nBut Cython allows one to specify that `i` shall be treated as a C `int`, for example by using the cython syntax `cdef int i` or also with Cython 3.0 `i = cython.declare(cython.int)`. Then in the transpiled C code (cool thing is that you can actually inspect that transpiled C code) one will see that that range becomes something way faster like `for(int i = 0; i < 9000; ++i)`.\n\nThis is already done by Cython, but one should somehow write that line to tell Cython \"hey, treat that i variable like a C integer, not a Python object\". I just wanted to make a library the adds these lines to improve the performance of cythonized code.\n\nI hope I was correct and clear.",
            "I would say readability of `x : cython.int` is better than `x = cython.declare(cython.int)` but it's your choice. Nevertheless, cool project friend, hope people will like it too.",
            "Ya I remeber looking at cython code it made meh c code. Like not the worse ever but u can defiantly tell it won't pass code review. Also pretty sure it was slower than my hand written c. \n\nSo ur basically trying to figure out the type for real before compiling to cython. That sounds very very hard because getting this wrong can do ub. \n\nCool idea tho defiantly intresting aproch"
        ]
    },
    "APScheduler vs Schedule package": {
        "title": "APScheduler vs Schedule package",
        "score": 10,
        "url": "https://www.reddit.com/r/Python/comments/1cpj8ra/apscheduler_vs_schedule_package/",
        "content": "Hey folks, looking to use one library to implement some background scheduling logic on my application.\n\nI find in Google search [APScheduler](https://pypi.org/project/APScheduler/) to be frequently mentioned, but I can see the [Schedule](https://schedule.readthedocs.io/) package has more GH stars. \n\nWas curious if anybody has used one of them, and which one would you recommend based on your own experience.",
        "num_comments": 6,
        "comments": [
            "I would recommend apschedular. Battle tested in production .",
            "Using either will likely leave you satisfied, they're both good - though it may depend on your specific needs. \n\nAPS is a much more advanced tool, although also supporting relatively straightforward basic setup.\n\nSchedule is simpler and more limited, but also does what it says on the package and will likely cover the common needs.\n\nI use APS more often since it seems easier to set up and get the project going. \n\nAs a side note - and a very personal subjective side note - I also don't think the maintenance of APS is adequate to it's popularity. I've been using it on and off for some 5 years now, and through that time I've seen features and bug fix suggestions rejected and marked for the next major update - which is still nowhere near release. The priorities frequently seem to be shifted elsewhere, while the current version gets hardly any meaningful development for many years now. I don't know if Schedule is any better in that sense though. Given that, as much as it's superb to have APS as a start, writing an in-house scheduler ended up being the safer way to go forward for certain projects in my case.",
            "What are you trying to accomplish?",
            "APScheduler. Using it for the company I work at, and it's doing a great job; easy to set up and reliable.",
            "Thanks for the reply! Will keep this in mind, curious why you ended up writing an in-house scheduler. \n\nYou just did not want the boilerplate you have with APS or stumbled upon any limitations?",
            "It's very much dependant on what you're trying to do. APS introduces a certain way of doing things that you have to adapt to, which ended up bringing unnecessary complexity. I don't recall all the issues, and some of them are understandable given the range of scenarios APS is trying to support, but some things that cropped up are:\n\n- it didn't execute its tasks at startup, only after the first interval. Therefore, job functions needed to be called manually only once at startup, needing extra code to do make it happen outside of APS. This was one of the biggest pain points, as suddenly a job function executes only once from a different thread, at a different point in the control flow, all of that has to be taken into account. This functionality was to be added into version 3.*, before it was scrapped and promised in version 4.0, which I've spent the past 4 years waiting for. I understand that open source is what it is, I publish my own libraries and can take up to a month to fix something, but waiting years for this kind of feature in my eyes is unreasonable, and was a clear indication that we should build something on our own rather than depend on the third party in this case.\n- Scheduling, modifying and unsubscribing jobs requires a certain format that we need to follow, storing jobs on our end. Doing it in house allows us to do it exactly how we want to without an overhead\n- reacting to its errors was cumbersome\n- we didn't like its logs as they can be confusing\n- Its shutdown mechanism sometimes caused threads to be left dangling\n\nAnd to be honest - in some cases it was quite easy to build the replacement. If you don't need all the features that APS offers, but just need something that runs roughly every N seconds, it's a relatively trivial task using a separate thread"
        ]
    },
    "Introducing Notolog: Python Markdown Editor built with PySide6": {
        "title": "Introducing Notolog: Python Markdown Editor built with PySide6",
        "score": 6,
        "url": "https://www.reddit.com/r/Python/comments/1cpidy2/introducing_notolog_python_markdown_editor_built/",
        "content": "Excited to share my personal open-source project: Notolog - Python Markdown Editor (MIT License).\n\nThe main motivation for developing another markdown editor was my passion for learning new things and enhancing my development skills in Python. I developed it in my spare time over a few months, despite having no prior experience in creating full-scale Python applications.\n\n**What My Project Does**\n\n\u2217 Multiplatform\n\n\u2217 Markdown async syntax highlighting created by me\n\n\u2217 Several pre-installed color themes\n\n\u2217 Supports English and 17 other languages right out of the box\n\n\u2217 Integration with OpenAI API for AI-assisted features\n\n\u2217 Optional file encryption/decryption\n\n**Target Audience**\n\nPrimarily developers who write markdown documents and notes.\n\n**Comparison**\n\nThis is more of a personal learning project, so it's hard to compare it directly with others.\n\n**How to install**\n\nDiscover Notolog on [GitHub](https://github.com/notolog/notolog-editor) \ud83c\udf1f and [PyPI](https://pypi.org/project/notolog/).\n\nInstallation is as easy as running a single command:\n\n    pip install notolog",
        "num_comments": 3,
        "comments": [
            "This looks really cool! I don't know of too many markdown editors that operate on the Python MD library.\n\nAny plans to support Pymdown extensions? I found your app looking for an editor that supports [SuperFences](https://facelessuser.github.io/pymdown-extensions/extensions/superfences/), a feature I have rarely seen in MD based documentation.  Either way I'm definitely planning to check it out!",
            "Thanks for the feedback! I'm currently focused on integrating on-device AI and local LLM support. After that I plan to add more functionality especially with Markdown-related features. Really appreciate your interest!"
        ]
    },
    "I've developed a library for send metrics to zabbix asynchronously ": {
        "title": "I've developed a library for send metrics to zabbix asynchronously ",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1cpw67l/ive_developed_a_library_for_send_metrics_to/",
        "content": "I have been using zabbix for monitoring a lot of metrics in my work, none of the most popular zabbix were capable of doing async tasks, so I've developed some simple package capable of doing this.\n\nTests, examples and how-tos can be found here: [https://github.com/gustavofbreunig/zabbix-sender-async](https://github.com/gustavofbreunig/zabbix-sender-async)\n\n**What My Project Does**\n\nSend zabbix sender messages using asyncio tasks.\n\n**Target Audience**\n\nSysAdmins who use Zabbix to monitor a large number of metrics.\n\n**Comparison**\n\nInstead of doing traditional way, using these abandoned library: [https://github.com/adubkov/py-zabbix](https://github.com/adubkov/py-zabbix)\n\n    from pyzabbix import ZabbixMetric, ZabbixSender\n    \n    # Send metrics to zabbix trapper\n    packet = [\n      ZabbixMetric('hostname1', 'test[cpu_usage]', 2),\n      ZabbixMetric('hostname1', 'test[system_status]', \"OK\"),\n      ZabbixMetric('hostname1', 'test[disk_io]', '0.1'),\n      ZabbixMetric('hostname1', 'test[cpu_usage]', 20, 1411598020),\n    ]\n    \n    result = ZabbixSender(use_config=True).send(packet)\n\nYou can do this:\n\n    async def sendmetrics():\n        sender = AsyncSender('localhost', 10051)\n        metric = ItemData(host='hostname', key='test.metric.text', value='test package import')\n        result = await sender.send(metric)",
        "num_comments": 4,
        "comments": [
            "- Send is coupled with opening the connection, if you try to send many metrics this won't scale. Also there's no exc/err being handled. To use as a script run once type of thing it can be useful, but as a general client it needs to be improved.",
            "I assume that sending them with async in an array you can send multiple metrics in a single call. So you can send more metrics or more often with the same hardware.\n\nBut, if your server is busy, doesn't the server launch the triggers for not getting the data when it expects them?",
            "The send is coupled with connection, but you can send an array of metrics, so it opens the connection only once:\n\n            sender = AsyncSender('localhost', 10051)\n            metrics = []\n            metrics.append(ItemData('async-sender-test-host', 'test.metric.unsigned', 1234))\n            metrics.append(ItemData('async-sender-test-host', 'test.metric.float', math.pi))\n            response = await sender.send(metrics)\n\nAnd about the exception handling, Zabbix responses are too poor on information to do some decent exception handling, but I'm working on this.\n\nThanks for the feedback.",
            ">I assume that sending them with async in an array you can send multiple metrics in a single call. So you can send more metrics or more often with the same hardware.\n\nCorrect ![gif](emote|free_emotes_pack|grin)\n\n>But, if your server is busy, doesn't the server launch the triggers for not getting the data when it expects them?\n\nIn a busy server, async calls is even better because the python script can collect metrics and send at same time without using multi threads and the synchronization/mutexes problem. But yes, if the server cannot process messages fast enough, it fires triggers, but these problems [we solved using proxies](https://www.zabbix.com/documentation/current/en/manual/distributed_monitoring/proxies) to distribute effort."
        ]
    },
    "I made a Python text to speech library - Pyt2s": {
        "title": "I made a Python text to speech library - Pyt2s",
        "score": 14,
        "url": "https://www.reddit.com/r/Python/comments/1cpbn3u/i_made_a_python_text_to_speech_library_pyt2s/",
        "content": "**What my project does**: It supports services like IBM Watson, Acapela and Stream labs' demo websites to convert your text to speech.\n\n**Target audience**: It's a toy project and would not recommend you to use in Production.\n\n**Comparison**: It's wayyyyy easy to use. Just pip install and use in your project. No extra setup required like other libraries. Also supports various languages and voices and accents. Check [docs](https://sumanth.dev/pyt2s/) for more.\n\n[Here](https://github.com/supersu-man/pyt2s)\u00a0is the link to repository.\n\nPlease go do check it out and star it if it's helpful to you guys. Thank you.\n\nI made this library taking inspiration from\u00a0[this](https://github.com/chrisjp/tts)\u00a0php tts library by chrisjp.",
        "num_comments": 13,
        "comments": [
            "So basically it's a wrapper around various TTS websites? \n\nI see an API key in there and you probably don't want to make that public. You could be liable for usage if it costs money, nevertheless any other things.\n\n**Edit:**\n\n\"The Python Text to Speech library you've been looking for.\"\n\nNot really...\n\nIt's a neat idea, but I really don't think you put much thought into it. It's pretty much a full copy/paste job from the \"inspired\" repo, but done in Python and done worse from a developer perspective.\n\nSome specific ideas you may want to consider\n\n1. Remove the .vscode folder. It's not needed and your settings will most likely not work for anyone pulling down your repo. Your .gitignore is the template for Python, but you'll want to also add .vscode and other stuff relevant to your own development environment. When you're using git, don't just raw dawg everything. Be cognizant of what you're actually committing.\n\n2. Where are the comments? The repo you copied from had them and the repo that person copied from had much better ones. They explained where that API key came from at least.\n\n3. Use enums for the voices instead of string matching. Your voice choices are well defined and as a developer I don't want to monkey around with figuring out what string values work. For instance if I want the voice \"lawrence\" for my cepstral model it will cause an exception since it is capitalized in your voice list. There's no string sanitation at all. If you use eums then you only get valid choices.\n\n4. The url variable names are not great. What is the meaning of \\_\\_url1\\_\\_, \\_\\_url2\\_\\_, etc...? The original repository had real variable names. This is like reading a Ghidra decompile output.\n\n5. All of these look like evaluation or demo URLs. I would guess that they only work for a limited amount of time and possibly IP ban you for abusing them. For example, the Acapella one is kind of a hack grabbing demo credentials. If you read their documentation it has good examples of how to actually use their API.\n\n6. Why even have the service class?? It appears to have class variables that aren't even used in it. It's almost as if you wanted to make a virtual class, but then forgot about it mid-way through the project. That's just sloppy. You've got to instantiate the super class and then call it's requestTTS() function? And all that does is just cause an exception if you input the wrong string for your voice? This has real meeting that could be an email kind of energy. It's almost as if you are adding some special code that should be called when you run a function. Like if you were adding your own touch to the function. Dare I say, [decorating](https://pythonbasics.org/decorators/) the function?",
            "I had been saving this post to give similar feedback, but less savagely. I suspect this is just a learning project despite how the docs present it. \n\nOP toy projects should be clearly marked as such in the docs so people don\u2019t get wrong expectations. Docs also aren\u2019t really readable on mobile.\n\nI think you could do with learning a bit more about OOP and how to design classes, but you\u2019ve got some ideas already, keep learning!",
            "Thanks for the feedback. Also check [docs](https://sumanth.dev/pyt2s/docs/acapela) so you don't have to monkey around for voice values. Feel free to raise a pr, it's open sourced for a reason :)",
            "> Remove the .vscode folder. It's not needed and your settings will most likely not work for anyone pulling down your repo. \n\nvscode actually changes this paradigm, the settings in the dir are the settings for the project not the user. We don't need to set our editors up anymore, it's a very cool and modern approach.",
            "I don't think he's getting paid to build these like any other open-source dev. Relax.",
            "Ooops, I didn't mean to sound like an ass. I was just trying to be funny.\n\nBut IDK, it seems every project I see is just someone wrapping other people's code and lauding it as their own creation. Like putting birthday candles on a store bought cake and telling your friends you designed the cake. Calling a web API and yeeting out results is just like that. It's not even the proper way to do it. Like literally go to any one of those websites and you're bound to find the [actual API](https://www.acapela-cloud.com/docs_api/). So then what does this library actually do? All the work is done by the TTS providers.\n\nAnd OP is already [lobbing it off to people](https://www.reddit.com/r/learnpython/comments/174ugz7/struggling_with_text_to_speech_using_pydroid_3/l1deoos/) like it's something that can be used in a project. Maybe here, but the readme in the repo doesn't mention that it's a toy project and shouldn't be used for production.\n\nI don't mean to be discouraging and I hope OP continues to improve their Python skills. It's a good way to venture into something beyond the basic syntax. I'm just old and crotchety C dev.",
            "He specifically states it is a toy project and not designed for production.",
            "Ignore the .vscode dir comment! \n\nSome things to consider: \n\n* If `which say` returns a path, you have a system TTS which could be an option. (Mac/BSD/Linux)\n* Windows has a TTS too\n* TikTok have a public API with their voiceover voices\n* If Docker is installed, you have self-hosted options like Mozilla TTS, Voice Cloning App and Mycroft's Mimic (Mimic is low resource use)",
            "People forget they can raise a pr \ud83d\ude02. I was reading a blog of nutjs developer on why he left open source contribution. He mainly explained how people always complained about something forgetting it's open-source. People don't get paid for making these. You can't complain if something goes wrong.\n\nRaise a PR.",
            "Yeah no he shouldn\u2019t be advertising it like that, I totally agree.",
            "Code review and critique is always good, even if it's harsh it's donated labour. Robustness to criticism and egoless development makes good software; you're doing god's work.",
            "Only in this post, that\u2019s why I mentioned the docs",
            "There's a difference between free code review by someone giving their time and expertise to help another dev level up their skills, and non paying users feeling entitled and making demands.\n\nFree code review is donated labour, even if it is critical it should be embraced and encouraged. Keeping the bar low for that helps everyone"
        ]
    },
    "Interactive plots in the terminal": {
        "title": "Interactive plots in the terminal",
        "score": 88,
        "url": "https://www.reddit.com/r/Python/comments/1cor562/interactive_plots_in_the_terminal/",
        "content": "I made a library to create interactive plots in the terminal ([pip install itrm](https://pypi.org/project/itrm/)). It uses braille characters (by default) to display the data with sub-character resolution. There are several keybindings for moving a vertical cursor left and right, for zooming in or out on data, and for changing which curve to focus on. There are occasions (such as when working with a server) where MatPlotLib is not an option and the terminal is the only available tool. But, in my opinion, it is actually faster to use this tool (itrm) to zoom in on interesting parts of data and analyze patterns than using other tools like MatPlotLib. In fact, with large data sets (\\~1 million points), this tool actually renders faster than MatPlotLib. Please check it out and let know what you think.\n![](https://gitlab.com/davidwoodburn/itrm/-/raw/main/figures/fig_iplot.png)",
        "num_comments": 9,
        "comments": [
            "This looks pretty cool, I\u2019ll check it out. Thanks!",
            "Had a quick look, it's really nice! I haven't quite found out how to label the axis or run it in OO mod ala matplotlib but I might use it more broadly for fast plotting!",
            "Very cool!\n\nTwo comments:\n- Would be nice if logarithmic axis could be applied\n- Make the program run directly in the terminal, like \"itrm -interactive -data data.txt\" or something like that.",
            "This is great!",
            "That\u2019s neat ty. I definitely have use cases for this. It would be cool if you could maintain the same api as matplotlib",
            "Thank you. There is no mechanism for labeling axes, just as there is no mechanism for tick marks or grids because it is not meant for presentation but for inspection. The intended viewer is the developer. However, there is a plot `label` parameter to help keep track which plot is which. You could put axis information there: \u201cPosition vs. time (s)\u201d.",
            "Thank you. Yes, while you can just apply `np. log10` to the inputs, I have found that tedious. I like both of your suggestions, and I think I\u2019ll try to add them. Thank you.",
            "I've added an \\`lg\\` parameter to the \\`plot\\` and \\`iplot\\` functions for applying logarithmic scaling. Calling itrm directly in the terminal will take me a bit more time to figure out how to do.",
            "One way to call python code directly could be to add a pyproject.toml to your repo, and add a scripts section:\n\nhttps://packaging.python.org/en/latest/guides/writing-pyproject-toml/#creating-executable-scripts"
        ]
    },
    "Hi! I've published a Python client for IBKR REST and WebSocket APIs - IBind. Hope you like it \ud83d\udc4b": {
        "title": "Hi! I've published a Python client for IBKR REST and WebSocket APIs - IBind. Hope you like it \ud83d\udc4b",
        "score": 7,
        "url": "https://www.reddit.com/r/Python/comments/1cp8vnj/hi_ive_published_a_python_client_for_ibkr_rest/",
        "content": "Hi! I want to share a library I've built recently. IBind is a REST and WebSocket Python client for [Interactive Brokers Client Portal Web API](https://ibkrcampus.com/ibkr-api-page/cpapi-v1). It is directed at IBKR users.\n\nYou can find IBind on GitHub: [https://github.com/Voyz/ibind](https://github.com/Voyz/ibind)\n\n**What My Project Does:**\n\nIt is a REST and WebSocket API for the Interactive Brokers' Web API.\n\nI'm particularly proud of a few things in this release:\n\n1. The REST and WebSocket API clients are based on an abstract base class `RestClient` and `WsClient` accordingly. These could be implemented to use some other Web APIs in a relatively straightforward way. I have in fact used a version of that `WsClient` for a cryptocurrency WebSocket API, and it is nice to see it adapt to a different environment.\n2. I've covered most of the codebase with automated tests (appx 80%). Contrary to some of my other libraries, these are mainly integration tests which feel to provide a stronger test coverage than only unit tests.\n3. I've learned how to use class mixins in this project, and it aids the maintainability by a lot! The REST client itself is pretty barebone, but has a lot of mixin classes - all corresponding to the endpoint categories the broker uses, making it easy to search for the right piece of code and documentation.\n4. There's a lot of things that make this client as plug-and-play as possible. The broker requires the user to specify a bunch of things - account ids, certificates, URLs, etc. - which the class either reads from the environment variables or assumes (given that some things would be common for most users). In either case, all these are customisable by parameters if needed, but it is nice to just write `client = IbkrClient()` in various projects having set just a couple of env vars.\n5. I think the [documentation](https://github.com/Voyz/ibind/wiki) is pretty in-depth but readable. It's always hard to judge whether docs are well written, but I think it is nicely broken down. Also, I managed to use `pydoc-markdown` package to create [API reference](https://github.com/Voyz/ibind/wiki/API-Reference-%E2%80%90-IbkrClient) in markdown, which works nicely with the GitHub Wiki. I'd prefer it to be even easier, but compared to Sphinx and readthedocs it's a much quicker job.\n6. The WebSocket class does a ton to keep the connection alive and recover from connection losses. Maintaining active subscriptions after a re-connect can be a real pain, and I think this class does it in a nice and reliable way. I've tested it for various types of connectivity loss, and it manages to recover and re-establish the WebSocket data stream. Pretty crucial in the trading environment.\n7. I made a nice logo for it \ud83e\udd73\n\n**Target Audience:**\n\nTraders using IBKR who want to automate their trading through this Web API.\n\n**Comparison (A brief comparison explaining how it differs from existing alternatives.) :**\n\nThere are two similar libraries that I know of. They aren't bad, but seem not very well maintained and incomplete:\n\n* [https://github.com/areed1192/interactive-brokers-api](https://github.com/areed1192/interactive-brokers-api) \\- outdated and stale, last update 3 years ago\n* [https://github.com/utilmon/EasyIB](https://github.com/utilmon/EasyIB) \\- stale and incomplete\n\nThe library I've published covers a much wider range of endpoints, adds WebSocket support and a bunch of wrapper methods to simplify the usage of the API.\n\nIBind has a bunch of features that make using the IBKR APIs much easier. Some of these are:\n\nREST:\n\n* **Automated question/answer handling** \\- streamlining placing orders.\n* **Parallel requests** \\- speeding up collection of price data.\n* **Rate limiting** \\- guarding against account bans.\n* **Conid unpacking** \\- helping to find the right contract.\n\nWebSocket:\n\n* **WebSocket thread lifecycle handling** \\- ensuring the connection is alive.\n* **Thread-safe Queue data stream** \\- exposing the collected data in a safe way.\n* **Internal subscription tracking** \\- recreating subscriptions upon re-connections.\n* **Health monitoring** \\- Acting on unusual ping or heartbeat.\n\nREST Example:\n\n    from ibind import IbkrClient\n    \n    # Construct the client\n    client = IbkrClient()\n    \n    print(client.tickle().data)\n\nWebSocket Example:\n\n    from ibind import IbkrWsKey, IbkrWsClient\n    \n    # Construct the client.\n    ws_client = IbkrWsClient(start=True)\n    \n    # Choose the WebSocket channel\n    key = IbkrWsKey.PNL\n    \n    # Subscribe to the PNL channel\n    ws_client.subscribe(channel=key.channel)\n    \n    print(ws_client.get(key))\n\nI just wanted to share my experience of publishing Open Source. For some reason I get a lot of motivation when I can publish code that makes peoples' lives easier. The library could use some code review on it, so if you\u2019d feel like reading some code and helping out - drop me a message. Other than that, happy to answer any questions, and - if you are an algo trader - let me know if you get a chance to use it. Thanks for reading!",
        "num_comments": 2,
        "comments": [
            "Hey there, sounds good but i am using tws too and I am looking for an Python api that can use info from discord group and put it in to action on tws. Is there already something like that?"
        ]
    },
    "Python Streamlit Spotlight Tutorial: an Interactive Dashboard using UNHCR Refugee Data": {
        "title": "Python Streamlit Spotlight Tutorial: an Interactive Dashboard using UNHCR Refugee Data",
        "score": 50,
        "url": "https://www.reddit.com/r/Python/comments/1com0mh/python_streamlit_spotlight_tutorial_an/",
        "content": "Python\u00a0***Streamlit***\u00a0is a terrific tool for creating interactive data visualizations.\n\nIt packages all your visualizations up into a neat little application - including charts and maps - and displays them in your default browser. No muss, no fuss.\n\nRecently, I found a new dataset (to me) on the UN High Commission for Refugees (UNHCR) website. It contains country-to-country movements for refugees both from origin country and country of asylum\n\nUsing this dataset, here's a step-by-step on how to code a Python\u00a0***Streamlit***\u00a0application that has:\n\n1. ***A dropdown menu***\u00a0to select by country\n2. ***A second dropdown menu***\u00a0to select by year\n3. ***Radio buttons***\u00a0(2) to select country of origin or county of asylum\n4. ***A global choropleth map***\u00a0to display the results by country and year.\n\nFree article [HERE](https://johnloewen.substack.com/p/python-streamlit-spotlight-an-interactive).",
        "num_comments": 3,
        "comments": [
            "When you say it packages it up, you do have to run it in a python env right?",
            "yes, this example is running within a Python env.",
            "So then it isn\u2019t packaging anything. You\u2019re just running a script inside a virtual environment that you had to setup.\n\nNo offense, but it\u2019s hard for anyone to justify spending time reading a blog post about a technical topic when the person who wrote doesn\u2019t seem to understand the material."
        ]
    },
    "IP subnet or IP calculator tool need feedback": {
        "title": "IP subnet or IP calculator tool need feedback",
        "score": 42,
        "url": "https://www.reddit.com/r/Python/comments/1comgeg/ip_subnet_or_ip_calculator_tool_need_feedback/",
        "content": "Hey folks,\n\nI've been dabbling with a Python project recently that's all about making life easier for us I.T. people. It's a nifty little tool that calculates IP subnets and does IP calculations from the command or CLI.\n\nHere's the GitHub link and the code:\n\n[https://github.com/nicanorflavier/ipnet](https://github.com/nicanorflavier/ipnet)\n\nI\u2019m pretty stoked about it, but I know there\u2019s always room for improvement. So, I thought, better to turn to than the wise minds of this python community?\n\nI\u2019m all ears for any feedback, tips, tricks, or advice you guys might have. Thanks a ton in advance!",
        "num_comments": 9,
        "comments": [
            "I know python has built-in ipaddress module, but us programmers usually avoid writing any code when existing solution exists and works fine. In this case, I mean ipcalc tool, which should be in any distro's repo.\n\nIf it's just for learning, it could be a good practice project.",
            "2 things:\n\n1) Skimmed the code, but I did not see you using any bitwise operations. IPs + masks go hand in hand with bitwise operations and I think once you see that your code would be much better and easier to add features.\n\n2) The idea of classes in networking is archaic and needs to die.  Nonetheless, I only see 3 classes in your code AND class D and E are getting classified as class C in your code. Try 244.0.0.4 -- pretty cude your code will say it's class C but it is a class D.",
            "[ipaddress](https://docs.python.org/3/library/ipaddress.html)",
            "The best one that I have found so far, is https://www.davidc.net/sites/default/subnets/subnets.html. It's easy to understand.  \n\nYou can put in whatever Network address and mask, and it shows you the range of IPs available. And it can even split the given range into smaller ranges.",
            "Thanks for all your feedbacks., this is all more for learning.  \nI have made changes to the code and have managed to sort out all your feedbacks and thanks to those.\n\n* I change the code to use bitwise operation\n* I added the CLASS C and D.\n* I updated the README file too on why use this project and everyone is welcome to see the code and contribute and rise issues and features. \n* And I added a minor version release that have a binary file for ubuntu and windows.  \n\nAny other feedback?",
            "The biggest issue I see is that it's functionally impossible to execute. If I have to cd to a directory and type `python3 ipcalc.py` *in addition* to the actual command I want, or use a potentially long absolute path, I'm going to gravitate to some other tool.\n\n* Why is this not a package?\n* Why does this not install a binary/shim?\n* IPv6?\n* The README should really include an example of the *output* without having to wait for a GIF to reach a certain timestamp.\n\nHere is my internal-use WIP if you want to compare:\n\nhttps://github.com/therealzanfar/iptool/tree/feature-summarization",
            "Yeah, my first thought here also was that [ipcalc](https://github.com/kjokjo/ipcalc) ([website](https://jodies.de/ipcalc)) feature parity would be nice.\n\nI would also assume it to be more of a learning experience, unless some problem with the existing tool annoys someone and they'd rather write a replacement in another language than touch perl (I wouldn't blame them for that decision; it's been decades since I really wrote perl).",
            "Good points here that I have not thought about thanks for the suggestions!",
            "Thanks for the points here, I will try and see if I can accommodate what you mentioned here, and thanks for pointing me to your project."
        ]
    },
    "S.T.A.R.K \u2014 The First Voice Assistant's Framework": {
        "title": "S.T.A.R.K \u2014 The First Voice Assistant's Framework",
        "score": 1,
        "url": "https://www.reddit.com/r/Python/comments/1cp4jmk/stark_the_first_voice_assistants_framework/",
        "content": "Welcome to S.T.A.R.K., a modern, advanced, asynchronous, and fast framework designed for creating intuitive natural language interfaces, especially voice-based. Think of it as the FastAPI but with speech instead of http.\n\nNew to S.T.A.R.K.? Consider reading the articles in navigation sequentially for a comprehensive understanding of the framework, including the \"Advanced\" section.\n\n# \ud83d\udd0d Key Features\n\n\ud83d\udee1\ufe0f Autonomous and Privacy-Focused: Stark operates entirely on-device, ensuring your data remains private. Dive deeper into hosting options here.\n\n\ud83e\udde0 Context-Aware: Easily define context and parameters for subsequent requests or parse multiple commands simultaneously. Discover the power of Commands Context.\n\n\ud83d\ude80 Asynchronous Commands: Start lengthy tasks and continue using Stark. You'll be notified upon completion. Learn about Sync vs Async Commands and Creating Commands.\n\n\ud83d\udcc8 Multiple Responses: Get real-time updates for long tasks, like monitoring download progress. More on this in Creating Commands.\n\n\ud83e\udde9 Advanced Patterns Parsing: Our custom patterns syntax makes parsing any parameter from strings effortless.\n\n\ud83e\udde0 Extendable with LLMs: Enhance Stark's cognition by integrating leading language models like ChatGPT. More in Fallback Command\n\n\ud83c\udf10 Multilingual Support: Interact with Stark in multiple languages.\n\n\ud83d\udd27 Absolute Customization: Craft complex commands, integrate various speech or text interfaces, adapt voice assistant modes, or even override existing classes.\n\n\ud83c\udf0d Community Support: Join STARK-PLACE repository, the platform library filled with community extensions. Utilize commands crafted by others and share your creations. Further information in Contributing and Shared Usage.\n\n# Programming Language\n\nModern python\n\n# What My Project Does\n\nS.T.A.R.K. provides a robust framework for developing natural language interfaces, focusing on voice commands but also adept at handling text input. It excels in creating private, context-aware, and multilingual voice assistants that can perform asynchronous operations. The system allows users to define complex command structures, parse intricate patterns, and extend functionality with advanced language models, all while operating on-device for heightened privacy.\n\n# Target Audience\n\nS.T.A.R.K. was initially crafted for my own voice assistant projects, so it's perfect for individuals like myself who desire a custom voice interface for their personal ventures. It\u2019s particularly suited for hobbyists and developers looking to add a unique, private voice capability to their projects. As a versatile tool, its use is only limited by one's imagination.\n\n# Comparison\n\nOther tools are too complex to customize, while in STARK, turning a regular function into a voice command is no more difficult than adding a single decorator.\n\n# Documentation\n\n[stark.markparker.me](https://stark.markparker.me)\n\n# Repo\n\n[github.com/MarkParker5/STARK](http://github.com/MarkParker5/STARK)",
        "num_comments": 1,
        "comments": []
    },
    "Pre-commit hook to keep coverage badge in README up to date": {
        "title": "Pre-commit hook to keep coverage badge in README up to date",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1cotppy/precommit_hook_to_keep_coverage_badge_in_readme/",
        "content": "Wrote this as a tool to keep README coverage badges up to date without relying on 3rd party services or having to do anything extra, thought others might get some utility out of it: [coverage-pre-commit](https://github.com/Weird-Sheep-Labs/coverage-pre-commit).\n\nA `.coverage` file is expected at the root of the project, generated by running `coverage run` directly or using a plugin such as [pytest-cov](https://github.com/pytest-dev/pytest-cov) when running tests.\n\nMost convenient when used as a `pre-push` hook imo. Feel free to opine, be it positive or negative!",
        "num_comments": 0,
        "comments": []
    },
    "PyWolt: Wolt food delivery service API wrapper": {
        "title": "PyWolt: Wolt food delivery service API wrapper",
        "score": 3,
        "url": "https://www.reddit.com/r/Python/comments/1col34c/pywolt_wolt_food_delivery_service_api_wrapper/",
        "content": "I'm thrilled to share my first open-source project with you all: [PyWolt](https://github.com/ilyafeldman/pywolt.git)! \ud83c\udf89\n\n[PyWolt](https://github.com/ilyafeldman/pywolt.git) is a Python library that makes it super easy to interact with the Wolt API.\n\n# What My Project Does:\n\n* Discover Venues: Find nearby spots to grab a bite.\n* Explore Menus: Dive into a venue's menu and pick your favorites.\n\n# Target Audience:\n\n* **Software Engineers**: Professionals who build web or mobile applications, particularly those in the food delivery or restaurant industry, looking to incorporate Wolt's services seamlessly into their platforms.\n* **Data Scientists/Analysts**: Individuals analyzing food delivery data, consumer behavior, or market trends, who may utilize PyWolt to gather data from Wolt's API for analysis and insights.\n* **Students/Learners**: Those studying Python programming, web development, or API integration, who can use PyWolt as a practical example or learning tool to understand how to interact with RESTful APIs in Python.\n* **Freelancers/Entrepreneurs**: Independent developers or startup founders looking to build new food-related applications or services leveraging Wolt's platform without reinventing the wheel.\n\n# Comparison:\n\n* [woltcheck](https://github.com/muttley79/woltcheck): only offers a script to check if a wolt restaurant is ready to deliver to your location.\n* [what-to-eat](https://github.com/Valaraucoo/what-to-eat): a pretty neat cli tool that offers all of pywolt's functionality. In my opinion it overcomplicates things a little, and doesn't offer straight-forward RESTful functionality to interact with the API itself.\n\n# ",
        "num_comments": 1,
        "comments": []
    },
    "I made a React-like web framework for Python \ud83d\udc4b": {
        "title": "I made a React-like web framework for Python \ud83d\udc4b",
        "score": 29,
        "url": "https://www.reddit.com/r/Python/comments/1cnttw2/i_made_a_reactlike_web_framework_for_python/",
        "content": "I'm Paul, one of the creators of Rio. Over the years I've tried many different established python GUI frameworks, but none of them really satisfied me. So I teamed up with a few like minded developers and spent the last few months to create our own framework. Rio is the result of this effort.\n\n## What My Project Does\n\nRio is a brand new GUI framework that lets you create modern web apps in just a few lines of Python. Our goal is to simplify web and app development, so you can focus on the things you care about, instead of wasting countless hours on frustrating user interface details.\n\nWe do this by following the core principles of Python that we all know and love. Python is supposed to be simple and compact - and so is Rio. There is no need to learn any additional languages such as HTML, CSS or JavaScript, because all of the UI, Logic, Components and even layouting is done entirely in Python. There\u2019s not even a distinction between front-end and back-end. Rio handles all of the communication transparently for you.\n\n## Key Features\n\n- **Full-Stack Web Development:** Rio handles front-end and backend for you. In fact, you won't even notice they exist. Create your UI, and Rio will take care of the rest.\n- **Python Native:** Rio apps are written in 100% Python, meaning you don't need to write a single line of CSS or JavaScript.\n- **Modern Python:** We embrace modern Python features, such as type annotations and asynchrony. This keeps your code clean and maintainable, and helps your code editor help you out with code completions and type checking.\n- **Python Debugger Compatible:** Since Rio runs on Python, you can connect directly to the running process with a debugger. This makes it easy to identify and fix bugs in your code.\n- **Declarative Interface:** Rio apps are built using reusable components, inspired by React, Flutter & Vue. They're declaratively combined to create modular and maintainable UIs.\n- **Batteries included:** Over 50 builtin components based on Google's Material Design\n\n[Demo Video](https://github.com/rio-labs/rio/assets/41641225/44279406-0c2d-47e2-98b5-4582722054b2)\n\n## Target Audience\n\nWhether you need to build dashboards, CRUD apps, or just want to make a personal website, Rio makes it possible without any web development knowledge. Because Rio was developed from the ground up for Python programmers, it was designed to be concise and readable, just like Python itself.\n\n## Comparison\n\nRio doesn't just serve HTML templates like you might be used to from frameworks like Flask. In Rio you define components as simple dataclasses with a React/Flutter style build method. Rio continuously watches your attributes for changes and updates the UI as necessary.\n\n    class MyComponent(rio.Component):\n        clicks: int = 0\n\n        def _on_press(self) -> None:\n            self.clicks += 1\n\n        def build(self) -> rio.Component:\n            return rio.Column(\n                rio.Button('Click me', on_press=self._on_press),\n                rio.Text(f'You clicked the button {self.clicks} time(s)'),\n            )\n\n    app = rio.App(build=MyComponent)\n    app.run_in_browser()\n\nNotice how there is no need for any explicit HTTP requests. In fact there isn't even a distinction between frontend and backend. Rio handles all communication transparently for you. Unlike ancient libraries like Tkinter, Rio ships with over 50 builtin components in Google's Material Design. Moreover the same exact codebase can be used for both local apps and websites.\n\n## We Want Your Feedback!\n\nThe first alpha version of Rio is available on PyPi now:\n\n    pip install rio-ui\n    rio new my-project --template tic-tac-toe\n    cd my-project\n    rio run\n\n- [Discord](https://discord.gg/7ejXaPwhyH)\n- [GitHub](https://github.com/rio-labs/rio)\n- [Tutorial](https://rio.dev/get-started)\n- [Website](https://rio.dev/)\n\nLet us know what you think - any feedback, ideas, or even a helping hand are hugely welcome! Just hop on our Discord server and say hello!",
        "num_comments": 6,
        "comments": [
            "Hi, I\u2019m also part of the rio team and I hope rio can help you with your projects! :)\n\nCurrently, our main efforts are directed towards fine-tuning the rio concept, enhancing the overall user experience, and fostering a more conducive environment for community involvement.\n\nAdditionally, we're striving to streamline the deployment processes by working towards seamless integration with hosting platforms, enabling users to deploy their Rio applications with just a single click.",
            "First off, the documentation is fantastic so far! I haven\u2019t gotten into it too deep but I was able to install and start a project in a matter of minutes -most of which I spent upgrading my Python version haha. I can tell the docs are very clear and I\u2019m excited about this framework. Can\u2019t wait to really dig in.",
            "I've been diving deep into building interactive web apps with Dash.\u00a0I'm curious about the differences between Dash and this framework called Rio.\u00a0\n\nAre there any contrasting features?",
            "Thanks for your positive feedback! :)",
            "Thanks for your attention. Hi I'm chris and also core developer at Rio.\n\nThe main differences are:\n- with Rio you don't need HTML and CSS for styling.\n- in Rio you create your components mostly in classes, in Dash you will use a functional approach. \n- Rio handles the client-server communication for you.\n- Compared to Dash, Rio is a much newer framework and doesn't have a big community yet.\n\nThere are many more differences, but I would appreciate it, if you could test it out and provide us with your feedback!"
        ]
    },
    "The new REPL in Python 3.13.0 beta 1": {
        "title": "The new REPL in Python 3.13.0 beta 1",
        "score": 308,
        "url": "https://www.reddit.com/r/Python/comments/1cnf0p5/the_new_repl_in_python_3130_beta_1/",
        "content": "Python 3.13.0 beta 1 was released today.\n\nThe feature I'm most excited about is the new Python REPL.\n\n[Here's a summary of my favorite features in the new REPL along with animated gifs](https://treyhunner.com/2024/05/my-favorite-python-3-dot-13-feature/).\n\nThe TLDR:\n\n* Support for block-leveling history and block-level editing\n* Pasting code (even with blank lines within it) works as expected now\n* Typing `exit` will exit (no more `Use exit() or Ctrl-D (i.e. EOF) to exit` message)",
        "num_comments": 89,
        "comments": [
            "> Pasting code (even with blank lines within it) works as expected now\n\nMy god..... I thought I'd die before this was ever implemented",
            "To unbury the lede - it has adopted pypy\u2019s repl: https://x.com/pypyproject/status/1786705942438179279",
            "Great post, appreciate the gifs\n\nUltimately I don't see any reason to use the basic repl over ipython, but it's nice to have it when that's not available",
            "oh my god that block level history is gonna be amazing",
            "I'm exited to just be able to type `exit` to quit. I always seem to make this mistake",
            "I just use ptpython or bython and have been pleased with them so far",
            "Doesn't support Windows :(",
            "Still don't know why I'd use this over IPython.",
            "Cool! These are great QoL changes but\u2026 does anyone really even *use* the REPL?",
            "kinda weird that it doesn't support windows since ipython can do these things on all platforms",
            "When typing exit you still have to hit enter to make it exit, right? Otherwise I can see this messing up someone's naming convention (not mine).",
            "iPython is great but it behaves strangely with async code. Often exceptions in the code crashes the whole thing and it just exists. Once this launches, I will definitely pick it over iPython.",
            "Pasting code (even with blank lines within it) works as expected now is something I dreamed of.",
            "No windows support sucks. I code 99% of my time in windows. I know I might be a minority but that's a reality.",
            "Finally",
            "> So editing a block of code in the old REPL required hitting the up arrow many times, hitting Enter, hitting the up arrow many more times, hitting Enter, etc. until each line in a block was chosen.\n\nTechnically, you hit the up arrow the same amount of times each time \ud83d\ude09 You have to go past the lines you've rerun, but the next line to run is one line below the previous line.\n\nBut still, game changer.",
            "Also experimental support for removing the GIL. Exciting!",
            "\ud83d\ude02... So gets like one or two ipython features... But probably still terrible in comparison.",
            ">Typing `exit` will exit (no more `Use exit() or Ctrl-D (i.e. EOF) to exit` message)\n\nAbout time!!!!!!!!",
            "Oh... Doesn't support windows! Cool :D I hope that can be seen as a motivation to stop using legacy systems that stopped in the 90'.",
            "I wonder if this'll be better or worse than IPython. They had some catching up to do, and this sounds almost like feature parity, but it'd take a lot to convince me to switch",
            "I can't believe even Powershell doesn't have readline and curses yet. What's the hold up? Windows sucks.",
            "Single reason why I just automatically install ipython in any dev environment I create.",
            "I've been using ipython forever, when I end up without it my hands stop working.",
            "It's great to see CPython and PyPy working together and I hope we see more of it.",
            "It's good to have a good REPL if you're debugging in a production environment. Sometimes I fire up a REPL to test some stuff in an environment I can't install ipython",
            "For new Python users one of the first things they may try is pasting code into the REPL.",
            "> it's nice to have it when that's not available\n\nExactly this. When teaching, I often can't control the environments my students are running Python in and I try to avoid requiring them to install third-party packages. Also every new virtual environment I make lacks an IPython package until I actively install it. Having a much more usable default REPL is great for these cases.\n\nI'm glad you appreciated the gifs!",
            "Yep. Agree. Use ipython. \n\nSounds like it gets one or two ipyth features... But probably still terrible in comparison.",
            "I'm curious how it's implemented.\n\nWithout looking, I wonder if the old one had `Use exit() or Ctrl-D (i.e. EOF) to exit` as the `__repr__` for the `exit` function. Maybe now the `__repr__` just straight up calls `sys.exit()` instead?\n\n\nEDIT: Looks like my first guess was correct: https://github.com/python/cpython/blob/2f4db5a04d6fa7ba5c1c6b82b482dd7ca48f3382/Lib/code.py#L330\n\nnew repl has \"special\" commands that override the interpreter:\n\nhttps://github.com/python/cpython/blame/2f4db5a04d6fa7ba5c1c6b82b482dd7ca48f3382/Lib/_pyrepl/simple_interact.py#L60\n\nkinda ugly imo",
            "All the time, REPL is extremely useful for quick prototyping and sanity checks.\u00a0",
            "I do quite often to prototype a concept before implementing.",
            "Not the default one, but yeah ipython all the time",
            "Every day..  it's incredible useful.",
            "It's no Lisp sure, but yeah, fire up ipython (or one of the alternatives like ptpython), do quick sketches of code there. \n\nThen move it to your editor or jupyter when you're done. \n\nIt's kinda like creating SQL queries, honing them incrementally and testing it at the same time before actually putting it into code and eventually use.\nI *don't* know any python person who doesn't use the REPL. That's one of the strengths of any scripting language.",
            "Every pro I know uses the REPL quite often, for simple tests and to check snippets. Even for Q&D benchmarking.",
            "Constantly.",
            "I use ptpython all the time for one time quick automations.",
            "Actually yes! Several times per week usually, via the Django shell on my production websites. I don't want to have ipython/jupyter installed (personal choice, don't want to maintain yet another dependency), so I'll be very happy to see upgrades to the built-in functionality.\u00a0",
            "Many times per day. I use the standard built-in REPL, haven't used ipython in many years.",
            "Multiple times a day. I have ipython and bpython installed, and every once in a while I'll reach for one, but I'm generally just double checking that I understand how some bit of functionality works.\n\nMore often than a more robust repl, I'll just have the file I'm working on in one tmux pane and run it after saving in another.",
            "I use a REPL or REPL-like environment in Python every day.\n\nMy most common quick uses are as a calculator or as a \"let me quickly write a regular expression to grab specific values from this block of text\" tool.\n\nBut I also use the REPL for code exploration and discovery, especially when I don't quite know what I need to do to accomplish a specific task.\n\nIt might be `ipython` in a Django project that has `shell_plus` or I might launch it by running a file in interactive mode with `-i` or I might type `interact` from the Python debugger, which launches the default REPL.",
            "I use it every single day. The improvements in this post make me very excited. Block level history? Yes please!",
            "It's quite useful as a calculator. For me at least, it's easier to type something like \\`5+14/(9.5\\*\\*2)\\` in the repl then anywhere else. Or if I have a string in my clipboard I want to figure out the length of, it's faster than navigating to some web based character counter. Stuff like that. I can't imagine doing actual work with it.",
            "I'm surprised by the number of yes's here. Given the ergonomics (even with iPython), I find it way easier to prototype just keeping a throwaway file that I use for new code and can easily execute. That way I don't have to deal with paste or typo issues, have full editor support with keyboard shortcuts, get autocomplete, etc. Use what works for you obviously, but I have a hard time seeing how the repl can be faster for more than like 3 lines of code.",
            "Yes... But ipyth on repl... Not standard... Because it is pos.",
            "IPython relies on [prompt toolkit](https://github.com/prompt-toolkit/python-prompt-toolkit) which is a third-party library that avoids the use of the `curses` module, which this new REPL uses.  \n  \nThis REPL was borrowed from PyPy, so it's pure Python without any third-party requirements and was licensed in such a way that including it in core Python was relatively simple (in comparison to borrowing code from prompt toolkit).\n\nCore Python development is complex and changes are usually made fairly conservatively. I'm guessing (and hoping) that this change might encourage work on adding support for Python's built-in `curses` module on Windows, which would be a huge step in the direction of adding Windows support.",
            "That's right. Also, if you've defined a variable named \"exit\" (shadowing the built-in `exit` function) then typing `exit` will not exit either.",
            "Since when is Windows a 90s legacy system? Lack of Windows support for the new REPL is not the end of the world, but core Python will need to be supported for Windows for several decades still. Sure, most people will not be deploying Python on Windows; but as Windows is the majority of user desktop systems, most casual programmers will be using Windows. That will not change for a while.",
            "IPython has a superset of the features of the new REPL and I assume that will always be the case.\n\n\nIf you're happy using IPython, I'd stick with it!",
            "Auto complete in ipython is a killer feature.",
            "Try `bpython` and `pudb`! I personally like their autocompletion, coloring, and TUIs better than iPython/ipdb.",
            "If anything they should just have adopted ipython.",
            "To kind of answer the question below about whether someone uses the repl, my instinct here was to fire up the repl and do\n\n    >>> print(f\"the exit repr is '{exit}'\")\n    the exit repr is 'Use exit() or Ctrl-D (i.e. EOF) to exit'",
            "They didn't make `__repr__` call `sys.exit` because then simply looking at the string representation of all the builtins would exit the REPL.\n\n    >>> import sys\n    >>> def __repr__(self):\n    ...     sys.exit()\n    ...\n    >>> type(exit).__repr__ = __repr__\n    >>> help(\"builtins\")  # This will exit!",
            "> kinda ugly imo\n\nI remember there was some debate over this, I *think* this was the discussion that ended up leading it to be implemented: https://discuss.python.org/t/can-quit-be-made-to-quit/25072/39",
            "You're likely talking about ipython, not the standard REPL",
            "aware homeless illegal snails license marble airport paint school disgusted\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
            "This is mind blowing to me. I thought the REPL was for beginners and pros use notebooks.",
            "Different intros to python, I suspect? My impression is that ipython and jupyter and that sort of thing is more directed towards literate code and papers, while my usecase for python is more something that would've been perl or bash some decades ago. I also kind of use it as a \u2026 more familiar variant of `jq`, e.g. if I need to anything more complicated than find a needle in a haystack. Loading a first attempt in the repl, digging around a bit, and then writing down what I want to repeat works fine.",
            "If you're not quite sure what you need to do, it's easier to poke at objects in the REPL than by adding `print(obj)`, then `print(type(obj))`, then `print(dir(obj))`, etc. to your code and re-running our code between each additional bit of debug information you'd like to see.\n\nIn short: the REPL is great for exploratory work.\n\nAlso note that running `interact` from the Python debugger (which is also great for exploratory work) will launch the REPL and running `python -i my_file.py` will launch the REPL after loading a Python file (a great in-between to your use of a `.py` file and using the REPL standalone). Enhancing all those environments will be very helpful too!",
            "If anybody really wants to suggest dropping Windows support, they might first want to look at the (relatively) esoteric platforms that are still officially supported\n\nhttps://peps.python.org/pep-0011/#tier-3",
            "Well... Just facts hard to swallow for some people that are insisting on that error for so many years. You can accept or enter in a delusional mode. Microsoft is slightly reducing work labor over windows development to focus in other markets (cloud provider through azure, Linux support, web softwares etc)\n\nWindows is just museum software for now.\n\nI would not be surprised in the next 20 years to see Microsoft migrating the NT kernel to use a forked version of Linux.",
            "Thanks will do!",
            "pt(i)python ftw!",
            "haha definitely a lot simpler",
            "by \"ugly\" i meant implementation wise. What I love about python is that everything is an object and inspectable. But now there's \"magic\" commands that are not. I'm not sure if there's a different cleaner way it could've been done. putting the exit inside the `__repr__` might've been confusing I guess",
            "While I can't talk for him I use the standard python repl because it's always installed to do quick prototyping.",
            "Don\u2019t tell me what i know son",
            "ipython isn't always available. The REPL is.",
            "I know I should at least give this a try and I could easily see it becoming part of my workflow, but I'm so used to the REPL at this point lol",
            "Nah, many pros go back to the basics that are pre-installed and work consistently everywhere\n\neventually you just get tired of setting up fancy tools over and over, even if they are marginally nicer",
            "There is probably a bit of a divide between the \"I always use a mouse\" vs the \"I always use a keyboard\" types there.  \n\nI'm very much a keyboard type, but the REPL I use is IPython, so there's a lot of common functionality with notebooks.",
            "Windows (and desktop in general) can be declining, and the claims you are making can be delusional - both at the same time. It\u2019s not an either-or situation. The idea that Python would be dropped for Windows, or that Microsoft would migrate Windows to the Linux kernel - those two things are never going to happen.",
            "ptpython is great! I tend to prefer bpython's autocomplete though.",
            "I haven't read the implementation, but the discussion I linked to did discuss whether or not they should be magic commands.\n\nMaking a call to repr exit the console could have weird side effects, like you might be wanting to inspect the exit object and instead it ends up exiting.",
            "grey agonizing engine wine plants subtract connect tease spark fanatical\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
            "Pretty much everyone uses an IDE though.",
            "A couple of decades ago I never would've guessed that MS would move into actually doing open source either though. At the time we were still in the SCO wars, [Ballmer called Linux cancer](https://www.theregister.com/2001/06/02/ballmer_linux_is_a_cancer/); a decade and a half later [he recanted](https://www.zdnet.com/article/ballmer-i-may-have-called-linux-a-cancer-but-now-i-love-it/). And now they're working with actual open source licenses rather than that \"shared source\" bullshit they were peddling. They fund development for languages that they don't \"own\".\n\nThey're extremely unlikely to ever make Windows GNU-based, but using the Linux or BSD _kernel_ a couple of decades down the road? It'll likely be at least as painful as the switch from DOS to NT, i.e. highly unlikely that they'll do it, but it might also turn into a bit more of a boring business decision over how much value they're actually getting out of their proprietary kernel over using a Linux or BSD kernel. I.e. basically the same decision Apple made with OSX. Or similar to the decision MS made earlier when they turned their browser into yet another Blink/WebKit/KHTML derivative, so in a really roundabout way, the KDE browser engine wound up running in an official MS product.\n\nThough even if they did switch the kernel, I get the impression that people who don't like _Windows_ and would like it to be more unix-y would wind up learning a thing or two about why Stallman and GNU have been insisting that we say GNU all these years, and the differences a `libc` makes. As in, even though both `glibc` and `musl` binaries run on Linux, they're not the same thing.",
            "I dunno I use ipython, `%autoreload` and my IDE to develop locally. Mainly because that environment setup is super easy to steer newer developers toward when learning python and such.",
            "And for VSCode users, .ipynb files can be created directly and used as notebooks without needing a jupyterlab server. That's how I do all my prototyping.",
            "I use Sublime with TabNine and a few plugins, but nothing too fancy.\n\nMost of the work I do is not made any faster by getting the words from my head to the page faster, so I don't optimize my IDE experience as much as I used to.",
            "husky forgetful crush expansion humor imminent chubby ad hoc overconfident start\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
            "How do you deal with the performance issues when the notebook gets too large? VSCode will slow to an absolute crawl when my notebook gets to a certain size. I\u2019ve seen other people talking about it on the vscode GitHub but I didn\u2019t see a resolution",
            "> without needing a jupyterlab server\n\nIt could've changed now, but that's what vscode does under the hood anyway.",
            "I've never had that issue. What do you mean by size? Just lots of figures?",
            "ossified sharp point voracious seemly north frighten air mighty office\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
            "It creates an IPython kernel when you first run a cell from an .ipynb file, but that's a simpler operation than launching a jupyter server and connecting to it in your web browser. Especially if you're already using VSCode anyway."
        ]
    },
    "Calculating Virtual Cycling Power With Python": {
        "title": "Calculating Virtual Cycling Power With Python",
        "score": 21,
        "url": "https://www.reddit.com/r/Python/comments/1cnr0g3/calculating_virtual_cycling_power_with_python/",
        "content": "I was doing some light reading and stumbled across Steve Gribbles Power vs Speed Calculator and thought I'd give it a go at rebuilding it based on his Physics model using Python. Then I wrote an article about. Thought I'd share it with you all: [Calculating Virtual Cycling Power (jasonlei.com)](https://jasonlei.com/calculating-virtual-cycling-power)",
        "num_comments": 2,
        "comments": [
            "This is really neat! Great to see the math and the physics, especially as Python code.",
            "This is super neat - I enjoyed the write-up and the clean code. I'm personally a huge cycling fan and a big python user. \n\nI built out this cycling ML model that was trained to predict my power output based on my historical riding data. Check it out if you're interested!\n\n[https://github.com/jairus-m/StravaCyclingMLProject](https://github.com/jairus-m/StravaCyclingMLProject)"
        ]
    },
    "InterProcessPyObjects: Fast IPC for Sharing and Modifying Objects Across Processes": {
        "title": "InterProcessPyObjects: Fast IPC for Sharing and Modifying Objects Across Processes",
        "score": 31,
        "url": "https://www.reddit.com/r/Python/comments/1cnlumy/interprocesspyobjects_fast_ipc_for_sharing_and/",
        "content": "# InterProcessPyObjects Python package\n\n[github.com/FI-Mihej/InterProcessPyObjects](https://github.com/FI-Mihej/InterProcessPyObjects) If you like the project, consider giving it a star on GitHub to show your support and help further development. :)\n\n[pypi.org/project/InterProcessPyObjects](https://pypi.org/project/InterProcessPyObjects/)\n\n# What My Project Does\n\n> InterProcessPyObjects is a part of the [Cengal](https://github.com/FI-Mihej/Cengal) library. If you have any questions or would like to participate in discussions, feel free to join the [Cengal Discord](https://discord.gg/TAy7xNgR). Your support and involvement are greatly appreciated as Cengal evolves.\n\nThis high-performance package delivers blazing-fast inter-process communication through shared memory, enabling Python objects to be shared across processes with exceptional efficiency. By minimizing the need for frequent serialization-deserialization, it enhances overall speed and responsiveness. The package offers a comprehensive suite of functionalities designed to support a diverse array of Python types and facilitate asynchronous IPC, optimizing performance for demanding applications.\n\n# Target Audience\n\nThis project is designed for production environments, offering a stable API suitable for developers looking to implement fast inter-process communication. Whether you're building complex systems or require robust data sharing and modification across processes, InterProcessPyObjects is ready to meet your needs.\n\n# Comparison\n\nComparison with `multiprocessing.shared_memory`\n\nWhile both InterProcessPyObjects and multiprocessing.shared_memory facilitate inter-process communication, there are several key differences to note. Unlike multiprocessing.shared_memory, InterProcessPyObjects offers the following enhancements:\n\n* High-Performance Mutable Objects: Both connected processes can modify shared objects at runtime, and these changes are immediately reflected on the other side. This feature not only increases flexibility but also delivers exceptional performance, with the capability to handle up to several million changes per second.\n* Synchronization Features: Ensures that operations are thread-safe and data integrity is maintained across processes.\n* Message Queue: Integrates a system for queuing messages, making communication between processes more structured and reliable.\n* Extended Type Support: Supports a broad range of data types, including custom classes, which goes beyond the basic types typically handled by multiprocessing.shared_memory.\n\nThese features make InterProcessPyObjects a more robust option for developers requiring advanced inter-process communication capabilities.\n\n# API State\n\nStable. Guaranteed not to have breaking changes in the future. (see [github.com/FI-Mihej/InterProcessPyObjects?tab=readme-ov-file#api-state](https://github.com/FI-Mihej/InterProcessPyObjects?tab=readme-ov-file#api-state) for details)\n\n# Key Features\n\n* Shared Memory Communication:\n    * Enables sharing of Python objects directly between processes using shared memory.\n    * Utilizes a linked list of global messages to inform connected processes about new shared objects.\n\n* Lock-Free Synchronization:\n    * Uses memory barriers for efficient communication, avoiding slow syscalls.\n    * Ensures each process can access and modify shared memory without contention.\n\n* Supported Python Types:\n    * Handles various Python data structures including:\n        * Basic types: `None`, `bool`, 64-bit `int`, large `int` (arbitrary precision integers), `float`, `complex`, `bytes`, `bytearray`, `str`.\n        * Standard types: `Decimal`, `slice`, `datetime`, `timedelta`, `timezone`, `date`, `time`\n        * Containers: `tuple`, `list`, classes inherited from: `AbstractSet` (`frozenset`), `MutableSet` (`set`), `Mapping` and `MutableMapping` (`dict`).\n        * Pickable classes instances: custom classes including `dataclass`\n    * Allows mutable containers (lists, sets, mappings) to save basic types (`None`, `bool`, 64 bit `int`, `float`) internally, optimizing memory use and speed.\n\n* NumPy and Torch Support:\n    * Supports numpy arrays by creating shared bytes objects coupled with independent arrays.\n    * Supports torch tensors by coupling them with shared numpy arrays.\n\n* Custom Class Support:\n    * Projects pickable custom classes instances (including `dataclasses`) onto shared dictionaries in shared memory.\n    * Modifies the class instance to override attribute access methods, managing data fields within the shared dictionary.\n    * supports classes with or without `__dict__` attr\n    * supports classes with or without `__slots__` attr\n\n* Asyncio Compatibility:\n    * Provides a wrapper module for async-await functionality, integrating seamlessly with asyncio.\n    * Ensures asynchronous operations work smoothly with the package's lock-free approach.\n\n# Main principles\n\n* only one process has access to the shared memory at the same time\n* working cycle:\n    1. work on your tasks\n    2. acquire access to shared memory\n    3. work with shared memory as fast as possible (read and/or update data structures in shared memory)\n    4. release access to shared memory\n    5. continue your work on other tasks\n* do not forget to manually destroy your shared objects when they are not needed already\n* feel free to not destroy your shared object if you need it for a whole run and/or do not care about the shared memory waste\n* data will not be preserved between Creator's sessions. Shared memory will be wiped just before Creator finished its work with a shared memory instance (Consumer's session will be finished already at this point)\n\n# Examples\n\n* An async examples (with asyncio):\n    * [sender.py](https://github.com/FI-Mihej/InterProcessPyObjects/blob/master/example/sender.py)\n    * [receiver.py](https://github.com/FI-Mihej/InterProcessPyObjects/blob/master/example/receiver.py)\n    * [shared_objects__types.py](https://github.com/FI-Mihej/InterProcessPyObjects/blob/master/example/shared_objects__types.py)\n\n## Receiver.py performance measurements\n\n* CPU: i5-3570@3.40GHz (Ivy Bridge)\n* RAM: 32 GBytes, DDR3, dual channel, 655 MHz\n* OS: Ubuntu 20.04.6 LTS under WSL2. Windows 10\n\n```python\nasync with ashared_memory_context_manager.if_has_messages() as shared_memory:\n    # Taking a message with an object from the queue.\n    sso: SomeSharedObject = shared_memory.value.take_message()  # 5_833 iterations/seconds\n\n    # We create local variables once in order to access them many times in the future, ensuring high performance.\n    # Applying a principle that is widely recommended for improving Python code.\n    company_metrics: List = sso.company_info.company_metrics  # 12_479 iterations/seconds\n    some_employee: Employee = sso.company_info.some_employee  # 10_568 iterations/seconds\n    data_dict: Dict = sso.data_dict  # 16_362 iterations/seconds\n    numpy_ndarray: np.ndarray = data_dict['key3']  # 26_223 iterations/seconds\n\n# Optimal work with shared data (through local variables):\nasync with ashared_memory_context_manager as shared_memory:\n    # List\n    k = company_metrics[CompanyMetrics.avg_salary]  # 1_535_267 iterations/seconds\n    k = company_metrics[CompanyMetrics.employees]  # 1_498_278 iterations/seconds\n    k = company_metrics[CompanyMetrics.in_a_good_state]  # 1_154_454 iterations/seconds\n    k = company_metrics[CompanyMetrics.websites]  # 380_258 iterations/seconds\n    company_metrics[CompanyMetrics.annual_income] = 2_000_000.0  # 1_380_983 iterations/seconds\n    company_metrics[CompanyMetrics.employees] = 20  # 1_352_799 iterations/seconds\n    company_metrics[CompanyMetrics.avg_salary] = 5_000.0  # 1_300_966 iterations/seconds\n    company_metrics[CompanyMetrics.in_a_good_state] = None  # 1_224_573 iterations/seconds\n    company_metrics[CompanyMetrics.in_a_good_state] = False  # 1_213_175 iterations/seconds\n    company_metrics[CompanyMetrics.avg_salary] += 1.1  # 299_415 iterations/seconds\n    company_metrics[CompanyMetrics.employees] += 1  # 247_476 iterations/seconds\n    company_metrics[CompanyMetrics.emails] = tuple()  # 55_335 iterations/seconds (memory allocation performance is planned to be improved)\n    company_metrics[CompanyMetrics.emails] = ('sails@company.com',)  # 30_314 iterations/seconds (memory allocation performance is planned to be improved)\n    company_metrics[CompanyMetrics.emails] = ('sails@company.com', 'support@company.com')  # 20_860 iterations/seconds (memory allocation performance is planned to be improved)\n    company_metrics[CompanyMetrics.websites] = ['http://company.com', 'http://company.org']  # 10_465 iterations/seconds (memory allocation performance is planned to be improved)\n    \n    # Method call on a shared object that changes a property through the method\n    some_employee.increase_years_of_employment()  # 80548 iterations/seconds\n\n    # Object properties\n    k = sso.int_value  # 850_098 iterations/seconds\n    k = sso.str_value  # 228_966 iterations/seconds\n    sso.int_value = 200  # 207_480 iterations/seconds\n    sso.int_value += 1  # 152_263 iterations/seconds\n    sso.str_value = 'Hello. '  # 52_390 iterations/seconds (memory allocation performance is planned to be improved)\n    sso.str_value += '!'  # 35_823 iterations/seconds (memory allocation performance is planned to be improved)\n\n    # Numpy.ndarray\n    numpy_ndarray += 10  # 403_646 iterations/seconds\n    numpy_ndarray -= 15  # 402_107 iterations/seconds\n\n    # Dict\n    k = data_dict['key1']  # 87_558 iterations/seconds\n    k = data_dict[('key', 2)]  # 49_338 iterations/seconds\n    data_dict['key1'] = 200  # 86_744 iterations/seconds\n    data_dict['key1'] += 3  # 41_409 iterations/seconds\n    data_dict['key1'] *= 1  # 40_927 iterations/seconds\n    data_dict[('key', 2)] = 'value2'  # 31_460 iterations/seconds (memory allocation performance is planned to be improved)\n    data_dict[('key', 2)] = data_dict[('key', 2)] + 'd'  # 18_972 iterations/seconds (memory allocation performance is planned to be improved)\n    data_dict[('key', 2)] = 'value2'  # 10_941 iterations/seconds (memory allocation performance is planned to be improved)\n    data_dict[('key', 2)] += 'd'  # 16_568 iterations/seconds (memory allocation performance is planned to be improved)\n\n# An example of non-optimal work with shared data (without using a local variables):\nasync with ashared_memory_context_manager as shared_memory:\n    # An example of a non-optimal method call (without using a local variable) that changes a property through the method\n    sso.company_info.some_employee.increase_years_of_employment()  # 9_418 iterations/seconds\n\n    # An example of non-optimal work with object properties (without using local variables)\n    k = sso.company_info.income  # 20_445 iterations/seconds\n    sso.company_info.income = 3_000_000.0  # 13_899 iterations/seconds\n    sso.company_info.income *= 1.1  # 17_272 iterations/seconds \n    sso.company_info.income += 500_000.0  # 18_376 iterations/seconds\n    \n    # Example of non-optimal usage of numpy.ndarray without a proper local variable\n    data_dict['key3'] += 10  # 6_319 iterations/seconds\n\n# Notify the sender about the completion of work on the shared object\nasync with ashared_memory_context_manager as shared_memory:\n    sso.some_processing_stage_control = True  # 298_968 iterations/seconds\n```\n\n# Throughput Benchmarks\n\n* CPU: i5-3570@3.40GHz (Ivy Bridge)\n* RAM: 32 GBytes, DDR3, dual channel, 655 MHz\n* OS: Ubuntu 20.04.6 LTS under WSL2. Windows 10\n\n## Refference results (sysbench)\n\n```bash\nsysbench memory --memory-oper=write run\n```\n\n```\n5499.28 MiB/sec\n```\n\n## Benchmarks results table GiB/s\n\n| Approach                        | sync/async | Throughput GiB/s |\n|---------------------------------|------------|------------------|\n| InterProcessPyObjects (sync)    | sync       | 3.770            |\n| InterProcessPyObjects + uvloop  | async      | 3.222            |\n| InterProcessPyObjects + asyncio | async      | 3.079            |\n| multiprocessing.shared_memory * | sync       | 2.685            |\n| uvloop.UnixDomainSockets        | async      | 0.966            |\n| asyncio + cengal.Streams        | async      | 0.942            |\n| uvloop.Streams                  | async      | 0.922            |\n| asyncio.Streams                 | async      | 0.784            |\n| asyncio.UnixDomainSockets       | async      | 0.708            |\n| multiprocessing.Queue           | sync       | 0.669            |\n| multiprocessing.Pipe            | sync       | 0.469            |\n\n`*` [multiprocessing.shared_memory.py](https://github.com/FI-Mihej/Cengal/blob/master/cengal/parallel_execution/asyncio/ashared_memory_manager/versions/v_0/development/plain_python__send_bytes__shared_memory.py) - simple implementation. This is a simple implementation because it uses a similar approach to the one used in `uvloop.*`, `asyncio.*`, `multiprocessing.Queue`, and `multiprocessing.Pipe` benchmarking scripts. Similar implementations are expected to be used by the majority of projects.\n\n# Todo\n\n* Connect more than two processes\n* Use third-party fast hashing implementations instead of or in addition to built in `hash()` call\n* Continuous performance improvements\n\n# Conclusion\n\nThis Python package provides a robust solution for inter-process communication, supporting a variety of Python data structures, types, and third-party libraries. Its lock-free synchronization and asyncio compatibility make it an ideal choice for high-performance, concurrent execution.\n\n# Based on [Cengal](https://github.com/FI-Mihej/Cengal)\n\nThis is a stand-alone package for a specific Cengal module. Package is designed to offer users the ability to install specific Cengal functionality without the burden of the library's full set of dependencies.\n\nThe core of this approach lies in our 'cengal-light' package, which houses both Python and compiled Cengal modules. The 'cengal' package itself serves as a lightweight shell, devoid of its own modules, but dependent on 'cengal-light[full]' for a complete Cengal library installation with all required dependencies.\n\nAn equivalent import:\n\n```python\nfrom cengal.hardware.memory.shared_memory import *\nfrom cengal.parallel_execution.asyncio.ashared_memory_manager import *\n```\n\nCengal library can be installed by:\n\n```bash\npip install cengal\n```\n\nhttps://github.com/FI-Mihej/Cengal\n\nhttps://pypi.org/project/cengal/\n\n# Projects using Cengal\n\n* [CengalPolyBuild](https://github.com/FI-Mihej/CengalPolyBuild) - A Comprehensive and Hackable Build System for Multilingual Python Packages: Cython (including automatic conversion from Python to Cython), C/C++, Objective-C, Go, and Nim, with ongoing expansions to include additional languages. (Planned to be released soon) \n* [cengal_app_dir_path_finder](https://github.com/FI-Mihej/cengal_app_dir_path_finder) - A Python module offering a unified API for easy retrieval of OS-specific application directories, enhancing data management across Windows, Linux, and macOS \n* [cengal_cpu_info](https://github.com/FI-Mihej/cengal_cpu_info) - Extended, cached CPU info with consistent output format.\n* [cengal_memory_barriers](https://github.com/FI-Mihej/cengal_memory_barriers) - Fast cross-platform memory barriers for Python.\n* [flet_async](https://github.com/FI-Mihej/flet_async) - wrapper which makes [Flet](https://github.com/flet-dev/flet) async and brings booth Cengal.coroutines and asyncio to Flet (Flutter based UI)\n* [justpy_containers](https://github.com/FI-Mihej/justpy_containers) - wrapper around [JustPy](https://github.com/justpy-org/justpy) in order to bring more security and more production-needed features to JustPy (VueJS based UI)\n* [Bensbach](https://github.com/FI-Mihej/Bensbach) - decompiler from Unreal Engine 3 bytecode to a Lisp-like script and compiler back to Unreal Engine 3 bytecode. Made for a game modding purposes\n* [Realistic-Damage-Model-mod-for-Long-War](https://github.com/FI-Mihej/Realistic-Damage-Model-mod-for-Long-War) - Mod for both the original XCOM:EW and the mod Long War. Was made with a Bensbach, which was made with Cengal\n* [SmartCATaloguer.com](http://www.smartcataloguer.com/index.html) - TagDB based catalog of images (tags), music albums (genre tags) and apps (categories)\n\n# License\n\nLicensed under the Apache License, Version 2.0.\n",
        "num_comments": 1,
        "comments": [
            "Feel free to share your thoughts and ask questions in the comments! If you like the project, consider giving it a star on GitHub to show your support and help further development. :)"
        ]
    },
    "AzuracastPy: An Unofficial Python Wrapper for the Azuracast API.": {
        "title": "AzuracastPy: An Unofficial Python Wrapper for the Azuracast API.",
        "score": 7,
        "url": "https://www.reddit.com/r/Python/comments/1cnsoz5/azuracastpy_an_unofficial_python_wrapper_for_the/",
        "content": "[Source code](https://github.com/ARandomBoiIsMe/AzuracastPy)\n\n**What My Project Does:**\n\nIt acts as a wrapper for the [AzuraCast](https://www.azuracast.com/) API, providing custom functions and classes for more straightforward use of the API in python projects.\n\n**Target Audience:**\n\nPython users who are interested in programmatically interacting with online radios hosted on [AzuraCast](https://www.azuracast.com/).\n\n**Comparison:**\n\nThe idea of API Wrappers is not new. However, I noticed that the only existing wrapper for this API is written in [PHP](https://github.com/AzuraCast/php-api-client), which I am not experienced with. I created this project so I, and other python programmers by extension, could have an easier time working with the API.\n\nThis is my first \"major\" programming project, so thoughts and feedback are welcome and greatly appreciated.\n\nPS: Shoutout to [PRAW](https://github.com/praw-dev/praw) for \"inspiring\" basically everything about the project's structure and functionality.",
        "num_comments": 1,
        "comments": [
            "first time i hear about azuracast, seems amazing. i ran a radio a few years ago but it was cobbled togheter with liquidsoap, icecast and a flask web ui. getting info of the current song on the website required me to scrape the icecast status page"
        ]
    },
    "diskcache: This key-value store library is faster than Redis and Memcached \ud83d\ude2e (built by Grant Jenks)": {
        "title": "diskcache: This key-value store library is faster than Redis and Memcached \ud83d\ude2e (built by Grant Jenks)",
        "score": 5,
        "url": "https://www.reddit.com/r/Python/comments/1cnsgs1/diskcache_this_keyvalue_store_library_is_faster/",
        "content": "[PYPI](https://pypi.org/project/diskcache/)\n\n(From the README, Released Last Year, Edited by Grammarly)  \n  \n[Github](https://github.com/grantjenks/python-diskcache)\n\n`pip install diskcache`\n\nThe cloud-based computing of 2024 puts a premium on memory. Gigabytes of space are left on disks as processes vie for memory. Memcached (and sometimes Redis) is used as a cache among these processes. Wouldn\u2019t it be nice to leverage empty disk space for caching?\n\nDjango is Python\u2019s most popular web framework and has several caching backends. Unfortunately, the file-based cache in Django is essentially broken. The culling method is random and large caches repeatedly scan a cache directory which slows linearly with growth. Can you allow it to take sixty milliseconds to store a key in a cache with a thousand items?\n\nIs it that fast?\n\n    In [1]: import pylibmc\n    In [2]: client = pylibmc.Client(['127.0.0.1'], binary=True)\n    In [3]: client[b'key'] = b'value'\n    In [4]: %timeit client[b'key']\n    \n    10000 loops, best of 3: 25.4 \u00b5s per loop\n    \n    In [5]: import diskcache as dc\n    In [6]: cache = dc.Cache('tmp')\n    In [7]: cache[b'key'] = b'value'\n    In [8]: %timeit cache[b'key']\n    \n    100000 loops, best of 3: 11.8 \u00b5s per loop",
        "num_comments": 3,
        "comments": [
            "Does it say why? Like what do they do differently?\n\n\n Because redis threading model makes it close to optimal for the single threaded case (in terms of the number of locks/aromics needed) but it's nit the best in the multithreaded case and keydb showed that",
            "It's in process so you don't need to do sockets which makes it faster.\nThis is a very nice use case. \n\nIf u wanted it even faster I bet u can use c for a lot of itninstead of the raw python.\n\n I have been toying around with the idea of making a high preformance c/zig lib for python web apps. If this is something that's needed I may start working on it"
        ]
    },
    "Who is using quart framework for microservices?": {
        "title": "Who is using quart framework for microservices?",
        "score": 34,
        "url": "https://www.reddit.com/r/Python/comments/1cn8zg3/who_is_using_quart_framework_for_microservices/",
        "content": "I am using quart framework (https://quart.palletsprojects.com) for a number of microservices in a SaaS application. However, I hardly hear anything about this framework on any social media platform which seems to be dominated by FastAPI. Also I'm unable to find which all projects/companies are using this framework. All this is leading to anxiety around the future of this project. \n\nAre there any well known projects / companies which are using this framework for microservices?",
        "num_comments": 28,
        "comments": [
            "I've never even heard of it until this post.",
            "I think a relevant question is: with the likes of Flask, Django and FastAPI - which all have positive track records, significant communities and all but guaranteed support for years to come - what problem is Quart solving that those do not which led you to select it?",
            "I used Quart when I had to build a service endpoint that had to handle multiple streaming requests concurrently, relaying the streams to an internal service and streaming the results back to the client. It would have been extremely inefficient to use a non async-capable framework, and it was super easy to adopt since most Flask middlewares and decorators are either supported or ported.",
            "Hello /u/Dry_Raspberry4514 thank you for using Quart! I think the reason you don't hear much about Quart is that I'm terrible at marketing.\n\n> All this is leading to anxiety around the future of this project.\n\nI think Quart's future is very rosy; as of 2 years ago [Quart joined Pallets](https://palletsprojects.com/blog/quart-pallets/) who maintain Flask with the stated aim of merging the frameworks. Whilst this aim is [tricky](https://youtu.be/bw1qeMoFBmw) Quart now has a dedicated and funded group as its custodian.\n\nI should also point out that Quart is a fairly mature async project now - it started in 2017 and is mostly based on Werkzeug (and parts of Flask) that have been maintained since ~2010. \n\n> dominated by FastAPI\n\nI'm often asked about how Quart compares with FastAPI so I wrote this [blog post](https://pgjones.dev/blog/fastapi-flask-quart-2022/). \n\nYou may not be aware of [Quart-Schema](https://github.com/pgjones/quart-schema) which provides OpenAPI autogenerated documentation and validation using Pydantic, msgspec, or attrs. \n\nThank you for the comments saying how it made for an easy Flask -> async transition. This was the driving motivation for Quart.",
            "I have been aware of it, not having built anything with it yet.\nI've read that it is fairly similar to Flask but better support for async operations.",
            "I am using Nameko for a fairly large project and I dont hear anything about it either. Which is a shame",
            "I actually switched from Flask to Quart for (https://doroad.ai) and the most important thing for me to make the move was how simple it was, I was my own biggest lazy hurdle in the transition by not updating somethings to async which is to say it was super easy to switch.",
            "I\u2019ve been using Quart for a recent project of mine, I have been enjoying it so far. I like that Quart supports blueprints that came from Flask. Being backwards compatible with Flask extensions is also a nice bonus.",
            "We have a user facing service in production, It has only one path and it does not require complex authentication. It has been providing a good performance with a single and very resource constrained pod in k8s. It was running for almost 8 months before we needed to do some changes, pretty solid.\n\nI agree that is not that popular, but I believe is due to its nature. Usually you need something that already implements common features instead of needing to write everything from scratch.",
            "I used it and am still using it for 1 product (not scaled), companies that use this framework are mostly micro services, I have a group of dev founders few of them also uses it",
            "Been working on an events-driven rewrite of a professionnal project that is running on a custom framework on top of aiohttp, so far so good. I had a bit of trouble integrating SocketIO in it but it works now. I just wish the community was a bit bigger",
            "I've heard of it, messed with it a bit. It's basically asynchronous Flask.  I bought a book about python microservices, and this is the framework they taught under. That's as much as I've done with it. I wouldn't worry  about your projects future. I'm sure it'll (Quart) be around a while.  Personally I use FastAPI. It just has features that I enjoy using more than any other and I'm just really comfortable with the layout. \n\nI'm not sure why we haven't heard much about many professionals using it at work or for work. It's likely just that Flask and Django dominate the Python ecosystem so much more when it comes to frameworks for the web. There are also about 50 other python frameworks that are equally as good as any it these.  Bottle, Black sheep, tornado, there are a ton of them .",
            "I started to migrate from flask to quart but had to stop midway because quart-session library was not drop-in replacement for flask-session. I needed filesystem session storage however iirc, quart-session supports redis only. This prob creates an area for contribution to library as well I guess but that is what my observation was. Otherwise I found quart pretty good.",
            "ME! the app of my company, that I projected and writed, was initially writted in flask but I needed to migrate to flask due to performance and async/await issues",
            "Just you",
            "I'm not surprised at your comment. It seems I need to do the marketing for this framework :-)\n\nI switched from flask to quart when I was looking for something which has been designed from scratch as async  first framework and I liked it very much. Recently looked into FastAPI as well but found quart ~~more useful and easy~~ easier for someone who would like to migrate away from flask for async.",
            "I have heard of Quart sometime back and I thought it was just a gimmick or else there would have been some kind of chatter in the web about this.",
            "Quart is an async first framework and Flask didn't have support for async when I looked into it last time few years back. That was the whole reason to go for Quart.\n\nMigration from Flask to Quart is as simple as replacing flask word with quart word and using async in front of function definitions. I don't think migration from Flask to FastAPI is this much simple.\n\nHaving worked with Pydantic extensively, tight integration of it with fastapi can cause issues IMO. For example, whenever I persist a business object in the DB, we generate id and populate some other fields (e.g. tenant id, user id etc) before initializing the pydantic model class to trigger the validation where all these parameters are marked as mandatory. I believe in case of FastAPI you need to mark such fields as optional as it converts request body to Pydantic model class object automatically. This may result in NOT triggering validation errors until business object is persisted in the DB.\n\nOther thing which I found little strange is supporting before\\_request using [dependency injection](https://engineering.forethought.ai/blog/2023/02/14/migrating-from-flask-to-fastapi-part-2/#flask-before_request) which will pollute function inputs parameters. This one may not be an issue for someone who is starting with FastAPI directly instead of migrating from Flask to FastAPI.",
            "Flask only support WSGI. So it is essentialky outdated. The thing that makes FastAPI \"fast\" is the fact it uses ASGI instead.\n\n\nQuart is literally the ASGI version of Flask. Even made by the same group of devs (Pallets Projects).\u00a0",
            "  \nHi u/stetio , Thanks for your inputs. I found you on twitter and was going to ping you there to get your inputs on this topic. Glad that you provided your inputs here before that.  I'm now convinced that I didn't make a wrong choice.\n\n>I think the reason you don't hear much about Quart is that I'm terrible at marketing.\n\nThat is true for most of the developers (including me), if not all. \n\nLooking at your post history in this sub, I can see that you have been posting about quart here regularly for quite some time. So I'm surprised that a lot of people are not aware about this framework. Probably posting on twitter (with a dedicated handle for quart) and linkedin will help you and the team/community working on Pallets project to get good visibility for these tools/frameworks.\n\nFinally thanks to you and the community for creating such an amazing framework.",
            "I, too, chose Quart due to exact same reason.",
            "I'm moving my FOSS automation server to Quart right now after ten years on CherryPy.\n\nI choose it largely because it's a fairly easy migration path thanks to still being request context based, but also because of it's close ties with Flask.\n\nI assume it won't just vanish in a few years if Pallets is in on it, and it mostly just reimplements flask, which l like and more importantly, everyone else seems to like too, it's a standard everyone knows.\n\nIn the process I discovered just how much CherryPy's implicitly class navigation routing was holding me back and how nice the explicit model is especially when you have a partly plugin based architecture.\n\nI also really like that it has some limited support for synchronous handlers, and helpers to do sync tasks, so gradual migration is possible.\n\nSome of what I used to do with Cherrypy tools I now do with ASGI Middleware, and I love how easy it is to write those, and how you can compose smaller ASGI apps with dispatchers.\n\n  \nBut.... I still feel some of the concerns you mention, and wonder if I should have used FastAPI, because it seems like the popular choice.",
            "what parts did you find more useful?",
            "Im not sure I entirely understand your issue with FastAPI and pydantic, but generally my approach is to have the API use a pydantic \"creation\" schema, and then the response schema is then complete schema with the IDs.\n\nFor example, then request schema could be:\n\n```python\nclass UserCreationSchema(BaseModel):\n    email: string\n```\n\nAnd the response schema:\n\n```\nclass UserSchema(UserCreationSchema):\n    id: int\n```\n\nThen you can even have intermediate schemas like \"UserCreationAPISchema(BaseModel)\" which is then expanded upon by a service level schema that adds any internal fields \"UserCreationServiceSchema(UserCreationAPISchema)\", etc.",
            "I wouldn\u2019t call Flask outdated because it uses WSGI",
            "Yes Flask is not outdated but I believe it should be deprecated in favor of Quart or something similar. An async first framework can be used as both synchronous and asynchronous framework but vice versa is not true.",
            "Why Quart over aiohttp?",
            "I'd say it depends highly on your use case, but if you do not have long running or real-time connections, then I'd even say WSGI is the preferred option since it avoids the added complexity of asynchronous programming, thus resulting in a more maintainable and debugable application\n\nEdit: When deploying a Flask app with Gunicorn, you can run it with greenlet workers, which essentially makes it behave like an ASGI application\u00a0"
        ]
    },
    "Why is Plotly so cumbersome to tweak?": {
        "title": "Why is Plotly so cumbersome to tweak?",
        "score": 119,
        "url": "https://www.reddit.com/r/Python/comments/1cn01jc/why_is_plotly_so_cumbersome_to_tweak/",
        "content": "I made this [visualisation](https://imgur.com/a/f4joWfl) with this [code](https://smalldev.tools/share-bin/KBzld6Wi).\n\nI have three questions:\n\n1. Is Plotly supposed to be this cumbersome to tweak? Would other libraries require the same amount of code to add the details I did?\n2. Can my code be reduced in size? Maybe it's me who is complicating things with Plotly and there are easier ways to do what I am doing.\n3. Any R enthusiast who can tell me how much shorter this code would look like with ggplot2? I asked ChatGPT but the result was garbage.\n\nBonus question: This took me an entire morning. Is it normal to be \"that slow\" to plot a simple figure?",
        "num_comments": 77,
        "comments": [
            ">This took me an entire morning. Is it normal to be \"that slow\" to plot a simple figure?\n\n\nThe first time i always hard. Most basic tutorials often fail at the first sign of reality, especially when you add graphics,  usability and other usable output.\n\nKnowing which knobs to turn is the skill you learn.",
            "You have quite some reptition. I'm on mobile, but to make my point, some pseudocode:\n\n\n```python\ndef add_line(plot, region, color, etc...):\n       #add line to plot\n\ndef add_area(plot, region, color, etc...):\n       # Add sd area to plot\n\n\ndef add_annotation(plot, region, color, etc...):\n       # Add annotation\n\ndef add_data_to_plot(plot, region, color, etc...):\n       add_line(arguments)\n       add_area(arguments)\n       add_annotation(arguments)\n\n\nPlot = InitializePlot()\nFor region in regions:\n   add_data_to_plot()\n```\n\n\n\nAs for R: yeah its probably less code but trust me,continue to learn python. R is great for analytics (and some academic modelling). Python is better for almost everything else. In Ggplot or any other language the same suggestions I made above apply.",
            "IMO ggplot is substantially better than anything python has to offer (for static charts). The way of expressing the mapping between data and aesthetics enables succinct descriptions of all sorts of vizualisations.\n\nThat being said, charting is always an 80-20 exercise, where very little time might be spent to get something useful but then the final tweaks and labelling takes a lot longer.\n\nFor your comparison I've (nearly) recreated your chart using ggplot. I first reshaped the SSP data into a data frame with the relevant columns: Region, Year, Pop\\_SSP1, Pop\\_SSP2, Pop\\_SSP3:\n\n```r\ndf_chart <- df %>%\n  pivot_longer(\n    -c(\"Model\":\"Unit\"), \n    names_to = \"Year\",\n    values_to = \"Population\",\n    names_transform = as.integer\n  ) %>%\n  pivot_wider(names_from = Scenario, values_from = Population, names_prefix = \"Pop_\")\n```\n\nGetting a quick chart is easy:\n```r\nggplot(df_chart, aes(x = Year)) +\n  geom_ribbon(aes(ymin = Pop_SSP1, ymax = Pop_SSP3, fill = Region), alpha = 0.5) +\n  geom_line(aes(y = Pop_SSP2, col = Region))\n\n```\n\nAdding the labels and formatting requires a few more lines (but is still but simpler and easier than in plotly (IMO)):\n```r\nregion_colors <- c(\n  \"Ghana\" = rgb(201, 53, 26, maxColorValue = 255),\n  \"Zimbabwe\" = rgb(197, 90, 28, maxColorValue = 255),\n  \"Kenya\" = rgb(202, 163, 40, maxColorValue = 255)\n)\n\ntransition_year <- 2040\nlabel_year <- 2050\nmax_pop <- max(df_chart$Pop_SSP3)\n\nggplot(df_chart, aes(x = Year, y = Pop_SSP2)) +\n  geom_ribbon(aes(ymin = Pop_SSP1, ymax = Pop_SSP3, fill = Region), alpha = 0.5) +\n  geom_line(aes(col = Region)) +\n  geom_vline(aes(xintercept = transition_year), linetype = \"dashed\") +\n  geom_text(data = . %>% filter(Year == max(Year)), aes(label = sprintf(\"%0.2fM\", Pop_SSP2)), hjust = 0) +\n  geom_text(data = . %>% filter(Year == label_year), aes(label = Region, y = Pop_SSP1), hjust = 0, vjust = 1) +\n  annotate(\"text\", x = transition_year, y = max_pop, label = \"Estimation\", hjust = 1.1) +\n  annotate(\"text\", x = transition_year, y = max_pop, label = \"Projection\", hjust = -0.1) + \n  scale_x_continuous(expand = expansion(add = c(NA, 10))) + \n  scale_y_continuous(labels = function(x) sprintf(\"%dM\", x)) +\n  scale_color_manual(values = region_colors, aesthetics = c(\"color\", \"fill\")) +\n  theme_minimal() +\n  theme(panel.grid = element_blank(), axis.title = element_blank(), legend.position = \"none\") +\n  labs(\n    title = \"Population in the three case study countries\",\n    subtitle = \"Based on SSP 2024 release. Thick lines represent SSP2, lower and upper bounds correspond to SSP1 and SSP3.\"\n  )\n```",
            "You have the wrong approach to plotly. Thats all! First,  only use the plotly.go if you really need to. Continous error bands that you have are actually one of the few examples I use plotly.go . Second, I recommend you to use plotly.express. If you need error bands wrap plotly.go functionality with the figure.data object of plotly express. It is done here: https://stackoverflow.com/questions/69587547/continuous-error-band-with-plotly-express-in-python\n\nUsing plotly express makes your code more modular since you separate the code for visualization and the data. It is also much faster to develope and cleaner ro read. A plot like you have done would take me maybe 5 minutes.",
            "> Is it normal to be \"that slow\" to plot a simple figure?\n\nDepends if you've already worked with the library many times in the last few months, or if this was basically the first time and every second line of code you were going back to the reference docs to know how to adjust things.\n\n\n---\n\nI've probably fucked at least one thing up in this code, but you can see you have lots of repeated but slightly different scatter calls. Those can be reduced with some functions and arguments.\n\n    for i, region in enumerate(regions):\n        regionData = sspPop[sspPop[\"Region\"] == region]\n        colorLine = colorLines[i]\n        colorArea = colorAreas[i]\n\n        def custom_scatter(data, scenario, line_width, fill_type=None):\n            args = dict(\n                    x=data[data[\"Scenario\"] == scenario][\"Year\"],\n                    y=data[data[\"Scenario\"] == scenario][\"Population\"],\n                    mode=\"lines\",\n                    name=region,\n                    line=dict(color=colorLine, width=line_width),\n                    legendgroup=region,\n                    showlegend=False,\n            )\n            if fill_type is not None:\n                args.update(fill_type)\n            fig.add_trace(go.Scatter(**args))\n\n        scenario_config = {\n            \"Historical Reference\": {\"line_width\": 1},\n            \"SSP1\": {\"line_width\": 0},\n            \"SSP2\": {\"line_width\": 1},\n            \"SSP3\": {\"line_width\": 0, \"fill_type\": {\"fill\": \"tonexty\", \"fillcolor\": colorArea}},\n        }\n\n        for scenario in regionData[\"Scenario\"].unique():\n            args = scenario_config[scenario]\n            custom_scatter(regionData, scenario, **args)",
            "This doesn't seem like that much code to produce a highly customized graphic like that. If you're producing a lot of similar graphics with the same customizations, you could definitely put a lot of the boilerplate into a shared function/definition. But I don't think there's much fat to trim for just a single graphic.",
            "Omg you used fig. Try plotly express - lots of modular code you can tweak. I am in no means an expert but over time (starting with fig) and eventually moving to px and dash ddk - was able to exponentially get more efficient. \n\nAt that time - Examples on the internet were non existent - you sadly have to trawl through the documentation and create unique examples for yourself.\n\nYou should be able to drastically reduce the lines of code for your particular chart imho",
            "Plotly express is super easy to do very basic things without much customization.\n\nGraph objects (go) is much more versatile and after a while I can do things in a quick amount of time and with mnay more specifications.\n\nIt'll take some time but you'll get proficient and by then it's a breeze.",
            "Not to be that guy, but plotly kind of blows. \n\nI find the syntax of Altair to be a lot better and easier to write code for.\n\nOnly thing it's not as great at is outputting the plot images. It can be done natively in the Altair package now, it's just slower than comparable.plotly plots.",
            "People have already mentioned your repetitive code a bit, the more you work with it the faster it'll get. It takes me awhile to write code with new libraries.\n\nA different issue ive been having with plotly is how un-mobile friendly it is. For the life of me I haven't been able to figure out anything that makes charts readable on mobile. How does your look if you change the aspect ratio?",
            "Plotly's paradigm kind of expects you to put together a couple templates and consistent workflows for yourself. The cold start is brutal, tbh",
            "Apropos of nothing else, that's a really well-done visualization.",
            "All of plotly can be initialized in one line\u2026.\n\ngo.Figure(data=[dict(type=\u201cscatter\u201d,\u2026), layout=dict(),\u2026)",
            "Pygwalker in a jupyter notebook is a good alternative too, no tweaking required since there is a GUI\n\nEdit: typo",
            "Over the last 3 weeks, I used JavaScript for the first time really and then learned Typescript for D3 because of a frustration with plotly.",
            "Plotly is not great. Don't waste your time.\n\nI gave up on it very quickly when I realised it was lacking super basic features.\n\nUse a real charting library like Highcharts",
            "Give bokeh a try. \u00a0I find it less cumbersome that plotly\u00a0",
            "(Nice chart!)\n\nHave you checked out Altair?\n\nIt looks similar to a combination of:\n\n- https://altair-viz.github.io/gallery/line_with_ci.html\n- https://altair-viz.github.io/gallery/line_chart_with_color_datum.html\n\ne.g.\n\n    import altair as alt\n    from vega_datasets import data\n\n    source = data.movies()\n\n    lines = alt.Chart(source).mark_line().encode(\n        x=alt.X(\"IMDB_Rating\").bin(),\n        y=alt.Y(alt.repeat(\"layer\")).aggregate(\"mean\").title(\"Mean of US and Worldwide Gross\"),\n        color=alt.ColorDatum(alt.repeat(\"layer\"))\n    )\n\n    bands = alt.Chart(source).mark_errorband(extent=\"ci\").encode(\n        x=alt.X(\"IMDB_Rating\").bin(),\n        y=alt.Y(alt.repeat(\"layer\")).aggregate(\"mean\").title(\"Mean of US and Worldwide Gross\"),\n        color=alt.ColorDatum(alt.repeat(\"layer\"))\n    )\n\n    out = (lines + bands).repeat(layer=[\"US_Gross\", \"Worldwide_Gross\"])\n    out.save(\"trends.pdf\")\n\n(The `.encode()` is duplicated in this example, but you could also factor that out.)\n\nI had to also install `vl-convert-python` to save to PDFs.\n\n    # pip install altair vl-convert-python\n\n- https://altair-viz.github.io/user_guide/saving_charts.html#png-svg-and-pdf-format",
            "you can use pygwalker as alternative, not tweak, easy-to-use.",
            "You need to write your own helpers to do the things u regularly use. Plotly does so many things and so many parameters can be customized. But usually u use the same default parameters over and over again. \nI have a global config dictionary, and a default dictionary for every plot type that i reuse. I basically only write the labels and set the data for every new plot i make",
            "Put everything in a Pandas or Polars dataframe and use the .plot method. Much much easier and simpler, since the data is already prepared within the DataFrame",
            "Plotly is not supposed to be used in this way, declarative. Organize your data in a long/tidy format to use it as a functional grammar. It\u2019s like you\u2019re writing mpl code on plotly",
            "I often save the data on clipboard or on a csv, load it on R and use ggplot.\n\nIf I need an interactive plot, I use ggplotly to transform the ggplot to plotly.\n\nThat's with complex plots. For easy ones I use plotly on Python directly",
            "I never really understood the allure of interactive graphs. The whole point of a visual is to get information just by looking. Geospatial of course is different, but plotly is overkill for a lot of simple tasks. Just my opinion!",
            "Chatgpt. Stop complaining",
            "Might not be super helpful but I often save figures to svg and do some labelling, arrows etc on Inkscape",
            "yes, there are zero good plotting libraries in python",
            "Thank you. It's not my first time, unfortunately haha. I've used plotly several times, and each time I end up with a cumbersome code that is not modular, simply because I think of new additions as I go and don't spend the time/have the capacity to remake it into a modular way. The use of shaded areas is new for me, tho, and it took me some time to get how it works.",
            "In ggplot you don\u2019t need to write your own functions to tweak your plots because the natural grammar is so powerful. I use plotnine in python wherever I can but it\u2019s not a complete recreation.",
            "Thank you. I'll try to implement these suggestions, I get the point now.",
            "This would make a good class, wrapping plotlys terrible API with something more pythonic",
            "I love reddit. Thanks for this.",
            "Thanks a lot. Yes, I realize I need to change to plotly express for most plots. \n\nBut the answer in the link you share also uses a lengthy function, right? Is this what you mean by having to use the plotly.go for error bars? And you could make it in 5 mins using that function or with a different approach?",
            "Thanks for taking the time. This helps a lot. The reason I end up with my code is that I have new ideas as I go (for example changing the line width for each plot) and then keep adding things instead of remaking the code to make it modular. It's hard for me to think ahead and plan the code for new additions. I will remake it using your advice to learn and change the mindset for the next time.\n\nI used Plotly a lot last year, but hadn't used it in a few months. And I had never used the fillarea. That's the other reason I don't plan my code: I usually make many different plots so can't reuse the code from a previous plot, which defies the purpose of the modular approach, I guess?\n\n  \nEdit: would it help changing the data to a long format as another redditor mentioned? Rn it's four columns (Region, Scenario, Year, Population).",
            "Yes you are right about Express being well, express. Last year I was creating a facet figure with many boxplots in each facet and hit a wall with Express when trying to tweak something, so I had to change to fig.go and didn't consider going back for other plots, which is my mistake. Will try this with express and see the difference.",
            "Thanks. So you happen to use templates? I keep seeing myself going back to my old layout code to copy and paste things that I would use for every plot.",
            "Do you mean changing the width and height when saving the figure? Or interactive visual on HTML? Look at the image with aspect ratio for a phone: [https://imgur.com/a/L9W1app](https://imgur.com/a/L9W1app)",
            "Thank you",
            "Thanks for that, I didn't know. Would this change the rest of the code much, tho?",
            "A few years ago, my wife and I spent about three hours each evening for a week and a half learning d3. It made me feel like a wizard. \n\nFast forward a few months and she's making fun of how cumbersome and unmaintainable my d3js code is compared to her echarts+chartjs.",
            "and what's the verdict?",
            "Wikipedia: Highcharts is a software library for charting written in pure JavaScript, first released in 2009. **The license is proprietary**. It is free for personal/non-commercial uses and paid for commercial applications.",
            "Thanks a lot. Yes, I've seen Altair being mentioned and looks promising for my case. Each person mentions another library tho, so I'm trying to estimate if the change to any of them will compensate for the effort of having to learn it.",
            "Yes I've realized this now. I'll spend some time organizing a dictionary and setup I can reuse",
            "The data are in a Pandas dataframe. But the .plot method doesn't offer a lot of customization, or does it?",
            "Could you give an example of the better way to do it please?",
            "And how complex would my plot be under your criteria, for me to understand better what you mean",
            "Yes, I saw plotnine being mentioned in another thread. I had my suspicions that it wouldn't mimic ggplot2 perfectly and wondered whether it would add any benefits to replace plotly with it.",
            "Yeah I get that, but still the idea of DRY is applicable to most languages. In R I mostly use highcharter, which is also similar to the Ggplot syntax.  Ggplot also comes with Python",
            "Yeah, it is lengthy but it generalizes the problem. Unfortunately, plotly express is not able to do continous error bands. The shared solution solves this by using plotly go to extend the plotly express line plot. I use plotly quiet a lot in my work, but I rarly have so complex problems where I have to use plotly go functions. Error bands and heatmaps are the only exceptions so far. Since I already knew the stackoverflow post, I can make it in 5 minutes. Otherwise it would take me longer. As I mentioned plotly go is rarly needed since plotly express covers a lot.",
            "> The reason I end up with my code is that I have new ideas as I go (for example changing the line width for each plot) and then keep adding things instead of remaking the code to make it modular. It's hard for me to think ahead and plan the code for new additions.\n\nIt is perfectly normal to have some \"scruffy\" code that you get working as you like, especially for finicky things like graphical presentation, and then only afterwards refactor it to be cleaner. After all, it is impossible to know what bits will be similar and different before you write it out!",
            "You can create base plot with px and still call fig on that plot to modify it.\n\nFrom the docs - \n>If none of the built-in Plotly Express arguments allow you to customize the figure the way you need to, you can use the update_* and add_* methods on the plotly.graph_objects.Figure object returned by the PX function to make any further modifications to the figure. This approach is the one used throughout the Plotly.py documentation to customize axes, control legends and colorbars, add shapes and annotations etc.\n\n>Here is the same figure as above, with some additional customizations to the axes and legend via .update_yaxes(), and .update_layout(), as well as some annotations added via .add_shape() and .add_annotation().",
            "Yeah that said I typically use the same style plots over and over again and incrementally add / improve things.\n\nBut there are so many things you can do with go plots. There's typically a link somewhere in all the documentations for each plot style that goes in depth with the customizations in go",
            "The latter for me, I've tried looking up ways to make it work but have mostly given up. The chart is pretty busy in the first place so it just might be meant to be",
            "from your plot your u would need 9 traces so the \ngo.Figure(data=[t1,t2\u2026])\n\nThe fill can be done in the dictionaries the curves with fill=\u201ctonexty\u201d.\n\nAlso if your just plotting a stats frame u can start with \n\nfig = px.scatter(df, x=\u201cxcol\u201d,\u2026 color=\u201ccolorcol\u201d..)",
            "I hate Javascript, Typescript is not as impressive as I expected (though obviously an improvement), but at this point I'll probably stick with D3 and not return to Python (for the graphing visualization). I added a WebSocket though so that I can do the data processing in Python and Scala as needed, the Typescript just talks to D3, doesn't contain any logic that could exist in the server.",
            "I am all for open-source except when it's crap.\n\nyou do you, if you enjoy suffering, then by all means, continue with Plotly\n\nthe issues I found within days of using the library were reported for many years and the devs never bothered to solve them",
            "Yeah, I found it a bit surprising there was no \"defacto\" library.\n\n`hvplot` is another one, but I've not used it. (I think it may be more for interactive stuff?)\n\n- https://hvplot.holoviz.org/",
            "Actually last time I checked it returned a matplotlib figure you can customize",
            "I was going to ask the same. I understand the grammar of graphics approach, as explained [here](https://safjan.com/grammar-of-graphics/). But I don't know what specifics I could change apart from the feedback from the others (basically calling functions). I could indeed change my data from having four columns (Region, Scenario, Year, Population) to a long format, but wouldn't know how that affects the implementation on plotly.",
            "Tough to tell, it's not an automatic \"yes\" but you might try it out. If you're used to relying on ggplot extensions, it may not be enough for you. It also won't be able to do anything dynamic or interactive. But for EDA and churning out plots for analysis, it's still great (like ggplot).",
            "I guess I'm lucky I posted the code for one of those rare cases. Thanks again for the resource and tips",
            "I get you. I did ask for alternatives so thank you. It seems different strokes for different folks since Ive gotten at least three alternative libraries in this post. Cheers",
            "Can change the pandas backend option to return a Plotly figure instead of matplotlib",
            "Matplotlib is horrendous to use",
            "Ha ha, I just found [the ggplot2 page](https://ggplot2.tidyverse.org/) that claims to *declaratively* use \"the Grammar of Graphics\".\n\nYeah, I'm pretty sure that GOG is just a buzzphrase that means \"code to draw a graph -- any sort of code, using any sort of coding style\". Change My Mind.",
            "That \"grammar of graphics\" page you link to is not very useful. It doesn't explain what GOG is supposed to be.\n\nQuote: \"A \"grammar of graphics\" is a set of instructions for creating pictures using code.\"\n\nRight. And the Matplotlib approach is **also** a set of instructions for creating pictures using code.\n\nMy *wild guess* is that the author wants to distinguish between imperative style (like matplotlib uses) and object-oriented style used by plotly, but doesn't know that second term so he just made up \"grammar of graphics\". Or perhaps he just wants to make it sound more profound than it really is. \n\nIt would have been more helpful to compare the plotly and matplotlib code for the exact same graph. Don't forget the code to put your data into a dataframe!",
            "No problem. It now has a python wrapper I haven't tried yet. At the time I made it work by using Javascript directly, with jinja2.\n\nIt's infinitely better than Plotly and constantly updated. But it's not free nor open source.\n\nIf you find a good opensource alternative, please let me know :)\n\nCheers",
            "TIL",
            "How?",
            "It\u2019s extremely idiosyncratic, but there\u2019s a lot of power under the hood that\u2019s great for churning out on static reports or slides in my experience.",
            "Haha, good one",
            "True. I also thought it was weird that he didn't create the same graph with both libraries to compare. Any other resource I can use to extend my understanding of GOG?\n\nEdit: just read your second comment.",
            "https://plotly.com/python/pandas-backend/",
            "it's the assembly code of python plotting"
        ]
    },
    "I connected LLM to Python runtime and generated unit-tests (OpenSource)": {
        "title": "I connected LLM to Python runtime and generated unit-tests (OpenSource)",
        "score": 5,
        "url": "https://www.reddit.com/r/Python/comments/1cnhzmy/i_connected_llm_to_python_runtime_and_generated/",
        "content": "*Hi all, I initially started this adventure by trying to automate bug fixes with the help of LLMs. However, I received feedback saying the fixes aren't always correct, leading to the question: why bother reviewing PRs that might add more issues? (It's really hard for LLMs to say \"I don't know\").*\n\nSo, I decided to focus on reliability perfecting unit tests. \n\nThe source code is available at:[ https://github.com/CaptureFlow/captureflow-py](https://github.com/CaptureFlow/captureflow-py)\n\n**What My Project Does:**\n\nIt incorporates a tracer client-side Python library and a backend that accumulates such traces and is capable of proposing code improvements and generating tests for your repository. It traverses the execution graph, extracts relevant parts, enriches them with implementation data from the GitHub API, and then generates tests with the help of GPT4.\n\n**Target Audience:**\n\nPython users interested in discovering what LLMs can achieve when given detailed runtime information from your app. Generally, this approach somewhat reverses the concept of TDD, but in my day job I deal with many legacy apps that have poor test coverage, and having it really helps. I suspect I\u2019m not alone in finding value in this.\n\n**Comparison:**\n\nI think idea of using LLMs to generate tests is not new, but generating them actually based on application's performance is inspired by Jane Street's[ article](https://blog.janestreet.com/the-joy-of-expect-tests/) on how they automated test boilerplate creation and recent Facebook's[ research paper](https://arxiv.org/pdf/2402.06111).\n\n**Disclaimer:** More work needs to be done to make it work for any Python app and not just a subset of FastAPI servers. I'm curious if you folks would find it useful.\n\n**Example:** you can check[ this PR](https://github.com/CaptureFlow/captureflow-py/pull/62) for reference. feedback / stars / contributions are welcome.",
        "num_comments": 5,
        "comments": [
            "\"Patch the methods with mock data\": The most unhelpful comment you can get in the code. I know what patch does, I don't need comment on it.\n\nHow about explaining what is in the patching? What behavior do you replicate? Where data fro mocking are coming from?\n\nHalf-year later, I do refactoring, getting this test red. Why? What had I broke? What this test is testing and why do you insist it is a correct test?\n\nOh, sorry, it was written by AI. May be I broke someone hallucination.",
            "icky advise threatening alive crowd coherent cake file roof glorious\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
            "Sounds like an interesting project",
            "This is actually awesome, and there not being many comments just goes to show why people need more tests in their apps. I'm gonna check this out! Thanks :)",
            "PMed :)"
        ]
    },
    "Seeking Your Input: Let's Co-Create FreeCodeCamp for python together": {
        "title": "Seeking Your Input: Let's Co-Create FreeCodeCamp for python together",
        "score": 2,
        "url": "https://www.reddit.com/r/Python/comments/1cnf7o3/seeking_your_input_lets_cocreate_freecodecamp_for/",
        "content": "Hello all,\n\nThis is probably my first post here. I usuallly lurk around here and Django subreddits.\n\nI've been brewing up an idea and I need your input before I take the plunge!\n\nPicture this: a website like FreeCodeCamp but for python and related technologies, a learning oasis where anyone can kickstart their journey from Python newbie to job-ready pro, and it's all free!\n\nBut here's the thing, I want this to be our platform, crafted with your needs and dreams in mind. So, before I start, I need to know: would this be something that gets you excited?\n\nImagine quizzes helping you find your starting point, interactive challenges that keep you in the zone, and a supportive community to cheer you on every step of the way. Plus, videos, written tutorials, and a progress tracker to keep you motivated!\n\nWhat would make you go, \"Wow, I need this in my life!\"? \n\nWhat features would you love to see? \n\nAny suggestions or wild ideas ?\n\nMy aim is to give back to the community by assisting new learners in navigating common pitfalls when they start their Python journey",
        "num_comments": 1,
        "comments": [
            "Hi there, from the /r/Python mods.\n\nIt looks like you are asking for help. We suggest re-reading the r/Python rules and directing all help or \"How do I...?\"-type questions to\nr/LearnPython.\n\nIf this is not the case, a moderator will be along soon to review your post.\n\nWarm regards and all the best for your future Pythoneering,\n\n/r/Python moderator team\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Python) if you have any questions or concerns.*"
        ]
    },
    "Tutorial on Creating Useful Data Visuals with Python seaborn and matplotlib libraries": {
        "title": "Tutorial on Creating Useful Data Visuals with Python seaborn and matplotlib libraries",
        "score": 8,
        "url": "https://www.reddit.com/r/Python/comments/1cn24ar/tutorial_on_creating_useful_data_visuals_with/",
        "content": "With the current global deluge of data and information, there has never been a more important to visualize your data in a clear and simple manner.\n\nPython is a terrific tool to help us do this.\n\nThe key to this lies in choosing the the right data visualization techniques to tell the most interesting and relevant story.\n\nThree useful visuals are:\n\n1. ***small multiples***\n2. ***heat maps***\n3. ***stacked area charts***\n\nIn this tutorial, using\u00a0***pandas, seaborn,***\u00a0and\u00a0***matplotlib.pyplot,*** we create the Python code for each data visual\n\nLink to free [Tutorial](https://johnloewen.substack.com/p/python-mastery-choosing-the-right)\n\n",
        "num_comments": 7,
        "comments": [
            "Thanks I\u2019ll check it out. I noticed that you use PyCharm. I use Jupyter Lab, which I like because you can run code snippets and track variables. Is there a reason why you\u2019d use PyCharm over Jupyter?",
            "Purely familiarity - I come from a formal teaching background where advanced code editing and debugging tools are more important. I've just been using it for a long time. I know that Jupyter Lab may work better for these types of projects, I just haven't switched over yet. But I do plan to.",
            "They serve pretty different purposes, I always explain it as VSCode is like Flask, Pycharm is like Django and Jupyter is like fastAPI. \n\nIf you just need a visualization, Jupyter is the lightest and easiest to get started with, if you want to fork and make pull requests for NumPy, you'll probably like some of Pycharm's features.",
            "I\u2019m actually trying to incorporate python into dashboard for my company and I\u2019m a heavy Excel user, just wanted to start with something that I would not need to change from down the road. The choice here is PyCharm or Jupyter",
            "Pycharm will be nice when you go to actually deploy the dashboard or have to maintain it (if that's even on you), but you'll probably still use Jupyter for prototyping visualizations and code if you find you like it (I do). You'll have to do the deployment from the terminal or with web interfaces though if you go with only Jupyter, which isn't bad, and will probably be how most of the documentation is written anyway, pycharm just makes those tasks easier.\n\nAgain, different tools for different purposes, you don't need to worry about changing, pycharm builds on Jupyter if anything. It's kind of like saying I don't want to learn to drive a car because I might want to be a professional trucker later on. The skills and concepts will mostly transfer.",
            "Yeah just to add on to /u/dparks71 VS code has a nice Jupyter Notebooks extension. \u00a0So I use it a bit like a scratchpad. \u00a0I prototype individual functions, or verify file formats and the results of parsing them in Jupyter, then move them into my actual program.\u00a0",
            "Ty"
        ]
    },
    "Rethinking String Encoding: a 37.5% space efficient string encoding than UTF-8 in Apache Fury": {
        "title": "Rethinking String Encoding: a 37.5% space efficient string encoding than UTF-8 in Apache Fury",
        "score": 81,
        "url": "https://www.reddit.com/r/Python/comments/1cmcy3y/rethinking_string_encoding_a_375_space_efficient/",
        "content": "In rpc/serialization systems, we often need to send namespace/path/filename/fieldName/packageName/moduleName/className/enumValue string between processes.  \nThose strings are mostly ascii strings. In order to transfer between processes, we encode such strings using utf-8 encodings. Such encoding will take one byte for every char, which is not space efficient actually.  \nIf we take a deeper look, we will found that most chars are lowercase chars, ., $ and \\_, which can be expressed in a much smaller range 0\\~32. But one byte can represent range 0\\~255, the significant bits are wasted, and this cost is not ignorable. In a dynamic serialization framework, such meta will take considerable cost compared to actual data.  \nSo we proposed a new string encoding which we called meta string encoding in Fury. It will encode most chars using 5 bits instead of 8 bits in utf-8 encoding, which can bring 37.5% space cost savings compared to utf-8 encoding.  \nFor string can't be represented by 5 bits, we also proposed encoding using 6 bits which can bring 25% space cost savings\n\nMore details can be found in: [https://fury.apache.org/blog/fury\\_meta\\_string\\_37\\_5\\_percent\\_space\\_efficient\\_encoding\\_than\\_utf8](https://fury.apache.org/blog/fury_meta_string_37_5_percent_space_efficient_encoding_than_utf8) and [https://github.com/apache/incubator-fury/blob/main/docs/specification/xlang\\_serialization\\_spec.md#meta-string](https://github.com/apache/incubator-fury/blob/main/docs/specification/xlang_serialization_spec.md#meta-string)",
        "num_comments": 73,
        "comments": [
            "\"this cost is not ignorable\" - err, what?\n\nDebatable.How long are such names now? 10? 30? 50 characters? So we save 3, 10, 16 bytes or so?\n\nExamples from the article:\n\n30 -> 19\n\n11 -> 9\n\nSorry. But I don't see the value.\n\nThere's plenty situations where this should be easily ignorable. Especially if this comes at extra complexity, reduced debugability, extra/unusual processing.\n\nUTF8 is great. It saves a lot of otherwise unneeded bytes and for very many simple cases is indistinguishable from ASCII. Which means that every debugger/editor on this planet make at least parts of the string immediately recognizable, just because almost everything can at least display as ASCii. Great fallback.\n\nFor small strings paying with extra complexity and processing for saving a few bytes and the getting something unusual/non- standard doesn't sound worthwhile to me.\n\nAnd for larger text blobs where the savings start to matter (KB to MB), I would just zip the big text for transfer.",
            "Lmao, please do a benchmark comparing this and just Unicode and tell us how many ms and kb RAM you saved. This is such a specific microoptimization that there\u2019s probably 100 things you can do before this is worth it",
            "A more efficient means of doing this, if you absolutely must (and you don't), would be static Huffman, which this kinda is, but not quite.",
            "I don't think the\u00a0advantage\u00a0of\u00a0this string encoding is really worthwhile over just compressing the data.\n\nMost general purpose compression algorithms can take advantage of data with limited character sets.\u00a0\n\nFor example, this:\n\n\n    >>> data = \"\".join(random.choices(string.ascii_lowercase + \".$_\", k=1000000))\n    >>> len(data)\n    1000000\n    >>> print(len(bz2.compress(data.encode())))\n    616403\n\nThat's about 38% compression rate which is a compression rate that's in similar ballpark as the proposed 5-bit string encoding.\u00a0lzma and gzip can do something similar as well. This is on a random data, so the 38% compression rate is the lower bound; the compression rate would be even better for non random texts that usually has other exploitable patterns. \n\nMoreover, a\u00a0general\u00a0purpose compressor\u00a0will be able to adapt to other arbitrarily restricted character sets, and take advantage of other patterns in the data, like\u00a0JSON key names, or namespace/paths that keeps being repeated in multiple places. They're a more reliable way to compress than just using a custom encoding.\n\nFor RPC/APIs serialisation where there's often repeated key names, you can do even better compression rates if using preshared dictionary compression\u00a0like brotli or zstd or using data format with preshared schema like protobuf.",
            "\u201cSuch encoding will take one byte for every char\u2026\u201d\n\nthis is not accurate. See the first sentence from Wikipedia\u2019s UTF-8 article for details",
            "Look at this: https://pypi.org/project/protobuf/",
            "How does this compare to making a array and replacing names with indexes?\n\nLike just dedup",
            "You are almost always better off encoding with UTF-8 and then gzipping.  A string encoding format's primary virtue is portability: the most important thing is that other systems understand you, not how compact you can make it.  UTF-8 is reasonably compact, but the real reason it's used is because it's a superset of ASCII, so all the old code that handles ASCII strings does not need to be retooled.\n\nGZip is a lossless compression format.  It has been very tightly engineered to operate on the efficient frontier between space savings and fast decoding, and modern implementations can trade off between them.  It's also a well-known standard with hundreds of tools that can handle it.\n\nWhen you have namespace/path/filename/fieldName/etc strings, they are frequently repeated, and they frequently draw from a very small lexicon.  You can do way better than 5 bits per character for this; you can often get away with less than 1 bit amortized per character, because the whole token can be encoded in just a few bits.  GZip regularly achieves 80-90% compression on code.",
            "It seems that applying compression would save you more space without creating a new string standard.\n\nAs someone who remembers the latin 1 code page and other non standard 8851 code pages please dont leave utf8 as you introduce translitteration back into the world.",
            "HTTP has dealt with this issue by simply gzipping entire streams, which yields greater compression and a lot less overhead.",
            "Can't wait for encoding hell to return",
            "This is very impressive. I don't understand any of the rationale I've read from the people who are criticizing you. Their arguments scream 'inexperienced' to me.\n\nI implemented my own serialization for a low level game networking library a few years ago in C++ and it was a major PITA. None of the serialization libraries I found met my requirements of being extremely fast and space efficient.\n\nI looked for a method to compress the data I was sending that would give any benefit while being fast and I wasn't able to find anything useful. Standard compression methods require headers that make them inefficient on small amounts of data. This encoding method fits a nice niche for compressing small amounts of text.\n\nPython's other serialization options are seriously lacking. They are slow and produce bloated serializations. Another option that is available that may fit the requirements of some projects should be extolled. As much as these ridiculous criticisms are claiming otherwise, I immediately see the value of fury if the claims are true and have several projects I could see it being used in.\n\nI like how the serialization is performed via introspection instead of redefinition. All of the 'fast' options I've seen ignore the usefulness of using class or struct definitions to save time in defining a packet format. This library and its language wrappers look very well designed. I really like how it is multilanguage. Are the different wrappers interoperable? EG can a class definition encoded in one language produce a decoded class in another language? If so, that is amazingly useful.",
            "It looks neat, but I'm struggling to think of a scenario where this would be a big win. I guess if you're doing high throughout serialization, then minimizing overhead is never a bad thing. But even with that it would seem to me that this sort of optimization would be way down on the list of when sorted by the cost/benefit ratio. Is network latency and/or bandwidth really constrained enough that saving a few bits would make a material difference? I guess enough people thought so to make this.",
            "Utf8's purpose isnt to be efficient, but to be the most universal encoding",
            "Meta string spec can be found in\u00a0[https://github.com/apache/incubator-fury/blob/main/docs/specification/xlang\\_serialization\\_spec.md#meta-string](https://github.com/apache/incubator-fury/blob/main/docs/specification/xlang_serialization_spec.md#meta-string)",
            "The meta string here are used in binary serialization format internally. It's not about encoding general text. This is why we name it as meta string.\n\nFor general string encoding, utf8 are always better.\n\nIf you take pickle as an example, you will found it write many string such as module name, class name into the binary data. It's such data we want to reduce cost. \u00a0And in data classes, field names may take considerable cost If the value are just a number",
            "If I am writing a program that logs a sensor value as a half precision floating point number 200 times per second, I would gladly shave the entire payload from 32 -> 21 bytes if it means having my serialization metadata not be human readable",
            "Maybe we are talking different things. What meta string is used for encoding things like \\`namespace/path/filename/fieldName/packageName/moduleName/className/enumValue\\` only. Such string are limited, the encoded results can be cached. So the performance is not an issue here",
            "[deleted]",
            "Yep, static Huffman may works. But Fury is a serialization framework, we can't assume which data to used to build Huffman tree. If we build it and include it in fury wheel. It may not reflect the actualy data in users.\n\nAnother way is that Fury provide an interface to let users build such Huffman tree and pass it to fury, but that is not easy to use for users.\n\nWe may try the first way and see how much gains it can brings",
            "Meta string is not designed for general compression. We tried to use gzip. But meta string are smaller, only 20\\~50 chars mostly, not enough for such general compression to work",
            "I mean took one byte for ascii chars. Our sentense is not accurate, I will update it later",
            "We already did this. Writing same string will jsut write an index. But many string just happens only once. In such cases, this won't work",
            "In rpc/serialization systems, there won't be many strings repeation. And for repeated strings, w've already encoded it with dict encoding. But dict itself also needs to send to peer. Meta string will  be used to encode such dict self.",
            "compression can be used jointly, but it's outside of serializaiton. At most cases, one will use zstd after Fury serialization. But not all users use zstd too. And compression introduce more performance cost.",
            "gzip has a 10 byte header. When your input is only 10-40 characters in the first place you cannot reduce it's size with a general compression algorithm",
            "This is not a general encoding, it's only used for meta string such as \\`namespace/path/filename/fieldName/packageName/moduleName/className/enumValue\\`. No encoding hell will happen",
            "Thank you u/1ncehost , your insights into this algorithm are very profound, precisely conveying why I design this  encoding.\n\nI also like introspection instead of redefinition(IDL compilation if I understand right). This is why I create Fury. Frameworks like protobuf/flatbuffers needs to define the schema using IDL, then generate the code for serialization, which is not convenient.\n\nThe different wrappers are interoperable. They are not wrappers, we implement Fury serialization in every language independently. \n\nAnd for \\`a class definition encoded in one language produce a decoded class in another language\\`. If you mean whether serialized bytes of  an object of a class defined in one language can be deserialized on another language. Yes, we can. Fury will carry some type meta, so another knows how to deserialize such objects. This is why we try to reduce meta cost. It would be big if we carry field names too.\n\nAlthough we supprt field name tag id, but not all users like to use it.",
            "> I'm struggling to think of a scenario where this would be a big win. I guess if you're doing high throughout serialization, then minimizing overhead is never a bad thing.\n\nApache fury is literally a high throughput serialization engine for working with big data",
            "Depends on the rpc frequency. Image that you send millilons of RPC every second. This will make a big difference. And it's common in quantitative trading and shopping system",
            "No, that\u2019s utf32. UTF8 trades simplicity for performance in several ways.",
            "Meta string is not used to replace Utf8. It never be. It's just used to encode classname/fieldname/packagename/namespace/path/modulename more space efficiently than utf8",
            "There are three situations:\n\n1. The string is small. In this case, the cost of serializing/deserializing the string is greater than the cost of copying the extra handful of bytes. In this case, you should not use this string encoding.\n1. The string is medium. In this case, you need to show that meta string is better than either raw strings or zstd encoded strings.\n1. The string is large. In this case, zstd will be better. In this case, you should not use this string encoding.\n\nBasically you need to prove it to me. I want to see this benchmark:\n\n| Encoding | Small | Medium | Large |\n|---|---|---|---|\n| utf8 |||\n| zstd |||\n| meta string |||\n\nI want end to end speed/throughput, not number of bytes saved.",
            "Sure, but even if I debug binary data, being able to easily recognize string characters is very helpful.\n\nSaving 30% on strings of length 100 or less doesn't look worthwhile to me.\n\nUnder what circumstances would I be worried about a few bytes more or less?\n\nSay, I pickle a module and the contained strings using a total  of 1000 bytes and now it's 700 bytes instead.\n\nSaving those 300 bytes - how would I ever notice that?",
            "Surely at that point you'd just replace the strings with enums and not transmit text at all.",
            "Ok, but the proposed Meta-\"strings\" wouldn't help you with that.\n\nI'm after a use case where the non-standard representation and extra processing is worthwhile. Just shortening a handful of len 30 strings to len 19 is not worthwhile to me in any scenario I can think of right away.\n\nEven a len 100 str compacted to 65 bytes is completely irrelevant IMHO. I would need millions of those to consider this a worthwhile investment. Otherwise I would always prefer the boring standard UTF8 strings that are mostly ASCII and easily debug scannable and don't require additional processing back and forth. And if it's milliions in a batch and there a bottleneck I would rather crush this with established boring compression.",
            "Just to clarify, you\u2019re not transmitting the value as text, right? A 16 bit float should take 2 bytes of payload, maybe add another 2 bytes to identify the value and 4 bytes for a timestamp and you\u2019re still only at 8 bytes. Are you sending the value as a string?",
            "The size of a model isn\u2019t because of text though, it\u2019s just the raw number of weights you have. The tokenization itself is very small. You wouldn\u2019t save anything by doing this",
            "But you are assuming the data that is used, just at a low level of granularity.  It's almost like a three node Huffman tree (lowercase, uppercase+digit+special, other), but with some extra processing in the encoding flags.",
            "Try zstd, with and without custom dictionaries.\u00a0",
            "This is about rpc,why not prepare a shared index so no message has to repeat the index",
            "If your input is 10-40 characters, compression of any kind is extremely unlikely to be worth the time or space overhead. How many bytes is the de/compression code?",
            "This is seriously impressive. Thank you for making it! I had thought of making something similar for C++ only... quite an achievement in making it multilanguage!",
            "Exactly. I'm looking for a use-case where getting an obscured string with extra processing leads to a saving anyone can care about.",
            "All strings use this encoding will cache the encoded results, and the serialization will be just an copy. Since such strings are limited, we won't have millions of module/classname for serialization. So it's ok to cache the encoded result",
            "In many case, the payload size is not important. UTF-8 will better for binary debug.\n\nBut there do have cases we need smaller size, in such cases 30% gains may be worthwile.\n\nBut we may should provide a switch to to allow users disable such optimization.",
            "It really depends on the scale you are talking about. If you are running a service that handles millions of QPS 24/7 then seemingly small optimizations like this can translate into 6 or 7 figure savings over time.",
            "what if you are serializing millions of db rows?",
            "Perhaps in a 1500 MTU network package?",
            "> the proposed Meta-\"strings\" wouldn't help you with that.\u00a0\n\n\nThey would reduce the total size for billions of RPC requests by ~10 bytes each.\u00a0\n\n\nHaving to send 30 byte headers when your actual serialized payload is only 5 is really dumb, this is a solution for that.\n\n\n\n> And if it's milliions in a batch and there a bottleneck I would rather crush this with established boring compression.\u00a0\n\n\nI don't think you understand the use case for this",
            "2 bytes for the float, plus the 30/19 byte header (from the example above)\n\n\nYes saving 10 bytes on the header makes no sense when you are sending 200kb payloads, but when you are serializing tiny objects millions of time, this is a dramatic savings over UTF8.",
            "But we don't know the frequency of every char. All we know is most string are in range \\`a-z0-9A-Z.\\_$/\\`",
            "We can't, Fury is just a serialization framework. We can't assume the corpus for user's classnames/fieldnames. I thought crawler some github repo such as apache ofbiz and collect all domain objects, and use such data as the corpus to get a static huffman/zstd stats. But this is another issue, and introduce an extra dependencises. we may try it in the future and provide it as an optional method.",
            "We support it, users can register a class with an id, so later writing class name will just wirte an id. But not all users want to do this. It's not that convenient. Meta string encoding are just for such case.",
            "Yes. Which is why they are using this alternate text encoding instead of compression",
            "You can take [https://github.com/apache/incubator-fury/blob/main/docs/specification/xlang\\_serialization\\_spec.md](https://github.com/apache/incubator-fury/blob/main/docs/specification/xlang_serialization_spec.md) for more details. \n\nThe C++ implementation are not finished, but the spec is finished. And macro/meta programing can be used to generate serialize code at compile time, so we can get best usability and the performance at the same time. \n\nWe've used this way to generate code in c++ for xlang row format. But haven't do it for the graph stream wire format. The core developers are on apache kvrocks recently, and has no time for it now.",
            "Although we don't have jit code gen for c++ memory model. We can geneate swich code which can be optimized to jump finally for type forward/backkward mode, and it would be much faster than protobuf.\n\nMore details can be found on [https://github.com/apache/incubator-fury/blob/main/docs/specification/xlang\\_serialization\\_spec.md#fast-deserialization-for-static-languages-without-runtime-codegen-support](https://github.com/apache/incubator-fury/blob/main/docs/specification/xlang_serialization_spec.md#fast-deserialization-for-static-languages-without-runtime-codegen-support)",
            "Image such an case, you are send an obejct of type \\`Point\\` with two int fields \\`x\\` and \\`y\\`. The fields only took 2 bytes. But pickle serialized result is 53 bytes. With metastring, we can make serialized result much smaller.\n\nMaybe cost of one object is not big, but if you need to send millions of RPC",
            "Yes, but you pay with extra 2-way processing and the applications where that might perhaps lead to any savings seem very restricted to me.",
            "Zip it. Text compression is extremely efficient (90% or so).",
            "If we have enough network band width\u00a0, this compression won't be necessary. But many systems also cache the serialized data in redis, the memory would be expensive.\n\nAgain, whether this encoding is useful always depends on cases",
            "You were talking about floating point \"numbers\". If bytes are a concern, why would you present those as \"strings\" at all?",
            "But if you\u2019re counting individual bytes, you just shouldn\u2019t send text when it\u2019s not needed. If you only have a list of possible categories, you don\u2019t send the category name as a string but just send a number and have a lookup table for encoding and decoding.",
            "Yes, meta string is an encoding, not a compression algorithm. It's just because that namespace/path/filename/fieldName/packageName/moduleName/className/enumValue\u00a0 are too small, only 5\\~50 characters. We never get a chance to compress such string using gzip.",
            "thanks for the info. What are the requirements for fury to come out of incubation and have production level support?",
            "also another couple questions: can you specify class variables that should not be serialized? Can internal datastructures be serialized along with the objects? For instance in my c++ example above, I would want to serialize simulation entities, but I wouldn't want to serialize certain things on them such as local time variables. I would want to serialize lists of related objects such as mutators, effects, and related entities.",
            "Zip it good.",
            "Because you aren't converting the number to the string at all. When you serialize data you perform conversion steps and then put a header in the front to explain what you did. Read up on how gzip works - it compresses the data and slaps a 10 byte header in the front so when you need to decompress it you know how. Having the header become human readable is such a non-concern because its doubtful the actual data serializer leaves the payload contents in a human readable format\n\nIf you are implementing custom serializers/deserializers, this text encoding lets you reduce the size of your serialization header in addition to the content. So your \"json.gzip.then.base64\" header becomes \\~15 bytes instead of 21 - if you tried using gzip it would increase in size to 41 bytes, plus the size of whatever your actual serialization content is",
            "And if you are using Apache Fury (or some other similar technology), you need to include a header in your payload so that when it gets a message with a value of `13` it knows whether to look up the corresponding text value in the `categories` or `usernames` table upon deserialization",
            "Fury already did this. If a classname is serialized in the second time. Fury will write it by a varint ID. But for the first-time write, Fury still needs to write the original data. Othewise, how can we recover the string from the ID.\n\n  \nWhat meta string did is for optimize the encoded size when the classname is serialized in the first time. Because in many cases if you don't use \\`List\\[ClassXXX\\]/Dict\\[K, V\\]\\`, there won't be repeated classname for dict encoding.",
            "The graduation needs a bigger community. i.e. more maintainers, committers, contributors, and more release and users",
            "If you use fury c++, you can invoke \\`FURY\\_FIELD\\_INFO(field1, field2, ...)\\` with the fields you want to serialize. We use \\`FURY\\_FIELD\\_INFO\\` macro to get the fields name for serialization.",
            "But does Apache Fury understand your custom text encoding? If it doesn\u2019t, you either have to use plain text anyways, or treat the header as binary data, in which case you can just treat the header as a binary encoded number and reduce its size that way, right?",
            ">But does Apache Fury understand your custom text encoding?\n\nThis is literally an entire thread about how Apache Fury implemented this custom text encoding to dramatically improve efficiency"
        ]
    },
    "Python script to convert Spotify Artists to Playlists": {
        "title": "Python script to convert Spotify Artists to Playlists",
        "score": 29,
        "url": "https://www.reddit.com/r/Python/comments/1cm8s6f/python_script_to_convert_spotify_artists_to/",
        "content": "I've made my first bit of useful software and I wanted to share it here. I'd love some feedback (and it would be amazing to hear if someone has used it!)\n\n**What My Project Does:**\n\nUsing the third party requests package, the script interacts with the Spotify web API to request all albums from the given Artist, then all the tracks from all of those albums. It then goes through the list to remove any duplicates and also tries to remove any unwanted versions (only done by examining the name of the track, since Spotify does not attribute a version type to its tracks). Once that's done a playlist is then created on your Spotify account with the name of the Artist and all the tracks are posted there in chronological (essentially per album) order.\n\n**Target Audience:**\n\nAnyone who struggles like me when they find a new Artist and they want to listen to every conceivable song from them!\n\nLink to GitHub: [https://github.com/RJW20/spotify-artist-to-playlist](https://github.com/RJW20/spotify-artist-to-playlist)",
        "num_comments": 5,
        "comments": [
            "Nice to remember Spotify has a general purpose API, there might be other use for it too!",
            "Good project, keep it up! Hope you're proud of it :) \n\nConstructive feedback:\n\nLook into itertools.batched for iterating through your urls to post to the playlist.\n\nGeneral python advice: In general if you can do things with a for loop, dont use a while loop. It usually makes things easier to understand. \n\nThe duplicate removal can probably be written more readably using sets, which are inherently deduplicated.\n\nSome tests would be great. If there were tests I would have played around getting the deduplication function using sets. I like to use pytest, and you can easily mock requests.\n\nArgparse wouldn't go amiss either, rather than having to manually edit the settings file when you want to run it. \n\nGood stuff :)",
            "Decently knew to creating larger scale projects and was wondering if this is common practice to separate all of your methods by  the area you want to use them in then combine all of it in a main file? Typically I've established all classes and methods at the top and written everything in one main file. Thanks!",
            "Thank you for the feedback!\n\n  \nI've switched to itertools.batched, thanks for the recommendation. Testing has always been something I've said I'll do but never really got around to learning how to do it, so I'll use this as an excuse to do so and then I'll rewrite the duplicate removal more clearly with the aid of the tests to make sure it still functions correctly :)",
            "Nice :D, you're very welcome. Writing tests seems like a drag at first, but honestly it's incredibly valuable, and ends up saving time in the long run, even if it doesn't seem like it at first. It's basically a must have if you're writing production ready code for a company too.\nAll the best with it:)"
        ]
    },
    "List of Sites that Packages Need to Connect to?": {
        "title": "List of Sites that Packages Need to Connect to?",
        "score": 12,
        "url": "https://www.reddit.com/r/Python/comments/1cmdfvy/list_of_sites_that_packages_need_to_connect_to/",
        "content": "I'm doing most of my work behind a government firewall, and I'm having trouble connecting to certain sites.   I can do the usual \"pip\" installs just fine, but I'm talking about packages that need to download data to do their job.  An example is the NLTK (Natural Language Toolkit) package, which downloads dictionaries, lookup tables for sentiment analysis, and so on.  I know what sites to open up for that particular problem (pastebin.com and nltk.org), but I wonder if anybody's made a list of such sites for different packages.   \n\nI can ask for the two sites I know about to be opened up, but I'd like to have a more comprehensive list so I don't have to go through the red tape multiple times.",
        "num_comments": 12,
        "comments": [
            "You can look at the source code on Github, separately download those datasets, then transfer them to yourself with DoD safe [https://safe.apps.mil](https://safe.apps.mil)\n\nGood luck; the government constantly chooses to fail here when the bar is in hell.",
            "If you're gonna whitelist pastebin.com, you might as well shut the firewall down.",
            "Unfortunately it's not easy especially generically.\n\n\n\u00a0\u00a0If you are doing data science (nltk suggests so) then a big one would be hugging face for models. And GitHub itself as many places host their models there. And then places like pytorch model zoo (and keras/tensorflow equivalent).\n\n\nI would say most packages not hosting ML models tend not to have external data though.\n\n\nYou'll also run into issues we JavaScript if you're doing plotting/mapping as those tend to hit the web. Bokeh, plotly etc",
            "Looking at this, that site is basically like 'pastebin.com' for the government, then?   This is intriguing.  I haven't seen it yet.    I do have a \"secure\" USB drive that's gov't approved that I use, but this looks like a more secure and approved way of moving files between locations that would otherwise be prevented or gray-area.",
            "Weird assumption that he works for the US government. And federal government.And is DoD safe universal for all of US federal government even?",
            "I like it because at the very least there's an auditable trail of what you've brought in. It's a really neat tool!",
            "Not a weird assumption. He may not be DoD, but the US gov's security posture forces devs to ask questions like this. I haven't seen these issues coming out of other western governments so they've either solved the problem or they aren't doing the work.",
            "I did say I was 'behind a gov't firewall', so it's not an assumption.  I do in fact work for the government, so security regulations do apply, but I work for an agency that has sort of a \"trusted\" security level, not a literal \"secret\", let alone \"top secret\" level, if that makes sense.",
            "I work for the Canadian government. I know people who work for other Western governments. The \"offline resources for packages\" is pretty universal.",
            "You said government. You did not specify which country or which level of government. So it certainly is an assumption to go from \"government\" to \"US federal government\"",
            "They just don't ask \"how to\" in public because they know \"how to\" or ask the intern staff.",
            "Talent in the DoD space is.... Not great. No one wants to work in an environment where your hands are essentially tied behind your back and every day is spent fighting system restrictions to actually do your job."
        ]
    },
    "Pip 24.1 beta released, and it's a big one": {
        "title": "Pip 24.1 beta released, and it's a big one",
        "score": 173,
        "url": "https://www.reddit.com/r/Python/comments/1clx454/pip_241_beta_released_and_its_a_big_one/",
        "content": "I'd like to call attention to pip 24.1 beta asit is unusual for the pip team to release betas:\n\n* https://pip.pypa.io/en/latest/news/#b1-2024-05-06\n* https://pypi.org/project/pip/24.1b1/\n\nYou can install with:\n\n\tpython -m pip install pip==24.1b1\n\nIn particular they have upgraded their vendored version of packaging from 21.3 to 24.0, this was a [big effort](https://github.com/pypa/pip/pull/12300) and [fixed](https://github.com/pypa/pip/issues/7650) [many](https://github.com/pypa/pip/issues/9613) [bugs](https://github.com/pypa/pip/issues/10098), included significant performance improvements, and will allow pip to support [free threaded packages](https://github.com/pypa/packaging/pull/728). However, it also means legacy versions and specifiers are [no longer compatible](https://github.com/pypa/pip/issues/12063) with pip.\n\nBecause this was such a big land the pip maintainers have released a beta in the hopes people will test their workflows, and if something fails in an expected way report their steps as best as possible back to pip: https://github.com/pypa/pip/issues\n\nI've been testing, and contributing a little bit, to the improved performance in this release, it is most noticeable on large dependency trees or long backtracking. For example, a dry run of \"apache-airflow[all]\" using cached packages on my machine goes from ~418 seconds to ~185 seconds.",
        "num_comments": 23,
        "comments": [
            "Is there anything else besides package version that package maintainers need to watch out for?",
            "What are legacy version specifiers?",
            "Does pip support pyproject.toml yet?",
            "PIP INSTALL PIP -> love it!",
            "Wow, it's fascinating to see the Pip team releasing a beta version with such significant upgrades! This shows their dedication to improving performance and fixing bugs. I'll definitely be testing out this version and providing feedback to help make it even better. Great job, Pip team!",
            "That was the big jump with regards to packaging, almost all other PRs were performance, bug, or quality of life related.\n\nMost other vendored libraries haven't been stuck for so long on an old version, so I suspect any surprises are likely to come from packaging and mostly from malformed versions or specifiers that are no longer accepted.",
            "A specifier is an operator (equals, not equals, greater than, less than, etc.) and a version (1.0.0).\n\nA legacy specifier is a specifier that is no longer accepted because it doesn't conform to the spec, mostly this is because the version in the specifier is not compliant with the spec, e.g. `3.29.20240426-g5deef9c` is not a valid version anymore because a `-` and random letters aren't accepted in the \"non-local\" part of the version.\n\nHere is the spec if you're ever curious: https://packaging.python.org/en/latest/specifications/version-specifiers/",
            "Pip defaults to using pyproject.toml to read the projects metadata for quite a few versions now.\n\nThe pip project itself no longer keeps a legacy setup py or cfg (which had stuck around a while for vendoring reasons): https://github.com/pypa/pip/blob/main/pyproject.toml",
            "It was working a year ago when I learned pyproject.toml, so it\u2019s been a while.",
            "Interesting...looks like someone is using reddit to test their AI comment bots. User already banned",
            "Thanks for sharing the spec.",
            "Good news, thanks. Would like to have cargo like tool with built-in python",
            "I've switched to rust, just curious.",
            "Core CPython developers seem pretty uninterested about it being built in, but there are increasingly number of workflow tools that are all getting better every day (rye, hatch, pixi, poetry, pdm, etc.).",
            "https://rye-up.com/guide/",
            "It's sad. \"Should be only one good way to make a thing\". Maybe uv/poetry or something else should be used by majority of the community and after that integrated in python's distribution.",
            "https://i.kym-cdn.com/entries/icons/original/000/019/580/anotheronelol.JPG",
            "I really don't want another tool in this space, but I'm really excited to see what Astral does with this project. If anyone can unify the ecosystem, they can.",
            "unfortunately python doesn't adhere to that point in the zen of python in a lot of other places as well... don't think it counts as a source of truth unfortunately.",
            "From what I understand it isn't from lack of care, but lack of available man power to maintain yet more code. The core python team doesn't have room for more things on their plate .",
            "Yes, another one, but - finally the ONE.",
            "They've made it with ruff, they will make it with rye. Give it a try, really. It's not hard to change it (from Poetry or pip) you will never go back. Also, it natively supports pip requirements.txt format and it doesn't require to export it (like Poetry does). That is really convenient with Docker. As I said, it's easy to switch, give it a try.",
            "What about hatch? It too looks promising. Encourages good practices. Uses uv, ruff, mypy, pytest under the hood."
        ]
    },
    "How Python Asyncio Works: Recreating it from Scratch": {
        "title": "How Python Asyncio Works: Recreating it from Scratch",
        "score": 74,
        "url": "https://www.reddit.com/r/Python/comments/1clz4dy/how_python_asyncio_works_recreating_it_from/",
        "content": "Do you understand how asyncio works behind the scenes? Read this article and see how you can use Python generators to create your own version of asyncio, and then use the \\_\\_await\\_\\_ dunder method to use the async/await keywords to come full circle!\n\n\n\n[https://jacobpadilla.com/articles/recreating-asyncio](https://jacobpadilla.com/articles/recreating-asyncio)",
        "num_comments": 12,
        "comments": [
            "This is quality content!",
            "Those of you that find the article interesting, might also like David Beazley giving a talk on the same note back in 2019.\n\nhttps://www.youtube.com/watch?v=Y4Gt3Xjd7G8",
            "This is cool!\n\nRandom question but is there a reason you use queue.Queue which is synchronized per thread rather than an unsynchronized container like collections.deque? Since it is running on a single thread.\n\nAs a second question, is there any reason you chose time.time instead of time.perf_counter (since clock changes due to NTP could cause your sleep to terminate sooner than expected).",
            "This is really good. The other articles as well. You should send this to Pycoders Weekly.",
            "Thank you for the great content!",
            "Nice !",
            "Thanks!",
            "Thanks for the link - I remember watching a great talk on the GIL by him from that same channel!",
            "Those are both great points! Both definitely make sense, I just didn\u2019t think about them when writing the article :/",
            "Glad you like the article. I never knew you could submit articles to them!",
            "content for the next post? really loved this post",
            "Thanks! Next post is on technical SEO, then probably one on the different PostgreSQL transaction isolation levels, then an article about the inner workings of FastAPI, and then I want to write a quick article about Python buffers."
        ]
    },
    "Build tool support for PySide / PyQt\n": {
        "title": "Build tool support for PySide / PyQt\n",
        "score": 4,
        "url": "https://www.reddit.com/r/Python/comments/1cmg5fv/build_tool_support_for_pyside_pyqt/",
        "content": "Just interested in how people approach this, typically I just use VSCode or QtCreator to build simple projects. However I now want to automate some of the build process such as running uic, and rcc.\n\nI've tried to use CMake but can't seem to get it to work without a lot of custom scripting (for example the AUTOUIC etc functions need c++ projects), can't see any info on running uic in QtCreator (which would be ideal but python support is really just an after thought). \n\nI could write some Makefiles but this is a little ad-hoc and also confuses the IDE's (and at the end of the day I want a simple process for my students to use and I already teach cmake for C++ dev). \n\nSo I guess my questions are what workflows do people use, can you recommend any tools to help, or do you just have a per project script to run uic and rcc?\n\n(I may cross post this in both qt and python subreddits as I'm not sure where it fits best)\n",
        "num_comments": 9,
        "comments": [
            "At my work, we just have a script that globs for the ui files and runs the pyuic tool on it. We also have a pre-commit hook to make sure no commits are made with out-of-date ui files. If you want to automate the process, you could set up a preLaunchTask in VSCode (I don\u2019t know if there\u2019s an equivalent in QtCreator).\n\nYou could also consider using the QUiLoader class to load the ui files directly at runtime.",
            "maybe a docker image if you want it to be in a more share-able format?",
            "What about qmake?",
            "There is a plugin for VSCode called Qt for Python that automates ui, rc file compilation and a bunch of other things.\n\nWhen I'm happy with a project version I use nuitka to build to an exe.",
            "Can\u2019t you use proton native front end and Django backend",
            "thanks, I think I need to do the script approach, the QUiLoader is sometimes an issue especially when using Maya as there are some weird issues with PySide loading and you need to add extra code. I'm trying to make it as simple as possible.",
            "This is more automating the build process, for example I want to run uic and rcc before running my program, so it's not a deployment process. \n\nI have discovered that pyside6-project can do most of what I need, unfortunatly I mainly use PySide2 / PyQt5 at present.",
            "think qmake will give the same issues as cmake (and is also no being deprecated), it will work well for C++ but trying to get it to work with python is a pain. I think my main limiting factor at present is I need to use PySide2  (as this is what a lot of the 3rd party tools I develop for use maya / houdini) so I need that ecosystem.",
            "You could have custom launch bash scripts then?"
        ]
    },
    "relax-py - Web framework for htmx with hot module replacement": {
        "title": "relax-py - Web framework for htmx with hot module replacement",
        "score": 35,
        "url": "https://www.reddit.com/r/Python/comments/1clrnce/relaxpy_web_framework_for_htmx_with_hot_module/",
        "content": "Excited to finally showcase this!\n\nIt's still pretty rough around the edges, but I'm finally happy enough with the feature set and curious to see what the community thinks about a framework like this.\n\nCode: [github.com/crpier/relax-py](http://github.com/crpier/relax-py)\n\nDocumentation: [crpier.github.io/relax-py](http://crpier.github.io/relax-py)\n\n **What My Project Does**\n\n`relax-py` is a Python framework for building full-stack applications with `htmx`\n\nIt provides tools for writing HTML in a manner similar to [simple\\_html](https://github.com/keithasaurus/simple_html) (which also inspired the decision to use standard Python to write HTML, rather than use `Jinja2` or to make something like [templ](https://github.com/a-h/templ) work in Python)\n\nIt has:\n\n* Hot Module Replacement (meaning, when you update the code that generates HTML templates, the browser also updates instantly) - see the video in the documentation for a quick demo of this\n* URL resolution with type hinting - you can get the URL of an endpoint to use in your templates by using the function that handles that URL, and get help from static typing (for example, for putting path parameters in the URL)\n* Helpers for dependency injection\n\nIn essence, this framework is just a bunch of decorators and functions over [starlette](https://www.starlette.io/), meaning everything that starlette has can be used alongside the framework.\n\n**Target Audience**\n\nDevelopers interested in building web applications with `htmx` that like new shiny things and static typing support\n\n**Comparison**\n\nAs far as I know, the only other backend framework that has Hot Module Replacement is [turbo](https://www.hotrails.dev/) in Ruby on Rails, but there might be something I missed.\n\nAs for other points of comparison with other frameworks:\n\n* Django\n   * `relax` is less opinionated about what's done in the backend (.e.g there is preference to what ORM is used)\n   * using standard Python code to generate HTML has nicer static typing\n   * the URL resolution is more complex and provides errors in the IDE by way of static typing\n   * the `component` decorator provides nicer ways to reuse template functions and helpers for interoperability with JavaScript\n* [templ](https://github.com/a-h/templ) in Go\n   * templ allows writing actual HTML in go files, but requires an additional compilation step\n   * plugins for whatever IDE/code editor is used are needed parsing templ files\n* FastAPI (with something to generate HTML like simple\\_html or Jinja2)\n   * since FastAPI is built for RESTful APIs, it lacks niceties like URL resolution, or a mechanism to manage the sprawling mess of interconnected HTML components that apps tend to develop\n   * dependency injection in FastAPI is \"encouraged\" to happen in the path functions, but in `relax` it's meant to happen at any level of the app (either in path functions, or in service-level functions, or in util functions)\n* simple\\_html (with a backend like Flask or FastAPI): the main differences between simple\\_html and the `relax.html` module are that\n   * CSS classes are provided as a list of strings - this makes it easier to reuse them in different components, and will make it easier to implement other helpers in the future, like a Python version of [tailwind-merge](https://github.com/dcastil/tailwind-merge), or a formatter that sorts tailwind classes\n   * htmx-related attributes are included in the elements\n   * inserting children to an HTML element is done after instantiating the element, making it easier to reuse components\n\nHere's the code again: [github.com/crpier/relax-py](http://github.com/crpier/relax-py)\n\nThere's more details in the documentation: [crpier.github.io/relax-py](http://crpier.github.io/relax-py)\n\nWhile this framework is definitely not production ready, in the \"Other\" page of the documentation there's an example app built with this framework, which shows how it can be used in conjuction with some real-life scenarios (production environment for tailwind with plugins, working in a bunch of interactivity with JavaScript, in either separate js files and inline scripts, Dockerfiles and deployments, authentication and authorization, configuration etc.)\n\nPlease let me know what you think (are there better alternatives, is writing HTML in standard Python a deal-breaker, is investing in making something templ in Python worth it?)\n\nHope you're intrigued by this!",
        "num_comments": 13,
        "comments": [
            "Looks like a hell of a lot of work on your behalf, <standing, clapping>. I hope to carve out the time to check this out, I've got a large FastAPI application that illustrates the need for some of your mentioned pain points.",
            "is it possible to have one of those swagger out of the box screens? but this time the focus would be on the returned html snippet and perhaps query parameters, path variables and headers. That would be a great start to making htmx based apps more decoupled without extra code. What you think?",
            "Great work! I wish I had a brain to build something like you did!",
            "I don't see a license",
            "Video link not working",
            "How does this project compare to Litestar?\n\nhttps://docs.litestar.dev/2/usage/htmx.html",
            "Thanks! Most of the time was spent playing with various designs until settling on this one\n\nI haven't considered integrating with other frameworks so far, but you've given me food for thought. FastAPI would be a good contender since it's also based on Starlette",
            "It's certainly possible to implement, but I'm not sure in which context it would be most impactful.\n\nMy thinking is that for RESTful APIs you want this decoupling because people building the API and people consuming the API are on different functions, different teams, or even different companies.  \nBut for a full-stack app built with `htmx`, you'd have the same person (or the same team) building an endpoint and the HTML template that uses the endpoint, so decoupling wouldn't help so much.\n\nFor query parameters and path parameters, the URL locators can give you hints in the IDE on having the correct values, but I didn't think about headers until now.  \nMaybe you could have an endpoint that could respond with either HTML or something else based on the \"Accept\" header, and you'd like to document possible values?\n\nDo you have any examples/ideas for ways to use headers like this?",
            "Are you working on your own?",
            "perhaps it seems valuable for me because I see it as a documentation of the system. Aswell as a lighter way to develop it using the \u201cswagger\u201d as opposite to always running the app to see changes and behavior. Anyway, I\u2019m just stretching the htmx experience considerations, I don\u2019t have an example about the headers thing, but thank you for considering it",
            "Yep",
            "I work on my own too. Are you aware of any subredits or online communities targeting solo developers? Back in the 90's there was a fantastic email list for solo game developers that was incredible, but I left the games industry soon after the 90's ended, and have not found a good solo dev community since.",
            "ah, not really, sorry"
        ]
    },
    "python-oracledb 2.2 and the VECTOR type in Oracle Database 23ai": {
        "title": "python-oracledb 2.2 and the VECTOR type in Oracle Database 23ai",
        "score": 2,
        "url": "https://www.reddit.com/r/Python/comments/1cm3j4q/pythonoracledb_22_and_the_vector_type_in_oracle/",
        "content": "python-oracledb 2.2, the Oracle Database driver, has been released with support for Oracle Database 23ai features such as the VECTOR and BOOLEAN data types, Implicit Connection Pooling, and improved connection performance.  See the [release announcement](https://github.com/oracle/python-oracledb/issues/332).",
        "num_comments": 0,
        "comments": []
    },
    "I've started writing Python bindings for lexertl": {
        "title": "I've started writing Python bindings for lexertl",
        "score": 7,
        "url": "https://www.reddit.com/r/Python/comments/1clpq5l/ive_started_writing_python_bindings_for_lexertl/",
        "content": "See https://github.com/BenHanson/pylexertl\n\nI will see about registering as an official library when I am happy I have completed all the bindings. I added all the missing functions for the rules objects today, so things are in reasonable shape already.\n\nMy python experience has been limited up until now, but it is big for my new role.\n\nI have a runtime parser generator https://github.com/BenHanson/parsertl17 which I also plan to add bindings for.\n\nI hope this is of interest to somebody!\n\n**What My Project Does**\n\nAllows you to build lexical analysers at runtime and use them to lex text (in this case utf-8)\n\n**Target Audience**\n\nThe C++ library has been used in production for over 10 years.\n\n**Comparison**\n\nI'm not aware of any competing library.",
        "num_comments": 0,
        "comments": []
    },
    "Introducing PgQueuer: A Minimalist Python Job Queue Built on PostgreSQL": {
        "title": "Introducing PgQueuer: A Minimalist Python Job Queue Built on PostgreSQL",
        "score": 126,
        "url": "https://www.reddit.com/r/Python/comments/1ckrmog/introducing_pgqueuer_a_minimalist_python_job/",
        "content": "**What My Project Does**\n\nPgQueuer is a Python library designed to manage job queues using  PostgreSQL features. It leverages PostgreSQL's native LISTEN/NOTIFY, along with advanced locking mechanisms, to handle job queues efficiently. This allows for real-time job processing, concurrency, and reliable task execution without the need for a separate queuing system.\n\n**Target Audience**\n\nPgQueuer is ideal for developers and teams who already use PostgreSQL in their projects and are looking for a simple, integrated way to handle background tasks and job queues. It's designed for production use, offering a dependable solution that scales seamlessly with existing PostgreSQL databases.\n\n**Comparison**\n\nUnlike many other job queue solutions that require additional services or complex setups (such as Redis or RabbitMQ), PgQueuer operates directly within PostgreSQL. This removes the overhead of integrating and maintaining separate systems for job management.\n\n**How PgQueuer stands out**\n\n* **Integration Simplicity**: Integrates directly with existing PostgreSQL setups without additional infrastructure.\n* **Efficiency**: Uses PostgreSQL\u2019s `FOR UPDATE SKIP LOCKED` for high concurrency, allowing multiple workers to process tasks simultaneously without conflict.\n* **Real-time Updates**: Utilizes PostgreSQL's LISTEN/NOTIFY for immediate job processing updates, reducing latency compared to polling-based systems.\n\n**Request for Feedback on Useful Features**\n\nIm always looking to improve PgQueuer and make it more useful for our users. If you have any features you'd like to see, or if there's something you think could be improved, please let me know! Your feedback is invaluable! Share your thoughts, suggestions, or feature requests either here in the comments or via [GitHub](https://github.com/janbjorge/PgQueuer).",
        "num_comments": 25,
        "comments": [
            "You should probably cross-post this to r/django, given that it's one of the largest python web frameworks, job queues are always a hot-topic there, and postgres is the recommended database for django.\n\nIn fact, I'd suggest that, if possible, you write a \"integrating with django\" section in your documentation, that would surely help garner attention from that demographic.",
            "A friend of mine wrote [qbert](https://github.com/backwardspy/qbert) which more or less does the same thing. I\u2019m still not sure I\u2019m sold on Postgres queuing vs AMQP/MQTT/RQ, but good to see more examples of it.",
            "Superb. I don't really see a major flaw in this. Well done.",
            "Interesting, and very nice work the sql side.  Is the focus here PG or python, though?  \n\nIf it is python, how would this replace something like [https://python-rq.org/](https://python-rq.org/) or provide an alternate backend for it or celery?\n\nThe sql side made met think of this:  [https://github.com/tembo-io/pgmq](https://github.com/tembo-io/pgmq), which also feel very much still a work in progress.\n\nTheir presentation at pgconf: [https://www.youtube.com/watch?v=GG2C7gktfoQ](https://www.youtube.com/watch?v=GG2C7gktfoQ)\n\n>**A lightweight message queue. Like\u00a0AWS SQS\u00a0and\u00a0RSMQ\u00a0but on Postgres.**\n\n>Lightweight - No background worker or external dependencies, just Postgres functions packaged in an extension\n\n>Guaranteed \"exactly once\" delivery of messages to a consumer within a visibility timeout\n\n>API parity with\u00a0[AWS SQS](https://aws.amazon.com/sqs/)\u00a0and\u00a0[RSMQ](https://github.com/smrchy/rsmq)\n\n>Messages stay in the queue until explicitly removed\n\n>Messages can be archived, instead of deleted, for long-term retention and replayability",
            "You should add transactional enqueuing to the API... somewhat wasteful not to offer it if you are focusing on postgres.",
            "Amazing, will take a look tomorrow and see how i can contribute :)",
            "How does it release a \u201cskip update lock\u201ded-task in case of a crash when processing ?",
            "This is cool, thanks for sharing!\n\nDoes this function name have a typo in it? \n\nhttps://github.com/janbjorge/PgQueuer/blob/9258ef412b8ba7f57cf31308ab65b7b045ba658e/src/PgQueuer/cli.py#L43",
            "I unfortunately also created my own queue.\nI would've suggested to be a plugin of dramatic so others can more easily contribute too. I know there is dramatiq-pg but it uses listen-notify which I don't like (heavy, not scalable, a bit old).",
            "For sure.\n\n\nI'll try this with a Django app.\u00a0\n\n\nUsing Postgres for queues is even more interesting now that Redis is pulling those shenanigans\u00a0",
            "Thanks for the mention of qbert! It's always interesting to see how different projects tackle similar challenges. One of the key distinctions with PgQueuer is its use of PostgreSQL's LISTEN/NOTIFY feature instead of polling? My approach leverages PostgreSQL's built-in capabilities to react to queue changes in real time, which can lead to more efficient resource usage and quicker response times compared to traditional polling methods.",
            "Thank you for the encouragement! If you have any suggestions feel free to share in the future.",
            "Thanks for the comment and the references! PgQueuer is designed with a dual focus on both PostgreSQL and Python, aiming to leverage existing PostgreSQL infrastructure to manage queues efficiently. This approach minimizes the need for additional dependencies or external queue management systems.\n\nWhile tools like RQ and Celery are fantastic for task management across various backends, PgQueuer offers a simplified, database-centric approach, making it ideal for projects already invested in PostgreSQL. I provide a straightforward way to integrate queuing directly within the database layer, which can be particularly beneficial for systems where minimizing architectural complexity is crucial",
            "Could you elaborate a bit more on how you envision transactional enqueuing enhancing PgQueuer's functionality?",
            "Thanks for the support. Looking forward to your contributions.",
            "Currently, if a crash occurs, tasks might be logged as exceptions or remain marked as running in the queue table. I'm working on implementing a retry strategy to handle such cases more effectively.",
            "It does, thanks (fixed).",
            ">Using Postgres for queues is even more interesting now that Redis is pulling those shenanigans\n\nSorry if this is a bit off-topic, but what kind of shenanigans is Redis pulling? I'm afraid I'm not up-to-date on the topic.",
            "cool project! i am the aforementioned friend. qbert was built for a fairly specific (and low throughput) internal use-case for my last job, which is why it's tied to piccolo ORM and doesn't do anything particularly clever. even so, i was very pleasantly surprised at how far i could push it (and postgres itself) even with those fairly rudimentary queries. it served our needs perfectly for the duration of the project, which i was quite happy about.\n\nall that said, for a new project or something with higher demands i would certainly want to make changes to qbert or just reach for something else like what you've built here. it looks like really nice work!",
            "Here: https://riverqueue.com/docs/transactional-enqueueing\n\nThe gist is that you can guarantee atomicity of job enqueuing and other database operations within a transaction.",
            "For example, read a message from the queue and insert a record to a table, and delete message within same transaction.",
            "Licensing change",
            "It\u2019s great to hear about your success with leveraging PostgreSQL for job queuing in a specific context. I designed PgQueuer to maximize PostgreSQL's robust features like LISTEN/NOTIFY for higher throughput and efficiency, particularly in more demanding environments. \n\nCurrently, [PgQueuer](https://github.com/janbjorge/PgQueuer) uses [asyncpg](https://magicstack.github.io/asyncpg/current/) to manage PostgreSQL connections, which from my experience, seems to be one of the better Python PostgreSQL clients in terms of performance and features. However, I'm open to exploring whether PgQueuer should support other types of connections to broaden its compatibility and flexibility.",
            "I think implementing transactional would require a connection to remain open for the duration of the job execution? This could potentially affect performance due to the increased resources on the db?",
            "For a long running job, you may consider only executing the delete/archive of the message and the arbitrary table insert within the same transaction. I know several [pgmq](https://github.com/tembo-io/pgmq) users that implement a flow like:  \n- read message from queue, set VT to something large\n\n- do expensive long running work, like call a LLM or some large aggregate\n\n- open a transaction: insert record to a table (results from agg or LLM call) and call pgmq.archive() or pgmq.delete() on the initial message."
        ]
    },
    "Reboot Your Router with a Python Script": {
        "title": "Reboot Your Router with a Python Script",
        "score": 76,
        "url": "https://www.reddit.com/r/Python/comments/1ck452a/reboot_your_router_with_a_python_script/",
        "content": "Hello r/python,\n\nI've developed a Python script that allows you to reboot your router remotely via SSH! This script handles the countdown and checks when the router is back online after a reboot.\n\n## What My Project Does:\n\n**Key Features:**\n- **Automated Router Reboot:** Remotely trigger a reboot of your router.\n- **Monitoring:** After sending the reboot command, the script counts down from 350 seconds and starts checking the router's status by pinging it after the first 100 seconds have passed.\n- **Flexibility:** You can pass arguments dynamically (router IP, username, password, and port) or use hardcoded values within the script.\n\n**Method of Execution:**\nTo execute the script from the command line:\n```bash\npython3 reboot-router.py --ip <router_ip> --username <username> --password <password> --port <port_number>\n```\nDefault values are set, but it's highly recommended to pass arguments to the script for security reasons.\n\n## Target Audience:\n\nThis script is intended for:\n- **Tech Enthusiasts** and **Home Users** who enjoy managing their home network setups and want a quick way to automate router management.\n\n## Requirements:\n\n**Required Modules and Programs:**\n- **Python 3:** The script is written in Python 3. Ensure you have Python 3.6 or newer installed.\n- **subprocess and argparse modules:** These are standard libraries in Python and should be available with your Python installation.\n- **sshpass:** This utility is used for noninteractive password authentication with SSH. Install it using your package manager, e.g., `sudo apt-get install sshpass` for Debian/Ubuntu.\n\n## Important Router Configuration:\n\nBefore using this script, make sure your router is configured to:\n- **Enable SSH Access:** Ensure SSH is turned on and configured to accept password authentication. This setting is usually found under the `Administration` tab in your router settings.\n- **Allow ICMP Echo (Ping) Requests:** Some routers disable ICMP Echo requests by default for security. You must enable `Respond ICMP Echo (ping) Request from WAN` under the `Firewall` tab.\n\n## Comparison:\n\nUnlike many GUI-based tools, this script provides a simple, lightweight command-line solution easily integrated into larger automation workflows or triggered manually without logging into the router interface.\n\n### For People New to Python:\n\nIf you're new to scripting or network management, be cautious about storing sensitive information like passwords directly in scripts. While hardcoded values can be used for ease and demonstration, the best practice is to pass these securely as arguments to prevent exposure.\n\n### Access to the script\nYou can access the script on my GitHub page [here](https://github.com/slyfox1186/script-repo/blob/main/Python3/reboot-router.py)\n\nFeel free to use, modify, and share this script! I look forward to your feedback and enhancements!\n\nCheers -J",
        "num_comments": 25,
        "comments": [
            "A few things I'd consider bad:\n\n- The sudo/root stuff is simply pointless and a terrible idea as others pointed out.\n- Password login on SSH should always be disabled, SSH keys exist for a reason\n- Disabling hostkey checking is a bad idea. Make a manual connection once and then trust the host key, don't simply ignore invalid host keys. Sure, a MITM is extremely unlikely here, but it's a bad practice nonetheless.\n\nAnd then of course there's the question of why you need this to begin with. If my router sucked so much that it needs regular reboots, I'd probably get a different router...",
            "You need sudo to make a network call, eh? How intriguing...",
            "DevOps / Network nerd here, if you need to frequently reboot your router, you likely have a firmware bug. Usually one relating to the NAT or ARP tables not being cleaned down. Replace the device.\n\nI have a router at a remote site with ~500 days of uptime, I don\u2019t anticipate rebooting it any time soon (no patches are available right now).",
            "As someone who makes a living in cyber, I\u2019d advise nobody use this.  Under his \u201cimportant router configuration\u201d section, he tells you to enable ssh access, allow password authentication, and allow ICMP from WAN.  \n\nMost folks don\u2019t need to enable ssh on their router and if you do need to do so, there is no need to enable password authentication.  Absolutely pointless risk.\n\nEnable ping from WAN - self explanatory useless risk.\n\nTo the developer, if you want to do this yourself, whatever, but I\u2019d recommend against it.  But actually recommending this to others is harmful.  You should probably remove this post.  If you feel the need to keep it up then you should at least inform users of the risks they run by running this setup.\n\n  \nEDIT: You say your target audience includes network admins.  This would never be allowed in a corporate environment and no network admin would ever use this.  There wouldn\u2019t even be a need for this in a corporate environment but if there was, they\u2019d be using Cisco equipment and use the Cisco IOS.  This is something that a home user would use and most likely shouldn\u2019t use due to not knowing the risks or how to manage them.  This repo should just be set to private, dude.",
            "I'm going to sound a bit harsh, but don't take it as such.\n\nYou don't live up to the expecation of a target audience, network admins who value.. I mean, it is essentially a glorified shell script. You can do what you do in a couple of lines of bash/zsh:\n\n    ssh $host /usr/sbin/reboot\n    [ $? -ne 0 ] && echo \"Failed to reboot $host\" >&2 && exit 1\n    \n    while : ; do\n      ping -n -w 2  -c 4 $host && break\n      echo \"Did not hear back from $host yet.. \"\n      sleep 2\n    done\n\nYour script falls flat for various reasons:\n\n1. Like I said, a shell script can do what you do here.\n2. You use shell utilities, which I guess is fine, but if you are going to use python, use python modules to ping and ssh to a host. Think modules such as pythonping, paramiko and/or ssh-python.\n3. If you are going to use the shell utilities, make sure you respect their configuration. Eg, ssh has `.ssh/config` where I can set my username, port etc configuration for hosts. Use them, when the default port of 22 is used, don't override it with your default 22 because it breaks my `.ssh/config` default. When there isn't a username, don't insert your default, my default is the username of the current user, so use the shell environment $USER.. Although rather, don't set it at all, ssh is smart enough.",
            "A $10 smart plug (with built in timer functionality) would be a lot quicker and more secure.",
            "Here's one I hacked together that just uses the http interface; this was for a netgear orbi pro.\n\n    import requests\n    import re\n    RETRIES = 3\n    BASE_ADDRESS = 'https://192.168.1.1'\n    AUTH=('username', 'password')\n    for i in range(RETRIES):\n        r=requests.get(f'{BASE_ADDRESS}/reboot.htm', auth=AUTH, verify=False)\n        if r.status_code == 200:\n            ts = re.search(r'timestamp=\\d+', r.text).group()\n            break\n    else:\n        exit(1)\n    \n    for i in range(RETRIES):\n        p=requests.post(f'{BASE_ADDRESS}/apply.cgi?/reboot_waiting.htm {ts}', auth=AUTH, verify=False, data={'submit_flag':'reboot', 'yes':'Yes'})\n        if r.status_code == 200:\n            exit(0)\n    else:\n        exit(1)",
            "SSH is not normally running on my router.  How does the script start it?",
            "what kind of router? Do all routers adhere to the same commands?",
            "SSH doesn't normally run on my router. How does your script initiate SSH? Also I don't see the point of the sudo/root thing.",
            "I get that OP\u2019s code is for home users but you could do this much more securely with paramiko (ssh protocol package), Netmiko (multivendor router/switch package), and/or ncclient (package for interacting with NETCONF clients)",
            "I had this problem like 10 years ago. Just buy a new one.",
            "[deleted]",
            "Nice in theory, but in practice, if the vendor isn't pushing updates anymore, and you don't want to fork out $$ for new kit, a solution like this works fine.",
            "Agreeed with the other criticisms except 1.\n\nA LOT of python libraries are glorified shell scripts. `pytesseract` is something that comes to mind.",
            "[deleted]",
            "[deleted]",
            "Even easier as a home user... Walk over and reboot the router. Sure, it can be a tad inconvenient at times, if it is upstairs or downstairs, but as infrequently as one should need to do it, that is my preferred method. Of course, as my home is single floor and the router is centralized, nit isn't that far to go most of the time. And if the access point in the shop goes down, it only matters to me if I'm in the shop and it is right there to fix. Suppose it could be a bit inconvenient to go in the house to reset the router for the shop, but it really isn't that far a walk.",
            "Sudo makes things less safe. Never use it unless you have to. \n\nIt's like giving a program a key to your house when it only needs to go into the shed\n\nIt's probably not a major concern here, but it's best practices to avoid using it if you don't need to",
            "Ddwrt is an option, depends on the router if it supported.",
            "You wanted feedback, you got it, but now you feel offended.\n\nYou don't need to worry about me or proving me wrong, I don't need a python script to reboot a router from an anon on the internet. Especially not in a corporate environment.\n\nThe while loop works fine btw, 0 python was written today to make it work.. \n\n```\nwhile :\ndo\nping -n -w 2 -c 2 quasar && break\necho \"nope\"\nsleep 2\ndone\n\n# yields:\nPING quasar (192.168.0.8) 56(84) bytes of data.\n64 bytes from 192.168.0.8: icmp_seq=1 ttl=64 time=7.29 ms\n64 bytes from 192.168.0.8: icmp_seq=2 ttl=64 time=2.65 ms\n\n--- quasar ping statistics ---\n2 packets transmitted, 2 received, 0% packet loss, time 1002ms\nrtt min/avg/max/mdev = 2.648/4.967/7.287/2.319 ms\n```",
            ">  do this stuff because it is really fun to me, and I want others to find ways to appreciate my efforts. If only one person thinks what I did was useful then I'm good, and if zero do then I can still use what I've created. I'm glad I like this stuff, it gives me excitement and makes my mind light up thinking about it. This is the internet and it's full of haters and naysayers. It is what it is. \n\nThat is fine, but don't say, the target audience is propro network admins. And I gave constructive feedback, with: use module X, make sure to respect config Y. \n\nBut yeah, have a great day.",
            "Better yet, walk over and manually do it. How often does one need to reset a router these days anyways? The only ones I've gotten to the point of needing to do this regularly are older ones on their last legs. Eventually it is easier to upgrade or replace.",
            "Im lazy. Im so lazy that i wrote code to turn my (home) office zone AC on with an IOT button on my  desk.  A desk that is maybe 2 feet away.\n\nMy point is my laziness wouldn\u2019t let me deal with a router that had to be rebooted at regular intervals. I would have probably slammed together some bash code until a new router came in.  Personally I think this should have been a shell script for the OP\u2019s own personal use.\n\nI\u2019ve used Python to directly integrate with ssh without libraries and it is a pain - it is a pain when you\u2019re dealing with the exact same (ssh server) hardware every time with the exact same auth method + key exchange protocol, etc.  then you have to deal with device (router) terminal weirdness and more.\n\nThere\u2019s a reason paramiko exists.",
            "I understand that for other scripts (ones that are out to get you) this is a major concern. Regardless, I removed the requirement and now sudo is no longer required.",
            "non stock firmware can cause a significant performance hit due to closed source drivers for some hardware or another. probably most common with wireless hardware, but it's a consideration.",
            "The main concern is if other libraries or tools within your script get compromised. My analogy could probably be improved with \"it's like giving a contractor and all his employees the keys to your house when they just need to get into the shed\". In this script it's probably not a big deal because you're probably not using a ton of 3rd party packages and the ones you are using likely have a ton of people also using them and holding them accountable for their security practices and behavior. Meaning if there's a flaw or vulnerability it's more likely to get found and fixed quicker, but if you were using a less well-intentioned (or competent, or responsive) dev's work, you're giving *them* root access, too",
            "Ok thanks for the explanation. That makes sense and I'm better off for know it now."
        ]
    },
    "Opinions sought: Modernising the Apache NiFi Python client": {
        "title": "Opinions sought: Modernising the Apache NiFi Python client",
        "score": 3,
        "url": "https://www.reddit.com/r/Python/comments/1cknhb0/opinions_sought_modernising_the_apache_nifi/",
        "content": "Hello folks, I am the author of [NiPyAPI](https://github.com/Chaffelson/nipyapi), the defacto Python client for the Apache NiFi project.\n\nFor those unfamiliar, [Apache NiFi](https://nifi.apache.org/) is an open-source ETL tool designed around the flow-based programming paradigm. It excels at continuously moving and managing arbitrary data flows between disparate systems with low latency at large scale, and is often contrasted with Airflow.\n\nAmongst many features, NiFi allows for Command & Control via a native UI, enabling live edits to data routing and transformation. NiFi also enforces an API-first approach, and produces a swagger definition during code compilation, which allowed creation of a Python client to enable automated Data Flow testing and a Design & Deploy approach by running it through [Swagger Codegen 2.3](https://github.com/Chaffelson/nipyapi/blob/main/resources/client_gen/generate_api_client.sh) tool shaped by mustache templates. This produces a **very** verbose low-level client, which I then leverage in higher-level operational functions and demo scripts in the library.\n\nHowever it's always bugged me that this produces literally 10's of thousands of lines of boilerplate, so potentially replacing the low level client with something more modern would ideally massively reduce the codebase without impacting the high-level functionality of the library.\n\nNow, I first started it mid last decade with Python2 for broad compatibility and times have moved on significantly (as has my skill with Python) but it's finally time to drop Python2 support and move to a better build & release process, which opens the door to a larger update, and I am frankly not across modern best-practices around ClientGen so I come seeking r/Python's advice: How would you modernise this venerable artefact?\n\nI could simply move to a newer version of Swagger Codegen, or move into the OpenAPI Generator, I could get fancy with something like [Fern](https://www.buildwithfern.com/) \\- or I could leave well enough alone and just accept that the tons of boilerplate are at least very readable.",
        "num_comments": 1,
        "comments": []
    },
    "Python Test 220: Getting the most out of PyCon, including juggling - Rob Ludwick": {
        "title": "Python Test 220: Getting the most out of PyCon, including juggling - Rob Ludwick",
        "score": 4,
        "url": "https://www.reddit.com/r/Python/comments/1ckc18e/python_test_220_getting_the_most_out_of_pycon/",
        "content": "Listen at [https://podcast.pythontest.com/episodes/220-juggling-pycon](https://podcast.pythontest.com/episodes/220-juggling-pycon)  \nEven if you never get a chance to go to PyCon, I hope this interview helps you get a feel for the welcoming aspect of the Python community.\n\nThe juggling at PyCon is one of the inspirations for [PythonPeople.fm](https://PythonPeople.fm), one of PythonTests's sibling podcasts.\n\nDo you have any conference tips to add?",
        "num_comments": 1,
        "comments": [
            "good"
        ]
    },
    "Suggestions for python libraries to contribute to": {
        "title": "Suggestions for python libraries to contribute to",
        "score": 9,
        "url": "https://www.reddit.com/r/Python/comments/1cjt02h/suggestions_for_python_libraries_to_contribute_to/",
        "content": "Hey, python folks ! I have been coding in python for around 3 years, 2 years professionally. I have worked with asyncio, typing and other stuff that is needed to build a server. I was looking for a small but impactful enough open source core python library/application to work on. I tried cpython but it seems to be beyond my capability at the moment. As for my interests I was interested in lower level stuff as well as libraries like asyncio and celery. Any suggestions for libraries that could use a bit of help and teach me some stuff as well would be appreciated",
        "num_comments": 16,
        "comments": [
            "You should only contribute to tools that you use and are familiar with. Otherwise, you will spend a lot of your time trying to understand how a project is set up or making poor-quality pull requests because of your unfamiliarity.\n\nWhy not work with asynchio? It sounds as if you are quite familiar with it.",
            "Try contributing to gevent as an alternative to asyncio.\n\nYou can contribute to opentelemtry (and it's contrib modules) which should touch many parts.",
            "\"I want to contribute to open source project by grapping the low hanging fruits\" - I think the low hanging fruits are already taken, so you will need to spend time to dig into the code base, its architecture decisions and investigate known issues before adding new features ...",
            "Most of my contributions to open source projects have either been fixes for bugs I've discovered or features I've implemented because they solved a problem I have.\u00a0\n\n\nThis is most likely a good place for you to start too. If none of them projects you work with have bugs you've encountered or missing features you'd really like, then you're probably best off waiting until you hit a bug or missing feature. If this never happens, then that means these projects are getting on fine without you and you don't need to worry too much about contributing.",
            "Geemap & leafmap",
            "check out these: https://tomaszs2.medium.com/10-awesome-python-open-source-projects-ep-7-a21405b3070e",
            "https://github.com/pygame-community/pygame-ce/issues",
            "[https://www.ursinaengine.org/](https://www.ursinaengine.org/) is about 20 years behind in usable editor user interface.",
            "RemindMe! 3 days",
            "AutoGen",
            "Problem is asyncio is integrated with the cpython codebase which is quite difficult to navigate and understand",
            "I will be messaging you in 3 days on [**2024-05-07 06:47:42 UTC**](http://www.wolframalpha.com/input/?i=2024-05-07%2006:47:42%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/Python/comments/1cjt02h/suggestions_for_python_libraries_to_contribute_to/l2id8lb/?context=3)\n\n[**4 OTHERS CLICKED THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2FPython%2Fcomments%2F1cjt02h%2Fsuggestions_for_python_libraries_to_contribute_to%2Fl2id8lb%2F%5D%0A%0ARemindMe%21%202024-05-07%2006%3A47%3A42%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%201cjt02h)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|",
            "There are some low-ish hanging fruits on wireup, a dependency injection library I maintain if you want to take a look. There's a few issues open. New integrations with frameworks are always welcome.\n\nhttps://github.com/maldoinc/wireup\n\nBut I will +1 the sentiment that you should look to first contribute to things you're using in a sort of scratch your own itch. That way you know what needs to change and you can propose changes upstream.",
            "Yup I agree, that it would be better to contribute to something I know. I have some work in asyncio but I am scared to contribute in cpython. Also I want to improve my code quality and find out different ways or coding styles python is used",
            "What about something like Poetry or maybe Pandas? I am not familiar with the libraries you like to use, but pick something that you use. Then, find a problem you want solved or a feature you wish was available. Then, start by writing well-documented issues on GitHub that discuss the problem, opening up a dialogue with others who may be more familiar with the project. Maybe one of them solves it, and you have just contributed to the project. Or maybe you can work with them to outline some solutions and write your own fix if it is a low-priority issue.\n\nOr, if you really want to be a core library maintainer, you should learn CPython. So, why not build a small project that solves a problem you experience that just happens to use CPython? This way, you can learn CPython before coming back to tackle problems with asyncio."
        ]
    },
    "Project: Simple Interactive Python Streamlit Maps With NASA GIS Data": {
        "title": "Project: Simple Interactive Python Streamlit Maps With NASA GIS Data",
        "score": 48,
        "url": "https://www.reddit.com/r/Python/comments/1cj57lw/project_simple_interactive_python_streamlit_maps/",
        "content": "Python Streamlit is terrific for putting together interactive dashboards. \n\nCombined with the geopandas library, streamlit can easily display GIS data points on a map for you. \n\nForest fires in my home province of British Columbia, Canada have been really bad recently. NASA has a terrific dataset that keeps track of forest fires by country. \n\nCan I use Streamlit to access this dataset and display a map off all the fires within a certain area (BC) for a particular time frame (2021)?\n\nAnd can I give the user the ability to choose a month? \n\nYou bet! Let me step you through how!\n\nFREE tutorial (with code):\n\n[https://johnloewen.substack.com/p/simple-interactive-python-streamlit](https://johnloewen.substack.com/p/simple-interactive-python-streamlit)",
        "num_comments": 6,
        "comments": [
            "This is cool.",
            "now figure out how to embed that interactive map in your blog ;)",
            "Thanks so much! It was so much fun to put this project together. Give it a go!",
            "Yes, that's a great next step. I used to host all my own stuff so it would have been easy. A bit more difficult on Substack. Suggestions? \n\nAnd thx for the comment - much appreciated :-)",
            "I actually just built a scheduling app for my work because my boss uses a piece of paper. I hooked up the stream lit to google sheets so my boss can enter the schedule to a format he has some familiarity with.\n\nI did my undergraduate degree in geography and would like to get into GIS if I can. I detoured into teaching for some time but I\u2019m really hoping to put that in the past.",
            "I'm not sure what the limitations of substack are, but it's possible that you could at least gain some ground by moving away from the streamlit model and instead try rebuilding this within the ipywidgets ecosystem. My go-to stack is to use the [Panel](https://panel.holoviz.org/) library with [Param](https://panel.holoviz.org/explanation/dependencies/param.html), which can then build your app into a static web page so you don't need a live python server hosting the app components. This trick even works for bokeh tooling. \n\nTry playing with this: https://ipyleaflet.readthedocs.io/en/latest/index.html\n\nAlso [Voila](https://github.com/voila-dashboards/voila) is neat."
        ]
    },
    "New book! The Quick Python Book, Fourth Edition by Naomi Ceder": {
        "title": "New book! The Quick Python Book, Fourth Edition by Naomi Ceder",
        "score": 10,
        "url": "https://www.reddit.com/r/Python/comments/1cj8zp2/new_book_the_quick_python_book_fourth_edition_by/",
        "content": "Hello everybody,\n\nThank you for having us here, and a huge \"Thank you\" to the moderators for letting us post.\n\nWe have just released the latest edition of The Quick Python Book by the one-and-only Naomi Ceder, and I wanted to share that news with the community. \n\nMany of you are already familiar with Naomi's work and her massive contributions to the world of Python programming language.\n\nThe Quick Python Book has aided over 100,000 developers in mastering Python. The Fourth Edition of the book has been revised to include the latest features, control structures, and libraries of Python, along with new coverage of working with AI-generated Python code. Naomi, the author, has beautifully balanced the details of the language with the insights and advice required to accomplish any task. Her personal touch has made learning Python an enjoyable experience for countless developers.\n\n\ud83d\udcda You can find the book here: [https://mng.bz/aEQj](https://shortener.manning.com/aEQj)\n\n\ud83d\udcd6 Get into the liveBook: [https://mng.bz/gvee](https://shortener.manning.com/gvee)\n\nAnd last but not the least, get 46% off with code: **receder46**\n\nHope you find the book helpful.\n\nThank you.\n\nCheers,\n\n",
        "num_comments": 1,
        "comments": []
    },
    "typedattr: Autocompletion and typechecking for CLI script arguments, using standard argparse syntax": {
        "title": "typedattr: Autocompletion and typechecking for CLI script arguments, using standard argparse syntax",
        "score": 18,
        "url": "https://www.reddit.com/r/Python/comments/1cj2ztk/typedattr_autocompletion_and_typechecking_for_cli/",
        "content": "Excited to share my pypi package [typedparser](https://github.com/simon-ging/typedparser) I have been working on for around 1 year now.\n\n**What My Project Does**: It enables writing CLI scripts and create an \"args\" variable with autocompleted members and type checks, but still keeps the simple and universally understood syntax of the stdlib argarse module.\n\n**Target Audience**: For stability, I battletested it in my research projects and added automatic builds as well as 80%+ test coverage. So I believe it is pretty stable.\n\n**Comparison**: For typing functionality it uses the `attrs` package as backend. It also provides some additional features for object and dictionary manipulation. Of course there are many other CLI argument packages out there, but this one stands out in that it tries to keep the syntax of the argparse standard library as much as possible, making it easy for others to figure out what your script does. Check it out and let me know what you think.\n",
        "num_comments": 7,
        "comments": [
            "In general if you're depending on a PyPI package directly in your code, you should declare it in your requirements to guarantee that it's installed and not rely on it being installed by another dependency.\n\nAt the moment for Python 3.7 you're relying on the fact that `attrs` depends on `importlib-metadata` which depends on `typing_extensions` in order for `typing_extensions` to be in place for `_typedattr.py`. \n\nIt's unlikely in this specific case (I'd expect 3.7 support to be dropped first) but if there was an `attrs` update that removed the dependency on `importlib-metadata` your module would no longer work on Python 3.7 when someone installed it.\n\n(Note that this probably wouldn't show up in your tests, because installing `pytest` on 3.7 also installs `typing_extensions` and would only show up when someone used it without either of these modules.)",
            "I really like the approach you've taken here.  It builds on familiarity with two commonly used Python libraries.\n\nI was thinking about adding environment variable support.\n\nPerhaps with a second decorator as described in https://www.attrs.org/en/stable/extending.html\n\n    @read_env(prefix=\"FOOBAR\")\n    @define\n    class Args:   \n        # omit the argument name to have it inferred from the field name\n        foo: str = add_argument(positional=True)\n        bar: int = add_argument(shortcut=\"-b\", type=int, default=0)\n        opt: Optional[str] = add_argument()\n\nThen values would be read from FOOBAR_FOO, FOOBAR_BAR, and FOOBAR_OPT, with explicit commandline args taking preference over env variables.\n\nIs this something you would be interested in as a contribution?",
            "I think is overkill to use numpy",
            "I'll try to look into it, but it's going to take a lot to get me to give up fire.",
            "Good point. I updated the `requirements.txt` to require those packages explicitly.\n\n```\nattrs\nimportlib_metadata;python_version<'3.8'\ntyping_extensions;python_version<'3.8'\n```",
            "Happy you like it.\n\nYour idea sounds interesting, but you would have to solve some edge cases, as here: foo is positional so it's required and the env var will never be used. bar has a default value, that would overwrite the env as well.\n\nI would probably just do default=int(os.environ.get(\"FOOBAR\\_BAR\", 0)) but if you use env vars alot your contribution might be very useful.\n\nSo in short, yes, you are welcome to contribute.",
            "good point. i made the numpy support optional."
        ]
    },
    "Dash vs Reflex vs Others": {
        "title": "Dash vs Reflex vs Others",
        "score": 43,
        "url": "https://www.reddit.com/r/Python/comments/1citedj/dash_vs_reflex_vs_others/",
        "content": "Where can I find a decent comparison (pros and cons) of these 5 solutions? They seem to be solving the same problem, which is, afaiu, separating the frontend \u2018annoyance\u2019 from Python scripting  / math. \n\n1.\t\u2060Reflex (used to be called Pynecone) https://reflex.dev\n2.\t\u2060Streamlit https://streamlit.io\n3.\t\u2060Gradio https://gradio.app\n4.\t\u2060Dash https://dash.plotly.com\n5.\t\u2060Panel https://panel.holoviz.org/\n6.\t\u2060Anvil https://anvil.works/\n7.    Quarto \n\nMy use case: user access the web app, choose some parameters, selects things that go or not into a model. Python returns results of my math. \nNeeds to be somewhat eye-candy and I need to use a lot of pictures to get the user input (i.e. \u201cwhich of these figures you like most? 1,2,3. User clicks on \u201c3\u201d, 3 is considered in the model. ",
        "num_comments": 25,
        "comments": [
            "I love dash. Currently using for building a MVP at work. It\u2019s basically Flask with react on top of it, so I use Jinja templates for simple pages and Dash for the actual webapp. \n\nStreamlit is more for prototyping and smaller/simpler projects or tools.\n\nCan\u2019t speak for the others frameworks as I haven\u2019t used them, but Dash would fit very nicely with your use case.",
            "[nicegui](https://nicegui.io/)",
            "Quarto is different from the other on your list. It isn't an app but a publishing framework. If I'm not mistaken, no server/ui so you'll get less possibilities, but on the other hand it allows to create self-contained .html (among other formats) that may be easier to share if you're not in a logic of hosting an app.\nPlus, it is multi-language (Python, R, Julia)\u00a0",
            "Can't help you with a comparison, but I've been working on a work project in Reflex and I like it pretty well so far. I can write front end code in Python, which is nice, but I also don't have to maintain an API between server/client- that all happens automagically. \n\nI'm skeptical of magic stuff in general, and the \\`State\\` abstraction that maintains state between server & client is a little inscrutable, BUT it's saving me a bunch of extra maintenance and build work that I'd have to do otherwise. I'm here for it.",
            "PyWebIO & Nicegui will fit your needs.",
            "I don\u2019t know about the others, but this can certainly be done in Dash.\n\n[some inspo](https://plotly.com/examples/)",
            "We use Dash for multiple producuction apps, it does all that you want in the post.",
            "Adding [solara.dev](http://solara.dev) to the mix. My favourite when you start work in jupyter notebooks and want to go towards building full apps.",
            "Check out [illa-builder](https://github.com/illacloud/illa-builder)",
            "Those are mostly for rough drafts and internal company projects for now.\n\nAlso look into pyscript. If they can increase the speed of the library, then you got yourself the golden goose egg for what you need. You use normal web dev tools and able to insert a dash of python where you need it. Only issue is C compiled libraries, which I wouldn't be surprised if this is a issue elsewhere.",
            "Thanks Alpaca. Where would I get the \u201cJinja templates\u201d to try this out ?",
            "Yeah I\u2019ve been messing around with Dash recently too, it\u2019s great.",
            "That and https://flet.dev are always my two go-to's.",
            "I checked but it doesn\u2019t seem like that link provides a comparison.",
            "![gif](emote|free_emotes_pack|snoo)thanks",
            "Read the details on their website. Promising. Thanks for your reply",
            "Great addition. Thanks !",
            "This looks promising ! Thanks crawl",
            "Many thanks for this, @Iwill. Not sure I fully grasp the proposal of pyscript but I am reading the docs. Wanted to see a full big project using the tool but haven\u2019t found it yet. Thanks",
            "I worked on dash for about a month last year. It was a pain whenever I needed any element which wasn't in dash standard library. It required JS/react knowledge, which I unfortunately didnt have. If you/colleague has that, it should be a breeze.",
            "Anaconda is maintaining it. It\u2019s in their interest to make their infrastructure more useful.",
            "Check out https://htmx.org/",
            "Hah ![img](emote|t5_2qh0y|598)![gif](emote|free_emotes_pack|feels_good_man)"
        ]
    },
    "I made a python package that can parse Excel Formula Strings into dictionary structures! ": {
        "title": "I made a python package that can parse Excel Formula Strings into dictionary structures! ",
        "score": 56,
        "url": "https://www.reddit.com/r/Python/comments/1cipq2f/i_made_a_python_package_that_can_parse_excel/",
        "content": "What my project does:\n\n\n\nIt basically takes a formula string like you'd get from Openpyxl like \"=SUM(A1:B2)\" and breaks it all out into a dictionary structure for you to then navigate through, modify, and then reformat that modified structure back into an excel friendly formula string again!\n\n\n\nTarget Audience: (People who modify Excel formula strings in automated spreadsheet modification scripts. Or people who need to analyze formulas in a spreadsheet to do some kind of logic based on that analysis).\n\n\n\nDisclaimer: For most people some simple regex pattern matching and str replaces would be fine to modify formulas but if you need a more structured approach to working with these strings, this package has you covered!\n\n\n\nHow does it differ compared to other projects: There are libraries like Openpyxl that allow you to tokenize and translate formulas but that's currently where it ends. It doesn't allow you to systematically parse out a formula and replace those pieces and add new structures and what not into it. Currently the best you can really do is translate formulas and anything other than that would need to rely on regex string matching logic or string replacements. (Which still would be fine for most people, but this just adds another layer of organization and scalability to the format).\n\n\n\nMore info about it here: https://github.com/Voltaic314/ExcelFormulaParser\n\n\n\nTo install, just do: pip install ExcelFormulaParser\n\n\n\nThank you for reading this!! Hope you guys find it useful if you're ever systematically modifying (or analyzing) spreadsheets!\n\n",
        "num_comments": 8,
        "comments": [
            "By the way, this type of data structure is called an *abstract syntax tree* (AST).",
            "Thanks for sharing, but how would you differentiate your package from what [formulas](https://github.com/vinci1it2000/formulas) does?",
            "This project looks interesting to me! But may you specify more on what specific task at your job would need the functions you mentioned? Just would like to have an example to demonstrate the use cases. PS: I\u2019m currently a student so I\u2019m not very familiar with the workplace scenarios yet.",
            "Nice!",
            "My days. You are legendary. Thank you!",
            "Thank you for letting me know! I will research it a bit more and update the wording on the library for it. :)",
            "I didn't know about this library, thanks for sharing! \n\nIt looks like the way it breaks up formulas into a different kind of json structure than mine. I have yet to actually use it but looking at the dictionary structure in the documentation it looks like it doesn't break up smaller bits into a hierarchy structure the way mine does but maybe it's not that way when you actually print or save the dictionary structure as a json file. \n\nIt also looks like it has extended functionality but my library is meant to just focus specifically on the lightweight aspect of breaking out formulas into a dictionary and then reconstructing them with any modifications back into an excel friendly formula string. \n\nThe whole reason I even made this library was to help me at my job so if someone has a better library that accomplishes these tasks then I'll gladly use that instead of reinventing the wheel. But if my library can help others then great!",
            "Thank you! A lot of my work involving spreadsheets has me writing code to take the values and formatting of cells from one spreadsheet to another. When you read a formula in Openpyxl (library for interacting with spreadsheets), it just displays the formula and not the calculated value. The formula is just a string, and it can include many different components, cell ranges, cell references, functions with arguments that are functions and so on. It can get pretty messy. \n\nThe problem is, when I have to remap a formula to point it's references to a new row / column, I need a way to tell python to find those references and modify their values. \n\nSometimes I may need to quickly modify a bunch of formulas by changing one of their arguments to something else. \n\nMost of this logic can be done with regex string matching and built in string methods in Python but the point of the library is to not have to do that and instead be able to modify parts of it more precisely (like for example doing str.replace() will replace all instances of that (or you can provide a count argument but then it only replaces each one from left to right but it just can be a pain to try to do this in a precise consistent way of modifying these formulas every time. \n\nWhen transforming spreadsheets or taking data from one spreadsheet to another, accuracy is the most important thing. You need to know that your formulas are being modified in an extremely consistent and predictable way every time. \n\nBy transforming the formulas into a dictionary structure you can know exactly which key and value you're modifying instead of the chaotic nature of strings and string replacements. \n\nSo it's mainly for better precision and control. :)"
        ]
    },
    "Hatch v1.10.0 - UV support, new test command and built-in script runner": {
        "title": "Hatch v1.10.0 - UV support, new test command and built-in script runner",
        "score": 41,
        "url": "https://www.reddit.com/r/Python/comments/1cigfix/hatch_v1100_uv_support_new_test_command_and/",
        "content": "Hello everyone! I'd like to announce version 1.10.0: [https://hatch.pypa.io/latest/blog/2024/05/02/hatch-v1100/](https://hatch.pypa.io/latest/blog/2024/05/02/hatch-v1100/)\n\nFeel free to provide any feedback either here or as a discussion on the repo: [https://github.com/pypa/hatch](https://github.com/pypa/hatch)",
        "num_comments": 6,
        "comments": [
            "\"\"\"\n\nHatch is a modern, extensible Python project manager.\n\n# Features\n\n* Standardized\u00a0[build system](https://hatch.pypa.io/latest/config/build/#build-system)\u00a0with reproducible builds by default\n* Robust\u00a0[environment management](https://hatch.pypa.io/latest/environment/)\u00a0with support for custom scripts and UV\n* Configurable\u00a0[Python distribution management](https://hatch.pypa.io/latest/cli/reference/#hatch-python)\n* [Test execution](https://hatch.pypa.io/dev/tutorials/testing/overview/)\u00a0with known best practices\n* [Static analysis](https://hatch.pypa.io/latest/config/static-analysis/)\u00a0with sane defaults\n* Built-in Python\u00a0[script runner](https://hatch.pypa.io/dev/how-to/run/python-scripts/)\n* Easy\u00a0[publishing](https://hatch.pypa.io/latest/publish/)\u00a0to PyPI or other indices\n* [Version](https://hatch.pypa.io/latest/version/)\u00a0management\n* Best practice\u00a0[project generation](https://hatch.pypa.io/latest/config/project-templates/)\n* Responsive\u00a0[CLI](https://hatch.pypa.io/latest/cli/about/), \\~2-3x\u00a0[faster](https://github.com/pypa/hatch/blob/hatch-v1.5.0/.github/workflows/test.yml#L76-L108)\u00a0than equivalent tools\n\n\"\"\"",
            "I\u2019ve used Hatch before but looks like it\u2019s now updated to use modern tooling like ruff and uv. I\u2019ll give it another go.",
            "Awesome.",
            "How does hatch deal with locking dependencies? This is the primary reason I am using poetry (despite other gripes I have with it). Hatch looks better on most other fronts, but that is a big one for me...",
            "Hatch is awesome and simplified our workflow a lot. \nWe were waiting for the 1.10 release with UV support already, it speeds up our pipelines by at least 25%!\nNow we just need better support for enterprise CI environments without Internet access (but internal mirrors for most stuff) ;)\nSee https://github.com/pypa/hatch/pull/1455 for example ;)",
            "This is the plugin that everyone uses for that [https://github.com/juftin/hatch-pip-compile](https://github.com/juftin/hatch-pip-compile)",
            "Cheers, I will give hatch a spin tomorrow and see how I like it ;)",
            "Cheers, I will give hatch a spin tomorrow and see how I like it ;)",
            "Cheers, I will give hatch a spin tomorrow and see how I like it ;)",
            "Cheers, I will give hatch a spin tomorrow and see how I like it ;)"
        ]
    },
    "What does your python development setup look like?": {
        "title": "What does your python development setup look like?",
        "score": 89,
        "url": "https://www.reddit.com/r/Python/comments/1cib6to/what_does_your_python_development_setup_look_like/",
        "content": "I'd like to explore other people's setup and perhaps try need things or extra tools. What kind IDE, any extra tools to make it easier for you, etc. Looking forward to everyone's responses! ",
        "num_comments": 112,
        "comments": [
            "Your submission has been automatically queued for manual review by the moderation team because it has been reported more than 3 times.\n\nPlease wait until the moderation team reviews your post. Do not manually message modmail, as that will not expedite the review process.\n\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/Python) if you have any questions or concerns.*",
            "I keep it simple with neovim, pre-commit (mypy, ruff), pytest. For debugging I just use the breakpoint function.",
            "For exploring datasets, plotting data, reading Excel files or accessing databases I use jupyter.\nFor other projects I use PyCharm IDE",
            "Vscode for normal coding /projects stuff\n\n\nThonny for DSA (very good debugger)",
            "PyCharm, poetry, pyenv, isort, black, mypy.",
            "1.VSCode with the following plugins:  \nCodeium (or Continue with Ollama/Deepseek Coder for when I must work offline)  \nPython and Python debugger (from Microsoft)  \nPython Environment Manager (by Don Jayamanne)  \nSnippets`(`by Taha BASRI)\n\n2. Zed Attack Proxy (ZAP) for software security testing  \n3. DBeaver for database management  \n4. GIT GUI (by Shawn O. Pearce)  \n5. MySQL\n\nAnd lately, I have been experimenting with these quite interesting inventions:\n\n1. [Brython](https://brython.info/index.html), a Python replacement for Javascript on the Web.\n2. [PyScript | Run Python in your HTML](https://pyscript.net/).\n3. [Pyston | Python Performance](https://www.pyston.org/) (support only up to 3.10)",
            "Mostly Spyder. And for displaying outputs to colleagues Jupyter Notebook, as it makes it easier for them to understand which output corresponds to which part of the code and it does not just look like a block of code",
            "PyCharm pro, Hatch, UV, ruff, pre commit.",
            "For Windows:\n - VSCode for editing code (I probably have too many plugins/extensions)\n - NotePad++ for reviewing output and print files (One of the scripting languages I use puts the script in the print file, and the number of times I've fixed a bug in the print file is frankly embarrassing...)\n - Running Code, depends on the project - mostly Cygwin shell, or within an application.\n\nFor Linux/macOS:\n - Coding in Vim/GVim for editing for Python/Perl/Shell, but sometimes VSCode as well. I use Xcode for Swift.\n - Running code from the command line for python, in Xcode for Swift.\n\nThe most useful tools is probably an Opinionated Linter (I use Ruff and AutoPep8, and a decent autocomplete engine that shows the function details for functions calls.",
            "Neovim + pyright + black for general use. DataSpell for working with data and plotting.",
            "I keep it pretty simple. Jupyter labs and neovim.\n\nJupyter labs for initial development and hard debugs as you can test out segments of your code.\n\nNeovim for maintenance on deployed scripts,  minor revisions, and general use.\n\nI'll show line numbers and that's it.",
            "I just use vscode with copilot, I use the standard Microsoft plugin for python for other code specific features.\n\nGunicorn and flask for web services and micro services.\n\nWsl Debian, python Venv\n\nAlong with standard numpy, pandas, requests.\n\nLately I\u2019ve been using the huggingface libraries a lot.",
            "Vim and gnome-terminal.\n\nA number of Vim plugins: ALE for realtime linting, gutentags for keeping my ctags database up-to-date, a couple of my own plugins for locating source locations from traceback lines copied into the clipboard and for preparing pytest command-lines to run the test under cursor, fugitive and gitgutter for git integration.\n\nI keep Vim in one terminal tab, and run the tests/perform git operations in other tabs.",
            "Sublime Text with breakpoint() commands, run from the command-line with Python 3.12.\u00a0",
            "vscode/devcontainers, pylint. Notebooks (in vscode) for exploratory data analysis.",
            "Neovim with Conqueror of Code plugin and python-language-server as a development environment.\n\nFor Python specific development tools I use:\n- pylint\n- black\n- pyenv \n- mypy \n\nPlus, when I am in charge of developing a new package I use Poetry.\n\nAnd that\u2019s basically it.",
            "IDLE on my windows school laptop. Fr up till recently. Sublime with copilot and I remote into my linux PC for real shit now",
            "I use Replit on my iPhone lol",
            "neovim rye ruff",
            "Spacemacs, lsp/pyright, ruff, copilot, magit \ud83e\uddd8",
            "Because I mostly work with Linux HPC from Windows and Mac, I use VS Code with remote development and several Microsoft extensions.\nI only use notebook to provide tutorials for workshop.\nFor environments, I mainly use miniconda.",
            "Anaconda and vscode only.",
            "Consistent folder structure in a venv folder. No IDE except Eclipse when I need to do remote debugging. \n\nEmacs or sublime as an editor. (Yes, I'm an old dude, I work a shitload over terminals on a bunch of servers)\n\npdb as my good old standby for regular debugging.\n\nYou have to understand that I work very much in the philosophy of Neil Stephenson in his essay \"in the beginning was the command line\". I write code and I don't want any distractions, whistles or bells with that. We don't put music players or GPS systems in Race cars either.",
            "Pycharm Pro, Dataspell, The OG Thonny",
            "Sublime Text for Little Projects.  Spyder for everything else.",
            "Docker containers set up with docker-compose, vim, and testing depends on what I'm doing. If I'm doing Django, then I use the built in test suite",
            "Neovim (AstroNvim to be precise) in tmux, poetry and ruff (instead of the classic zoo of linters and formatters). All of this works ultra-fast and all of this is enough even for complex projects. Also: ipython, ipdb, nushell (take a look, cool stuff) and many less important CLI tools, like bat and jq.",
            "Pycharm, pyenv, pipfile/poetry(depending on project), ruff(with pre-commit hooks), docker and SourceTree\n\nI also use a JavaScript toolchain because it do be like that sometimes: Nodejs, nvm and npm.\n\nEDIT: also dbeaver",
            "I am probably the outlier --- I've been using Literate Programming with my LaTeX work for a while now, so I am programming using LP in an ltxdoc using the docmfp package in TeXworks (on Windows) or TeXshop (on Mac) and then running the code using PythonSCAD (the Python-enabled OpenSCAD variant).\n\nI would be very interested in a Pythonic Literate Programming environment --- for folks not familiar with it:\n\nhttps://www.goodreads.com/book/show/112245.Literate_Programming_Lecture_Notes_",
            "mine looks like this.\n\na distrobox box fedora just for python with its own home holder so it only has python extensions (doesn't shave with node/go etc.)\n\nextensions:\n\npython (the ms one)\n\nFlake 8\n\nblack formatter\n\nmakefile tools\n\n  \nthen i use poetry to manage my dependencies. \n\n  \nI have and immutable / so all things i have are installed via flatpak OR in a pod and exported with distrobox",
            "PyCharm + PyEnv with occasional multipass boxes for isolated dev.",
            "For work: Databricks (Jupyter notebooks basically) and a striped down version of the vscode IDE built into GitLab.\n\nAt home: vscode",
            "Debugger driven development: \n\n    pytest --ipdb --pdbcls=IPython.terminal.debugger:TerminalPdb \\\n       --ignore=tests/data --capture=tee-sys --log-cli-level=ERROR\n\nI have it set to launch into debugger on an error if [any level of verbosity has been passed as command-line arguments](https://github.com/chapmanjacobd/library/blob/3bc71f0b7adf6b30bf89a09e96f254d7588e6c0a/xklb/utils/log_utils.py#L31)\n\nLinting\n\n    pycln --all && ssort && isort --profile black --line-length=120 && \n       black --line-length=120 --skip-string-normalization",
            "VSCode, pyenv, PDM, ruff, pytest, mypy and playwright also DBeaver\n\nVSCode extension-ids:\n\n* ms-python.python - Does the job well enough\n* humao.rest-client - Easy testing of endpoints\n* Gruntfuggly.todo-tree - This one does a good job with todos\n* ms-playwright.playwright - Covers end to end tests\n* ms-azuretools.vscode-docker\n* miragon-gmbh.vs-code-bpmn-modeler - Good for sketching up BPMN quickly to check the process in my head\n* github.vscode-github-actions",
            "On Windows, Notepad++, pytest, flake8, black, and isort.  On Linux, vim and whatever tools the package I'm working on wants.",
            "At work (under windows):\n\nVS Code, but primarily for the excellent Juypter notebook integration and extension ecosystem. For basic data science work flows nothing beats the utility of the Data Wrangler extension with the biggest benefit being that the dataframe is displayed and updates in real time while you type in the python scratchpad. I use it frequently in meetings to show the transformation steps to non-coders. Other than that, I keep my normal development workflow pretty simple: the python extension, black, and the built-in debugger. Mypy has been an absolute gamechanger in helping spot potential edge cases. For things I run on our compute cluster, I have a very specific work flow since it is near impossible to debug in that environment: write the program, change the linting rules to strict and turn typechecking on, run mypy, address any potential issues, then setup a mock environment and step through the script with the debugger and verify the control flow all before testing on the cluster. This workflow cuts total debugging time down significantly because I have identified almost all potential errors before testing in a hard environment to debug. \n\nAt home (Linux):\n\nIn the process of switching to emacs currently, but in the meantime I use VS Code for larger projects and Neovim for quick edits/scripts. Vscode configuration is similarly basic to work, and I just use the python LSP on the Neovim side.",
            "VSCode with Vim extension, Miniconda with mamba solver, conda-forge with pip at the end if needed. No Anaconda channels because licensing.Vanilla pyflakes and pylint. Notepad++. Git bash.",
            "Pycharm, qodana ( experimental), poetry, ruff, pytest, responses, pydantic, flask\n\nSoon, my pi\n\nPostgres being my DB of choice.\n\nPre-commit hooks",
            "Somewhat unrelated, but a question for those working with VS Code and data frames (pandas / polars): have you found a good way to view a data frame when working interactively? Something like `View` in RStudio. I know I can print it in the console but that truncates it. Also aware that I can use Jupyter but I'm not a fan.",
            "New coder here, since fall, but with several years of PowerShell experience. Python is WAY better IMO.\n\nVScode, Stream Deck, 48in 4k screen. Code on my gaming rig for local AI when I need it. Use Black formatter, but with line limit set to 200 for ease of use on my screens.",
            "VSCode with GitHub Copilot \ud83d\ude80",
            "VSCode with quite some extensions, the main ones being:\n- Pylance (along with some other python-specific extensions kindly shipped to us by M*crosoft)\n- Jupyter Notebook\n- Codeium\n- For quite some time I'd been using the Vim extension, but it doesn't work quite well with .ipynb files (specifically, it had independent modes for each cell and it didn't switch to normal once you run it) so I disabled it until I find a solution to that \n- Docker\n\nAlso I use venv-s but I guess it goes without saying",
            "vim for small jobs or fast work\n\npycharm for big projects / big work\n\nrun the project from the command line, manage environments with venv\n\nEvery time I try to add novel tools it ends up being more effort than it's worth.",
            "Astronvim for editing, pyright for type checking, ruff and uv for everything else. I don\u2019t even use a python version manager, I just install directly from my package manager and symlink the version I want to be standard as .local/bin/python.",
            "Macvim and a terminal window",
            "I put my projects in ~/code/<project name>/ each as a GitHub repo.  Virtual env for each one and asdf to use different python versions when required.  Usually just use 3.10 for everything when I can.  Black to format on save with 120 character line limit.  Requirements.txt and pip.  \n\nI\u2019ve used poetry on more mature projects and it was great!",
            "`fvwm`, `xterm` and `vi`. That's basically all you need.",
            "vim, black, isort, docker.",
            "Jupyter lab with multiple themes plus git and lsp extensions (including pyright), pre-commit (black, isort, flake8 but want to switch to ruff, mypy), virtualenv.",
            "Pycharm pro, pyenv, ruff , pre-commit",
            "PyCharm, pyenv, black, flake8, isort. venv with requirements.txt for dependency management.",
            "VS Code, GitHub, chatgpt. Have a standard template that boilerplates the imports I usually use. That\u2019s about it.",
            "WingIDE Professional, black, ssort, isort, mypy, ruff.",
            "Vscode on local MacOS/Windows, Colab for ML prototyping",
            "Nvim, black, ruff.",
            "I have not yet found a compelling reason to leave IDLE.\nI generally start on paper with a flowchart, so I don't really need anything IDLE doesn't already provide.\nIf I need to edit anything pushed to the Raspberry Pi, Nano works as well.",
            "Vs code and the interpreter. Pretty much it. If I'm doing something with a lot of boilerplate or repetitive code, I'll lean on an LLM. And I use CodiumAI to generate most of my tests.",
            "VSCode for IDE\n\nconda as an environment manager (interested in pyenv but don't want to rock the boat just yet)\n\nruff\n\npyscaffold for packaging\n\njupyter notebooks for analyses\n\ngithub desktop for version control",
            "Pycharm with vim plugin, ruff, Github Copilot, mypy",
            "Trying to use VS Code like the cool kids but I always have trouble remembering all the functionalities. If not using VS Code, I typically juste use Notepad++, and an IPython console on the side.",
            "A Fedora Laptop with VScode with some extensions, remote developer, Podman MySQL workbench. Remmina. Regular terminals with or without tmux and or vim. The brave browser. Bitwarden.",
            "virtualenvwrapper, vscode, poetry\n\nI have windows machine but i like to develop in wsl",
            "I just use PyCharm or VSCode at-home or when I have my laptop with me, but if I'm on the go I usually just hop on GitHub Codespaces (or clone a repo and use Termux on my tablet) because all of my code is usually stored on GitHub nowadays.",
            "Spyder, spyder, and spyder. \n\nMight have to replace my F9 key soon",
            "VSCode, Pyright, Pre-commit(Format, Yelp secret scan), Ruff, Poetry, Pytest, Codeium, Git-Cola, Pipx for actually deploying, Make to keep track of all the single line commands like rebuilding documentation.",
            "I suggest getting super comfortable with Docker.\n\nBeing fed up with managing multiple Python versions installed at once, virtual environments, and a surprise I\u2019ve had with a Python behaving differently when running the same program on different operating systems, I do 100% of my Python work within a Docker container.",
            "Vscode, poetry, ruff, pylint, flake8, pytest, tox, hypothesis with hypofuzz, mypy on strict mode, mkdocs, azure pipelines for cicd, mccabe complexity and maintenance index checks in tox,",
            "PyCharm Pro, Docker (WSL 2), Miniconda, CUDA, CuDNN, Git (command line), Notepad++ (Git editor)  \npytest, coverage, ruff (if I can't get it on a project I use black, isort, pylint), mypy, pre-commit",
            "Pycharm, git and a RTX4080 for the cuda cores",
            "It varies a lot because I use so many different computers. VS Code when working on a windows machine. vim on linux machines. I've use Jupyter notbook, but not a fan. pyenv is handy for version conflicts. git everywhere",
            "Do you also have mypy/ruff integrated into neovim, or are they just pre-commit hooks?\n\n  \nAlso not sure if you have ipython installed, but it includes a pretty nice debugger (ipdb) compared to the default.",
            "Very similar here. pytest --pdb is 99% of my debugging.",
            "Did you try to see if your ruff lsp has the same results as ruff itself? I've been trying to move to neovim, I have a set up I like a lot, but even though everything is in the pyproject.toml, I get different result when using ruff in neovim compared to all other ways. Like in neovim, it tells me that some file need to have their imports reordered, but when using the command line or vscode, it does not.",
            "Better than the VS Code debugger?",
            "What's DSA??",
            "This is me :P although I have recently leaned more towards ruff for linting and formatting (its sooo fast)",
            "Is PyCharm a big enough step up from something like VS Code to be worth it in your opinion? Trying to convince my company to buy our team licenses, but not sure if that will ever happen!",
            "I used to use poetry but stopped using it after hanging dependencie checks.",
            "Have you looked at hatch? It could replace/manage all of those packages for you.",
            "Would you mind explaining to a recent poetry convert; given that poetry  has its own environment management, how does adding pyenv to the mix help you? Thanks!",
            "Pycharm CE or professional?",
            "Plus GitHub Copilot for me.",
            "It's actually \"DBeaver\"",
            "Love Spyder's variable explorer",
            "Have you tried WSL2 instead of Cygwin?",
            "This was me, and kind of still is. But I recently set up pyright and ruff_lsp in neovim, along with adopting and helping maintain a hatch/hatch-pip-compile/uv/ruff template for use across my team (DS at a mid size company). I have to say, the additional tooling is wonderful. I catch mistakes earlier, occasionally pick up best practices I wasn't yet aware of, and perhaps most importantly, I no longer need to worry about whether my teammates are as attentive as me since the pre-commit hooks normalize across editor configs.",
            "Check out tmux for a more fluid as well as safer alternative to terminal tabs!",
            "What do you use for type checking?",
            "Have you tried uv, from the makers of ruff, for resolving and installing packages? It's seriously fast. You can get a similar experience to poetry, but with the speed of uv, using hatch with hatch-pip-compile and uv. (Eventually uv will probably replace all these tools all on its own)",
            "Add mypy and we're cooking.",
            "You really might want to try uv. It's an ultra fast drop in replacement for pip, pip-tools, and venv. Many more features are in the works, but it's already super handy.",
            "I am using ruff-lsp but it doesn't support definitions. So you can't jump to one or see type hints. I am going to add none-lsp at some point but couldn't squeeze the time just yet.\n\nThanks for pointing to ipdb, I'll try it out.",
            "ruff-lsp uses the settings specified on editor-level (init.lua). The only lsp that respected project-level settings that I tried was null-lsp (which is abandoned so we are supposed to use none-lsp now). It was a bummer for me at first. But if you're using pre-commit, it's doesn't matter too much.",
            "Yes\n\nThe visualisation it provides is really helpful.\n\nVscode just goes line by line\n\nBut thonny debugger goes to token by token\n\nWhich makes understanding really easy",
            "Data structures and algorithms.\n\nSince I have to debug each step while solving leetcode problems",
            "My company and I work on long-term projects with relatively big code bases, we are not yet prepared to make the switch to ruff but it's somewhere far down in the backlog with a low priority :)",
            "Ruff is great, except for the fact that this actually lints:\n\n    y = 3\n    \n    if y > 4:\n    \n        x = 1\n    \n    print(x)\n\nSo the reason ruff is so fast is because it doesn't really analyze the code very well.",
            "My opinion, yes.  I use VS Code for everything else, but for Python - PyCharm is too big an upgrade to stick with VS Code.",
            "I've never really used VSCode for python development.\n\nI use PyCharm because I'm a big fan of all jetbrains products. Also, I like that it is dedicated to python development, unlike VSCode.\n\nMy company buys licences for the Professional version because it comes with nice features that the Community Edition, which is 100% free) does not have and we find nice to have (SQL support, flask/fastapi/django frameworks, [and more](https://www.jetbrains.com/products/compare/?product=pycharm-ce&product=pycharm)).\n\nIMHO, the Community Edition is sufficient enough for everyday development, unless you really want some extra features that are found only in the Professional version (or not provided by some free plugins).",
            "Were you using multiple Poetry repo sources? This can make resolution really slow unless you set the `priority` option correctly for each source.",
            "pyenv is almost exclusively used on developers workstations.\n\nWe have different projects targeting different versions of python. Localy, each project has its own virtualenv managed by poetry ; we install the different versions of python using pyenv then set the version of each poetry environment version as [described in the documentation](https://python-poetry.org/docs/managing-environments/) (or via `poetry env use`).",
            "Profesionnal but as I've said [in this comment](https://www.reddit.com/r/Python/comments/1cib6to/what_does_your_python_development_setup_look_like/l28yylr/), CE is good enough unless you really need the extra features (or you want to support a company that makes a really good software \\^^ ).",
            "It's actually \"DBeaver\"",
            "Thank you, typo corrected.",
            "we have switched recently in a few smaller projects and it has been pretty painless, especially if you don't add extra rules",
            "Actually it does excellent analysis, and such robustness against errors is an explicit design goal.",
            "What are some advantages over vscode?",
            "This sounds like unnecessary complexity. Personally I use conda and export to a requirements file before installing in docker.",
            "Did you try my example? It shouldn't lint yet ruff thinks this is totally OK code. How many other bugs is ruff missing because they haven't implemented all of pylints rules? I think people see the time savings graph in the ruff Readme on github and think it's magically better, yet it can't catch this simple bug.",
            "I think conda is unbearably slow",
            "One extra line in your TOML file isn't really complexity. If you have a 100 packages to install from pypi.org and 1 from your private repo, you don't want Poetry to arbitrarily decide to look for all 101 in one or both sources.",
            "They are pretty upfront with the fact they're not fully 1-1 with pylint. Last I checked they even have a tracker that shows which rules are still not implemented. It's very easy to know exactly what you're signing up for. When my team evaluated we didn't think any of the missing rules were impactful enough to affect the decision"
        ]
    },
    "Tutorial on Building a Server-to-Server Zoom App with Python": {
        "title": "Tutorial on Building a Server-to-Server Zoom App with Python",
        "score": 4,
        "url": "https://www.reddit.com/r/Python/comments/1cinnql/tutorial_on_building_a_servertoserver_zoom_app/",
        "content": "I made a tutorial on how to build a **server-to-server Zoom OAuth application using Python**. This application can transcribe Zoom meeting recordings, print the transcripts to the terminal, and save the transcripts as text files.\n\n* [video tutorial](https://www.youtube.com/watch?v=sQVliRl5uKw)\n* [repo](https://github.com/AssemblyAI-Examples/assemblyai-zoom-transcripts)\n* [written tutorial](https://www.assemblyai.com/blog/zoom-transcription-zoom-api/?utm_source=youtube&utm_medium=referral&utm_campaign=yt_ry_8)\n\n  \nThis tutorial covers:\n\n* Setting up OAuth authentication for server-to-server apps\n* Utilizing the Zoom API to access recordings\n* Implementing automatic transcription using Python",
        "num_comments": 0,
        "comments": []
    },
    "Multipart File Uploads to S3 with Python": {
        "title": "Multipart File Uploads to S3 with Python",
        "score": 5,
        "url": "https://www.reddit.com/r/Python/comments/1ciiim4/multipart_file_uploads_to_s3_with_python/",
        "content": "I created [this tutorial](https://www.youtube.com/watch?v=HkF3_GLVKEg) after overcoming a difficult challenge myself: uploading 5GB+ files to AWS. This approach allows the browser to securely upload directly to an S3 bucket without the file having to travel through the backend server. The implementation is written in python (backend) and vanilla js (frontend).",
        "num_comments": 6,
        "comments": [
            "This is a great bit of work, Ive hit this problem quite a few times and having the web browser upload multipart with a self signed url was the least friction to the user.\n\nWill bookmark this and see if I can use it in the future.",
            "You might also need a \"list chunks\", for when you want to resume an upload.\n\nAnd \"abort upload\" for when you want to abort it.\n\nA nice library for the frontend is also https://github.com/transloadit/uppy",
            "Did the AWS CLI not perform well? Just curious why you went with this route.",
            "Thanks! \ud83d\ude4f",
            "Yes, there\u2019s a lot more you can do (for example, progress bar) but was trying to keep this video as short as possible and it is not very short lol.",
            "This is meant to be used for a web app to allow other users to upload files - not for myself to upload files."
        ]
    },
    "Suggestions for a self-hosted authentication as a service?": {
        "title": "Suggestions for a self-hosted authentication as a service?",
        "score": 22,
        "url": "https://www.reddit.com/r/Python/comments/1ci9ijz/suggestions_for_a_selfhosted_authentication_as_a/",
        "content": "I have a simple backend REST API service that is serving a few ML models. I have made it \"secured\" by implementing an API key in order call those endpoints. \n\n  \nI was wondering, how common it is for people to use services that can be self-hosted as their authentication/authorization.\n\n  \nIf it is common and reliable, what are the best options to go for? \n\nI've read that building your own authentication/authorization service with email verification, password reset, and social auth can be a pain. \n\n  \nAlso, did some googling and found this [General - Fief](https://docs.fief.dev/integrate/python/). Has anyone ever tried using this? If so, how was the experience? \n\n  \nThanks in advance. ",
        "num_comments": 17,
        "comments": [
            "With social auth you probably mean oauth2?\n\nYou can go with \u201ekeycloak\u201c. It\u2019s open source, battle tested and we, like many others, use it in production at work.\nDeploying it on kubernetes via helm was fine, configuring it etc. might be more work though.",
            "I use authelia.\n\nhttps://github.com/authelia/authelia",
            "[Zitadel](https://zitadel.com/). They've got Python integrations (Django and Flask specifically) and they support everything you could want out of an auth provider incl passkeys, social auth, multi-tenancy, etc.\n\nThey're primarily a SaaS but the entire stack is open source and self-hosting is well-supported.\n\nedit: if you're expecting your service to remain quite small, i think they have a permanent free tier on the SaaS as well.",
            "Just a random question (sorry I can\u2019t help). Did you build the models yourself?",
            "Tbh if you are a saas based org not even bother about adding extra Auth. API keys are pretty strong if you are using a strong logic on generating API keys and strong email encryption. Just maintain code properly as Auth routes and unauthorized routes.\n\nMake sure: API keys are not guessable or generate random keys",
            "+1 for key cloak. I've been using it for years on both personal and work projects. As you mentioned, it's definitely battle tested from a security perspective. Very complicated to configure initially, but is worth it in the end.",
            "Thanks for the shoutout!\n\nOne small amendment here.\n\nYou can also self-host with commercial contract of Zitadel (we have many customers that do that) ;-)\n\nSo you have 3 options:\n\n1) Self-hosting Zitadel open source\n\n2) Zitadel cloud (which has a free tier)\n\n3) Self-hosting Zitadel with a commercial license (gives you support, engineering access and so on)",
            "Hello!\n\nI guess I should have mentioned that I'm using FastAPI. Don't see any official integration for FastAPI. But I did see a guide on how to integrate it. \n\n  \nAmong all the solutions I've seen, Zitadel looks the most appealing to me. Hence, I will go for this one as my first choice. Plus, I can self-host it. So, big win there.",
            "Yeah, collected the data, trained, evaluated, put into production.",
            "Sorry, but I think you posted another comment on how to get into the field? \n\nThe way that I started was, I went for machine learning first. So, learning basic ML algorithms such as Linear/Logistic Regression, Naive Bayes, KNN, Decision Trees, etc. \n\nFrom there, I learned how important it is of having clean data. Thus, I learned how to clean data properly and experiment it with some statistical analysis. \n\nAfter that, I would go for Deep Learning. Learning Artificial Neural Networks, Multilayer Perceptrons, RNN, CNN, etc. Then, maybe go for transformer-based architectures. But after that, it's really up to you on how you would like to go from there. \n\n  \nBest of luck. There's so many resources out there now, to the point it becomes overwhelming. Take your time and just learn what you can from those resources.",
            "From what I can remember, I generated the key using secrets. Then I stored it in a .env file. I do agree with you though that an API key is strong enough. But, I foresee that this application may scale up to the point where I need to handle users. So that's why I'm exploring suitable options to handle user auth.",
            "is there such thing as keycloak as a service anywhere?",
            "Hello!\n\nAs stated before, I do like how Zitadel looks, so will be sure to try it out first. \n\n  \nAny chance the team will publish some docs on how to integrate Zitadel with FastAPI? Would appreciate if there's some official docs coming from you guys. \n\n  \nCheers\\~",
            "Great to hear. Let us know how it goes with the FastAPI integration! As far as I know we have multiple devs in the community working with FastAPI. Those members could for sure help you. Some are also actively working on a guide that can be published.",
            "You don't need to be regular, just think out of the box. You can always correlate email to API keys or API keys to email in vice-versa if you need to scale up and have to just create a user table that checks with API keys to email and then create sessions upon them it's easy and passwordless and unguessable. I'm not saying not to use extra options that are ready to use but the external piece of software is also hackable and will be having CVEs, and it will be sometimes costly. It's better to think before than later and have your own logical middleware as you can expand more when necessary.",
            "Good question... From a quick search there's a few different SaaS providers offering it, but I've never used one. \n\nOne other thing I forgot to mention is the [oauth2-proxy](https://github.com/oauth2-proxy/oauth2-proxy) that integrates nicely with keycloak (and a few other IAM solutions) very nicely and rather effortlessly. It sits in front of your app and acts as a reverse proxy pushing in the authorization attributes into your upstream app via http headers.",
            "Hey. There's multiple people in the community working with FastAPI and some are committed to draft up a guide. This would be great coming from the community for the community."
        ]
    },
    "One pytest marker to track the performance of your tests": {
        "title": "One pytest marker to track the performance of your tests",
        "score": 17,
        "url": "https://www.reddit.com/r/Python/comments/1ci7m95/one_pytest_marker_to_track_the_performance_of/",
        "content": "Hello Pythonistas!  \nI just wrote a blog post about measuring performance inside pytest test cases. We dive into why it\u2019s important to test for performance and how to integrate the measurements in the CI.  \nHere is the link to the blog: [https://codspeed.io/blog/one-pytest-marker-to-track-the-performance-of-your-tests](https://codspeed.io/blog/one-pytest-marker-to-track-the-performance-of-your-tests)\n\n&#x200B;",
        "num_comments": 2,
        "comments": [
            "When I looked into it I found it weird there was no easy way to run the test multiple times with setup and teardown run between each execution. May I missed something?",
            "There are multiple ways to have setup and teardown working with pytest.\n\nYou can use `setup_*` or `teardown_*` functions, like explained in the [x-unit style pytest setup docs](https://docs.pytest.org/en/stable/how-to/xunit_setup.html).\n\nBut the recommended `pytest`way of writing same is to use fixtures (I really recommend reading [the docs about it](https://docs.pytest.org/en/stable/how-to/fixtures), they are quite well written). A simple setup will look like this\n\n    import pytest\n    \n    @pytest.fixture\n    def setup():\n        data = generate_data()        # < will run before the test\n        yield data                    # < pass data to the test\n        data.clear()                  # < will run after the test\n    \n    \n    def test_my_fn(setup, benchmark): # < you can use multiple fixture\n        data = setup\n        result = benchmark(my_fn, data)\n        assert result == \"expected\"p\n\nNote that CodSpeed will run your benchmarks only once, as what is [measured is the CPU instructions](https://docs.codspeed.io/features/understanding-the-metrics/#execution-speed-measurement), and not the wall clock time.\n\nHope this helps!"
        ]
    },
    "How to create architecture diagrams from code in Jupyter Notebook": {
        "title": "How to create architecture diagrams from code in Jupyter Notebook",
        "score": 27,
        "url": "https://www.reddit.com/r/Python/comments/1ci4l9t/how_to_create_architecture_diagrams_from_code_in/",
        "content": "Hello world,I wrote an article about creating diagrams from code on Jupyter Notebook inside VS Code. It will give you a brief on the setup and also an overview of concepts. Within 5 minutes, you should be able to start making cool architecture diagrams.\n\n\\[TO MODERATOR: This link does not contain any paywalled or paid content. All the contents are available for free\\]\n\nArticle link: [https://ashgaikwad.substack.com/p/how-to-create-architecture-diagrams](https://ashgaikwad.substack.com/p/how-to-create-architecture-diagrams) ",
        "num_comments": 2,
        "comments": [
            "Great! Check out [Kroki!](https://kroki.io/)\n\nIt also has a jupyter magic plugin.",
            "This looks interesting \ud83d\ude00. Thanks for sharing. I'll try it out. Kroki is much bigger in terms of functionality, it might satisfy some of my other use cases apart from arch/cloud diagrams"
        ]
    },
    "Starter Code for a LLM-based AI Assistant ": {
        "title": "Starter Code for a LLM-based AI Assistant ",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1cinjg9/starter_code_for_a_llmbased_ai_assistant/",
        "content": "Hey everyone \ud83d\udc4b\n\n**TL;DR**  \nSince everyone is talking about the Humane AI Pin and the Rabbit R1, I decided to make a short 5 minute tutorial on how people can setup and customize their own little AI assistant on their machine.\n\nI've uploaded a video tutorial here:\u00a0[https://www.youtube.com/watch?v=2fD\\_SAouoOs&ab\\_channel=2BytesGoat](https://www.youtube.com/watch?v=2fD_SAouoOs&ab_channel=2BytesGoat)\n\nAnd the Github code is here:\u00a0[https://github.com/2BYTESGOAT/AI-ASSISTANT](https://github.com/2BYTESGOAT/AI-ASSISTANT)\n\n  \n**Longer version**\n\n* **What my project does:** It's the starter code for an AI assistant that you can run locally. More precisely, it's a ChatGPT / Llama 2 agent that has access to Google Search and can get businesses nearby based on your location. The tool can be easily extended to support other APIs.\n* **Target audience**: Pythoneers that are curious about LLMs and LLM related libraries.\n* **Comparison**: It was inspired by projects such as the Humane AI Pin and the Rabbit R1. Though it's a inferior version to those, it serves more as a playground for people to develop their own AI assistants. ",
        "num_comments": 5,
        "comments": [
            "Literally who is talking about those two items",
            "[deleted]",
            "People are talking\u2026 negatively",
            "Maybe I\u2019m under the wrong impression, but I feel that since ChatGPT there are a few companies that appeared out of thin air that promise smarter AI assistants than Siri and Alexa.\n\nAlso lately there was a lot of attention in this direction, since both the Rabbit R1 and Humane Pin got somewhat released.\n\nMaybe they\u2019re not the best products yet, but people seemed to be interested in the subject, given all the tech bros making at least one review on them and still getting traction.\n\nI just wanted to shine some light on the subject for people that may be curious about them and maybe give some starting points \ud83d\ude05",
            "I can give it a spin and build a webui in Gradio if there are at least 5 people interested of that.\n\nThing is, you would still need to create your own tools for it, which would be a bit hard to do from the UI",
            "They are, but I feel that it\u2019s mostly because they\u2019re disappointed by the products being similar to Siri/Alexa or other assistants, but not as refined and sold as standalone solutions.\n\nWhat\u2019s interesting though is the way they\u2019re built, cuz the approach is totally different (you don\u2019t make rules, you kinda rely on the AI)."
        ]
    },
    "How to auto-instrument Python servers w/ OpenTelemetry for performance & error monitoring": {
        "title": "How to auto-instrument Python servers w/ OpenTelemetry for performance & error monitoring",
        "score": 22,
        "url": "https://www.reddit.com/r/Python/comments/1chtmle/how_to_autoinstrument_python_servers_w/",
        "content": "Hi everyone! We've recently written up a guide for anyone running a Python server (ex. Flask, Django, FastAPI) to instrument their app to debug slow downs and errors using the CNCF OpenTelemetry project and their Python instrumentation package.\n\nIt's really straightforward to get started with just a few lines of added code and commands to any Python project, so hopefully helps some people out as they're looking to add better instrumentation to their servers.\n\nHere's the tutorial: [https://www.hyperdx.io/blog/opentelemetry-python-server-auto-instrumentation](https://www.hyperdx.io/blog/opentelemetry-python-server-auto-instrumentation)",
        "num_comments": 0,
        "comments": []
    },
    "k8sAI - my open-source GPT CLI tool for Kubernetes!": {
        "title": "k8sAI - my open-source GPT CLI tool for Kubernetes!",
        "score": 0,
        "url": "https://www.reddit.com/r/Python/comments/1cij4mp/k8sai_my_opensource_gpt_cli_tool_for_kubernetes/",
        "content": "**What my project does:**\n\nI wanted to share an open-source project I\u2019ve been working on called k8sAI. It\u2019s a personal AI Kubernetes expert that can answer questions about your cluster, suggests commands, and even executes relevant kubectl commands to help diagnose and suggest fixes to your cluster, all in the CLI!\n\n**Target Audience:**\n\nAs a relative newcomer to k8s, this tool has really streamlined my workflow. I can ask questions about my cluster, k8sAI will run kubectl commands to gather info, and then answer those question. It\u2019s also found several issues in my cluster for me - all I\u2019ve had to do is point it in the right direction. I\u2019ve really enjoyed making and using this so I thought it could be useful for others. Added bonus is that you don\u2019t need to copy and paste into ChatGPT anymore!\n\nk8sAI operates with read-only kubectl commands to make sure your cluster stays safe.\n\nAll you need is an OpenAI API key and a valid kubectl config. Start chatting with k8sAI using:\n\n    $ pip install k8sAI\n    $ k8sAI chat\n\nor to fix an issue:\n\n    $ k8sAI fix -p=\"take a look at the failing pod in the test namespace\"\n\nWould love to get any feedback you guys have!\n\n[Here's the repo](https://github.com/wilson090/k8sAI)\u00a0for anyone who wants to take a look\n\n**Comparison:**  \nI found a tool (k8sGPT) that I enjoyed using, but I felt it was still missing a few pieces on the chatbot side. You can't chat back and forth with k8sGPT and it doesn't suggest commands for you to execute, so I decided to make this. ",
        "num_comments": 7,
        "comments": [
            "This sounds somewhat dangerous to let AI model execute commands on the cluster? And if you are managing a cluster and you don't know what is going on to a point that ChatGPT has to quote some docs for you is also... questionable.",
            "You atleast need to add something that makes it more transparent what it would do to the cluster if it hast non read-only access. Otherwise it\u2019s way too dangerous to use. Add an explainer part to the output or something. \n\nThink of what GitHub Copilot workspaces will do: \n- Specification Phase (this is the prompt)\n- Planning Phase (this is missing from your tool)\n- Execution Phase (Runs the proposed and eventually adjusted plan)",
            "I've added a step before the LLM can execute the command where you can explicitly approve or deny them to make it safe",
            "Someone in r/kubernetes suggested using a read-only conf for kubectl for any GPT executions, so I\u2019m gonna implement that next",
            "I updated the flow so that the user has to explicitly approve or deny any command run, so that way there\u2019s now manual verification",
            "That\u2019s good!"
        ]
    },
    "PkgInspect - Inspect Local/External Python Packages": {
        "title": "PkgInspect - Inspect Local/External Python Packages",
        "score": 3,
        "url": "https://www.reddit.com/r/Python/comments/1ci4zd5/pkginspect_inspect_localexternal_python_packages/",
        "content": "[GitHub](https://github.com/yousefabuz17/PkgInspect)\n\n# What My Project Does\n\n`PkgInspect` is a comprehensive tool designed to inspect and compare Python packages and Python versions effortlessly. It equips users with a comprehensive set of tools and utility classes to retrieve essential information from installed Python packages, compare versions seamlessly, and extract various details about Python installations with ease.\n\n\n\n# Target Audience\n\nDevelopers and Python enthusiasts looking to streamline the process of inspecting Python packages, comparing versions, and extracting vital information from Python installations will find `PkgInspect` invaluable. Many current modules such as `importlib_metadata` and `pkg_resources` are fairly limited on what items can be inspected and retrieved for a specified python package. Also noticed `pkg_resources` has also deprecated some of its important retrieval methods.\n\n\n\n# Comparison\n\n`PkgInspect` stands out from other Python package inspection tools due to its robust features. Unlike traditional methods that require manual inspection and comparison, `PkgInspect` automates the process, saving developers valuable time and effort. With `PkgInspect`, you can effortlessly retrieve package information, compare versions across different Python installations, and extract crucial details with just a few simple commands.\n\n\n\n# Key Features\n\n* **Inspect Packages**: Retrieve comprehensive information about installed Python packages.\n* **Compare Versions**: Seamlessly compare package data across different Python versions.\n* **Retrieve Installed Pythons**: Identify and list installed Python versions effortlessly.\n* **Inspect PyPI Packages**: Gather detailed information about packages from the Python Package Index (PyPI).\n* **Fetch Available Updates**: Stay up-to-date with available updates for a package from the current version.\n* **List Inspection Fieldnames**: Access a list of available fieldnames for package inspection.\n* **Retrieve Package Metrics**: Extract OS statistics about a package effortlessly.\n* **Fetch GitHub Statistics**: Retrieve insightful statistics about a package from GitHub effortlessly.\n* **Retrieve all Python Packages**: Easily list all installed Python packages for a given Python version.\n\n  \nMain Components\n\n**Core Modules**\n\n- `PkgInspect`: Inspects Python packages and retrieves package information.  \n- `PkgVersions`: Retrieves and compares package data across different Python versions.  \n- `PkgMetrics`: Extracts OS statistics about a package.\n\n  \n**Functions**  \n- `inspect_package`: Inspects a Python package and retrieves package information.  \n- `inspect_pypi`: Inspects a package from the Python Package Index (PyPI).  \n- `get_available_updates`: Fetches available updates for a package from the current version.  \n- `get_installed_pythons`: Identifies and lists installed Python versions.  \n- `get_version_packages`: Lists all installed Python packages for a given Python version.  \n- `pkg_version_compare`: Compares package data across different Python versions.\n\n\n\n# Inspection Field Options\n\n***Any other field name will be treated as a file name to inspect from the packages' site-path directory.***\n\n    - `short_meta` (dict[str, Any]): Returns a dictionary of the most important metadata fields.\n        - If only one field is needed, you can use any of the following metadata fields.\n        - Possible Fields instead of `short_meta`:\n            - `Metadata-Version` (PackageVersion)\n            - `Name` (str)\n            - `Summary` (str)\n            - `Author-email` (str)\n            - `Home-page` (str)\n            - `Download-URL` (str)\n            - `Platform(s)` (set)\n            - `Author` (str)\n            - `Classifier(s)` (set)\n            - `Description-Content-Type` (str)\n    - `short_license` (str): Returns the name of the license being used.\n    - `metadata` (str): Returns the contents of the METADATA file.\n    - `installer` (str): Returns the installer tool used for installation.\n    - `license` (str): Returns the contents of the LICENSE file.\n    - `record` (str): Returns the list of installed files.\n    - `wheel` (str): Returns information about the Wheel distribution format.\n    - `requested` (str): Returns information about the requested installation.\n    - `authors` (str): Returns the contents of the AUTHORS.md file.\n    - `entry_points` (str): Returns the contents of the entry_points.txt file.\n    - `top_level` (str): Returns the contents of the top_level.txt file.\n    - `source_file` (str): Returns the source file path for the specified package.\n    - `source_code` (str): Returns the source code contents for the specified package.\n    - `doc` (str): Returns the documentation for the specified package.\n    \n    - `Pkg` Custom Class Fields\n        - `PkgInspect fields`: Possible Fields from the `PkgInspect` class.\n            - `site_path` (Path): Returns the site path of the package.\n            - `package_paths` (Iterable[Path]): Returns the package paths of the package.\n            - `package_versions` (Generator[tuple[str, tuple[tuple[Any, str]]]]): Returns the package versions of the package.\n            - `pyversions` (tuple[Path]): Returns the Python versions of the package.\n            - `installed_pythons` (TupleOfPkgVersions): Returns the installed Python versions of the package.\n            - `site_packages` (Iterable[str]): Returns the site packages of the package.\n            - `islatest_version` (bool): Returns True if the package is the latest version.\n            - `isinstalled_version` (bool): Returns True if the package is the installed version.\n            - `installed_version` (PackageVersion): Returns the installed version of the package.\n            - `available_updates` (TupleOfPkgVersions): Returns the available updates of the package.\n    \n        - `PkgVersions fields`: Possible Fields from the `PkgVersions` class.\n            - `initial_version` (PackageVersion): Returns the initial version of the package.\n            - `installed_version` (PackageVersion): Returns the installed version of the package.\n            - `latest_version` (PackageVersion): Returns the latest version of the package.\n            - `total_versions` (int): Returns the total number of versions of the package.\n            - `version_history` (TupleOfPkgVersions): Returns the version history of the specified package.\n            - `package_url`: Returns the URL of the package on PyPI.\n            - `github_stats_url` (str): Returns the GitHub statistics URL of the package.\n            - `github_stats` (dict[str, Any]): Returns the GitHub statistics of the package.\n                - The GitHub statistics are returned as a dictionary \\\n                    containing the following fields which can accessed using the `item` parameter:\n                    - `Forks` (int): Returns the number of forks on GitHub.\n                    - `Stars` (int): Returns the number of stars on GitHub.\n                    - `Watchers` (int): Returns the number of watchers on GitHub.\n                    - `Contributors` (int): Returns the number of contributors on GitHub.\n                    - `Dependencies` (int): Returns the number of dependencies on GitHub.\n                    - `Dependent repositories` (int): Returns the number of dependent repositories on GitHub.\n                    - `Dependent packages` (int): Returns the number of dependent packages on GitHub.\n                    - `Repository size` (NamedTuple): Returns the size of the repository on GitHub.\n                    - `SourceRank` (int): Returns the SourceRank of the package on GitHub.\n                    - `Total releases` (int): Returns the total number of releases on GitHub.\n        \n        - `PkgMetrics fields`: Possible Fields from the `PkgMetrics` class.\n            - `all_metric_stats` (dict[str, Any]): Returns all the OS statistics of the package.\n            - `total_size` (int): Returns the total size of the package.\n            - `date_installed` (datetime): Returns the date the package was installed.\n    \n    - `pypistats fields`: Possible Fields from the `pypistats` module.\n        - `all-pypi-stats` (dict[str, Any]): Returns all the statistics of the package on PyPI into a single dictionary.\n        - `stats-overall` (dict[str, Any]): Returns the overall statistics of the package on PyPI.\n        - `stats-major` (dict[str, Any]): Returns the major version statistics of the package on PyPI.\n        - `stats-minor` (dict[str, Any]): Returns the minor version statistics of the package on PyPI.\n        - `stats-recent` (dict[str, Any]): Returns the recent statistics of the package on PyPI.\n        - `stats-system` (dict[str, Any]): Returns the system statistics of the package on PyPI.\n\n\n\n# Downsides & Limitations\n\n**My algorithms are fairly well but do come with some important downsides.**\n\n* `PkgInspect` will ONLY inspect packages that are python files or contains a `dist-info` folder in the site-packages folder for a given Python version. Was not able to efficiently figure out a way to retrieve all necessary packages without containing unrelevant folders/files. Some personal packages may be skipped otherwise.\n* Beta (pre-releases) has not been implemented yet.\n* As many files may be handled, the runtime may be slow for some users. \n* The demand for a project like this is not so much in-demand but have noticed many people, including my self, still seeking for a project like this. However, this type of project does seem to exceed my experience level with Python and algorithms (hence the downsides) so not entirely sure how far this project may come in the future. Was hoping for it to be GUI based if possible.\n\n\n\n# Usage Examples\n\n    from pkg_inspect import inspect_package\n    \n    inspect_package(\"pkg_inspect\", itemOrfile=\"initial_version\")\n    # Output (Format - DateTimeAndVersion):\n    ('May 02, 2024', '0.1.0')\n    \n    \n    inspect_package(\"pkg_inspect\", itemOrfile=\"version_history\")\n    # Output (Format - tuple[DateTimeAndVersion]):\n    (('May 02, 2024', '0.1.2'), ('May 02, 2024', '0.1.1'), ('May 02, 2024', '0.1.0'))\n    \n    \n    inspect_package(\"pkg_inspect\", pyversion=\"3.12\", itemOrfile=\"short_meta\")\n    # Output (Format dict[str, Any]):\n    {'Author': 'Yousef Abuzahrieh',\n     'Author-email': 'yousefzahrieh17@gmail.com',\n     'Classifiers': {'Development Status 4 Beta',\n                     'Intended Audience Developers',\n                     'License OSI Approved Apache Software License',\n                     'Operating System OS Independent',\n                     'Programming Language Python 3',\n                     'Programming Language Python 3 Only',\n                     'Topic Utilities'},\n     'Description-Content-Type': 'text/markdown',\n     'Download-URL': 'https://github.com/yousefabuz17/PkgInspect.git',\n     'Home-page': 'https://github.com/yousefabuz17/PkgInspect',\n     'License': 'Apache Software License',\n     'Metadata-Version': <Version('2.1')>,\n     'Name': 'pkg-inspect',\n     'Platforms': {'Windows', 'MacOS', 'Linux'},\n     'Summary': 'A comprehensive tools to inspect Python packages and Python '\n                'installations.'}\n    \n    \n    inspect_package(\"pandas\", pyversion=\"3.12\", itemOrfile=\"github_stats\")\n    # Output (Format - dict[str, Any]):\n    {'Contributors': '1.09K',\n     'Dependencies': 3,\n     'Dependent packages': '41.3K',\n     'Dependent repositories': '38.4K',\n     'Forks': '17.3K',\n     'Repository size': Stats(symbolic='338.000 KB (Kilobytes)', calculated_size=338.0, bytes_size=346112.0),\n     'SourceRank': 32,\n     'Stars': '41.9K',\n     'Total releases': 126,\n     'Watchers': 1116}",
        "num_comments": 0,
        "comments": []
    },
    "2,000 free sign ups available for the \"Automate the Boring Stuff with Python\" online course. (May 20": {
        "title": "2,000 free sign ups available for the \"Automate the Boring Stuff with Python\" online course. (May 20",
        "score": 12,
        "url": "https://www.reddit.com/r/Python/comments/1chqnff/2000_free_sign_ups_available_for_the_automate_the/",
        "content": "If you want to learn to code, I've released 2,000 free sign ups for my course following my Automate the Boring Stuff with Python book (each has 1,000 sign ups, use the other one if one is sold out): \n\n*The sign ups are all used up, but you can still watch all the videos for free. Read below!\n\nhttps://udemy.com/course/automate/?couponCode=MAY2024FREE\n\nhttps://udemy.com/course/automate/?couponCode=MAY2024FREE2\n\nIf you are reading this after the sign ups are used up, you can always find [the first 15 of the course's 50 videos are free on YouTube if you want to preview them.](https://www.youtube.com/watch?v=1F_OgqRuSdI&list=PL0-84-yl1fUnRuXGFe_F7qSH1LEnn9LkW) YOU CAN ALSO WATCH THE VIDEOS WITHOUT SIGNING UP FOR THE COURSE. All of the videos on the course webpage have \"preview\" turned on. Scroll down to find and click \"Expand All Sections\" and then click the preview link. You won't have access to the forums and other materials, but you can watch the videos.\n\n**NOTE: Be sure to BUY the course for $0, and not sign up for Udemy's subscription plan. The subscription plan is free for the first seven days and then they charge you. It's selected by default. If you are on a laptop and can't click the BUY checkbox, try shrinking the browser window. Some have reported it works in mobile view.**\n\n**I'm also working on another Udemy course** that follows my recent book \"Beyond the Basic Stuff with Python\". So far I have [the first 15 of the planned 56 videos done. You can watch them for free on YouTube.](https://www.youtube.com/watch?v=kSrnLbioN6w&list=PL0-84-yl1fUmeV_2bBSguF_S0TVZk8wow&index=1)\n\n**Frequently Asked Questions:** (*read this before posting questions*)\n\n* This course is for beginners and assumes no previous programming experience, but the second half is useful for experienced programmers who want to learn about various third-party Python modules.\n* If you don't have time to take the course now, that's fine. Signing up gives you lifetime access so you can work on it at your own pace.\n* This Udemy course covers roughly the same content as the 1st edition book (the book has a little bit more, but all the basics are covered in the online course), which you can read for free online at https://inventwithpython.com\n* The 2nd edition of Automate the Boring Stuff with Python is free online: https://automatetheboringstuff.com/2e/\n* I do plan on updating the Udemy course, but it'll take a while because I have other book projects I'm working on. If you sign up for this Udemy course, you'll get the updated content automatically once I finish it. It won't be a separate course.\n* It's totally fine to start on the first edition and then read the second edition later. I'll be writing a blog post to guide first edition readers to the parts of the second edition they should read.\n* **You're not too old to learn to code. You don't need to be \"good at math\" to be good at coding.**\n* Signing up is the first step. Actually finishing the course is the next. :) [There are several ways to get/stay motivated.](https://www.reddit.com/r/learnprogramming/wiki/faq#wiki_how_can_i_get.2Fstay_motivated_to_learn_programming.3F) I suggest getting a \"gym buddy\" to learn with. Check out /r/ProgrammingBuddies",
        "num_comments": 3,
        "comments": [
            "Just got it! Hope to complete the course soon!",
            "So sad I keep missing this! I'm suspicious of a glitch, I tried using a different browser too but it says it is expired?  Anyone else having trouble? I will read in the meantime but would be awesome to do the udemy! <3"
        ]
    },
    "Best book for GUI development in Python": {
        "title": "Best book for GUI development in Python",
        "score": 69,
        "url": "https://www.reddit.com/r/Python/comments/1chdeym/best_book_for_gui_development_in_python/",
        "content": "Can you guys suggest some very good book for GUI development in Python? \n\nI'm currently working on a visualizer that needs many features to plot data on a 3D and 2D space. Using PyQt for this as it has threading support.",
        "num_comments": 57,
        "comments": [
            "Create GUI Applications with Python Qt6 PySide6",
            "https://www.pythonguis.com/books/",
            "[removed]",
            "https://pythonbooks.org/topical-books/graphical-user-interface/\n\n\nSeems legit.",
            "Any book with GTK4 in mind?",
            "Pyside6/PyQt6 with Matplotlib \"bindings\" seems to be appropriate to what you need. I've built data analysis tools with those, with the analysis in multithreading which then sent the data to the main thread for visualization. Regarding YT tutorials, I don't remember seeing many for multithreading using QT and you are mostly stuck with documentation and/or ChatGPT.  Send me a msg to see if I can be of help.",
            "Python really isn\u2019t ideal for GUI development. It\u2019s a scripting language. That\u2019s why you\u2019re having a hard time finding one.\u00a0",
            "Currently learning PySide6 myself. There's so much information it can be overwhelming. Best to take little bits at a time and hammer each thing into your memory via repetition before moving to more classes or methods. I'm thoroughly enjoying the process, though!",
            "These books look helpful indeed but I want an actual book, not eBook",
            "Depends what the project\u2019s goal is. If the goal is more or less a dashboard, then streamlit is an excellent choice. But if more customization and control is required, some proper app framework will be needed.",
            "Appreciate that, \nBut what I need is a step by step guide i.e. how an application works, how we can use signalling in a multi threaded application and all that kinda stuff \n\nI searched for PyQt tutorials over YT, but didn't find a proper tutorial that suits my needs",
            "I'm using Streamlit to link all of our company databases into one location for data exploration. It's stupid-simple, tons of tutorials and docs. If you're good, you can easily go beyond its base limits.\n\n10/10, would recommend for what your needs are.\n\nAnd... anything you dont know is a quick web search away.",
            "Streamlit is remotely an alternative to something like QT.",
            "There are literally thousands of Python GUI apps. It is often an excellent choice when you want to quickly make a GUI front end for a CLI app.",
            "There are tons of commercial and open source application written in python and using its available GUI frameworks and it has a lot of support for it, and they work very nicely, you are misinformed.",
            "I\u2019m the author of these books & they\u2019re available to buy in paperback on Amazon if you want.\n\nIf you buy the paperback you can send me your receipt to get the digital edition (& future updates) for free.\n\nI\u2019ll be releasing an update in the next week or so (there have been some changes in Qt)",
            "Please, read what you just said, again and again\n\nDo it a couple more times until you understand it, because I hope you know what the mistake is without us telling you",
            "You know you can just print it out, right?",
            "get a load of this guy",
            "At a certain point python is no longer the tool id choose\u00a0",
            "streamlit is very slow and heavy. it reruns everytime you make any change as an end user.",
            "Yes. Exactly. But if I was developing a distribution GUI I\u2019d never use python for that. As a bolt on for limited use sure. But these days I\u2019d probably just do a web app and not bother with tkinter and it\u2019s ilk",
            "There are GUI apps but on average if you look on local job offers most of the time you won't find any GUI job offer. For one Python desktop apps weren't that popular and then a lot of GUI apps migrated to web apps and mobile apps.",
            "Please share a standalone GUI professional application written in python. In 40 years I\u2019ve never seen one.\u00a0",
            "Sure, I'll check it out\nThank you very much",
            "Does this include an update to the PyQt6 book?\n\n[https://www.pythonguis.com/pyqt6-book/](https://www.pythonguis.com/pyqt6-book/)",
            "It depends on where you buy it.  Amazon won't allow some of their books to be printed out.\n\nTo be fair, it's never been an issue for me.",
            "But prior to that point, python remains the tool to choose.",
            "Would recommend Panel over Streamlit for that purpose. Doesn't rerun the whole app every time.",
            "This is slowly changing. There are already forms elements which don't cause any reruns until the form submit button is pressed, sending all data from the elements within the form at once.\n\nThen recently they also added a feature called \"fragment\" (currently listed as experimental, so the syntax could change) that can be used to break the app up into sections that update when interacted with.\n\nIf you're not making anything too big and complicated, I think streamlit does what it does really well. It's extremely simple and straightforward to set up, for its intended audience (data science people analysts, not app developers).",
            "Sure. But the OP didn\u2019t say anything regarding distribution. We should answer the question as stated. \n\nToo often, devs turn things into an x-y problem when it doesn\u2019t need to be.",
            "The fact that down votes on your reply were significant, is why I avoid posting in this r/.\n\nI can't shake the feeling that Python 'experts' have an Elitist mindset.  And I've been in computers for 40+ years.  \n\nNowhere else - not even data science or AI or advanced hardware or even telecommunications - in this gigantic field is there anywhere near the level of scorn, shun, scoff or something with a worse s rating that there is in the python spaces.\n\nBy the way, I agree.  Using Python for a GUI is like using a hammer to paint your wall.  Or powershell to drive your front end.",
            "**Deluge**  \n**Calibre**  \n**MusicBrainz Picard**  \n**Orange**  \n**Anki**",
            "https://www.spyder-ide.org/",
            "Off the top of my head:\n\n* Calibre,\n* Thonny,\n* IDLE,\n* Qt Designer,\n* TortoiseHg\n* Django\n* Jupyter Notebook\n* Cura\n\nAlso, at work we use several proprietary apps developed in-house with Python.",
            "Meld -- used for code comparision",
            ">Please share a standalone GUI professional application written in python.\n\nYou don't say that here if you don't intend on being given examples.",
            "Yep, all of them are getting an update: PyQt6 PySide6 PyQt5 & PySide2\n\nThe changes are done, just proofing now.",
            "I use Plotly Dash, never tried streamlit. Is there any advantage using streamlit over Dash?",
            "I mean.. OP asked for books about python GUI development, and the person replied by saying python isn\u2019t ideal for GUI development.\n\n- It doesn\u2019t address the question\n- it contains questionable or incorrect information (there are many many python gui libraries and many books on using them)\n- no alternatives were proposed\n- no clarifying questions to OP were asked to help potentially guide them to better options\n\nWhy exactly shouldn\u2019t it get downvoted?\n\nI don\u2019t even necessarily disagree that python isn\u2019t the ideal choice for a gui in some circumstances, but the OP didn\u2019t ask about whether it was or not. The only elitism I\u2019m seeing really is the outright dismissal of the notion of the OPs question.",
            "I've been in computers / software for 40+ years myself. Don't know why people are so weirdly sensitive. Python simply isn't a native application platform.",
            "If some downvotes are enough to stop you from sharing your opinion, you're taking this Reddit thing way too serious.",
            "Deluge is running daily here, as well as Nicotine+. Some other big examples are Gramps and Pitivi.\n\nAll with GTK by the way.",
            "https://wingware.com/",
            "Lol i was about to send that to him, but my pc shut down for some reason.",
            "Any idea how long before the updated paperbacks will be available?",
            "I'd say so! Dash is absolutely dreadful to use in my experience. Streamlit is far easier.",
            "Is downvoting a specific method to promote the right answer then?  \n\nThe more appropriate answer given a high level question - always to me - is an evaluation of the actual requirements that led the OP to infer that Python *was* appropriate for said GUI development.\n\nWouldn't a much more appropriate answer have been, \"Hey, Python may not be the ideal choice.  Unless you have hard requirements that led you here, have you considered X, Y or Z?\"\n\nInstead it's a seemingly terse exchange of value-driven hyper-context.\n\nStrict: \"Reply only with book recommendations for Python GUI Development, or don't respond at all.\"\n\nLoose: *we are here*\n\nMy hammer analogy stands.  It's like Python is the Snap-On of code.",
            "Hey u/mfitzp, sorry to bother but is there any update on when we can expect the new edition to drop?",
            "Thanks, I will give it a try",
            ">Is downvoting a specific method to promote the right answer then?\n\nYes. That is, quite literally, the reason why the downvote button was invented.\n\n>The more appropriate answer given a high level question - always to me - is an evaluation of the actual requirements that led the OP to infer that Python was appropriate for said GUI development.\n\nYes, this would have been a far better answer.\n\n>Wouldn't a much more appropriate answer have been, \"Hey, Python may not be the ideal choice.  Unless you have hard requirements that led you here, have you considered X, Y or Z?\"\n\nAgain, yes, this would have been a better approach.",
            ">Is downvoting a specific method to promote the right answer then? \n\nLiterally what downvoting is for. \n\nOP asked for something, and you and the to level comment are being elitist and deciding his question is wrong.",
            "I\u2019d say don\u2019t bother. Streamlit and dash are very different. If your needs are very simple and linear then streamlit is good. Otherwise, it\u2019s very limiting.",
            "Literally downvoting without giving a reason, is like taking a shit without thinking of the cleanup requirements.\n\nAnd nope - we didn't say his question was 'wrong' at all.  Where does it say that?\n\nOP asked for something - yes.\n\nBut these types of questions seem too broad.  Asking more details, or sharing opinions, is allowed.\n\nBut downvoting shit and explaining nothing along with the downvote, when not clearly and reasonably obvious why the downvote occurred, is annoying enough.\n\nWhat tops the cake, now, is the Pedantic Level being turned up to 12.\n\nWe aren't interpreters of your mental code, we are humans and the least common denominator in all of this is that you need to learn to speak TO people, not around them.\n\nHighly improbable here, though.  Too many savants with zero read the room skills.",
            "Naw, downvoting shouldn't require a comment. It would generate a ridiculous number of comments. Downvoting means something isn't contributing. \n\nPlenty of people have decent answers to OP's specific question. You deciding that it's the wrong question is the elitist element in this thread. You have an agenda about Python forums you want to push, so you are trying to hijack the thread with that intent.",
            "Nah, lol.  You see,  \"shouldn't\" and \"are the rules\" kinda mean different things, mate.\n\nFor instance, literal fucking rule #9, of THIS sub-reddit, r/python, says:\n\n\"Please don't downvote without commenting your reason for doing so.\"\n\nI mean, I hate to be the idiot to break it to ya mate, but you're clearly wrong according to the rules of our beloved community.\n\nYou'd like to respect those rules, yeah?\n\nHave at it!"
        ]
    },
    "ConfigClass - simple dataclass inspired configuration": {
        "title": "ConfigClass - simple dataclass inspired configuration",
        "score": 21,
        "url": "https://www.reddit.com/r/Python/comments/1chhm8x/configclass_simple_dataclass_inspired/",
        "content": "**What My Project Does**\n\nI'm making a simple configclass for handling configuration in smaller projects and scripts. Goal is to be as simple to start with as creating a dataclass.\n\nThe module itself works off dataclass and when you use it you just define a dataclass as normal, but decorate it with @configclass() instead.\n\nExample:\n\n    from configclass import configclass\n\n    @configclass()\n    class Settings:\n        foo: bool = False\n        url: str = \"\"\n        footoo: bool = True\n        my_model: str = \"model.pt\"\n\n    setting = Settings.load()\n\n    print(setting.foo, setting.footoo, setting.my_model)\n\nFrom that you got\n\n* JSON config file support (config.json)\n* YAML config file support (config.yaml)\n* Command line support (argparse)\n* Env variables support (CONFIG_SETTINGNAME)\n\nIt also support nested structures via nested dataclass classes.\n\n**Comparison**\n\nIt's meant as a quick and lightweight alternative to larger and more comprehensive config systems, for the small programs and scripts where you'd just use a dataclass, and maybe load the values from a config file.\n\n**Target Audience**\n\nSince it's pretty new and raw I wouldn't recommend it for heavy production settings or complex projects. That said, it should work fine for most cases.\n\nWhile I've worked with python for quite some time, this is the first time I've tried making a package, so I'd like some feedback on the project and it's structure before I push it anywhere. It'd also be nice to stress test it and shake out some bugs.\n\nMore info and code at https://github.com/TheTerrasque/python-configclass",
        "num_comments": 5,
        "comments": [
            "What are the benefits of using this over pydantic (which also has dataclasses, json/yaml conversion, and env var support)?",
            "I've written something similar, which is now a fairly mature project. If you want to take a look, I'm open to contributions if you have any ideas that might improve scriptconfig\n\nThe main difference in a scriptconfig.DataConfig is that it doesn't rely on the type system. Instead it uses wrapped values to hold metadata, which ultimately ends up being a lot more extensible and introspectable.\n\nIt can also create argparse CLIs (with Rich-argparse and argcomplete integration), serialize and deserialize from yaml or JSON, be used purely as a lightweight dictionary or namespace object, and it has decent support for modal CLIs.\n\nIn the future I'd like to add more support for jsonargparsre.\n\nhttps://pypi.org/project/scriptconfig/",
            "Yet another implementation of this same concept. Our approach includes automatic expansion of values ending in _env or _eval in case you need to include secrets in the co figuration file. \n\nhttps://github.com/glentner/cmdkit",
            "pydantic-settings is very nice, true. \n\nThis aims to be even simpler, somewhere in between of using pydantic and nothing, and be a drop-in replacement for a dataclass config. Also, this provides command line argument parsing and loading from file configs by default, without any extra setup.",
            "Nice! Yeah, had a similar thought. I wanted something really simple, and usually when developing my progress  goes like this:\n\n1. TOP_LEVEL_VARIABLES\n2. Move them into a dataclass for easier collection and editor completion\n3. Load from a file as I want some things out of GIT or want to experiment with different settings more quickly.\n4. Add command line for some parts because when developing and rapidly testing things changing options on a command line is super simple and straight forward. \n5. Want to deploy on docker or kubernetes and starting to read env vars.\n\nSo after going down that path multiple times I just wanted to have something super simple that wrapped that path from the start, while being no more work than writing a dataclass.\n\nI have tried a few different ones I found via google, but it either felt too much boilerplate, or the approach was not what I was looking for. pydantic-settings is close, but I still feel it's a tad too much boilerplate for a simple project."
        ]
    },
    "Is Litestar production ready 2024?": {
        "title": "Is Litestar production ready 2024?",
        "score": 38,
        "url": "https://www.reddit.com/r/Python/comments/1c3irsc/is_litestar_production_ready_2024/",
        "content": "At least a couple things that seems is that Litestar appears to be a fast  Django lite. Some batteries included, but not too many and opinionated. It's uses Rust so of course it's going to be fast, not that it really matters that much since IO > CPU for a website IMO. Which any async framework addresses this.\n\nI haven't heard many people using it though despite it having a lot of batteries included, but not dominating everything with first party support. Anyone using it in production in 2024?\n\nEdit:\n\nFact check it appers it isn't written in Rust, I probably confused it with something else or it might just be data serialization",
        "num_comments": 27,
        "comments": [
            "I think you're mixing something up regarding Rust. Check out [this comment](https://www.reddit.com/r/Python/comments/162siv5/litestar_20/jxz89xx/) by u/Goldziher from 7 months ago.\n\nRegarding your question, I am wondering the same thing. I found Litestar 2 weeks ago and build a little boilerplate for our Google Cloud Run services. I had a good time reading the documentation and code. For my purpose I definitely appreciate the use of msgspec, the performance, the easy setup and how quickly I was able to configure structlog (+ the built-in logging middleware) for Cloud Logging.\n\nOnly thing I disliked so far is that the documentation seemed inconsistent/outdated sometimes. Like in some places it's showing pydantic examples even though pydantic is now optional. Same for using dataclasses instead of always using msgspec and some other small things I noticed.",
            "yeah",
            "I\u2019m using litestar in production. Yes",
            "I'm curious what makes you think it hasn't been ready before 2024?\n\nIt's not the most popular framework, sure, but it receives regular updates, has multiple people working on it, and has a 100% code coverage unit test policy, uses type hints, requires docstrings for all methods, etc...",
            "I am using Litestar in production at my work. We have a bunch of flask services and just released our first Litestar service. AMA.",
            "I'm gradually transitioning my company away from Flask and Fastapi to Litestar and Django. It is at least as production ready as the big names, if not more so.",
            "You are talking about Robyn server written in RUST",
            "Seems like everything Python is getting implemented in Rust lately!",
            "Seems like a documentation contribution issue than a actual issue with the tool itself. I think that would get solved if it's more popular, which I see the main niche being Django users, not flask or fastapi users. FastAPI also greatly improved recently so I wouldn't be surprised if they did the same.",
            "Hadn\u2019t heard many stories of it getting taken to production as of late.",
            "How do you handle authentication and user management? I was planning on using Litestar for a new production app but I am hesitant because of security concerns",
            "What\u2019s your reason to move away from FastAPI? Being curious",
            "Please expand on \"if not more so\"?",
            "You didn't run into issues with some of the battery included parts like caching? I know Redis was one but their license change kind of made it not attractive to use anymore. This isn't a litestar issue though but they seem to have good documentation to make a good interface to implement.",
            "I think Emmett is also using a Rust-based server. I can't recall the exact name, but it\u2019s something like Granian",
            "Nah, misunderstanding of Litestar. Read /u/Ragoo_'s comment.",
            "That's purely a measure of popularity, not on production-readiness",
            "We use JWT with an auth service running as its own instance. So not touched by litestar at all, sorry.",
            "Issues I and my colleagues encountered with tiangolo's projects had gone without fixes for over a year, and hampered development. After that I swore to avoid his projects and followed the portion of the community that jumped ship to Starlite. Starlite was (foolishly imo) renamed to Litestar. All issues I encountered with Starlite/Litestar were fixed within 12 hours of reporting them. I can't argue with that level of support.",
            "At least according to the devs behind Litestar, they believe it is more feature complete than Fastapi. I'd agree.",
            "I only handle our internal facing software. All our services are self hosted, so the Redis license change doesn't concerns us.\n\nBattery included issues? Is this regarding Django? So far no issues.",
            "I just want to hear more stories of it. People who want a more batteries included should hear more stories of success.",
            "Okay, but let's say you would like to do a particular action in an endpoint depending on the users permissions. How would you do that then?",
            "This comment has been overwritten.",
            "Out of curiosity I just checked their issue count, it's now very low.. it used to be multiple hundreds, but I wonder if it's an increase in community will and manpower or just a lot of wontfix :)",
            "There are multiple problems with what you're asking:\n\n1. Even for something like django, outside of djangocon there are very few stories of success. And even at djangocon stories of success are much rarer than stories of \"Hey I was already using django and now I did X\"\n2. The vast majority of software is developed internally and often has stipulations on who and where people can publish their experiences\n3. What you're describing is a chicken-and-egg problem. If everyone waits to hear if other big groups are having huge success with something, nothing will ever get done.\n4. We're talking about something barely 3 years old and only 1.0 status for just over 2 years. Popularity and migrations take years to do usually.\n\nJust try it out, it you like it, use it. If you don't like it, don't use it. I like it, so I use it.\n\nAnd to answer your original question it literally says it's production-ready on their [github page](https://github.com/litestar-org/litestar)",
            "Our JWT tells us the permissions available for the user and we decide to allow it or not in code. I don\u2019t think Litestar includes any auth."
        ]
    },
    "Python isn't dramatic enough": {
        "title": "Python isn't dramatic enough",
        "score": 225,
        "url": "https://www.reddit.com/r/Python/comments/1btb20j/python_isnt_dramatic_enough/",
        "content": "Ever wished your Python interpreter had the dramatic feeling of a 300 baud modem connection?\n\nToday there's a solution: `pip install dramatic`\n\n[dramatic on PyPI](https://pypi.org/project/dramatic/)\n\n[dramatic on GitHub](https://github.com/treyhunner/dramatic)  \n\n\n## What My Project Does\n\nAll text output by Python will print character-by-character.\n\nIt works as a context manager, as a decorator, or as a simple function call.\n\nOther features include a dramatic REPL, ability to run specific Python modules/scripts dramatically, and a --max-drama argument to make all Python programs dramatic all the time.\n  \n## Target Audience\n\nThose seeking amusement.\n\n## Comparison\n\nJust like Python usually runs, but with the feeling that you're inside a text-based adventure game.",
        "num_comments": 29,
        "comments": [
            "This is so unnecessary\u2026and I love it. I do love me a good project that\u2019s really just about having fun.",
            "Hahahahaha this is great.\n\n    import dramatic\n\n    with dramatic.output:\n        import this",
            "Haha nice, but that's actually quite useful when recording GIFs of code examples to slow it down a bit I could imagine. Will remember it :)",
            "The trolley potential of setting it system wide as part of a build process.... \nYou can even do it randomly so people won't know why it's like that",
            "What do you use to record your demo gifs to use in your documentations btw?",
            "Could we have an option to increase baud to 1200?\n\nI'm too young to remember 300\n\nHow about 9600. That would be super dramatic",
            "I absolutely love this omfg yes \ud83d\ude02",
            "Numba, PyPy, Cython, Taichi, Mojo, LPython, Codon all trying to make Python faster, and this project comes along to make it *slower*. I love it!",
            "I love it!",
            "You get a star! \u2b50\ufe0f",
            "love it!",
            "Ahh the good CKA exam experience, r/kubernetes will be happy",
            "Lol ur program very slow lol![gif](emote|free_emotes_pack|facepalm)",
            "Having fun was the primary purpose of this pursuit. \ud83d\ude01\n\nI'm glad this brought you some joy as well!",
            "Hey, u/treyhunner, I was running this on my windows PC, and got the following error:\n\n    File <filename here>, line 79, in write\n      sleep(1 / self.speed - (perf_counter() - before))\n    ValueError: sleep length must be non-negative",
            "It could be! /u/AlSweigart had the idea that the sleep time could vary based on which character is being printed to make it look slightly more like actual typing.  \n\n\nPull requests welcome for that feature!",
            "I thought about it but I will admit that I haven\u2019t thought about how to do this beyond just opening the script and printing out the contents dramatically. That said, I haven\u2019t spent much time in the docs nor am I a Python expert so there may be a much nicer way of doing this",
            "I use [asciinema](https://asciinema.org/) to record locally and then use [asciinema-agg](https://github.com/asciinema/agg) to convert to a gif.\n[More details on how I made each gif](https://github.com/treyhunner/dramatic/tree/main/screenshots#readme)",
            "Yup!\n\nYou could use `dramatic.output.at_speed(...)` or `--speed` from the command-line.\n\nThe default speed is 75 characters per second. 300 baud should be around 30, 1200 around 120 and 9600 around 960.",
            "Now that's dramatic",
            "Thanks for noting this bug! I've [opened an issue](https://github.com/treyhunner/dramatic/issues/11) and will consider a workaround soon.",
            "I can hear the soap opera/drama sound effects flying around",
            "Ha ha, yeah. I had an elaborate idea of trying to figure out calculations based on QWERTY key position, etc. Then I realized I could probably just write a tool that records me typing and figures out the timing between any two keys from there.\n\nOr heck, just make it slightly random and it'll look realistic enough. :)",
            "coherent voiceless busy skirt teeny violet brave nutty fine air\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
            "I love that, let's over-engineer the hell out of it ![gif](emote|free_emotes_pack|grin)",
            "Just made a new PR! I have an algorithm that looks one character ahead and behind, and also checks whether you're currently indenting, and adds a bunch of rules for stuff that might slow people down.\n\nI speed through the indent a bit, but delay every 4 spaces to simulation how tab indent looks, I slow down when typing long numbers, complicated brackets, and punctuation that makes a natural speech pause.\n\nI tried to balance realism and aesthetics, but I'm not a touch typist so I might have gotten some of my values wrong, all the rules are just made up by trial and error.",
            "Oh I didnt know asciinema allows for local file save, interesting\n\nThanks! I'll take a look",
            "This is possible! `\\b` in ASCII is a \"backspace character\" and sending it right after another character will erase it and allow typing over the place that it previously showed up.\n\nHappy to brainstorm further. Sounds like a possible \"sloppy mode\" (?). Issue/pull request welcome too."
        ]
    },
    "The Best* Python Cheat Sheet": {
        "title": "The Best* Python Cheat Sheet",
        "score": 295,
        "url": "https://www.reddit.com/r/Python/comments/1bst810/the_best_python_cheat_sheet/",
        "content": "A dense Python cheat sheet with just what you need.  \nDesign principles:  \n\u2022 Focus on Python core  \n\u2022 Comprehensive but selective (Just what you need)  \n\u2022 Densely packed  \n\u2022 Well-linked  \n\u2022 Linkable  \n\u2022 Responsive  \n\u2022 Printable  \nIssues and feedback are tracked at the [best-python-cheat-sheet repository](https://github.com/kieranholland/best-python-cheat-sheet).  \n\\*It may not be the best Python cheat sheet, but it aspires to be.",
        "num_comments": 32,
        "comments": [
            "at first i was like 'pfft!' and then i was like 'dang!'\n\nnice work",
            "This is great thanks!",
            "Thanks for the cheat sheet.  \nI like the direct link to doc related for each section.  \nSome remarks I have noted about it:\n\n1. Python icon is to go back to the top, I found it by chance... Maybe it will be better to just write \"Back to top\" or change the icon to an arrow ? I was about to request it just before I found it...\n2. Full deep black for background with text above is very tiring to read. Looks like you are using Stackoverflow CSS. Look on Stackoverflow or Reddit, dark theme has more a greyish background than full deep black.\n3. Sections are well separated and visible in Light theme, that's not the case in Dark theme.\n4. Your banner at top should be used as a navigation bar as it stays always visible. Would be more useful in that case. Maybe to go back to the top of the visible section, navigate to previous and next section, going back to top ? Expand when mouse over to show direct link of summary ?",
            "I love a  good cheat sheet",
            "Awesome, thank you!",
            "Fantastic work!",
            "Saved. Nice work!",
            "Amazing. I want to share this in my newsletter if that's ok for you.",
            "Ow good gob",
            "Ty, needed this",
            "Great job!",
            "Very little runnable code. Hosted outside of git. I don't see the point.",
            "Fantastic I love it! Thank you!",
            "I\u2019m missing advanced stuff like:\n\n- walrus operator in comprehensions\n- decorator arguments\u2026 decorators for instance method or classes\n- position- or keyword-only parameters\n- metaprogramming\n- asyncio\n- itertools\n- typing\n- Enum",
            "Holy Guacamoly, that's some really powerfuk cheatsheet, although I didn't understand All of it (just started with Python)",
            "Are you update this within a week? If you don't I'm gonna print this, such a great page",
            "Thank you, kindhearted person",
            "Thanks to everyone for your feedback. I've released a new version today which improves the order of sections, refines dark mode colors, fixes font on MacOS, details built-in functions, has more internal linking, includes set/dict comprehensions, has deeper Python doc links, and fixes errors. I agree decorator section and navigation could still be improved.",
            "Awesome",
            "Nice work",
            "Forgot to tell you but I had printed the sheet and read it closely. I have got many suggestions for you. Please contact in Discord @barury797. I will tell you on details. Thanks",
            "This is amazing ty",
            "Thanks - good points I'll consider for next iteration.",
            "Sure.",
            "thanks, will consider these for future version",
            "updated today",
            "You can also open an issue on the github repo",
            "All suggestions incorporated - thanks",
            "If you don't mind can you please share your social media links. I want to tag that's why asking",
            "Other than the github link I don't have anything. Thanks"
        ]
    },
    "Automating Python with Google Cloud": {
        "title": "Automating Python with Google Cloud",
        "score": 117,
        "url": "https://www.reddit.com/r/Python/comments/1bpyduk/automating_python_with_google_cloud/",
        "content": "I just published a tutorial series on how to automate a Python script in Google Cloud using Cloud Functions and/or Cloud Run. Feedback would be great. Thanks!\n\n- [Automating Python with Google Cloud](https://www.scipress.io/post/rSp9Rov4ppvHgpHQaRPy/Automating-Python-with-Google-Cloud)\n    - [Automating Python with Google Cloud Functions](https://www.scipress.io/post/ZxywtSFdx5In7KTrVvNA/Automating-Python-with-Google-Cloud-Functions)\n    - [Automating Python with Google Cloud Run](https://www.scipress.io/post/FA9QzMVdssdMt4IYq0yX/Automating-Python-with-Google-Cloud-Run)",
        "num_comments": 29,
        "comments": [
            "This is very cool",
            "This tutorial is great. I really wanted to learn this.",
            "very cool. Google Cloud documentations and Google Cloud Console is a mess",
            "Unless you\u2019re behind a proxy",
            "The videos are awesome! What did you use to make them?",
            "I am just an amateur when it comes to python, but I\u2019ve managed to use it to build out an ETL process that grabs data from a few different sources (SQL server, API responses, share point file paths, etc.), performs some simple data comparison, and pushes the data to a SQL server that feeds some BI reports. \n\nIn order to run the script successfully, I need to be logged in to my company\u2019s VPN (for share point and SQL server access). I\u2019ve have tried and failed several times to automate this script - the closest of which I\u2019ve gotten is using task scheduler on a company VM that successfully executes some (but not all) of the code (which runs fine when I\u2019m logged in). \n\nAll of this to ask - do you think Google cloud could be a relatively simple yet more robust solution than Task Scheduler? I found Airflow/Prefect ideal but far out of my league to easily deploy\u2026 I\u2019m not a programmer and my day job keeps me tied up!",
            "Is it possible to differentiate the source of a Cloud Function run?\n\nFor example, executing a different function when you run it from Cloud Scheduler vs. invoking a HTTP run.",
            "Excelente, voy a practicarlo, grax",
            "Nice , Very useful as a reference ! Thanks",
            "Recently , I worked on migrating project from App engine to Cloud Run , the part of App engine Cron Jobs hesitated to do it in Cloud Run jobs since its way complicated that schedule Http Calls to my service on CR ? You think its valid to do so ?",
            "Detecting & Counting coins on images with Python using OpenCV: [https://youtu.be/VrgI1nPbV88](https://youtu.be/VrgI1nPbV88)",
            "Very timely, I was looking into this for the last few days!",
            "Nice \ud83d\udc4d\ud83c\udffb",
            "Python? Automate? The Cloud? Sign me up",
            "Appreciate the nice review! Let me know if you find any bugs or confusing sections.",
            "Is it? There's a lot of info there but, there's a lot of tooling going on as well. \n\nLots of things seemingly have similar functionality, but can be better tuned for a service or other products.\n\n\nOur team uses GCP for 80% of our workflow and we're all fans.",
            "I don\u2019t agree , it\u2019s one of the best documentations you have code snippets and all tutorial event qwicklab to launch your project and the Tuto is based 90% on gcp doc :\n\nhttps://cloud.google.com/run/docs/quickstarts/jobs/build-create-python?hl=fr",
            "Why is this guy being downvoted?",
            "[Screen Studio](https://www.screen.studio/) Thanks!",
            "Sorry, I'm not familiar with Task Scheduler. Just try Google Cloud and see if you like it.",
            "No. Now you have to worry about firewalls and permissions. Ask about the task scheduler issue it can be solved there I have plenty of things running like that.",
            " You have to use cloud vpn with cloud scheduler to schedule a job with the url of your ETL, airflow will be an overkill for your task.\n\nCreate a cloud function or a cloud run job then schedule them with cloud scheduler :\n\nhttps://cloud.google.com/run/docs/triggering/using-scheduler?hl=fr\n\nIf you want to automate your scripts you should whitelist the IP address of your cloud function or cloud run \n\nOr else create a vm instance white list the server IP address ( but it will cost a lot )",
            "If you want to build a more custom trigger you can use event tarc or also gcp workflow",
            "You know the trigger mechanism because you have to choose it when you deploy your function. Also..\n\n- pub/sub triggered functions get invoked with a [`CloudEvent`](https://cloud.google.com/eventarc/docs/workflows/cloudevents)\n- http triggered functions gets invoked with a [flask.Request](https://tedboy.github.io/flask/generated/generated/flask.Request.html)",
            "If I understand you correctly, you're concerned that scheduling HTTP Calls to your Cloud Run Function will be tricky. With Google Cloud Scheduler, it was pretty easy for me. Just try it. It should only take you a day or two to get the hang of things.",
            "We\u2019re all in on GCP and I think the issue is there\u2019s a huge disparity in the documentation.\n\nSome of it is excellent, the GKE documentation has everything you need to know the issue is finding what you\u2019re looking for because it\u2019s massive.\n\nI was hoping with the explosion in popularity they\u2019d use an LLM to replace their search function because it badly needs it.",
            "I gotchu. Here is what I am envisioning to do:\n\nMake an API with Cloud Function.\n\n- One function will go collect data and store it somewhere on the cloud. This function will run every 24 hrs\n- Another function is a HTTP function that will just return the JSON data stored on the cloud\n\nIs this setup possible?",
            "I agree with this. The docs are well written, but _finding_ stuff in the docs is hard. Especially for beginners.",
            "Yes this is possible"
        ]
    },
    "Reflex 0.4.0 - Web Apps in Pure Python": {
        "title": "Reflex 0.4.0 - Web Apps in Pure Python",
        "score": 121,
        "url": "https://www.reddit.com/r/Python/comments/1b7bgwn/reflex_040_web_apps_in_pure_python/",
        "content": "Hey everyone, we just released a new version of [reflex](https://github.com/reflex-dev/reflex) and wanted to share some updates.\n\nFor those who don\u2019t know about Reflex (we used to be called [Pynecone](https://www.reddit.com/r/Python/comments/zh0pmy/pynecone_web_apps_in_pure_python/)), it\u2019s a framework to build web apps in pure Python. We wanted to make it easy for Python developers to share their ideas without having to use Javascript and traditional frontend tools, while still being as flexible enough to create any type of web app.\n\nSince our last post, we\u2019ve made many improvements including:\n\n* We\u2019ve released our [hosting service](https://reflex.dev/docs/hosting/deploy-quick-start/) . Just type `reflex deploy` and we will set up your app, and give you a URL back to share with others. During our alpha we\u2019re giving free hosting for all apps (and always plan to have a free tier).\n* A tutorial on building a [ChatGPT clone](https://reflex.dev/docs/tutorial/intro/) using Reflex. See the final app [https://chat.reflex.run](https://chat.reflex.run)\n* New core components based on Radix UI, with a unified theming system.\n* More [guides](https://reflex.dev/docs/wrapping-react/overview/) on how to wrap custom React components. We\u2019re working now on building out our 3rd party component ecosystem.\n\nOur key focuses going forward are on making the framework stable, speed improvements, and growing out the ecosystem of 3rd party components. We\u2019ve published our roadmap [here](https://github.com/reflex-dev/reflex/issues/2727).\n\nLet us know what you think - we\u2019re fully open source and welcome contributions!\n\nWe also have a Reddit where we post updates: https://www.reddit.com/r/reflex/",
        "num_comments": 52,
        "comments": [
            "Cool. What's the differentiation with niceGUI?",
            "How does it compare with Plotly Dash?",
            "Amazing. What are the pros an cons of this vs Streamlit? Is it easy to add custom UI elements?",
            "My god, this thing has a ton of dependencies. Have you evaluated if you actually need all of them or can carve this up into different groups of optional dependencies depending on which parts of this project you?",
            "Is this based on JavaScript? Like WASM?",
            "Nice. Comparison with Anvil?",
            "Hi, I am relatively new to this space, but I am looking to build a python web based app with OpenCV. Would it be possible to build such an app with Reflex and OpenCV!  This work looks really interesting.",
            "Comparison with Panel?",
            "jappy cale day u/Boordman could you guys do a blog post on creating a barebones full stack LLM app including auth and Stripe integration",
            "I'm very new to all of this. please be kind. Can i build browser extensions with this tool ?",
            "Wow love the chat app UI, so cool!",
            "This is great and has a great User interface. Amazing!",
            "Can you easily deploy it on a service where you would only pay for the usage  per minute (paying for the sever only when a user is using it)",
            "Is it possible now to step through code for debugging? I recall trying to move from Streamlit to Reflex and the lack of debugging was the main reason we stuck with Streamlit",
            "Hi! i've got a question, i dont know too much about to webpage development, i just code in python. I want to make a web app and earn money through google ad sense. so the question is, can i make a regular webpage with this? or its the similar to streamlit, that its not a real web page, you have to send the url to. thanks.",
            "There are other Python libraries to make web apps, but we found they often have a ceiling and graduation risk, so when your app reaches a level of complexity the framework may not support it. At that point you either have to limit your idea to fit the framework, or restart your project using \"real web frameworks\" like Javascript/React. Our goal with Reflex is to grow with you, from a basic app to a full-fledged website.\n\nNiceGUI (and others like Streamlit) are imperative frameworks, so you declare the UI one statement at a time. This can be nice especially for spinning up small apps, but as your app grows it may be harder to reason about the UI / state. \n\nOn the frontend side Reflex is declarative (similar to React) where the UI is defined as components that are compiled up front. This makes it easier as your app grows larger, since you can have reusable components and even wrap your own React components.\n\nWe're also a bit more batteries-included - we have built-in database support, support for backend API routes, support for calling long-running background tasks, easy ways to access cookies/local storage, etc. Reflex apps should also be  more performant as your app state gets larger.\n\nIn short, we're trying to be as approachable as these other frameworks, while also having performance and customizability to make more complex apps.",
            "This is my question too",
            "I fear that it is state based and with this will rerender the whole page for every interaction.\n\nWhat makes niceGUI stand out is that only individual elements of the DOM are refreshed, making it more reactive and less sluggish.",
            "Hey! Streamlit is great, but it can be limiting in terms of UI elements, customizability, and performance. We wanted a framework where the end product looks like any other website you would build with traditional web tools. For example we made our main website using our framework: [https://reflex.dev](https://reflex.dev)\n\nWe support styling using any CSS: [https://reflex.dev/docs/styling/overview/](https://reflex.dev/docs/styling/overview/)  \n  \nAnd make it easy to wrap your own custom React components in a few lines of code (both local and any package on `npm`): [https://reflex.dev/docs/wrapping-react/overview/](https://reflex.dev/docs/wrapping-react/overview/)\n\nWe just started this week the start of our 3rd party component ecosystem, to make it easy to publish a component to Pypi once you wrap it, so you can share it with others. We want to include both wrapped React components, as well as higher level Reflex components. For example, in the future you should be able to do `pip install reflex-chat` and get a very high-level chat component without having to implement it yourself.\n\nOur goal is to have a lot of these out of the box features, while being flexible enough to customize it how you want.",
            "Hey - good call out, we're working on cutting this down. One reason for this is we're trying to be \"batteries-included\" so we have packages for frontend, backend, database, etc.\n\nBut we are working on splitting these up so we can have a slimmer \\`reflex-core\\` and then users can add the features they want incrementally. Definitely room for improvement here!",
            "We don't use WASM - only the frontend compiles down to a React app, and the backend is a FastAPI app (which is what allows all the logic to stay in Python). We use websockets to send events and state updates between the frontend and backend.\n\nI'm working on an architecture post this week to explain in more detail, but we've been working to make sure apps stay performant as they grow in size, and to keep the latency low.",
            "I've used both. Anvil is a good wysiwig, but is very slow on server calls and generally more difficult to style due to the css including all the code to render both the page, and what's necessary to style the editor. Switched over to reflex about 6 months ago and for my site has been huge in terms of speed, and ui polish. Very very happy. Only downside is the occasional bug that breaks one or two things, but is usually fixed within 1 or 2 patches.",
            "Well the obvious difference is that Anvil is a WYSIWIG approach to pure python development whereas Reflex is a programmatic approach.\n\nYou can work through the anvil tutorials and the pynecone tutorials and discover other differences.",
            "Yes have definitely seen reflex apps that use opencv for image processing - in general we are compatible with any Python library\u00a0",
            "Panel is so much more than [Panel](https://panel.holoviz.org/index.html) ... it has the entire [holoviz ecosystem](https://holoviz.org/)\n\nit would be useful to work through the tutorials of both products and see which fits your needs.",
            "Thanks! We have a chat app tutorial as well as a blog post on how to use auth. We will have more tutorials coming!\u00a0",
            "Hi, we're not really meant for browser extensions, we're a framework to build standalone web apps. The reason is that our apps also have a backend server where we run your Python functions, so it can't be run purely on the client.",
            "Yes, we have built in hosting, as well as self hosting guides on our website. The frontend is a static site you can host on S3 or GitHub Pages for free, the backend you can host on something like fly.io for by the minute usage\u00a0",
            "You should be able to set up breakpoints in your event handlers and step through them to debug. Do you recall what issues you ran into?",
            ">on about the UI / state.  \n>  \n>On the frontend side Reflex is \n\ncurious whether Reflex can be used for dapps/blockchain apps.",
            "This was only true in earlier versions of Reflex.\n\nNow we have made optimization so we rerender only what is needed.  \nLatest version also introduce state sharding for very fast updates.",
            "I starting playing with it last night, it doesn't re-render everything with every action like Streamlit does.",
            "This isn't true, we compile the frontend to a static app initially. During runtime, the only events and state updates are sent (which are pretty small), and the UI updates reactively. We're focused on making sure apps are scalable/performant.",
            "Thanks for the response, really appreciate it. I've been building a ChatGPT-like web app using Streamlit for the past month (it has additional features like the ability to upload documents to store in a vector db for RAG).\n\nStreamlit was useful as a prototyping tool, but I found it had too many limitations and I was having to write a lot of custom code for workarounds, so I am now looking into rebuilding it using React+FastAPI.\n\nThese are the main issues I had with Streamlit, I was wondering if Reflex solves these:\n\n1. Difficult to add custom React components/do styling (e.g. Streamlit only has two button types and there is no easy way to create more selectors/types of buttons for custom styling). It seems like Reflex makes this a lot easier!\n\n2. Authentication/DB Support. No native way to do auth using JWTs and integrate a database to manage users sessions.\n\n3. Optimization. The main downside of Streamlit for me was that every time you go on the app, it refreshes the page. This makes it difficult to do any sort of caching.\n\nI went through your documentation for the ChatGPT clone app and it looks great! Do you think it's worth it for me to switch to using Reflex instead of building it from scratch using React/FastAPI?",
            "Looks really cool, I'll check it out\n\nFYI, some of the examples in your websites lead to 404 on GitHub (graph traversal and sales email generator)",
            "How come you don't compile to WASM? How does the Python get compiled to React?",
            "Happy cake day @boordman. \n\nLooking forward to read the post. BTW project looks great and I'm going to try it as soon as possible.",
            "Personally, Panel and Holoviz seems far more developed, simple to use, and quite versatile.",
            "I followed the AI chat tutorial last night to make my own Claude 3 bot, I love it. The simplicity of your hosting options is great and I'd love to build on it, but I definitely need to run my app on my own domain. Are you planning on offering that? I'd be interested in paid plans as well for extra features, more storage, etc.",
            "I'm very happy to hear that!\nThanks for clarifying, I'll give it a shot!",
            "Yes we should cover all of those bases - I think Reflex would be a good fit for your project.\n\n1. We support any CSS styling support wrapping custom React components, so you can bring your own if we don't have it.  \n2. We have built in database support and guides on authentication (planning to add a builtin component for this soon as well)  \n3. Agreed - we really wanted the performance to be as snappy as a normal web app - our frontend is statically generated up front and only state is sent as runtime (whereas in Streamlit, the UI is generated dynamically on every event)",
            "not the OP but if I could do it in proper frontend frameworks I'd do that. I like the idea of Rx but it's still young (0.4.0) and I'm not sure how long it will be maintained.",
            "Ah thanks for pointing that out, we will fix that up",
            "We don't compile arbitrary Python to React - only the frontend portion.\n\nFor example the component `rx.heading(\"hello\")` we compile down to a React element `<Heading>hello</Heading>`.\n\nBut all the actual Python logic stays on the server on the backend FastAPI app. This is what allows you to use any Python packages such as `openai` or `pandas` on the backend.\n\nUnder the hood when you e.g. click a button, it will send the event to the backend, run your Python function, and send the state delta back to the React app. So even though there are roundtrips happening on every event, for most apps the performance is pretty good as we use websockets and the data transfer is small.",
            "Thank you! Awesome - would love to hear your feedback :)",
            "Hosting is still in alpha for now, the options you want will definitely come in the future though.",
            "This is it. I tried streamlit (and dash), both worked fine for personal (and internal team) use, but couldnt go to production/client facing for this reason. I think I'll try it out properly, was just starting to learn JS..",
            "Reflex has raised quite a significant amount of funding, and will be maintained.",
            "This is still a problem for 3 of your examples. Can you have a look?",
            "Are the backend APIs exposed in a way that they can be accessed externally as well? I have been pondering a project that would require this kind of access, and like the sound of your other features as well.",
            "Yes you can expose your own api as well - see here \u00a0https://reflex.dev/docs/api-routes/overview/"
        ]
    },
    "Automatically Generate Python Docstrings with LLMs": {
        "title": "Automatically Generate Python Docstrings with LLMs",
        "score": 42,
        "url": "https://www.reddit.com/r/Python/comments/1b2034r/automatically_generate_python_docstrings_with_llms/",
        "content": "Thank you for the all the great feedbacks on my last post.\n\nContext:\n\n**What My Project Does?**\n\nPenify is a GitHub App that auto-generates and dynamically updates documentation for your repo. It supports various styles like Google, Numpy, reST, and Epydoc, ensuring your documentation stays current with every change.\n\nCheck it out: \\[Penify GitHub App\\](https://github.com/apps/penify-dev).\n\nHere's how it works in action: \\[Sample PR\\](https://github.com/NVIDIA/trt-llm-rag-windows/pull/44/files).\n\n**Updates:**\n\n1. Generates consistent style docstrings: Google, reST, Numpy, Epydoc.\n2. Reduces hallucination through improved prompts and more context.\n3. Offers Full Repo documentation generation - previously it used to generate docs for only code changes.\n\n**Working on**\n\n* ignore-private\n* ignore-semiprivate\n* ignore-init-method\n* ignore-setters-getters\n\n**Target Audience:**\n\n* Ideal for freelance developers requiring high-quality project documentation.\n* Perfect for project managers desiring updated codebase docs for smooth onboarding of new developers.\n\n**Alternatives:** Copilot & Tabnine Cons:\n\n1. In consistent style docstring style - sometimes it generates Google,Numpy....\n2. Context selection is very limited in Co-pilot\n3. Need to manually do doc updates for each modified code; Penify does it automatically in the background(it detects code changes and generates docs)\n\n**Pros:**\n\n1. You can update the modified docstring before pushing it.\n\nI know the community believes that Docstring generation shouldn't be done by LLMs - but I am seeing some good results. Hence, I am giving my effort. Please try and let me know your feedback.",
        "num_comments": 39,
        "comments": [
            "My code is being sent to the LLM?",
            "I will give a try, thanks for sharing - I belive that we haven't reached a stage where LLMs can write effective docstring. Let's see what your app does.",
            "Change your name... there is already a snorkel-ai that's been around for years. https://snorkel.ai/",
            "Can you tell me how your product will work with other coding environment and languages. Can it also work with tsx/jsx files for React projects?",
            "I do this manually with a locally hosted LLM, and it\u2019s great within the limitations you would expect. Does this project have an easy way to switch backends?",
            "Writing docstrings is my favorite part.",
            "is it available in Tsx?",
            "\"Here's a bad thing I made, did I do good?\"",
            "Yes, the code is sent to the LLM for processing. However, our privacy policy ensures that such data is not used by LLMs like ChatGPT for their training purposes.",
            "Sure they can as long as your parameter names aren\u2019t garbage. Copilot already does a good job. \n\ncurious to see how this bulk tool does",
            "Thank you, do share the feedback.",
            "Next week I am moving to a different name... Thank you for the feedback.",
            "Yes, it's built to be async.\n\n[https://github.com/apps/snorkell-ai](https://github.com/apps/snorkell-ai) - after you install this app\n\n1. [Snorkell.ai](http://Snorkell.ai) will generate PR containing updated docstring for your code after your code is merged to main.\n\n2. Using our dashboard - you can generate documentaion of the entire repository in a single go - [https://dashboard.snorkell.ai/](https://dashboard.snorkell.ai/)\n\n  \nHere are list of sample PRs:\n\n1. [https://github.com/NVIDIA/trt-llm-rag-windows/pull/44](https://github.com/NVIDIA/trt-llm-rag-windows/pull/44)\n\n2.\u00a0[https://github.com/facebookresearch/DiT/pull/68](https://github.com/facebookresearch/DiT/pull/68)  \n3.\u00a0[https://github.com/schech1/remoteio/pull/1/files](https://github.com/schech1/remoteio/pull/1/files)",
            "You can add code comments and docstring will pick those and Snorkell will write a beautiful docstring. Hope that helps.",
            "Not yet, but we will add the support soon.",
            "Make suggestions instead. This is so unhelpful.",
            "It has been my paint point and I have to talked to multiple folks who like docstring to be automated. Can you please elaborate?",
            "gtfo with your bullshit. You're what's wrong with the internet",
            "[deleted]",
            "Your policy almost explicitly permits that:\n\n> Types of Data Collected\n\n> Personal Data\n\n> Usage Data\n\n...\n\n> Use of Your Personal Data\n\n> The Company may use Personal Data for the following purposes:\n\n> For other purposes: We may use Your information for other purposes, such as data analysis, identifying usage trends, determining the effectiveness of our promotional campaigns and to evaluate and improve our Service, products, services, marketing and your experience.\n\n> With Service Providers: We may share Your personal information with Service Providers to monitor and analyze the use of our Service, to contact You.\n\n> With business partners: We may share Your information with Our business partners to offer You certain products, services or promotions.",
            "I have multipler PRs that can help you evaluate  \n  \n1. [https://github.com/NVIDIA/trt-llm-rag-windows/pull/44](https://github.com/NVIDIA/trt-llm-rag-windows/pull/44)\n\n2. [https://github.com/facebookresearch/DiT/pull/68](https://github.com/facebookresearch/DiT/pull/68)  \n3. [https://github.com/schech1/remoteio/pull/1/files](https://github.com/schech1/remoteio/pull/1/files)",
            "I meant, can I use my own LLM?",
            "If I'm not mistaking them for somebody, OP is known to send pull requests to open source projects with bad AI-applied documentation comments on the level of `switchRed(x) // switches to red` to promote his project",
            "dependent bedroom panicky wasteful offer towering piquant slap worthless subsequent\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
            "> It has been my paint point\n\nI'm sorry that you find writing docstrings painful, but it is a skill that gets better with practice. If you can't write at least a first draft of a docstring, that probably means you don't understand what the function does.\n\nAnd that's the problem: a LLM doesn't understand *anything*. It's just a giant Markov chain with billions of alternatives generated dynamically, not an actual intelligence. While it is true that sometimes it may simulate understanding, the problem is that LLMs have total confidence in what they say even when they are \"hallucinating\" nonsense.",
            "No one believes that opanAI is telling the truth about that. That\u2019s why the downvotes.",
            "I am not sure about the downvote but you are correct. OpenAI\u2019s policy is that no data sent to the Api gets used for training.",
            "code isn't personal data or usage data, is it? personal data is PII, just not so named.",
            "tbh those are more detailed than I expected. going to take a look again later to see if they\u2019re accurate",
            "It will be easy to build, our architecture is very modular - can we connect on this?",
            "Sure u/moehassan6832 - can we connect on this? I would be very obliged if you can provide me your views.",
            "[deleted]",
            "Why wouldn't code be usage data?",
            "Yes, I realise that - currently I am working on adding config for these\n\n* ignore-private docstring\n* ignore-semiprivate dosctring\n* ignore-init-method docstring\n* ignore-setters-getters docstring\n* docstring based on code's cyclomatic complexity",
            "Lolol",
            "usage data usually means Metadata about how the application is used. reddit's app would collect like times of day I access, how I interact with ads presented in various ways, etc.",
            "[deleted]",
            "Thank you very much u/secretlyyourgrandma for  explaining.   \nI will explicitly mention in my privacy policy that customer's code is not used for training and testing purpose.",
            "I\u2019m laughing at you. Because you\u2019re a fucking clown.",
            "[deleted]",
            "Yes he\u2019s refuting the productivity boost. Plenty of good devs coding without LLMs, plenty of shit devs committing LLM code that doesn\u2019t work.",
            "I have zero interest in having any conversation with you about anything, ever. Apologies if you got the wrong impression. Bro asked why the downvotes; I explained the downvotes. You want to argue with the downvoters? I don\u2019t care. I didn\u2019t downvote. Go do your clowning with someone else."
        ]
    },
    "Cry Baby: A Tool to Detect Baby Cries": {
        "title": "Cry Baby: A Tool to Detect Baby Cries",
        "score": 180,
        "url": "https://www.reddit.com/r/Python/comments/1awbm1r/cry_baby_a_tool_to_detect_baby_cries/",
        "content": "Hi all, long-time reader and first-time poster. I recently had my 1st kid, have some time off, and built [Cry Baby](https://github.com/BaronBonet/cry-baby)\n\n# What My Project Does\n\nCry Baby provides a probability that your baby is crying by continuously recording audio, chunking it into 4-second clips, and feeding these clips into a Convolutional Neural Network (CNN).\n\nCry Baby is currently compatible with MAC and Linux, and you can find the setup instructions in the README.\n\n# Target Audience\n\nPeople with babies with too much time on their hands. I envisioned this tool as a high-tech baby monitor that could send notifications and allow live audio streaming. However, my partner opted for a traditional baby monitor instead. \ud83d\ude05\n\n# Comparison\n\nI know baby monitors exist that claim to notify you when a baby is crying, but the ones I've seen are only based on decibels. Then Amazon's Alexa seems to work based on crying...but I REALLY don't like the idea of having that in my house.\n\nI couldn't find an open source model that detected baby crying so I decided to make one myself. The model alone may be useful for someone, I'm happy to clean up the training code and publish that if anyone is interested.\n\nI'm taking a break from the project, but I'm eager to hear your thoughts, especially if you see potential uses or improvements. If there's interest, I'd love to collaborate further\u2014I still have four weeks of paternity leave to dive back in!\n\nUpdate:  \nI've noticed his poops are loud, which is one predictor of his crying. Have any other parents experienced this of 1 week-olds? I assume it's going to end once he starts eating solids. But it would be funny to try and train another model on the sound of babies pooping so I change his diaper before he starts crying.",
        "num_comments": 69,
        "comments": [
            "> Target Audience\n>\n> People with babies with too much time on their hands.\n\nI'm not a market specialist, but looks two disjoint sets hahaha",
            "I love this; overengineered niche projects are always fun",
            ">Target Audience\n\n>People with babies with too much time on their hands\n\nDo such people even exist ?? \ud83d\ude05",
            "Does it work well with bird screams? Where I live there are a lot of seagulls, sometimes they sound similar",
            "It will be practically useful baby monitoring tool when combined with motion - https://github.com/Motion-Project/motion",
            "This is actually a pretty great idea.  My wife is hearing impaired, and if we would have had something like this that could detect crying, and either send a notification to her phone, or connect to a home assistant and flash the lights in another room, it would have been incredible.  Keep up the great work!",
            "Hey cool project idea. Determining the type of cry would have extremely good medical and social effects, world changing even.\n\nBabies cry for different reasons, and the type of cry are different; discomfort, pain, attention and hunger seem (from what I remember) different enough that they distress us in different ways.\n\nHunger cries actually cause mothers to lactate! I always thought it'd be a cool hack to play the recording of a hungry baby in public to make women leak, but I'm not cruel enough to actually do it. They are shrill, screeching and gurgling, I think? But don't take my word for it, you have a way to gather data!\n\nI suspect, but can't know for sure, that attention cries are more easily ignored by fathers than mothers, and are easier to ignore for mothers with multiple children. More importantly, responding to these cries makes a rod for your own back because you'll teach your child to cry for company and you'll get a dead bedroom and no free time.\n\nIt would be amazing to actually be able to detect pain cries (most commonly caused by the acid fire-shits of teething and colic / reflux), because doctors are extremely slow to diagnose lactose intolerance and acid reflux issues, resulting in extended periods of suffering in babies who can't communicate their pain \ud83d\ude22\n\nIf you could tag recordings after the fact with \"very hungry\", \"needed change\", \"acidic poop\", \"needed burping\", \"wanted soothing/holding\" and so on, you could potentially make this into a system that is extremely useful for parents.",
            "Being just a week into my first I object to your target demo existing, unless it includes some sort of statement about being extremely tired.\n\nBut nifty project. Would be kinda interesting to be able to tell how much of the time he's properly crying just vs active sleeping.",
            "u/technologicalBridges I'm the father of a 4 month old and for sure I think there is major value in being able to identify the reason behind the crying from the main reasons.  Especially when it comes to changing their diaper when the baby cries, because it happens in such inconsistent increments of times.   \n\n\nThere's been many times where my daughter started crying after I changed her diaper 10 prior and I'm ripping out my hair to figure out why she's crying. Almost every time it was because she peed and had a wet diaper and I concluded that wasn't a possibility since I changed her wet diaper 10 minutes ago.",
            "Why not make your Neural network also detect why your baby is crying? Two common classes: they did poopoo and it\u2019s uncomfortable now. They are hungry",
            "High. Nice idea. I also intend to build a \"crying detection\" module to dim-on/-off light and maybe to start automatically some soothing sounds when our baby cries. You mentioned you might thinking about sharing your training code if anyone is interested. I might be interested to know more about your results.",
            "So, I love the crying idea, but what about nap time? What if the kid wakes up and isn\u2019t crying, but is just awake in the crib? Without a camera is there a way to check for this? I honestly mute our baby monitors a lot, especially when first putting the kids down, and just glance at the monitor every few seconds to make sure they\u2019re alright. Granted my kids are 10mo and 3 yrs so an infant wouldn\u2019t be doing this probably, they likely just cry.",
            "My baby monitor has a really nice function called a microphone and it detects live when the baby is crying. :))",
            "what's wrong with basing it on decibels?",
            "Haha I generally know when my baby is crying \ud83d\ude03! But it seems fun anyway !",
            "How can you estimate crying without using decibels?",
            "False negatives seem costly -- hope it has good recall!",
            "You could add feature for older cry babies \ud83d\ude02\ud83d\ude02\ud83d\ude02 my cousin could sure use this when he to throwing tantrums",
            "I was interested when I thought it was the guitar pedal.",
            "Very cool project! Just starred on GitHub,  would be more interesting if this can be connected to google home or alexa",
            "Can I have the source code of this model?",
            "I thought for sure this was going to scan github issues and label the ones complaining about exe\u2019s",
            "Rofling from that last sentence",
            "This is an awesome idea. Following this thread.",
            "Disjointed for sure",
            "i don't want to jinx it...but i've had a surprising amount of free time so far, when I'm watching him he's sleeping most of the time....\n\nIt also helps that my partner is off for the next 7 months and I have 6 weeks off.",
            "haha thanks! One thing that's bugging me is the model is constantly running. I want to have it triggered to start evaluating based on some decibel threshold, obviously doable but don\u2019t want to invest more time into iit now.",
            "Honestly, for the first kid, for the first few months, I did feel like I had more time than ever before. Kid just eat, sleeps, cries, repeats. The hard part was taking shifts overnight to deal from 10pm-6am. The baby didn't really have capacity to fuck shit up yet. The baby stays wherever you put them. Put them on cleanable surfaces. They have limited ways to fight you, say, during a diaper change.\n\nAt 2, well, I can just randomly lose 30 minutes of my morning to a kid eating too fast/much, and then playing a game of seeing how many intricate things they can throw up on before I can get things under control. Speed round, I still need to get everything done before work. There are some days I just know I need to make sure my spouse is available before I start a diaper change, because I just know today is one of the days my kid is going to immediately start reaching for their poopy bottom, and I need someone to control their hands lest we get poopy hands that go everywhere.",
            "I don't think it would work with bird screams. You'd need to train a model on those. But if you have the labeled data it would be much work to train another model and swap out the models",
            "Thanks, it wouldn't be much extra effort to connect this to some service like Twilio or AWS SNS to send text messages. \n\nIf it would help some people out I'd be happy to send the time. I'd just want to make sure people would actually use it 1st. \n\nFor now I'm going to let it run for a few days and monitor the data to see if I find anything interesting. \n\nHe takes really loud poops...which is a predictor for his crying. I was thinking about training another model on sounds of pooping to act as a warning system for the cries.",
            "Not to diminish this library, but this idea does exist in commercial form already. There's the Nanit baby monitor, which can send a notification to your phone when your baby is crying, or the Snoo smart bassinet which attempts to rock your baby to sleep when it hears crying, but will eventually send a notification to your phone if it's unsuccessful. \n\nWhat a time to be a parent.",
            "are these different cry types consistent across babies and cultures? not the categories, but characteristics of the various cries?",
            "Interesting idea.   \n  \nWould certainly be doable to add a User Interface (UI) to label the data, and a backend for that UI. But that would be a bit of work to implement so I'd want to be sure people would actually use this before investing the time.",
            "haha, i feel you on that one. For that reason I've stopped putting pants on my little one (I keep him under a blanket and he is plenty warn so no one freak out please), when he starts crying I'm now programmed to check if that line on his diper is blue (meaning it's wet) or not.",
            "> What if the kid wakes up and isn\u2019t crying, but is just awake in the crib?\n\nProper etiquette is to write a \"thank you\" card after receiving a gift.",
            "But not all sounds are cries, that's the point.",
            "You\u2019ll get a lot of false positives, we live in a small apartment and play music, watch movies etc. \n\nWe don\u2019t want it going off whenever there is a \u201cloud\u201d sound around the monitor",
            "By looking at the shape of the spectrogram. You use a bunch of fast fourier transforms to extract the frequency information from the waveform. You take time on the x-axis, frequency on the y-axis, and amplitude on the z-axis. You basically treat it like a computer vision task where the amplitude is the color at a specific intersection of frequency and time. The CNN handles identifying the shape/characteristics of a baby cry and differentiates it from something like a bird call. They may hit the same decibels and operate in similar frequency ranges, but because we're looking at time, frequency, and amplitude, we can easily differentiate.",
            "I don't have experience with either of those, but if they have some sort of an API then it would be possible.",
            "I published the model here:\n\n[https://huggingface.co/ericcbonet/cry-baby](https://huggingface.co/ericcbonet/cry-baby)\n\nThe code for extracting the mel's spectrogram is here\n\n[https://github.com/BaronBonet/cry-baby/blob/main/cry\\_baby/pkg/audio\\_file\\_client/adapters/librosa\\_client.py](https://github.com/BaronBonet/cry-baby/blob/main/cry_baby/pkg/audio_file_client/adapters/librosa_client.py)\n\nThe readme contains an overview of the model. As i mentioned i didn't spend the time cleaning up the training code. But I copied pasted the relevant code below.\n\nThe most time consuming part (like most ML projects was creating the features, I'm not going to take the time to clean that up and properly site all the data sources unless there is real interest in this project)",
            "Your partner is off for 7 months for a reason. Baby\u2019s are highly demanding when they are not your partner should be resting like the baby.\nAnd you\u2026 should be caring both, and taking care of the house. \ud83d\ude05",
            "the shitting and crying potato phase is the easiest, each phase after is another level of hardness haha",
            "A simple RMS computation on the audio input can be very easy to do. Lookup librosa, there is one function to do that and you can set a threshold based on some quick tests",
            "> Honestly, for the first kid, for the first few months, I did feel like I had more time than ever before. Kid just eat, sleeps, cries, repeats. The hard part was taking shifts overnight to deal from 10pm-6am. The baby didn't really have capacity to fuck shit up yet. The baby stays wherever you put them. Put them on cleanable surfaces. They have limited ways to fight you, say, during a diaper change.\n\nThis is exactly what I'm experiencing now, well said.",
            "I think what they mean is whether bird sounds would become false positives.",
            "I'm not sure. I ran a feed and change tent for a parenting charity for a while, and remember hunger, frustration and trapped wind / teething / reflux sounding different. Plus saying \"aww, [sad/hungry] babba?\" to random strangers and them responding knowingly; it's lived experience rather than science.\n\nI'd assume that babies are mostly relying on innate behaviour. It's possible that the speech centres develop in the womb in response to environmental sounds, but I'd be pretty surprised if a signal like \"I need food\" would actually benefit from being flexible, maybe \"I need attention\" would though as it's a signal that's actually in competition with other children, so having an edge there would likely be socially informed.",
            "I think this would make it way more useful. At the moment you risk responding to \"I want attention\" signals as much as \"I need food\" and \"I'm in pain\" ones, and training a dependency on that which is awful to break later on (\"crying it out\" is a miserable experience for the parents)",
            "I mean I wasn\u2019t complaining. Maybe it came off wrong, but these are suggestions to keep in mind for OPs future with his kid.",
            "I also have an advanced detection system called ears that detects in real time what the sound is. :))",
            "So if someone is shooting a gun next to your kid, you don't care",
            "```\n@dataclass\nclass PartitionedDataset:\n    features_train: np.ndarray[np.ndarray[np.ndarray[np.float32]]]\n    labels_train: np.ndarray[np.int64]\n    features_val: np.ndarray[np.ndarray[np.ndarray[np.float32]]]\n    labels_val: np.ndarray[np.int64]\n    features_test: np.ndarray[np.ndarray[np.ndarray[np.float32]]]\n    labels_test: np.ndarray[np.int64]\n\n    def reshape_features_for_cnn_input(self) -> \"PartitionedDataset\":\n        self.features_train = self.features_train[..., np.newaxis]\n        self.features_val = self.features_val[..., np.newaxis]\n        self.features_test = self.features_test[..., np.newaxis]\n        return self\n\n\nclass TrainingClient(ports.TrainingClient):\n    def __init__(self, logger: Logger):\n        self.logger = logger\n\n    def train(self, features_and_labels: domain.FeaturesAndLabels):\n        try:\n            features_and_labels.validate_no_nans()\n        except ValueError:\n            self.logger.error(\n                \"Features and labels contain NaNs, attempting to replace features NaNs with 0\"\n            )\n            features_and_labels.replace_nans_with_zero()\n        finally:\n            features_and_labels.validate_no_nans()\n\n        self.logger.info(\"Training model from validated features and labels\")\n        partitioned_dataset = self._partition_dataset(features_and_labels)\n        cnn_partitioned_dataset = partitioned_dataset.reshape_features_for_cnn_input()\n        # TODO we should pass 128 as a parameter\n        model = self._create_cnn4_model(\n            input_shape=(128, cnn_partitioned_dataset.features_train.shape[2], 1)\n        )\n        early_stopping = EarlyStopping(patience=5, restore_best_weights=True)\n        reduce_lr = ReduceLROnPlateau(factor=0.2, patience=3, min_lr=0.001)\n\n        history = model.fit(\n            cnn_partitioned_dataset.features_train,\n            cnn_partitioned_dataset.labels_train,\n            epochs=30,\n            batch_size=32,\n            validation_data=(\n                cnn_partitioned_dataset.features_val,\n                cnn_partitioned_dataset.labels_val,\n            ),\n            callbacks=[early_stopping, reduce_lr],\n        )\n        test_loss, test_acc = model.evaluate(\n            cnn_partitioned_dataset.features_test,\n            cnn_partitioned_dataset.labels_test,\n            verbose=0,\n        )\n        try:\n            model.save(\"model.keras\")\n        except Exception as e:\n            self.logger.error(\"Failed to save model\", error=e)\n        _plot_learning_curve(history)\n        self.logger.info(f\"Test accuracy: {test_acc:.4f}, Test loss: {test_loss:.4f}\")\n\n    def _create_cnn4_model(self, input_shape=(431, 80, 1)):\n        model = Sequential()\n\n        # First Convolutional Layer\n        model.add(\n            Conv2D(\n                filters=32,\n                kernel_size=(5, 5),\n                activation=\"relu\",\n                input_shape=input_shape,\n            )\n        )\n        model.add(MaxPooling2D(pool_size=(2, 2)))\n\n        # Second Convolutional Layer\n        model.add(Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\"))\n        model.add(MaxPooling2D(pool_size=(2, 2)))\n\n        # Third Convolutional Layer\n        model.add(Conv2D(filters=128, kernel_size=(3, 3), activation=\"relu\"))\n        model.add(MaxPooling2D(pool_size=(2, 2)))\n        model.add(Dropout(0.5))\n\n        # Fourth Convolutional Layer\n        model.add(Conv2D(filters=256, kernel_size=(3, 3), activation=\"relu\"))\n        model.add(MaxPooling2D(pool_size=(2, 2)))\n        model.add(Dropout(0.5))\n\n        # Fully connected layers\n        model.add(Flatten())\n        model.add(Dense(units=128, activation=\"relu\"))\n        model.add(Dropout(0.5))\n        model.add(Dense(units=1, activation=\"sigmoid\"))  # Binary classification\n\n        # Compile the model\n        model.compile(\n            optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"]\n        )\n        plot_model(model, to_file='model_visualization.png', show_shapes=True, show_layer_names=True)\n\n        return model\n\n    def _partition_dataset(\n        self, features_and_labels: domain.FeaturesAndLabels\n    ) -> PartitionedDataset:\n        train_features, temp_features, train_labels, temp_labels = train_test_split(\n            features_and_labels.features,\n            features_and_labels.labels,\n            test_size=0.2,\n            random_state=42,\n        )\n\n        val_features, test_features, val_labels, test_labels = train_test_split(\n            temp_features, temp_labels, test_size=0.5, random_state=42\n        )\n\n        self.logger.debug(\n            \"partitioned dataset\",\n            count_train=train_features.shape[0],\n            count_validation=val_features.shape[0],\n            count_test=test_features.shape[0],\n        )\n\n        return PartitionedDataset(\n            features_train=train_features,\n            labels_train=train_labels,\n            features_val=val_features,\n            labels_val=val_labels,\n            features_test=test_features,\n            labels_test=test_labels,\n        )\n\n\ndef _plot_learning_curve(history):\n    # Plot training & validation accuracy values\n    plt.figure(figsize=(12, 4))\n\n    plt.subplot(1, 2, 1)\n    plt.plot(history.history[\"accuracy\"])\n    plt.plot(history.history[\"val_accuracy\"])\n    plt.title(\"Model accuracy\")\n    plt.ylabel(\"Accuracy\")\n    plt.xlabel(\"Epoch\")\n    plt.legend([\"Train\", \"Validation\"], loc=\"upper left\")\n\n    # Plot training & validation loss values\n    plt.subplot(1, 2, 2)\n    plt.plot(history.history[\"loss\"])\n    plt.plot(history.history[\"val_loss\"])\n    plt.title(\"Model loss\")\n    plt.ylabel(\"Loss\")\n    plt.xlabel(\"Epoch\")\n    plt.legend([\"Train\", \"Validation\"], loc=\"upper left\")\n\n    plt.tight_layout()\n    plt.show()\n```",
            "\u20267 months?! must not be an american lol",
            "[deleted]",
            "But you'll have to admit that it also transmits other false positives like a car passing by your window or some soothing music playing in the background.\n\nI agree that this project is a case of over-engineering, but that's the fun!",
            "I think if a gun goes of by your kid he will start crying....",
            "Sounds like a moralistic straw man to me.",
            "Sir, not everyone lives in America.",
            "Hey, if the kid is fine with it, I'm getting my sleep while I can.",
            "There are countries that have up to 2 years of maternity/paternity leave",
            "If you could send me an audio file I could run it though the model and let you know what the output is (also compared to the prediction of my kids crying)",
            "It does, but it has to be pretty loud to catch it.",
            "Technically everyone does at this point. The culture is so ubiquitous, we\u2019re all mostly American.\n\nEdit: down vote all you want. It won\u2019t change the facts.",
            "I wanted to make it relatable to 'muricans. I don't live in america myself.\n\nBut stuff that has happened in my home:\n\nthe plaster on the ceiling collapsed, breaking a few things underneath. It was due to a leak in the roof which my dad said was condensation\n\nframes falling down due to earthquake\n\nWhy would you not want to be alerted by any loud noise?",
            "Don\u2019t you have hands to drive too? \n\nWhat is your point of trolling here?",
            "I'm not trolling, just don't understand the usefulness of the project. Or of making something just to make it.",
            "Well, those are two different issues altogether. It's completely fine not to understand the usefulness of the project, but you need to be willing to give the benefit of the doubt and to ask the appropriate questions to ensure that you understand why it was undertaken. On the other hand, if you take issue with people \"making something just to make it,\" then it seems like you're either a highly practical person who never does anything without a clear deliverable that appeals to the entire world *or* a massive hypocrite.",
            "> Or of making something just to make it.\n\nI myself don't understand the usefulness of posting a snarky comment to put someone down, but there we are.",
            "Couldn\u2019t have spelled it out better myself. To be clear I used to be that person too, completely practical no inefficiency. Then I realized I never got anything done worth my own approval.",
            "If I wanted to be snarky I would ask why it seems like a good idea to introduce 5+ seconds of latency between you and your baby's needs. Or even worse to miss cries all together. The baby needs attention and affection, not time consuming wonky software."
        ]
    },
    "I made an app that adds subtitles to any video": {
        "title": "I made an app that adds subtitles to any video",
        "score": 164,
        "url": "https://www.reddit.com/r/Python/comments/1apzzvp/i_made_an_app_that_adds_subtitles_to_any_video/",
        "content": "https://github.com/Dimitris02/subtitler/tree/main\n\n\nI made it in python 3.9. It uses the following libraries: speech_recognition, selenium, moviepy, pydub\n\n\nIt uses google's speech recognition as well as a deepl.com scraper (deepl is the most accurate translator out there afaik). Usually it works pretty well with the default variables but you can tweak the SILENCE and THRESH variables in the subtitler.py file for better results. You can also change the LANG variable to pick another language. To launch the app run the launch.bat file and enter the filename/path of the video you want to add subtitles to.\n\n\nThe default language is Russian because I was testing it on some Tarkovsky movie scenes.\n\n\nI hope you find it useful.\n\n\nEdit: I just added a feature where you can change the TRANSLATE_TO variable in the subtitler.py file to change the language of the resulting subtitles.",
        "num_comments": 30,
        "comments": [
            "Nice. Don't forget to include a requirements.txt file either.",
            "Nice work dude! How long did it Take?",
            "Why use selenium instead of deepl's API? https://www.deepl.com/en/docs-api",
            "I made one a while ago https://codeberg.org/ltworf/srtgen\n\nit uses openai's crap. It's terribly inaccurate. Most of the times I have to edit the files by hand, line by line. But at least the timestamps are kinda correct.",
            "Sounds really cool, will check this out",
            "Awesome work, looking forward to have time to test it!\n\nIf it doesn't do it already... could it be tweaked to sync and already known subtitle that is out of sync?\n\nCan it translate an already synched subtitle in another language?",
            "Interesting project\ud83d\udc4d\ud83d\udc4d\ud83d\udc4d\ud83d\udc4d\ud83d\udc4d\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f\u2b50\ufe0f",
            "Interesting project\ud83d\udc4d\ud83d\udc4d\ud83d\udc4d",
            "Now make a program that creates subtitles on any person talking to you in any language, translate to English and make the subtitles appear under them on an Apple vision.",
            "You are God send!",
            "I have spent a fair amount of time with your app and want to give you some\n\nfeedback.  There is a lot good to say, this may make you feel good, but\n\ninstead I am going to focus on issues that might help you make it better.\n\n\n\nI am running on Linux mint, python10 using anaconda and Spyder\n\nDid not install instead running from downloaded source.  You can see my code at\n\n[https://github.com/russ-hensel?tab=repositories](https://github.com/russ-hensel?tab=repositories)\n\n\n\nI have tried two video files, a Chinese costume drama ( detective-dee-episode.mp4 )\n\nand an Italian detective drama ( InspectorMontabano/Season01/11\\_Turning Point.mp4 ).\n\nUnfortunately neither gave me usable subtitles.  The Inspector.. was closest,\n\nbut despite asking for English I go Italian.\n\n\n\nSuggestions:\n\n\n\nThe Big Ones:\n\n\n\nClasses and functions lack documentation\n\nas to purpose ( and everything else ). ( this is biggest of the big )\n\n\n\nSome sort of documentation on what running it\n\nis like, not requiring the reading of any code\n\n( and include inputs and outputs ):\n\n\n\nFor example:\n\nThe application will prompt for a number of arguments\n\nthe control the application ( some are defaulted but\n\ncan be changed with user input )  This ends when\n\na file name ( of type mp4? ) is input.\n\n\n\nThe body of the app then begins.\n\nThere will be output to the console:\n\n\n\nOutput to: subtitler/geckodriver.log which contains\n\nwhat ??\n\n\n\nProcessing of a 1 hr file seems to take about 1 hr on\n\nmy ThinkPad P72",
            "comment continued...\n\n\n\nSome Less Major suggestions:\n\n\n\nWhy not add a wiki to the repo?  I would have put\n\nthis material there.\n\n\n\nMany variable names are not suggestive as\n\nto purpose ( all really short names ).\n\n\n\nLogging in addition to print might be nice.\n\n\n\nTime to use more fstrings, code is clearer then.\n\n\n\nMagic numbers -- move to constants, ex: \"chunk.wav\"\n\n\n\nfile     is a file\\_name\n\nf        is a file object, handle or stream\n\nperhaps use file or file\\_object or ...\n\nthere may be better names here, I am still\n\nthinking about best solution\n\n\n\nin capture\\_audio:\n\nprint( f\"Error: capture\\_audio {i}  {e}\" )\n\nis a better error message ( but still e is not a great var. name )\n\n\n\n===============\n\nI added logging using a module global\\_logger:\n\nimport logging\n\nLOGGER\\_ID              = \"g\\_log\"\n\nLOGGER\\_FN               = f\"{LOGGER\\_ID}.pylog\"\n\nlogger                  = logging.getLogger( LOGGER\\_ID )\n\nlogger.handlers         = \\[\\]\n\nlogger.setLevel( 10 )\n\nfile\\_handler            = logging.FileHandler( LOGGER\\_FN )\n\nformatter               = logging.Formatter( '%(asctime)s - %(name)s - %(levelname)s - %(message)s' )\n\nfile\\_handler.setFormatter( formatter )\n\nlogger.addHandler( file\\_handler )\n\n\n\nwhich I use as follows ( after importing )\n\nmsg          = f\"about to open file to readlines {file}  \"\n\nglobal\\_logger.logger.debug( msg )\n\nprint( msg )",
            "I have more comment... the logging results, but redit resists me posting it--- add a wiki at your repo and\n\ni will post it there.",
            "Looks really good. I'll chip in when I get a chance",
            "I did the same with openai and ffmpeg. How does your subs look? What styles can you do? Im trying to find a specific style for mine. Im trying to make the grey transparent background that wraps around white text.",
            "Do you need an api key for Google speech recognition api?",
            "Two days. It was surprisingly easy. I had used selenium before but not voice recognition",
            "I haven't used APIs before. Afaik you need to to use a key which sounds bothersome. When it's a scraper anyone can download and use it immediately",
            "That's weird, Whisper has been awesome in my experience.",
            ">Apple vision.\n\nyour 10,000$ open source translation station. :-)",
            "Now add automatic translation to a chosen language.  \n  \nI mean, if it is in chinese voice can I get korean subtitles?",
            "Nice. Keep it up!",
            "Using APIs is still web scraping. It's using backend rather than front end and is usually preferable in web scraping.",
            "I'm not american. Perhaps with other languages it is crap?",
            "Will do. When you open deepl it detects the input language and translates it to your language (or the language of the country of your IP). I'm not sure if deepl has Korean but it keeps adding new languages over time.",
            "Hello. Just thought I'd let you know that I did what you asked. There's now a TRANSLATE_TO variable in the subtitler.py file where you can pick any language you want for your subtitles (deepl has Korean after all)",
            "I am actually spanish but you get my point. Translating into another language is a huuuge good feature",
            "\ud83d\ude0d awesome!",
            "Yeah it's a super important feature I can watch anime without any worry \ud83e\udee0",
            "Touch some grass"
        ]
    },
    "TIL that `for x in 1, 2, 3:` is valid": {
        "title": "TIL that `for x in 1, 2, 3:` is valid",
        "score": 565,
        "url": "https://www.reddit.com/r/Python/comments/1ahfue0/til_that_for_x_in_1_2_3_is_valid/",
        "content": "I consider myself a Python expert. I don't know *everything* about it, but I've delved [very, *very* deep](https://github.com/alexmojaki).\n\nSo I was surprised when reading [this recent post](https://www.reddit.com/r/Python/comments/1ah05vt/summary_of_major_python_changes_between_versions/) by /u/nicholashairs to discover that 3.11 introduced this syntax:\n    \n    for x in *a, *b:\n      print(x)\n\nAnd I was even more surprised that just `for x in a, b` without the `*`s was also valid and has been since at least 2.7.\n\nI *know* that 'commas make the tuple', e.g. `x = 1,` is the same as `x = (1,)`. I can't believe I missed this implication or that I don't remember ever seeing this. It *is* used in library code, I can see it when I search for it, but I don't know if I've ever come across it without noticing.\n\nAnyone else feel this way?",
        "num_comments": 84,
        "comments": [
            "It's probably worth noting for the casual audience here that `for x in *a, *b` and `for x in a, b` do completely different things, though.\n\n```python\na = (1, 2)\nb = (3, 4, 5)\n\nfor x in *a, *b:\n    print(x)\n\n# 1\n# 2\n# 3\n# 4\n# 5\n\nfor x in a, b:\n    print(x)\n\n# (1, 2)\n# (3, 4, 5)\n```",
            "Commas make tuples, not () - they\u2019re just to disambiguate.",
            "Well, commas _usually_ make the tuple. For example, you cannot write `[i, j for i, j in enumerate(range(3))]`, it has to be `[(i, j) for i, j in enumerate(range(3))]`. It's nice that you can omit the parentheses sometimes, but since it is not always the case one ends up defaulting to adding them in most cases.\nEdit: I understand why you need the parentheses in the example above (\"is it a list comprehension or a list with `i` and a generator?\"). I'm not saying it is a mistake in the language, but since they are necessary in many cases it is normal to tend to use them in general.",
            "Apart from your point, the debugging tools you made seem really nice. Thanks for sharing!",
            "I\u2019m not surprised\u2026but I also learned this today from this. \n\nIs surprising how many weird combo Python has\u2026",
            "I didn\u2019t know this and I\u2019ve been writing python for over 15 years. It makes sense in retrospect but I\u2019ve been doing it with parens the whole time because it didn\u2019t occur to me to try. \n\nOP ignore the smarmy know it alls",
            "To be honest, I would still think that using brackets there is more readable\n\n\n    for key in ('key_to_validate', 'other_key_to_validate'):\n        assert key in some_dict\n\nvs.\n\n    for key in 'key_to_validate', 'other_key_to_validate':\n        assert key in some_dict",
            "learned something new thanks",
            "And now I've just discovered that `[x for x in 1, 2]` is valid in 2.7 but not in 3.x!\n\n(at least not in 3.8+)",
            "I think a better solution is compose the tuples/sets into a predefined variable that explains what it is and why you are iterating over them both.",
            "It is an iterable. Nothing surprising here.",
            "Wait does the new syntax also mean that you can do this?\n```\nfor x in (*inner for inner in nested):\n    ...\n```\nInstead of using `itertools.chain` or a nested loop?\n\nOr maybe\n```\nfor x in *(*inner for inner in nested):\n    ...\n```",
            "I'd prefer something a little more explicit like `itertools.chain(a, b)`",
            "The syntax *is* indeed interesting but you scattered the breadcrumbs to https://github.com/alexmojaki/snoop too sparsely. I'm definitely going to be @snooping all the time now -- that is an excellent project!",
            "Wow! I'm also an experienced python programmer and had never realized this implication. Thanks for sharing",
            "I'm surprised you didn't know about the `for x in a ,b` example. The parenthesis used in tuples have always just been a syntax convention and not enforced.",
            "I was also a little bit surprise by that, tho I already was aware of `for x in a, b` for some random stackoverflow question like forever ago, but knowing the unpack syntax stuff for creating the build-in types make this a natural consequence...",
            "Seems like an emergent pattern, that is one which was not explicitly designed to exist, but became a part of the language as a result of how the interpreter was written.",
            "I'm not sure that this was introduced in 3.11. I think it was a \"side effect\" of an update to the parser in an even earlier version. The behavior made sense, so it was documented in 3.11 and left it as-is.\n\nI don't see it too often, thankfully. I'd prefer if everyone assumed that parentheses made non-empty tuples and not commas \ud83d\ude02",
            "whhhaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaT.",
            "Awesome!\n\nI\u2019d also consider myself an expert in Python (have been using it professionally since the 1.5.2 days, with some gaps in between) and did not know this.\n\n~~And I\u2019m almost certain that this didn\u2019t used to work in older versions\u2026~~\n\n~~Could it be that the introduction of the peg parser made this syntax possible?~~\n\n/edit: As the comment below shows it already worked in at least 2.7",
            "    for x, y in itertools.product(range(4), \u201cabcd\u201d):\n         print(x, y)\n\nPrints:\n\n    0a\n    0b\n    1c\n    0d\n    1a\n    1b\n    \u2026\n    3d",
            "Sorry but \"commas make the tuple\" is enough for any *expert* programmer to conclude that.",
            "You probably recognise it from `a, b = 1, 2` etc",
            "This is a really nice shortcut I\u2019ll have to try to remember it!",
            "You say your a python expert I need a experts help how do get and the position from a mpu6050 and set a state for reference in a alarm system",
            "Well okay, that is what I would intuitively expect to happen. But super nice to see the example spelled out! The style really is pretty!",
            "So in essence, putting a * before the variable 'unpacks' it? Does this also work for lists and dictionaries?",
            "Thanks for explaining, I was feeling very lost. The examples were great. ![gif](emote|free_emotes_pack|give_upvote)",
            "Thank you sir",
            "Yeah, true. You might commonly think of this in cases where you write\n> return a, b\n\nOr\n> a, b = [], []\n\nBut it never occurred to me that it\u2019d work in a for loop",
            "My mind is blown",
            "More on this:\n```py\na = 1,\nprint(a)  # Output: (1,), a tuple.\nb, = a  # tuple unpacking\nprint(b)  # Output: 1\n```",
            "Sort of... an empty tuple is just `()`.",
            "> I understand why you need the parentheses in the example above (\"is it a list comprehension or a list with i and a generator?\")\n\nBut generator expressions always have to be surrounded by parentheses, even if they 'borrow' them from a function. So it's not really ambiguous.",
            "Egregiously put.",
            "Could almost be a good argument to have semicolumns in lists like in OCaml? Or would that be too confusing for beginners on when to use commas vs semicolumns?",
            "fucking legend!",
            "Exactly!",
            "Why? What are other possible interpretations could you confuse it with?",
            "This is exactly the point. If python parser like peg syntax supports it unambiguously then it works else won't. for x in *a, *b: works because of colon, but [x for x in a, b]is a list with two elements. A gen expr and value b.\n\nSo, for x in *a, *b syntax is not obvious to me, until I saw it here. Those saying it is not surprising are lying to look cool. If python parser wanted to enforce () there, it could have been the case. Enforcing () would be good idea, contributing towards readability.\n\nBtw, I have 15 years of experience writing python.",
            "Ok, at first I thought \u2018Am I missing something here?\u2019.",
            "No, just like you can't write `[x, y for x, y in ...]`. There you need parens for some reason.",
            "A working genexpr formulation would be:\n\n```python\nseq = [[1,2,3],[2,3,4]]\n\nfor x in (x for xs in seq for x in xs):\n\tprint(x)\n```",
            "No? As the op points out, it's a tuple. Looping over sequences is the intended behavior, so this is completely explicitly designed to exist.",
            "Isn't that just list unpacking? Why didn't it work before?",
            "`python2.7 -c 'print([x for x in 1, 2])'` works.",
            "If someone considers themselves an expert, he/she very likely isn't.",
            "why are you telling us this?\n\nAlso there should be a space between numbers and letters in your output.",
            "That sounds like a mpu6050 question, not a Python question.",
            "Yes, indeed, that is the unpacking operator. And a quick google search tells me that for dictionaries it is ** instead of *.",
            "Another note: inside a function signature, it has the opposite effect.\n\n```python\ndef f(*args):\n    print(args)\n\nf(1)\n# 1\n\nf(1, 2)\n# (1, 2)\n```\n\nHere our function collects all the arguments passed to it into a tuple called `args`.\nThis is why you'll often see functions (usually wrappers or overloads) with `*args, **kwargs` tacked on the end; it collects \"all the other arguments I didn't specify\" so they can be passed on.\n\n\nWhat happens if we combine them?\n```python\ndef f(*args):\n    print(*args)\n\nf(1, 2, 3)\n# 1 2 3\n```",
            "Technically it\u2019s the zero commas in there and the parentheses just disambiguate it from a syntax error. :P",
            "Yes, you are right, I think on the basis of that rule, there should be no ambiguity for the interpreter. I was thinking more of the potential ambiguity for the reader, although tbh it is hard to argue a reader could easily misinterpret it. In fact, it is one of those cases where the syntax error says \"did you forget parentheses here?\", which begs the question, why do I need to add them if you already know what I meant.",
            "you'd expect semicolons to be in a sense weaker binding than commas. Would probably be possible to confuse even professionals with that, especially if combined with parentheses.",
            "I'm pretty sure the PEG parser could support this if it wanted to and this has nothing to do with that.\n\n> [x for x in a, b]is a list with two elements. A gen expr and value b.\n\nLike I said [here](https://www.reddit.com/r/Python/comments/1ahfue0/til_that_for_x_in_1_2_3_is_valid/konzdof/?context=10000), I think it's easy for both the parser and the human reader to know that that isn't a genexpr.\n\nBUT Guido himself reveals that the decision here indeed has to do with genexprs: https://python-history.blogspot.com/2010/06/from-list-comprehensions-to-generator.html\n> \n> So in theory there would be two interpretations for something like this:\n> \n>     sum(x**2 for x in a, b)\n> \n> This could either be intended as:\n> \n>     sum(x**2 for x in (a, b))\n> \n> or as:\n> \n>     sum((x**2 for x in a), b)\n> \n> After a lot of hemming and hawing (IIRC) we decided not to guess in this case, and the generator comprehension was required to have a single expression (evaluating to an iterable, of course) after its 'in' keyword. But at the time we didn't want to break existing code using the (already hugely popular) list comprehensions.\n> \n> Then when we were designing Python 3, we decided that we wanted the list comprehension:\n> \n>     [f(x) for x in S if P(x)]\n> \n> to be fully equivalent to the following expansion using the built-in list() function applied to a generator expression:\n> \n>     list(f(x) for x in S if P(x))\n> \n> Thus we decided to use the slightly more restrictive syntax of generator expressions for list comprehensions as well.",
            "So you think the original Python developers sat down together and said we should make sure you can loop over a tuple defined in the itterable expression?",
            "It's worked since 3.9. At least, according to this ticket;\n\nhttps://github.com/python/cpython/issues/90881",
            "If someone denigrates others in an online forum without any cause he/she is likely an asshole.",
            "Well it is but thats because I don't know how to write my program I have some done but I can't figure out how to References the driver it is all in python",
            "Which is why we can find examples like this everywhere for beginners to stumble upon and trip over:\n\n    *args, **kwargs\n\nWhich respectively translate to:\n\n    Unpack these arguments,\n    Unpack these keyword arguments.",
            "I've been spending too long in Go. I thought they were pointers \ud83e\udd26\ud83c\udffb\u200d\u2640\ufe0f forgive me Python gods",
            "https://www.reddit.com/r/Python/comments/1ahfue0/til_that_for_x_in_1_2_3_is_valid/koqxn5m/?context=10000",
            "Yes. Let's say that was an explicitly defined list \\[1, 2, 3\\] would it seem weird then? No. This is the same thing. Also, what is the difference between using a range call, which we do all the time as a matter of course.",
            "Probably not exactly like that, but it probably came out of \"we need to make sure that data types behave consistently no matter where they are.\"",
            "Huh, it does work in 3.9 (and not 3.8) on my machine.",
            "Try writing a full question with details and I'll give you advice for it to be well received on StackOverflow.",
            "it's pretty useful when you want to pass optional arguments to a function based on a condition, for example\n\n    def test(a=None):\n        pass\n        \n    d = {}\n    if whatever:\n        d[\"a\"] = 123\n\n    test(**d)",
            "\ud83e\udd2f",
            "Super appreciate this comment. I\u2019ve always found this reference to be so difficult to decipher. Every guide I find seems to be written in \u201cProgrammer jargon\u201d.",
            "If it's any reconciliation, all Python variables are essentially just pointers with automatic dereferencing and all of the magic stuff abstracted away.",
            "Ahahah can totally relate. Knowing a little bit of c++ my genius brain saw the asterisk and immediately was \"oh ok, python also uses pointers\" lol",
            "Well range is a generator so it wouldn\u2019t be the same",
            "Right so they designed tuples then said tuples should be valid in any expression which led to them being a valid itterable in a for loop.",
            "K thanks",
            "Unless you assign something to a (non-attribute) variable, in which case the original isn\u2019t overwritten.",
            "Range is not exactly a generator.",
            "They made sequences and structures to iterate over sequences, so...behaving as designed? I can see you are willing to die on this hill, so I am done, but it's a weird one to pick.",
            "Yeah, because assignment implicitly creates a new pointer.",
            "Ah you're right it's not a generator type",
            "Dude all I\u2019m saying is allowing an inlined itterable expression is an emergent pattern\n```\ntuple = 1,2,3\nfor item in tuple:\n    pass\n```",
            "Ok, what about `for i in for j in range(x):` where the second for would be a generator expression? However, this gives a syntax error.",
            "I'm not sure if I'm following the logic of this debate. It sounds like it's a debate on whether or not it was intended for expressions that are interpreted as iterables to be iterable.",
            "Are you serious? This is just a syntax fail. The \\`for\\` is looking for the colon for the execution block and before it finds it another statement starts. \n\nWhen you use the correct syntax there instead of breaking the for loop construct itself it works fine: \n\n\\`for i in \\[j for j in range(x)\\]:\\`\n\nOr you can nest the loops.\n\nBut this has nothing to do with the actual argument which is if using a sequence literal instead of a variable in the for loop is intended behavior."
        ]
    },
    "Summary of major Python changes between versions": {
        "title": "Summary of major Python changes between versions",
        "score": 467,
        "url": "https://www.reddit.com/r/Python/comments/1ah05vt/summary_of_major_python_changes_between_versions/",
        "content": "TLDR: [I've thrown together a one \"page\" reference documenting the major changes to between Python versions](https://www.nicholashairs.com/posts/major-changes-between-python-versions/).\n\nI've spent a fair amount of time recently upgrading some old code-bases and would have found it helpful to have a one page summary of changes between versions. I couldn't find one via Google so decided to create one for myself.\n\nIt might be useful for others so sharing it \u263a\ufe0f",
        "num_comments": 43,
        "comments": [
            "I came in snarky \"oh look. Apparently people can't read release notes\" and found this a great walk through.\n\nI'm sorry OP. I'm used to people pointing me at useless medium articles. You've warmed my frozen heart.",
            "\"Self documenting f-strings\"\nVery cool!",
            "So many gems that I missed. Thank you!",
            "Thanks, found a couple of useful hints from there!",
            "Thanks for this. It would be so cool to have something like https://caniuse.com/ but for Python",
            "This is great! First Python resource I\u2019ve bookmarked in years.\n\nTwo things:\n\n1. Many people use Ruff to lint and format their code these days instead of flake8 and Black. Pyupgrade is included in Ruff as the `UP` class of codes. (`select = [..., 'UP', ...]`)\n2. Both Black and Ruff read the [standard](https://packaging.python.org/en/latest/specifications/pyproject-toml/#requires-python) `project.requires-python`, so almost nobody needs `tool.black.target-version`.\n\nYour example would be:\n\n    [project]\n    requires-python = '>=3.7'\n\nand that would apply to Black, Ruff, and of course people trying to install and use your project from PyPI.",
            "I didn't know I was missing ParamSpec",
            "You should probably make a note that PEP 563 has been usurped by PEP 649, which *should* be landing for Python 3.13 (although worryingly it's not landed yet and we're fast approaching beta 1).",
            "Have been looking a while for something exactly like this. Thank you!",
            "This is a really good summary \ud83d\udc4d\ud83c\udffb. Very nice.",
            "Is it just me or did 3.11 have a lot of features geared towards library developers?",
            "I was looking for something like this the other day. Thanks",
            "nice, I didn't know a couple of those...",
            "Whoa I missed the memo on self documenting f strings that\u2019s so cool. Thanks for this!",
            "TIL about importlib.metadata. now we can finally put the version in setup.py/pyproject.toml and have the package read its own version to expose as __version__ rather than an awkward hacky exec()-based import of the module containing the version in setup.py",
            "Not directly related, but I've used the walrus operator a few times since it got added, but it really has the ugliest and least self explanatory thing in Python. I would hesitate before using it in anything other than personal projects.",
            "That's a great article, made me learn a few things too, thanks!",
            "Thank U",
            "I am not afraid to admit that I didn't understand the part about self-documenting f-strings. (Actually, I was like \"What is an f-string?\"). And the example in the OP's blog post didn't make me see the light.\n\nSo I had to [look it up](https://realpython.com/python-f-strings/) and found this little gem:\n\n    >>> variable = \"Some mysterious value\"\n    >>> print(f\"{variable = }\")\n\n    variable = 'Some mysterious value'\n\nWow! To those of us who are not afraid to admit that we do debugging with print() statements, this is a gift from above. I have usually done this, which is not at all cool:\n\n    print('variable: ', variable)",
            "Very nice!\n\nOne thing I think that is often overlooked is pyproject.toml support to manage packages and no longer requiring setup.py or requirements.txt etc\n\nPyproject.toml is a great improvement, and I think it\u2019s only properly supported from 3.8 onward or something?",
            "Thanks! This is really useful.",
            "Nice Sleep Token reference ;)",
            "Hahah it's okay together we will stand against the onslaught of CrapGPT",
            "That\u2019s more useful than a doc rewrite.",
            "Honestly one of my favourite features to come from f-strings",
            "So *that's* why they want to use that syntax in the PEP for shorthand keyword arguments when calling functions...",
            "Which version of python was that added to?",
            "Do you know if there\u2019s something comparable out there that includes all the module changes grouped together like this?",
            "Thanks for the compliment \u263a\ufe0f\n\nNot sure how I missed those tools respecting requires-python, it was literally last week I moved to using toml config for black \ud83e\udd26\n\nIt's a good point about ruff, I'll probably add some info on it, I just haven't used it because I've got quite a few projects using the older tools and don't want to have to update all of their tooling yet.\n\nUpdate: have added info for `ruff` and updated the sample in `black`",
            "It's so powerful when working with decorators",
            "Good to know, thanks for the catch.\n\nI'll end up updating the post once 3.13 is officially released :)\n\nUpdate: Have added info relating to this.",
            "Oh, did they decide they were going to go with 649? I didn\u2019t read where this was the case (and can\u2019t seem to find it on Google/python.org regardless).",
            "When I first saw it I thought it was ugly. Now that I've used it about a dozen times in a single personal project I quite like it.\n\nDefinitely not something to use everywhere but I do like having it in my toolbox",
            "Thanks for the insight that it might not be obvious - I use f-strings so often I forgot that others might not know about them at all.\n\nI also find them incredibly useful for creating detailed exceptions, or for use with the logging module ^.\n\n^ the logging module (and many linters) recommends not to format strings before sending them to the logging module and instead using modules inbuilt formatting. It does this because if it's not going to log the message then it never formats it. Personally I don't do this because the formatting method it uses isn't as advanced as f-strings so instead if it's likely an expensive message that I'm producing I'll put it in a `if mylogger.enabledFor(\"DEBUG\"): mylogger.log(\"DEBUG\", f\"some expensive f-string\")`",
            "If you're distributing as wheels I don't think the users local version of python matters as the pyproject.toml is parsed into the appropriate metadata anyway.\n\nFor local development I think it depends more on your version of pip/setup tools.\n\nEither way, I know that my projects using pyproject.toml have no problems with 3.7 (no idea about earlier versions).",
            "FYI, package configuration files such as pyproject.toml, setup.py, and requirements.txt are independent of Python versions.\n\nThey are implemented by build backends (e.g. setuptools and hatching) and also used by build frontends (e.g. pip, poetry, pdm, and hatch). So it is upto those build backends and frontends to choose what versions of Python they want to support, Python itself doesn't use any of these configuration files.",
            "So I'm guessing this is from the 3.12 changes because I had to Google ever you were talking about. A bunch of the examples are lifted directly from official changes log so it was their reference not mine \ud83d\ude05",
            "It's in the link \ud83d\ude09\n\nAlso 3.8\n\nEdit: assuming you mean the and documenting. The kwarg thing I don't think has been approved yet",
            "I don't think so, but also the module changes tend to be very extensive - if you haven't already take a look at the some of the official release notes.\n\nThe official docs are generally also good at tracking changes to libraries as far as additions and changes go (\"new in ...\", \"changed in ...\"). Meaning you can just look at the latest version of the module's docs to know when new things are added. Doesn't cover removals.\n\nSomeone suggested making a python version of \"caniuse.com\" but there's far too much work in there for me to be interested in doing it.",
            "Yup: https://discuss.python.org/t/pep-649-deferred-evaluation-of-annotations-tentatively-accepted/21331/43",
            "Ah thank you for the clarification. That must be what I was seeing. I had trouble with editable installs using pyproject prior to python3.8. But essentially it\u2019s due to the version of setup tools that supports it is only compatible with python3.8 onward",
            "Oh man, I thought you provided the example. My bad! Thank you for the summaries regardless. Sometimes the backgrounds provided in PEP can be a lot to sift through.",
            "All good - some of them aren't mine so maybe I need to cite them \ud83e\udd14! Glad you found them useful  \ud83d\ude05"
        ]
    },
    "Ten Python datetime pitfalls, and what libraries are (not) doing about it": {
        "title": "Ten Python datetime pitfalls, and what libraries are (not) doing about it",
        "score": 201,
        "url": "https://www.reddit.com/r/Python/comments/1ag6uxc/ten_python_datetime_pitfalls_and_what_libraries/",
        "content": "Interesting article about datetime in Python: https://dev.arie.bovenberg.net/blog/python-datetime-pitfalls/\n\nThe library the author is working on looks really interesting too: https://github.com/ariebovenberg/whenever",
        "num_comments": 63,
        "comments": [
            "At some point we'll need to stop and think what's easier:\n\n* getting a library that perfectly handle datetime; or\n* getting rid of Daylight savings from all countries in the world",
            "I was skeptical reading the start of this blog, I have a lot of experience in this area and I've read a lot of armchair opinions about the what is right or wrong and am often dubious how implementable they are.\n\nBut the author has really put the effort in and made the library that addresses their complaints, which all are quite reasonable. I will be following along and hopefully it will gain some popularity.",
            "Yep - it\u2019s going to be a long, long process to sort this out in the standard library.",
            "This nonsense ran a train through one of my project timelines last year. I have learned to have immense trepidation and respect for the delicacy of handling datetimes. \n\nAnd then I read this: \n\n> Given that datetime supports timezones, you\u2019d reasonably expect that the +/- operators would take them into account\u2014but they don\u2019t!\n\n#WHAT.THE.FUCK. \n\nFucking hell. I might be approaching the skills necessary to begin contributing to open source projects. I was considering steering my attention  mostly to NiceGUI but the state of datetimes is just\u2026gottdamnit.\n\nA breaking change though \u2014 omg. It\u2019d be like someone going around in public and just slightly loosening all the screws they can find.",
            "&#x200B;\n\nAs always, there's an XKCD for that.\n\nhttps://xkcd.com/2867/",
            "I can add a bit of extra WTF to his example 2:\n\n    import datetime as dt\n    from zoneinfo import ZoneInfo\n    \n    paris = ZoneInfo(\"Europe/Paris\")\n    bedtime = dt.datetime(2023, 3, 25, 22, tzinfo=paris) \n    wake_up = dt.datetime(2023, 3, 26, 7, tzinfo=paris)\n    sleep = wake_up - bedtime\n    \n    print(bedtime)\n    print(wake_up)\n    print(sleep)\n    \n    bedtime2 = dt.datetime.fromisoformat('2023-03-25 22:00:00+01:00') \n    wake_up2 = dt.datetime.fromisoformat('2023-03-26 07:00:00+02:00')\n    sleep2 = wake_up2 - bedtime2\n    \n    print()\n    print(bedtime2)\n    print(wake_up2)\n    print(sleep2)\n\nOutput:\n\n    2023-03-25 22:00:00+01:00\n    2023-03-26 07:00:00+02:00\n    9:00:00\n    \n    2023-03-25 22:00:00+01:00\n    2023-03-26 07:00:00+02:00\n    8:00:00\n\nI can only guess about the reasoning behind this mind blowing difference. Perhaps the answer is indicated in [this very eloquent description](https://blog.ganssle.io/articles/2018/02/aware-datetime-arithmetic.html) of the distinction between wall time and absolute time.",
            "Waiting for this type of library for long time.",
            "I have been longing for a JSR 310 style datetime library in Python for so long. I am switching to this instantly.",
            "I hope this doesn\u2019t end up like the other frequently referred to xKCD comic: \u201cThere\u2019s 14 standards for doing something, I\u2019ll create a new one that fixes it all. Now there\u2019s 15 standards.\u201d I was fond of pendulum, but had to replace it in two of my repositories because it didn\u2019t work with 3.12, and it appeared the author had stepped away from the project. So if anything does come to the fore, it needs to be supported for the long-term by a community.",
            "Wow a surprisingly thorough article on the subject. Really good article well done.",
            "and still better than ln javascript...",
            "Something I'd like to see from `whenever` is an enumeration of possible time zones. Magic strings are terrible. I want to do `TimeZone. <TAB> <TAB> TimeZone.EUROPE_ <TAB> <TAB> TimeZone.EUROPE_PARIS`.",
            "Star date 298913.0141924711",
            "the default settings of datetime and unix's cal are incompatible in the distant past because cal switches from Gregorian to Julian for dates earlier than 3 September 1752; to align cal with datetime (proleptic gregorian for all dates), use the parameter **--reform gregorian** \n\njust in case that matters to anyone",
            "Good timing! Trying to upgrade my project to 3.12 and pendulum is blocking that.",
            "TL;DR: I have been extremely lucky not to need much date manipulation. \n\nI got tired of trying to remember whether strftime converted *to* a string or *from* a string, and I eventually settled on using the Arrow library for my admittedly rather simple needs.\n\nAnd then I got tired of needing to determine what data format (and style within that format) before I could process the data, so I wrote a small, simple library to return the format and style I needed.",
            "You never know when datetime is going to get you. Someone hands you requirements for a website and provides seemingly matching assets.\n\nThen daylight savings time strikes and, because it's a Marine Corp System, a Colonel is giving your contractor self a vigorous ass chewing because the website doesn't match the uniform of the day.\n\nI wear a green striped badge. Know my shame\n\n>1002. UNIFORM OF THE DAY\r\n1. The uniform of the day will be as prescribed by the commander, per guidance provided in chapter 2 of this Manual.\r\n2. The seasonal uniform change will coincide with Daylight Saving Time (DST)conversion.\r\n a. On the Monday after the fall DST change to standard time, the Marine Corps will transition to the winter season uniforms (Marine Corps combat utility uniform (MCCUU), woodland Marine Pattern (MARPAT) with the sleeves \r\nrolled down in garrison, service \"A/B\", dress blue \"A/B/C\").\r\n b. On the Monday after the spring DST change the Marine Corps will transition to the summer season uniforms (MCCUU, woodland MARPAT with the sleeves rolled up in garrison, service \"A/C\", dress blue \"A/B/D\", blue",
            "I'm so glad someone wrote this, I have problems with datetime so often. Especially the German format %d.%m.%y has caused me problems so often. (Admittedly, this is also due to the fact that this format is simply stupid)",
            "Decimal dates would be so much easier. \n\nToday is 2024.08196",
            "You'd still need to handle daylight savings for the period it was a thing.",
            "Get rid of *dates* is what I advocate. Today is 1706742000.",
            ">https://dev.arie.bovenberg.net/blog/python-datetime-pitfalls/\n\nWhy not both?",
            "There\u2019s a lot more to time than timezones",
            "or using a library that strictly uses the Unix timestamp format. I feel like that should be the only format people should be using for dates and timestamps.\n\nAnd before you people pitch in, yes the 2038 problem has been resolved some time ago.",
            "Even without daylight savings, getting a library that perfectly handles datetime is very difficult.",
            "I'm not sure we can really get this sorted in the standard library, I think it may be too ingrained in existing codebases by now. I'm hoping for a library to come up and become a defacto standard, kind of like `requests` is for HTTP calls. `whenever` looks to me like it has the right conceptual basis to be such a library, but it all depends on adoption. There's a reason the libraries discussed in the article exist yet are not adopted widely.",
            "> considering steering my attention mostly to NiceGUI\n\noff topic for this thread, but: I've contributed a handful of PRs to NiceGUI and every one has been a great experience. They've been quite open to improvements, and my code didn't get nitpicked to death and stuck in an endless back-and-forth. The devs jumped jumped straight in, edited my PRs in-place, got it merged, and the features were published in less than a week.",
            "I'm a little confused about this one, because I think 9 hours in the following example is actually correct?\n\n> paris = ZoneInfo(\"Europe/Paris\")\n>\n> \\# On the eve of moving the clock forward\n> \n> bedtime = datetime(2023, 3, 25, 22, tzinfo=paris)\n> wake_up = datetime(2023, 3, 26, 7, tzinfo=paris)\n> \n> \\# it says 9 hours, but it's actually 8!\n> \n> sleep = wake_up - bedtime\n\nA timezone doesn't have daylight savings time. When a region enters DST, _it's timezone changes_. So if you're comparing two different datetimes in the same timezone, daylight savings _should never be_ represented. Right? Confusing things here is that the timezone has been named \"paris\". This isn't correct, a timezone isn't a geography.",
            "And also a [Tom Scott ](https://youtu.be/-5wpm-gesOY?si=qNoVpeZ6MV1N4jin)",
            "Adding on to your addition: if you wake up in `Europe/Brussels` (same timezone as Paris, effectively), you get 8 instead of 9 hours again!\n\n```\nwake_up_in_brussels = datetime(2023, 3, 26, 7, tzinfo=ZoneInfo(\"Europe/Brussels\"))\n\nsleep = wake_up - bedtime  # 9 hours\nsleep = wake_up_in_brussels - bedtime  # 8 hours\n```\n\nAnd yes, Paul Ganssle's various articles on the subject of datetimes are great!",
            "Pendulum had new release some weeks ago.",
            "And as a further twist (i found out) Gregorian didn\u2019t happen all at once. It took the British world 2 hundred years to join in. So dates in the Papal States are different than what became the United States. So, just like DST, when gets mixed up with where to figure out what time it is.",
            "It's not really any worse than `%d/%m/%y`, certainly better than `%m/%d/%y`, although obviously far worse than `%y-%m-%d`.",
            "\"Python 6.2 does not handle the years 1969 through 2043 due to incompatible date management by the world at large\"",
            "Daylight savings is like a theme for your editor. The underlying system(seconds from epoch) doesn't change, just the display of the date(skin).\n\nTL;DR don't need to handle anything.",
            "\"Today\" is 1706742000 -1706828400. You need to specify because sometimes a \"day\" is 86400 seconds and sometimes it is 86401 seconds.",
            "So how do people convert the times and dates they actually use to your Unix timestamp?\n\nOr are you expecting the entire world to stop using human-comprehensible datetimes in favour of basically a counter?\n\n\"See you for lunch at 1708482600\"  \n(Later) \"Hey bro, you didn't show.\"  \n(\"Sorry man, I thought it was 1708486200.\"",
            "> strictly uses the Unix timestamp format.\n\nYou know that [Unix timestamps can be ambiguous](https://en.wikipedia.org/wiki/Unix_time) when dealing with leap seconds?\n\nFor example, 915148800 refers to both UTC 1998-12-31T23:59:60.00 and 1999-01-01T00:00:00.00. Likewise the Unix time number 1483142400 refers to both 2016-12-31 23:59:60 (a leap second) and one second later (2017-01-01 00:00:00).\n\nIf there is ever a negative leap second declared, then there will be Unix timestamps that refer to no actual datetime.\n\nNot to mention that there are at least three commonly used variants which are subtly different from each other: POSIX Unix time, NTP Unix time, and Linux Unix time, which some (but not all) Linux systems use.\n\nThat's what I love about standards. There are so many to choose from \ud83d\ude01",
            "Even if it's not possible to fix `datetime`, I could see it making sense to do what Java did and add an additional, less broken, datetime library to the standard library.",
            "I see them trying with the removal of utcnow. They\u2019re solidifying that naive means local time.",
            "Those guys are great; incredibly responsive.",
            "Author of the blogpost here\u2014\n\nIndeed I haven't done enough to clarify the difference between 'timezone' and IANA tz database. I've now adjusted the wording of this section to clarify somewhat.\n\nThe core pitfall remains though: the standard library allows you to implement DST transitions *but then the +/- operators ignore them.*",
            "Some of the terminology is overloaded, but at very least a `ZoneInfo` is geography. `Europe/Paris` refers to a database entry containing rules on when timezone offsets change for people within a geographical area.\n\n\nIn particular, it knows that those two datetimes have different offsets. If you convert `wake_up` and `bedtime` to UTC and then subtract them, you get 8 hours, as you should.\n\n\nThis is just a straight up bug.",
            "> When a region enters DST, its timezone changes.\n\nI think that's definitely a legitimate point, but if you're depending on that for math, I personally would expect the library to ``raise`` somewhere if I was trying to create a nonsense time. Using the Paris example, trying to create a summer datetime in the CET timezone, or a winter datetime in the CEST timezone.\n\nTo really embrace that API, I think you'd need a helper function that constructs an actual timezone from a locale and a naive datetime. Which, to be honest, wouldn't be that crazy -- a big part of me wonders why we aren't all just storing epoch timestamps **alongside** locale info, and using the locale info only for the functions that require it, instead of combining the two.",
            "In the example, a **region** info (in the sense that \"Europe/Paris\" describes a geographical location and not a UTC offset) was exactly what was given in the creation of the two datetime objects.\n\nAnd as a result of that, the two datetime objects being created had different UTC offsets - what you would call \"timezones\" in your terminology (which is probably correct).\n\nYou can easily verify that the two datetime objects have different UTC offsets:\n\n    print(bedtime, wake_up, sleep)\n\n    2023-03-25 22:00:00+01:00 2023-03-26 07:00:00+02:00 9:00:00\n\nSo basically, the UTC offsets are ignored when subtracting the two objects, which to me is a highly unexpected behaviour.",
            "No its Spring Foward so at like (2AM i think) on march 26, an hour got skipped. So it should be 8  hours.",
            "Highly recommended.  One of my favorites, in fact.  Don't know whether to laugh or cry.  Probably both.\n\nHis recommendation is spot-on.  It takes an extensive historical and geographic database, to get everything right.  And the database *keeps changing*...![gif](emote|free_emotes_pack|scream)",
            "And this, ladies and gentlemen, is how you get jet lag from a train ride.",
            "Yeah, I got tired of waiting and realized it was a bad idea to be dependent on a single owner library.",
            "yeah check out [September 1752 (Italy)](https://www.timeanddate.com/calendar/monthly.html?year=1752&month=9&country=13) and [September 1752 (UK)](https://www.timeanddate.com/calendar/monthly.html?year=1752&month=9&country=9)",
            "On the plus side, it lays the groundwork for finally removing the GIL.",
            "But sometimes you enter a blue date when the code expects a red date, and the UI is all grey.",
            "That's your problem right there. You don't think ahead.\n\nYou store the dates as timestamps, and then with libraries you convert the timestamps back into human readable dates. Unix timestamps should be used to prevent corruption of the dates.",
            "And POSIX is the common one all Linux systems use. There's no question about it. POSIX is default in modern Unix systems.",
            "subprocess and pathlib seem like examples of this. Neither immediately deprecated lower level libs, but they became the de facto high level interface for working with those kinds of things.",
            "> I personally would expect the library to raise somewhere if I was trying to create a nonsense time.\n\nThis is an interesting point. There's probably a use to a library behaving this way, but I'd argue the timezone does still exist, even if no region is using it. This is complicated by the fact that timezones are partially a political decision, and debates about whether DST should even exist rage on in many countries. If France were to decide tomorrow to stop doing DST, a library behaving in this way would instantly be broken and require patching.",
            "Please re-read my comment. The timezone does not \"spring forward\". The _region_ springs forward a timezone.",
            "Would it be worthwhile to you to wait on updating the python version of your projects if it meant using Pendulum?",
            "> You store the dates as timestamps\n\nAnd how *exactly* do you get the data as Unix timestamps in the first place, if you don't expect people to use Unix timestamps in Real Life? You still need to convert them from human date times to Unix timestamps, and that's going to need timezone conversions, just like now.\n\nAccording to you:\n\n> using a library that **strictly uses the Unix timestamp format**. I feel like that should be **the only format** people should be using\n\nso you rule out using libraries to convert between formats \ud83d\ude12\n\nBut maybe you didn't think your comment through when you made it. Maybe you meant that we should use a library that **doesn't** \"strictly use Unix timestamps\" but instead allows people to use **any** format they prefer.\n\nYou know. Like we already have \ud83d\ude44\n\nBy the way, using a numeric timestamp for dates and times is what most software already does -- not all, but most. If you enter a date into Excel, for example, it is converted to a timestamp (although not a Unix timestamp). Most databases used a timestamp internally, for example SQLServer:\n\n* https://dba.stackexchange.com/questions/150158/preferred-way-to-store-datetime#150161\n* https://bornsql.ca/blog/how-sql-server-stores-data-types-datetime-date-time-and-datetime2/\n\nWindows file system uses a timestamp (but different from either Excel or Unix time). Apple Macs used to use yet another timestamp, back in the classic Mac era, but don't know what they use now. iOS has yet another timestamp based system too, because why not?\n\n[Obligatory XKCD](https://xkcd.com/927/).\n\n> then with libraries you convert the timestamps back into human readable dates.\n\nOh, you mean just like we already do?\n\nUsing Unix timestamps as the internal format doesn't eliminate the need to know about timezones. Arithmetic on datetimes needs to know the timezone to be accurate, since days in the real world can be 23 hours, 24 hours or 25 hours according to DST changeovers.\n\nAnother [obligatory XKCD](https://xkcd.com/2867/).\n\n> Unix timestamps should be used to prevent corruption of the dates.\n\nRight, because an opaque cookie like 1708482600 is *so* much more error resistant than a structured record like 2024-02-21T13:30 where you can check each field for out-of-range errors \ud83d\ude44\n\nThere are advantages to numeric timestamps, but error correction is not one of them.",
            "> I'd argue the timezone does still exist, even if no region is using it\n\nI like where your head is at; this is also a good point. But from a library API design standpoint, this is pretty easy to get around -- simply add an ``allow_nonsense_combinations`` kwarg (with the safe default to ``True``). This, I think, is probably the best of both worlds.\n\n> If France were to decide tomorrow to stop doing DST, a library behaving in this way would instantly be broken and require patching.\n\nSure, but this problem is irreducible. If you have code expecting a particular political reality, and the political reality changes, then the code needs to change, too. The question is, would you rather have all of that logic centralized within the particular datetime implementation you're using, or spread across every single application that needs to implement code involving datetimes? Here, I would definitely agree with the OP's article: this is exactly the kind of thing that a datetime library should be doing.",
            "Ok. \n\nBut it\u2019s still returning 9 hours when it should be 8.",
            "If there was transparency and a rough plan, perhaps. But for all I knew pendulum was abandoned.",
            "Too long didn't read. Unix timestamps should always be used for accurate timestamps. You never know if some libraries that handle dates handle them incorrectly (like number of days in a month and leap years)."
        ]
    },
    "Tired of using TKinter": {
        "title": "Tired of using TKinter",
        "score": 300,
        "url": "https://www.reddit.com/r/Python/comments/1afm0yg/tired_of_using_tkinter/",
        "content": "I sometimes use Tkinter to make a GUI for small projects. The thing is I forget everything everytime I take a break and im tired of coding every single component, is there a better way to create GUIs in python?",
        "num_comments": 144,
        "comments": [
            "QtDesigner is pretty nice. \u00a0You literally get to draw out your program and it\u2019ll generate code for you. \u00a0Link some functions in and you\u2019re good.\n\n\u00a0I don\u2019t use it anymore because I can write clearer code, but as a tool to learn new components or get started, it\u2019s great. \u00a0Other people do their whole gui in it.\n\nQt is also way nicer looking than tk and handles way more things for you too.",
            "does it need to be accessible as a native application?  \n[https://github.com/zauberzeug/nicegui](https://github.com/zauberzeug/nicegui)  \nis nice for building quick web guis.",
            "You could try this, it's fresh, haven't used it yet, but looks promising [https://flet.dev/](https://flet.dev/)",
            "For apps that need boot incredibly quickly, great performance, no dependencies and small size, take a look at Dear PyGui: [Dear PyGui](https://github.com/hoffstadt/DearPyGui/wiki/Dear-PyGui-Showcase).\n\nFor a web-like interface, NiceGUI is great.",
            "try:  \nNicegui  \nReflex  \nPySide  \nTaipy  \nand follow Slint, currently for rust, c++ and javascript, but working on python bidings",
            "For me it was PySimpleGUI. Simplified everything about it.",
            "There's https://www.pysimplegui.org/en/latest/\n\nEDIT: WTF it's paid now???",
            "I like custom tkinter. https://customtkinter.tomschimansky.com/",
            "wxWidgets does have Python bindings too. There ist also a pretty good designer for fast prototyping.",
            "As you already know Thinter, then you might like my project [guitk](https://github.com/RhetTbull/guitk) which provides a declarative wrapper around Tkinter making it easy to create simple GUIs with little code. It's a hobby project and still has some rough edges but I've created several apps I use daily using this.\n\n```python\n\"\"\"Simple Hello World example using guitk \"\"\"\n\nimport guitk as ui\n\n\n# subclass guitk.Window as the starting point for your app's main window\nclass HelloWindow(ui.Window):\n    def config(self):\n        \"\"\"Configure the window\"\"\"\n\n        # set the window title\n        self.title = \"Hello, World\"\n\n        # define a layout for the window\n        # the layout manager will automatically add widgets to the window\n        with ui.HLayout():\n            ui.Label(\"What's your name?\")\n            ui.Entry(key=\"name\", focus=True)\n            ui.Button(\"Ok\", key=\"ok\")\n\n    @ui.on(key=\"ok\")\n    def on_ok(self, event: ui.Event):\n        \"\"\"Handle the Ok button click\"\"\"\n        print(\"Hello, \", self.get(\"name\").value)\n\n\n# run your event loop\nif __name__ == \"__main__\":\n    HelloWindow().run()\n```",
            "I liked wxpython . iirc, it came a nice demo gallery in its docs",
            "Still tkinter but with themes and styles like a css framework.\n\nhttps://ttkbootstrap.readthedocs.io/en/latest/",
            "You can try Kivy",
            "I can relate. I started writing my own GUI library a few months ago (guiml), it's a fun project and I am using the app I wrote with it daily. But I still need to look into my own docs regularly because, I forget how exactly some parts work, lol.",
            "PySide6 is great. Its extremely comprehensive",
            "I like NiceGUI and PySimpleGUI. Just depends on what kind of app you need to build",
            "Just build a webapp with streamlit. This is the way.",
            "Use Flet",
            "Pyqt?",
            "Maybe GTK bindings in Python?",
            "PySimpleGUI",
            "If you go down the Qt path, consider QtQuick / QML.\n\nIt's great to keep a clean separation of program logic and GUI. You can still use PySide6 as \"backend\" and create beautiful and functional GUIs in QML",
            "This is definitely an unusual suggestion, but have you ever tried using interactive widgets in jupyter notebook? I use it frequently for simple UIs for data analysis and labeling.",
            "[https://beeware.org/project/projects/libraries/toga/](https://beeware.org/project/projects/libraries/toga/)\n\n&#x200B;\n\nIt utilizes native widgets, ensuring that the GUI maintains a native appearance across various operating systems.",
            "I\u2019ve been having chatGPT create my Tkinter interfaces. It works surprisingly well, but I know this is a bad practice. It totally told me to use a library that literally doesn\u2019t exist once. Just made it up lol.",
            "pyQT",
            "1. PyQt or PySide.\n2. wxWidgets is also worth considering.",
            "If all you need are a few widgets and some output via tables and graphics, the easiest approach I\u2019ve found is [Jupyter Notebooks](https://jupyter-notebook.readthedocs.io/en/latest/notebook.html)",
            "Look up the library Gooey. you won't go back.",
            "Frankly shocked that no one has recommended [PySimpleGUI](https://github.com/PySimpleGUI/PySimpleGUI). I've used it for a number of my projects and it's great.\n\nEdit from future me: fuck PySimpleGUI",
            "Pyside6 or nicegui",
            "Anything that you use \"sometimes\" you will forget, it has nothing to do with tkinter.",
            "Kivy!",
            "The right answer is you don't make desktop apps with Python. There have been attempts \u2014 good and bad. \n\nHowever, I believe Python is great for GUIs, just not for desktop GUIs. For web, there's lot of good development, streamlit, NiceGUI, etc. Plus you can ship this code.",
            "Qt Designer isn't the only Python GUI Designer out there. \n\nCheck out LabDeck's [Python GUI Designer](https://labdeck.com/python-designer/python-gui-designer/), it offers suport for PySide2, Tkinter, Kivy and Custom Tkinter(This looks sooo much better than Tkinter - [Check it out here](https://github.com/TomSchimansky/CustomTkinter) ). The license is also like $60 for the GUI Designers which is way cheaper than QTs.",
            "Learn JavaScript and do webapp frontend!",
            "Does it need to be a standalone GUI? A web app can be pretty nice with Dash or streamlit for instance.\nWhen Tkinter is required, I use shamelessly ChatGPT.",
            "gradio/streamlit are nice  \n\n\nbig fan of gradio",
            "I like kivy",
            "Go to a different language. Python is great and all but some other languages are a bit better for GUIs",
            "What would be the difference of using one of the methods already mentioned for a GUI versus using streamlit to create a webapp frontend?",
            "You can try dearpygui",
            "QT ...or maybe flask+htmx?",
            "While I know about the limitations of ChatGPT and other LLMs, Ive found one of the things chatGPT is actually very good at is tkinter. As long as you\u2019re clear with instructions of what you want each element to do, it does the rest.",
            "Customtkinkter",
            "How about web UI with Streamlit?",
            "Streamlit is nice, if you can run your applications through the browser.",
            "Use flask. Leave os uis to other people.\u00a0",
            "Ya, use JavaScript and fetch() against a Python api",
            "Just host a local web app.",
            "\ud83e\udd2f\ud83e\udd2f\ud83e\udd2f",
            "I guess you are living in 90s.\nHave you heard of something called Streamlit?\nIts primarily used for data driven apps but can be used for general purpose app also.",
            "Depending on how much performance you need you might be better off building it using Electron. I find it a lot easier to build web apps and then convert them into a \u201cnative\u201d desktop app.  If your app is something not resource intensive (like interfacing with your own api servers) this might be the better choice if you have experience with front end web development.",
            "Just don\u2019t use tkinter then",
            "Super simple tkinter wrapper. Does a lot of nice things out of the box: www.gooeypie.dev",
            "I've done one relatively complex GUI in Python with pyqt5 and the biggest hurdle was generating an executable for users. I managed to do it with the cx_freeze library but the executables are so bloated (400mb +), even after reducing the dependancies. Is there any alternative way to make a small exe?",
            "I have used flask to create a very nice financial dashboard. Dash is also great. Tkinter is waste of time imho",
            "I started with PyQT and is amazing. Very complete, the documentation is... Bad, but the tool is very complete. Recommend 100%",
            "There are lots of good recommends. I'm just wondering if tk is still maintained... I thought it was old when i learned it...",
            "HTML+CSS, with Python code as a backend",
            "Wow there are as many options as there are comments! Says something that.",
            "insurance slap include deranged dazzling zephyr dull scarce direful puzzled\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
            "pyqt, flask, django.",
            "Or make a module which has defined functions for re-using same things you do. Suppose you want a window of size, lets say 400x400. Then make a defined function which takes only bg colour and window resolution. I re-module modules so that syntax is much lesser but implementation speed is same.",
            "Just go for PyQt or PySide. You won't look back to anything else once you're good at it. But it does have a steep learning curve.",
            "Chatgpt is excellent at making a tk outline you can add business logic into.\n\nThat said, I always use QT whenever possible. I like creating my GUIs programmatically and have evolved a structure which keeps all of the attendant complexity manageable.",
            "Use a web UI. There are libraries with pretty and extensible components. My favs rn are Ant Design and Mantine.",
            "pyqt5 newbie here. Are there any great tutorials that can help me learn fast?",
            "I had the same problem. I currently use flet instead if tkinter which imo is better than tkinter but i get sick of writing a lot of code. I havent published my project yet but its basically a ui renderer but instead if html it uses json. There is a package that does something similar in tkinter but the best alternative currently is qtdesigner. It has drag and drop design and css-style styling. The next best would be pysimplegui",
            "I got a chat GPT 4 subscription and I made a custom GPT that I told should be an expert in Tkinter UIs. \n\nI was able to create a GUI in 3 prompts by telling it what I wanted then running the code and suggesting modifications. \n\nAfter those 3 prompts I had a completely working simple GUI. \n\nProblem solved in 15 minutes. \n\nThis is the way!",
            "I see a lot of Love for Qt here, but what Py-ImGUI, I love working with ImGUI, very simple to use and wide range of support across platforms (due to being multi backend). It arguably looks far more modern than default Qt also",
            "Learn JS and React. Your future self is gonna be very grateful",
            "use streamlit",
            "Ever tried Qt? Or winforms builder?",
            "If you absolutely must have a GUI that isn't web based, then PyQt is my preference though the licence is restrictive. But web-based should be strongly considered. That could be as simple as Streamlit or Gradio or for something more substantial use a Flask/Django backend.",
            "Qt is awesome indeed. I would suggest PySide6, for me it was a huge improvement over PyQt, especially for someone who writes code.",
            "Give my (free) cookbook for Qt in Python a read for anyone who's interested: https://github.com/ericsnekbytes/python_qt_cookbook",
            "Second this. But instead of let qt translate it to ugly codes, I load the designer file (basically a XML) as it is. See here: https://doc.qt.io/qtforpython-6/tutorials/basictutorial/uifiles.html#option-b-loading-it-directly\u00a0\n\n\nYou basically get a html-js like architecture. Which is cleaner, and you don't need to deal with machine generated ugly code.",
            "I just did a pretty comprehensive interface in QtDesigner. Went from never having used Qt at all to a deployed exe in use by my team in like a week. For better or for worse, QtDesigner allows you to abstract away a decent amount of the low level Qt behaviors like signals and actions.",
            "QtDesigner is a fastest route to create ready-to-use UI.",
            "I also had the better experience of simply struggling through it and building a window with layouts and widgets myself. Once you've overcome this hurdle, you'll realize that the designer's output is just XML garbage. The handmade code is simply much cleaner, faster and easier to read. And especially in Python, OOP is very pleasant and has no baggage (in contrast to C++).",
            ">QtDesigner\n\nIs there something like this for creating web apps?  I want to create something similar to this [https://bahar.shinyapps.io/method\\_compare/](https://bahar.shinyapps.io/method_compare/)\n\nSorry for asking if this sounds stupid.",
            "is it like scene builder with javafx?",
            "What's the licensing like on QtDesigner? Can you use it for commercial projects? I get so confused every time I try reading the licensing.",
            "Second flet. I really like the UI it generated. You can create some beautiful stuff. But it's limited in the widgets for the moment. I was working on a project where I needed a tree view for files and folders and I ran into a bunch of layer problems with it. It actually led me to learn flutter which it uses under the hood.",
            "Flet looks promising. I\u2019ve used Flutter in the past, so it was quite cool being able to whip up a similar looking application in a tenth of the time using Python.",
            "Learning Flet while developing an app with it, recommend it 100%. The docs are very useful and youtubers Indently and Line Indent have content about it.",
            "DPG is fantastic. I use it and one of my projects is featured in the discord & on their GitHub somewhere.\n\nThe [edit theme plugin ](https://github.com/awcook97/DearPyGui_EditThemePlugin)  if you wanna check it out. Loads themes from an ini file and enables the user to change to literally any theme they want (idk why software is either dark/light theme, why not pure custom-ability? \n\nAlso, dearpygui compiles with Nuitka and PyInstaller super easily on every platform. MIT license as well.\n\nEdit to add: unlike other libraries, dpg also can handle big data really well. When I used custom tkinter, after adding like 300 buttons, the app slowed down so much. DPG handles millions of entities no problem. The only time my fps goes down is when I'm rendering frames manually (or doing insanely computationally heavy tasks). Even rendering animations with it is super duper smooth. \n\nThe drawing API is smooth AF, too. Creating custom widgets that have animations is my favorite feature by far. \n\nAlso, for an object oriented wrapper, try out [dearpypixl](https://github.com/Atlamillias/DearPyPixl)\n\nI'm rambling, but I love dpg.",
            "Thank you much!",
            ">PySimpleGUI\n\nWill look into this as well. Thank you.",
            "This is all I used, and I concur that it is indeed simple, and for me that was a very good thing. It's probably less powerful than Tkinter but all I and many others want is *a* GUI, and it did that very well.",
            "Yes I second this",
            "Wow, this looks very very cool!",
            "Kivy's kv language is really nice",
            "PyQt and PySide considered to be the first choice for many professionals, you can\u2019t really go wrong with them. \n\nwxWidget\u2019s python wrapper is called wxPython.",
            "Pyside is better because of PyQt's license issues.",
            "Python and desktop GUI development is perfectly fine, you just have to use the right framework.",
            "Technically on macos you can use the native GUI with python and it will look like any other objective-C app.",
            "I'm pretty sure if they asked for a replacement for a native UI toolkit they might want a native UI toolkit",
            "that's useful",
            "Streamlit is extremely painful for general purpose development. It took me about a day to start hitting the limits of steamlit's architecture, and there's really no way to work around those limitations. \n\nNiceGUI is superior in every way after that initial \"easy to use\" magic wears off.",
            "Why streamlit and not NiceGUI?",
            "worst shit every created is streamlit",
            "Are you dense or mentally challenged?",
            "Yeah, come to the realization that Python isn\u2019t for everything. \u00a0I know this makes people mad but if you need an executable don\u2019t use Python.\u00a0",
            "Pyside 6 comes with it's own packaging utility based on nuitka.",
            "Really? \u00a0I can\u2019t tell the difference between PyQt5/6 and PySide2/6 other than the license and the QComboBox interface.\n\nI use qtpy so I can support them all in my code. \u00a0Makes installation easier.",
            "GUI newbie here I've been wanting to learn PySide[x] or PyQt but I can't find any good documentation or tutorials on getting started.\n\nDo you know of anything good?",
            "I also prefer PySide, but only because of the license. However, PyQt integrates better into the desktop because it uses the existing Qt lib and doesn't come with its own version.",
            "Qt is a good choice for big apps, but making a small 5kbytes program and importing a huge 500Mb pyQt is an overkill 4 me.",
            "I always translated it because I couldn\u2019t get the behavior quite right otherwise.\n\nI also don\u2019t know html-js, so maybe that\u2019s why. \u00a0I do \u00a0lots of math, Qt and VTK for 3d rendering.",
            "You don\u2019t need to \u201cdeal\u201d with the ui compiler generated code, in fact, the generated code itself usually has a comment to discourage fiddling with the generated code, and recommends to use the designer to update the UI.",
            "Don't know that one.  It's just a gui builder.",
            "It\u2019s an output of a program, so it\u2019s not GPL. \u00a0You\u2019re bound by the license of PyQt or PySide and yeah, go with PySide if you plan on selling it.\n\nIt\u2019s still worth the effort to support PyQt with qtpy if internet users aren\u2019t great at installation",
            "I added the \\`edit theme plugin\\` to the GitHub page. It's a great utility you made, so thanks! Nice to meet you!\n\nGlad to you that you love DPG. If  you care to share some more of your work, could you share them here or on Discord?",
            "yes, that's right.  \nbut pyqt integrates better with the desktop because it uses the OS's existing Qt lib, while pyside2 brings its own. I think you can change that, but I haven't figured out how yet.",
            "Yes, I realize my comment was too short and may look bad. What I meant is developing executables for a few users with native GUI is really a phase you want to grow out of. It's better to learn a bit of front end and create a simple web-app . Sure, there are pros and cons: web-apps require a server (or eventually can run locally, can be simple if user can run docker). But if you are serious about coding and dev, native GUI stuff are really a dead end",
            "Just saying all of the different options are mind blowing.  I didn\u2019t realize there were so many options for gui development with Python.  \n\nI apologize for not using Reddit in a manner that meets your high standards.",
            "Yeah today I installed niceGUI and I must say Its superior than streamlit. \n\nFcuk streamlit. Go for niceGUI\n\nThanks bro. \nI guess I am living in 90s",
            "I'm starting to think these are all incels, lurking around for the opportunity to say \"if you don't like <X>, don't use it/move somewhere else/get over it\"",
            "Error handling. PySide6 has it!",
            "About the license, can I use PySide6 in a commercial closed-source application?",
            "[https://www.pythonguis.com/faq/pyside2-vs-pyside6/](https://www.pythonguis.com/faq/pyside2-vs-pyside6/)\n\nthis sums up most of it.",
            "I think www.pythonguis.com is very good and I wish it was there when I was starting out.",
            "Where do you even get those numbers? My current PySide6 project occupies only 26Mb compiled with Nuitka --onefile. And that includes all dependencies and a few bitmaps.",
            "I also notice that in consistency (qt5, don't know about qt6). But\u00a0it's normally just cosmetic, not functional. So I just accept it",
            "Same here. Design the ui, compile, import and use it. Couldn\u2019t be simpler, and it\u2019s faster.",
            "I get your point but in my opinion it's not always correct. It depends on the type of program you're developing. If you're developing system utilities, general-purpose desktop programs and such, native GUI would be the better choice generally.",
            "This is a much better response and I went from agreeing with the reply to agreeing with you. Web app development is a much more general skill and it is generally better to hone skills that have a broader application surface.",
            "yeah, well, maybe if you used actual words instead of inscrutable little pictograms, your intent would be clear, but even then, as a top-level comment that doesn't answer anything about what OP asked, it's pretty pointless.  It's nothing at all to do with my standards.",
            "\ud83e\udd2f\ud83e\udd2f\ud83e\udd2f",
            "LGPLv3/GPLv2 or commercial license available if you don't want to adhere to those terms. So, yes. But not as permissive as python itself. \n\nTypically LGPLv3 is pretty damned close to a do-anything license when used in the python context. Most interpretations of the LGPL in this context would read \"import foo\" as the equivalent of dynamic linking. As long as your shippable product had the option of swapping \"foo\" out for some fork of \"foo\" without having to decompile a static blob or something, you're probably in the clear. IANAL, and AFAIK, nothing has been tested in court.",
            "> PySide6\n\n... is LGPL.",
            "No, unless you buy the commercial license.",
            "Thanks I'll give it a look through.",
            "You\u2019re adding a lot of value perpetuating your petty dissatisfaction.  Hypocrite much?",
            "\ud83c\udfc8\ud83c\udfc8\ud83c\udfc8",
            "Please can you tell me what should I do when using PySide6?\u00a0 Should I just include the license in the help or credit window with a link to\u00a0PySide6 home page? Or something else?\u00a0",
            "Was mine a toplevel comment?  Is there no difference between an offense and the response to that offense?",
            "You should ask a lawyer instead of some random reddit guys.",
            "If you're including a copy of pyside6 in your project when you distribute it, make sure the license file is intact. Other than that, you aren't obligated to add anything in the user interface regarding licensing. Some people will put a note in their about dialog, but it's a force of habit rather than a necessity.\n\nException: if you're distributing it as a binary blob where the pyside6 source isn't human readable anymore. In which case I'm not entirely sure...",
            "\ud83e\udd26\u200d\u2642\ufe0f",
            "I think if you add info on where to get the code for LGPL software you're good to go."
        ]
    },
    "K Lars Lohn uses math and Python to triangulate the nighttime booms disturbing the sleep of his community.": {
        "title": "K Lars Lohn uses math and Python to triangulate the nighttime booms disturbing the sleep of his community.",
        "score": 476,
        "url": "https://www.reddit.com/r/Python/comments/1aerjpc/k_lars_lohn_uses_math_and_python_to_triangulate/",
        "content": "\"Finding the Air Cannon\"\n\nhttps://www.twobraids.com/2024/01/air-cannon.html\n\n>  It took three people stationed at remote locations miles apart using a synchronized clock on our cell phones. We each waited over the same ten minute period, noting the exact time for each of the five cannon shots that we heard. \n\n> ...\n\n> I wrote a program in Python (see source code below) that could iterate all the points in the image in the search area where we suspected the air cannon sat.\n\n> ...\n\n> I called the owner of the farm (headquartered in Monmouth) and asked if they used an air cannon on their property near the Corvallis airport. They confirmed that they do. I asked if they run it at night, they said they do not.\n\n> ...\n\n> However, in an amazing coincidence, the air cannons stopped that very evening of our phone conversation.",
        "num_comments": 35,
        "comments": [
            "Really interesting reading.\n\nSimple physics, programming and some initiative to save the sleep of an entire community.",
            ">     return sqrt((p2.x - p1.x) ** 2 + (p2.y - p1.y) ** 2)\n\nLet me tell you all about our lord and saviour `math.hypot(p2.x - p1.x, p2.y - p1.y)`.\n\n> def all_points_within_block_iter(a_block):\n\nHoly brute force, Batman!\n\nYeah, I suppose this was quicker than figuring out the formula about intersecting three circles.\n\nNice solve!",
            "That was an interesting read. The air cannons are used to scare away Canadian geese that hang out in the fields, every 2 minutes.",
            "Very cool read! Saw one of his talks at PyTN years ago and really enjoyed it as well!",
            "r/Bellingham is going to want to deploy this software.",
            "I would lose my mind, whether it was day or night.",
            "I know this is besides the point of the post, but `shapely` and `pyproj` will get you where you need to go....more than a bit of learning curve though",
            "If you want to do something similar:\n\nGet an ESP32 and sample a microphone or a differential pressure sensor with it. You can then can timestamp every sample utilizing SNTP within the uC. Lots of infastructure is available in the ESP-IDF.\n\nDoing that with several stations you have a perfect data pool of high precision timestamps and raw sensor data which then can be used this this kind of fun.",
            "So you made a diy shot spotter",
            "Cool story (not sarcasm, fwiw).  But isn't coding this a bit overkill here?",
            "Or, just look at the airport sectionals and see if they list birds or wildlife in/around the airport ... many will actually specify the use of canons or dogs or similar, too.",
            "Oh man, kids in my neighborhood set off firecrackers several times per week and the police do nothing. Very tempted to set up something like this to gather some data!",
            "I thought of using contact mics glued to the concrete floor to model and determine who the duck is listening to some loud bass music in the middle of the night.",
            "Well Robin, while I agree that there surely are more elegant solutions, we must remember that when the data is noisy, we do need at least some kind of optimization step, since the circles will usually not intersect exactly.",
            "`math.dist`",
            "Canada geese \u2014 unless they showed you a passport!  \ud83e\udd23",
            "Was it about using a deque and shuffling lights around? I was there for that talk.",
            "As they say, if it's stupid and it works, it's not stupid.",
            "What are the alternatives which are easier?\n\nI code things all the time because it allows me to write it down and then change things and correct them. Where if I did it with just a calculator I may make a mistake and then have to redo it all over again. Where in a program it is easy to make changes and re-run it.",
            "You could use a spreadsheet, but as someone who knows Python I'd rather write a short program",
            "The intersection of circles should produce either a point, a hyperbolic triangle, or a spheroid triangle, depending on whether the edges bend in or out. I think. Either way, the points defining the tips of the triangle can be pretty simply used to determine both a centroid and an uncertainty. Model the uncertainty as the stdev of a 2d normal, and you've got a probability distribution. Stack up a few probability distributions, and you should have a much steeper / more precise probability distributions (hopefully). \n\nIt's mathing an answer, for sure. Not sure how it counts as an optimization step.",
            "Only added in Python 3.8, too new for me ;)",
            "Did they apologise for their quacking?",
            "I really loved that talk demonstrating the flexibility of the Mozilla Things Gateway. The presentation slides themselves as well as the lights were controlled by the Things Gateway. It was so sad that Mozilla cancelled the project just before I gave that presentation. I had been scheduled to tour all over the US doing that talk.  I was so angry with the company, the night before I did the PyTN presentation I altered my code to self destruct  and delete the slides after the last screen was shown to the audience.  Probably kind of reckless, but I live an edgy life.",
            "Yea! Crazy small world! It was actually my first tech conference and I was self-teaching Python and enjoyed all of the talks even if I didn't understand some parts of them. Funny enough my starting point in learning was \"Automate the Boring Stuff\"",
            "This is like more than half of IT infrastructure on this planet \ud83d\ude02\ud83d\ude02",
            "I didn't say it was stupid.  Just probably more effort than needed.",
            "Easiest would be to just drive around until you've located the noise.  Second easiest would be some relatively simple math to triangulate the location after taking the readings.  \n\nCoding isn't really all that great (read: efficient)to solve a one-time problem.  It's great to solve somwth you do hundreds to trillions of times.",
            "True, but it is also possible that the circles do not intersect at all (or only 2 of them), and the spatial \"averaging\" has to be defined differently. I agree that if you are fine with a probability distribution as the result, this can be obtained as you described. But if you want to get a point as the answer, you need to find e. g. the maximum of the distribution, which I guess counts as an optimization problem.",
            "3.7 is sunset now, you should upgrade!",
            "Haha, Lars that\u2019s hilarious. Cheers bud, always up for attending one of your talks. Also dig your art. Take care.",
            "> Coding isn't really all that great (read: efficient)to solve a one-time problem. It's great to solve somwth you do hundreds to trillions of times.\n\nI guess we will disagree on that. I do it all the time. Write up a simple program in Python to solve simple things all the time.",
            "If the problem involves math that's more fun or less tedious to describe in code than to work out yourself, then coding is absolutely a superior solution to a one-time problem.",
            "There were no public roads in the search area of the air cannon. I was not willing to trespass - especially onto the grounds of an airport.\n\nJust using a compass and my elderly ears to get sound headings was remarkably difficult. With a dozen data points I was unable to narrow the search area to fewer that 15 landowners.\n\nCoding the problem took only a half hour and gave me the benefit of reproducability and ten thousand backseat programmers to audit my work.",
            "Ok, I was wrong.  Kudos."
        ]
    },
    "EasyGmail: A Lightweight, minimalistic Python Package for Sending Emails via Gmail": {
        "title": "EasyGmail: A Lightweight, minimalistic Python Package for Sending Emails via Gmail",
        "score": 173,
        "url": "https://www.reddit.com/r/Python/comments/1adk1fp/easygmail_a_lightweight_minimalistic_python/",
        "content": "I'm excited to share my first Python package, EasyGmail. It's an open-source package designed to simplify sending emails via Gmail. My goal was to create something lightweight and user-friendly, especially for those who are just starting with Python email automation.\n\n\ud83d\udd17 GitHub: [https://github.com/ayushgun/easygmail](https://github.com/ayushgun/easygmail)\n\n**Key Features**\n\n* Simplicity. The `easygmail.Client` interface is designed to be intuitive and minimal.\n* Provides `easygmail.EmailBuilder`, an intuitive abstraction for creating `email.message.EmailMessage` objects, Python's standard for structured emails.\n* Flexibility. Multiple way to construct client objects or build structured emails. See the README for more information.\n* Secure. Allows users to provide authentication details via `.env` files instead of hardcoded credentials. Uses Gmail app passwords instead of account passwords.\n\n**Quick Start**\n\nSee the README file for a quick start example.\n\nI would love to get your feedback on this project. Whether it's suggestions for improvement, feature requests, or just your thoughts on its usability, all feedback is greatly appreciated!",
        "num_comments": 67,
        "comments": [
            "Not much functionality besides sending single plain email msg but code is very clean and its excellent base for expanding further. Love it!!",
            "I\u2019m going to use this thanks!",
            "SMTP is deprecated for Gmail and for some users, it may not work. Also, it would be good to have some test coverage of a project ;)\n\nIt's recommended to use Google APIs and not SMTP.",
            "Good project...have been looking for something like this around a whole \ud83d\ude0a\n\nIf my gmail login has 2FA will it work?",
            "Hey thanks this looks cool! What problem / use case were you looking to solve for when you first decided to build this out?",
            "You might want to check [yagmail](https://github.com/kootenpv/yagmail).",
            "Looks cool! If I could make one suggestion it would be to look for username and app password in the Client and if not given, and no .env file is given, try to load .env from current working directory and even if that fails, look for creds in the established env vars.\n\nImagine if you deploy this in docker, you\u2019d just set the env vars there and have to modify the code.\n\nAgain, nice project overall!",
            "quick tip! try to refrain from placing your functions in something like \"[utility.py](https://utility.py)\". Just by looking at what's in there, I can easily conclude that this could be named f.e.: 'entry\\_validation.py', or even 'validation\\_helper.py' (although I'm not a big fan of 'helpers' either). Please refrain from naming things util/utilities as this doesn't say anything and I guarantee you that there's always some purpose to the functions besides them being a \"utility\" that could be used as the name.  \n\n\nBesides that, great code, I wish I was reviewing this type of code every day.   \n\n\nPS: Did you know that DocStrings are awesome? You should try them! (I know, I know, documentation is PIA and no one likes it)",
            "LOL, the \"Lightweight\" descriptor rears its head again. You guys, come on. You can't describe everything as \"Lightweight\" just because you barely wrote any code to make it work.\n\nAnd let's be real. It's \"Lightweight\" because you're just importing the email library and sending the email with that. There's no reason to pip install a whole separate package just so that it can be the middle man for an already simple to use email library.",
            "Sorry if this is a dumb question, so I can use this library from a connected PC to send emails via gmail? IE authenticate the account once and it will send emails without issue?",
            "Just 2 days ago I was writing my own methods to access my emails, this looks cool, I will definitely check it out.",
            "Nice pet-project!  \nI've looked around the code for fun, you can improve it with some simple changes (for loops, getters and setters..)",
            "well done",
            "Is there one for outlook 365?",
            "I would be very interested in this if you had html capability. I currently use JavaScript to automate sending some basic emails but if I could spruce it up a bit I\u2019d be all over it.",
            "nice",
            "Thanks for the kind words. This is v0.1, so my goal is that release v1.0 will include much needed additions like HTML emails, file attachments, unit testing, and component testing.",
            "Glad you think it\u2019s helpful :)",
            "Where do you see SMTP deprecated?",
            "Agreed. Those two are the next steps. \n\nEdit: Regarding SMTP deprecation: if I understand correctly, SMTP with regular passwords is deprecated. Using SMTP with app passwords, which `easygmail` uses, is a supported way to connect to Gmail.",
            "How would you connect a client like Thunderbird to it?",
            "Thank you! If I recall correctly, it should work if your account has 2FA since easygmail uses app passwords instead of the account password.",
            "Thanks! The primary issue was the amount of boilerplate/repeated code across projects where I needed quick email automation. Thought I\u2019d consolidate all of the repeated code into one library to make it easier to quickly send out emails.",
            "smtplib.SMTPAuthenticationError: (535, b'5.7.8 Username and Password not accepted. For more information, go to\\\\n5.7.8  https://support.google.com/mail/?p=BadCredentials bg24-20020a05600c3c9800b0040d91fa270fsm10177059wmb.36 - gsmtp')  \n(pythonDEV) juanjo@gamba0:\\~/pythonDEV/GambaGPT$  \n\n\nhttps://www.reddit.com/r/Python/comments/1adk1fp/comment/kk2rnoz/?utm\\_source=share&utm\\_medium=web2x&context=3",
            "The abstraction itself is lightweight.\n\nWould you have preferred that I wrote the SMTP server code myself (which would be pointless duplicate logic)? I felt like deferring to a stable, well-tested standard library module is much simpler and safer. The goal of the project was to provide an intuitive and light abstraction over the standard library\u2019s email module.\n\nApologies if my use of \u201clightweight\u201d was confusing in that sense.",
            "Do a better job then. It's easy to complain.\n\nEdit: if it reduces boilerplate, there _is_ a reason, or doesn't matter whether you like that reason or not.",
            "Authentication persists across the execution of a program; it does not persist over an entire PC, if that makes sense.",
            "This is just a SMTP wrapper. You store your login and password in the code and it authenticates while sending, assuming your account may use SMTP (as it's deprecated for Gmail)",
            "If it's just simple stuffs, I migrated to Twilio API.",
            "Hi, thanks for the comment! Where do you think I could implement the for loops? I didn\u2019t really see a use case myself.",
            "This is just an SMTP wrapper, you can send emails easily through any SMTP server. You can also check if Microsoft offers some better higher level API for their services - especially if you want to send mass mailing or monitor if your mail is going into spam (like with Amazon SES).",
            "Coming next!",
            "When you go into your Gmail settings to enable SMTP use of the email account. Has be flagged as such for many many years though.",
            "Ya I'd like to know too.",
            "Not for long afaik",
            "Needs a custom integration using their APIs. In one of our apps we are using OAuth/Authorization flow where a customer authorizes our app and gives us access to Gmail over API so we can send their mass mailing that way. We don't have their login/passwords, just the token obtained from the authorization process.\n\nMuch simpler is the direct access where you just use the API via their Python library on your own account.",
            "[removed]",
            "Great idea. Presumably this also works with a non gmail.com email address that is hosted on the gmail platform? If you know what I mean (the way I can have @companyname.com emails via the gmail interface)\u00a0",
            "Funny... I built something similar. Although, i wanted the message to be http, so i added things like p tags and h1...h4 tags. There's also a header, footer, and reply-to sections that can be configured. I was thinking next how i can add tables. Oh wait! Tabulate library... \n\nAnyways, i also needed mp3 and xlsx attachments. I did mine slightly different in that i created an email class. I instantiate it with a dict extracted from a json file. This also allows me to change the sender, subject, and recipient fields rather easily depending on the output of the script. \n\nI use this as output notifications for various automation scripts. I was thinking about adding text notifications as well (only in the event that something went wrong), but that's a whole other ball of wax. \n\nI have the majority of the code written now. I'm rewriting the cli part now. What i had before was a whole bunch of single use scripts that i would basically copy, modify slightly, and use that. Changing anything became a massive chore where some scripts still use the old Mailer, some use the new Mailer. Refactoring has taken some time. But it's almost there.",
            "Do you have 2fa enabled and are you using the app specific password?\n\nI cannot find the source for SMTP depreciation as per the other comment.",
            "What I would prefer is people to stop creating new packages that do nothing more than pass user input to another library that already does the thing the new package function claims to do. \n\nCan you imagine if I made a library called \u201cFastMathHelper\u201d and every single function you called just passed the function values to the numpy version of that function? So fmh.sin() just ran np.sin() and returns the value to the user. fmh.abs() just runs np.abs(), etc. \n\nIf I made such an absurdity, according to you I could call that a \u201clightweight abstraction\u201d even though I\u2019m needlessly adding overhead to the calculations.",
            "Do a better job of something unnecessary and pointless? No thanks, I\u2019ll just not waste time doing it at all.",
            "So, under [email.py](https://email.py) you have `build` method that have multiple:\n\n    if not self.message[field]:\n        raise ValueError(f'Email {field} is not set')\n\nYou can clearly use a for loop here...\n\nAlso, you can wrap the email.EmailMessage and control everything better, including the setters (which are not setters...)",
            "I'm just not seeing it, but my account has had this enabled for way too long. \n\nWhat I do know, regular password access has been deprecated for a while. That's basically using your own credentials for authenticating.\n\nApp Specific Passwords will be required soon,\n\n- https://workspaceupdates.googleblog.com/2023/09/winding-down-google-sync-and-less-secure-apps-support.html\n- https://support.google.com/accounts/answer/185833?hl=en\n- https://myaccount.google.com/apppasswords\n\nBut SMTP, I'm not seeing a notice.\n\nI am very curious because this would be a big change. I'm worried because so much I have, both at work and home, would break with this.",
            "What leads you to say this?",
            "I don't know why you're being downvoted: Google has announced they're dropping support in September: https://workspaceupdates.googleblog.com/2023/09/winding-down-google-sync-and-less-secure-apps-support.html",
            "I guess I'm asking where it's been stated that SMTP is deprecated, Thunderbird  and Outlook both still use POP/IMAP and SMTP. It's the auth sequence that is proprietary-ish, but it's just granting your mail client that long-lived token to use as passwords in the standard protocols.\n\nAre you referring to using your Google account credentials as SMTP credentials? Cause _that's_ been deprecated since 2022.",
            "Does this token expire if they change their password. I was working on a calender automation script and seem to be having this issue???",
            "Bad bot",
            "Unfortunately, I\u2019m not able to test those types of accounts myself since I don\u2019t have one. If I had to guess, I think they should work since they use the same SMTP interface as normal gmail accounts iirc.",
            "I dont have 2FA enabled, but my account is disabled for send mails from Python, i tried several times before.",
            "Well that\u2019s pointless, but this has one goal of reducing the boilerplate of maintaining an SMTP connection in addition to providing a simpler (in my subjective opinion) interface. That\u2019s the point of the abstraction.",
            "Are you referring to [this](https://github.com/ayushgun/easygmail/blob/bf61df2b9c2b0a81733d70f6dcfd8365165dddfa/easygmail/client.py#L23)? I think a for loop would look nice, but it comes at the sacrifice of readability. Adding loop overhead for 3 conditionals seems a bit overkill?",
            "I\u2019ve read something about depreciation of smtp one pop3 on gmail. Maybe I\u2019m mistaken, my memory isn\u2019t good.",
            "from your link,\n\n> If you have scanners or other devices using simple mail transfer protocol (SMTP) or LSAs to send emails, you\u2019ll need to either: configure them to use OAuth, use an alternative method, **or configure an App Password for use with the device.**\n\nThat\u2019s why.",
            "When you go into your Gmail settings to enable SMTP use of the email account. Has be flagged as such for many many years though.",
            "Unsure but I think not. There are cases where it can be revoked or expired - then you need them to re-authenticate.",
            "The legacy auth method is being disabled.\n\n[Here](https://www.reddit.com/r/Python/s/V9gt3J8kpq), this comment has the answer and what to do.",
            "I've edited my comment.\n\nRemember, you write code that scale, tomorrow you want to support new kind of data, will you add more identical lines? don't you want to improve the overall structure to support different types of the same check/error?",
            "Do you remember where you saw that?",
            "If they kill IMAP/SMTP, I'll drop gmail in a heartbeat. Bad enough I have to use their stupid webmail for my school account.",
            "IMAP and POP tho:\n\n>\tBeginning September 30, 2024:\nAccess to LSAs will be turned off for all Google Workspace accounts. CalDAV, CardDAV, IMAP, POP and Google Sync will no longer work when signing in with just a password \u2014 you will need to login with a more secure type of access called OAuth.",
            "Yeah that's not a deprecation though. Deprecation means \"we're going to remove it soon\", typically preceded by a pretty hard announcement. You understand that removing SMTP support would be removing the ability for Google to receive any email from other servers?\n\n> When you go into your Gmail settings to enable SMTP use of the email account. Has be flagged as such for many many years though.\n\nBut...that's not a thing. You don't have to do anything special to enable SMTP access of your Gmail account other than creating an app password.",
            "Tried to find, unsuccessfully, sorry",
            "Exactly! Okay, I posted this in another comment,\n\n> I'm just not seeing it, but my account has had this enabled for way too long.\n> \n> What I do know, regular password access has been deprecated for a while. That's basically using your own credentials for authenticating.\n> \n> App Specific Passwords will be required soon,\n> \n>   - https://workspaceupdates.googleblog.com/2023/09/winding-down-google-sync-and-less-secure-apps-support.html\n>   - https://support.google.com/accounts/answer/185833?hl=en\n>   - https://myaccount.google.com/apppasswords\n> \n> But SMTP, I'm not seeing a notice.\n> \n> I am very curious because this would be a big change. I'm worried because so much I have, both at work and home, would break with this.\n\nKind of freaked a bit",
            "I've seen cases where users weren't able to enable it at all. I think they are A/B testing removal of that feature on some sample sizes.",
            "> I've seen cases where users weren't able to enable it at all.\n\nThis is the third time I'm saying that you don't have to enable it in the first place."
        ]
    },
    "What are the coolest Python automaton projects that you know of?": {
        "title": "What are the coolest Python automaton projects that you know of?",
        "score": 278,
        "url": "https://www.reddit.com/r/Python/comments/1ad1stw/what_are_the_coolest_python_automaton_projects/",
        "content": "Whether if it's something simple and trivial or complex and robust, small project or well known library, you can describe what it is or even better post a link to the Github repository and elaborate what makes it cool.\n\nEdit: \"Python automation projects\" in the title, there is no edit option.",
        "num_comments": 91,
        "comments": [
            "Years ago I wrote a bot that logs into my Facebook daily, checks to see whose birthday it is that day, and writes a happy birthday message on their page. Fun little project if you want to learn selenium.",
            "I think OP is not searching for tools, he's searching for project ideas to use the tools.\n\nMany such cases : \"woah I have all these tools to automate everything I want !!! What do I do with these now?? *Stares into the void*",
            "If you want to make simple automations involving consecutive inputs, [PyautoGUI](https://pyautogui.readthedocs.io/en/latest/) can help you with that. I'm using it to fill some forms in my work and it's saving me a lot of time. \n\nI like it's simplicity, but the one using it must make sure that it will only interact with the intended interface, otherwise it can break other apps by accident.",
            "https://www.home-assistant.io/",
            "[deleted]",
            "I made a web app bot to automate my English and maths lessons. It's a requirement that I have 20 hours but they don't care about the score, so it just clicks through the questions. I made it multiprocessing as well, I can knock out about 2 hours with it running for 5 mins.\n\nEdit: it uses selenium, webdriver_manager, bs4 and os.shell. Headless browsers, cli for interacting and monitoring.",
            "I can't share the github links because private repos, but I've built some cool ones at work.  Some examples:\n\n- searching all our aws / gcp / azure environments for instances, k8s clusters, storage buckets belonging to any user leaving the organization.  Starts from an okta workflow trigger and ends in a Google Sheets report being stuck into a Drive folder and shared with the offboarded user's manager so they can delete or re-allocate the resources.  Some python cloud functions are the glue that make it all happen.  \n\n- a pre-deployment script that runs as part of our terraform ci, that checks via gitpython to see what files changed in the PR branch vs main branch and uses that list to make a decision on what directories to build packer images in before running the normal terraform plan/apply junk.  It also makes backups of specific files in instances that are to be replaced and then restores them after terraform rebuilds those instances.",
            "Try automating something using Airflow! Start with a simple cron job. Only then you\u2019ll understand the significance and potential of airflow. \n\nYou can automate an end to end ML pipeline. Extract data, train a sample model(learn to run Jupyter notebooks directly using paper mill) and then deploy the model. Scheduled at a specific time interval. Also, look into self hosting these on AWS or azure. There are a lot of interesting things that can be done! Exciting tool, if you\u2019re looking into the data engineering field!",
            "How to automate the boring stuff is a great read for you",
            "My gf was having an issue where the workout classes she wanted to sign up for were filling up faster than she could book. I made a script that logs into the gyms site, waits for the class to open ( they open 48 hrs in advance ), then instantly books it. Will also send her a text letting her know it\u2019s booked. I think it\u2019s pretty cool. Hasn\u2019t had an issue since.",
            "I love using python requests to scrape data from websites, or make my own API for websites. No real goal in the end, just seeing how much I can do without being blocked by their systems and remaining incognito.",
            "Idk about the coolest, but I find it helpful. I'm working on a project which automatically detects duplicate (and also very similar) files on your pc and lets you decide which one(s) to keep or delete!",
            "I have created a tool called [instld](https://github.com/pomponchik/instld). It automates the installation of libraries. You just write \"import\" in your code and the library is installed automatically, and when it becomes unnecessary, it is also automatically deleted. In fact, the tool can do a lot more, but I won't go into details here, it's better to read the documentation.",
            "Ansible.",
            "Hmm, the coolest one that I know of is the weather station and home automation system (eh, touchscreen control of Hue lights, mostly) running in my living room (and bedroom). Started out as wanting (1) a clock that was *always* accurate, even across DST changes (so, NTP and the time library), and (2) a multi-temperature display that is easily visible from across the room and color codes the temperatures, so one can tell at a glance if it\u2019s hotter or colder outside. It kind of expanded from there. Now, all told, it\u2019s something in the neighborhood of 15k lines of Python, running on 5 Raspberry Pi\u2019s (3 with displays). Been running continuously for many years (started on it in 2016) - some of the scripts have run continuously for upwards of a year on occasion (the Pi\u2019s have had uptimes over a year and a half at points). One of these days, I need to clean up the code a bit and get it onto GitHub.",
            "Created a small programme that would go onto a delivery platform site - Just Eat, go to the invoices and scrape all the transactions. Each invoice is for a week so I had to scrape them all, add all the transactions together and calculating a monthly value in sales for that month. Going back as far back as needed. \n\nSaved a TON OF TIME. \n\nSounds super boring but was so helpful. Needed build a report for clients about their performance on the platform.\n\nUsed Selenium and loads of help from chatGPT and Copilot!",
            "Maybe interview your colleagues and find out what they do and how they do it.\nThat might give you ideas on how you can help them with automation, and create your own automation projects",
            "Projects like AutoIt and AutoHotkey were and remain pretty popular today for automating tasks, creating macros, and more on Windows platforms. For Python, I author a wrapper library around the AutoHotkey language to access its powerful automation features from a Python API. You can check out [ahk on GitHub](https://github.com/spyoungtech/ahk) for more information.\n\nOne redditor has mentioned they've used this library for creating a \"Twitch plays\" bot, where users input chat commands on Twitch to trigger inputs on the streamer's game. Back when GitHub showed my dependents directly, I also saw users making cool things like programs that play video games, TAS bots, and more.\n\nIn the README, I also link to several other similar projects you may be interested in, including PyWinAuto, mouse, keyboard, pyautogui and more.",
            "I can make a nice calculator.",
            "To be clear, are you asking about automaton (e.g. Cellular Automaton) or are you asking about automation?",
            "For browser automation, The package giving Pythonic bindings for Selenium is solid.\n\nhttps://selenium-python.readthedocs.io/installation.html#installing-python-bindings-for-selenium",
            "Webscraping and extracting data from documents to form datasets has gotten so much easier. Just have the LLM extract the information you need. All done in Django using Celery, Celery Beat, and Flower.",
            "I have a thing where I record lectures and then transcribe the audio, then I use the ChatGPT api to take notes from the transcription.",
            "Not very 'cool', but we get masterdata from suppliers in all various formats, especially measurements (Like 50x50H60, D50xH55, L25xD38, 30x30x60 etc.) and I've made a script that loads the excel-file, transforms the data based on RegEx and dumps it in each column; width, length, depth, height, diameter etc. in a new excelfile. Saves me a ton of time when it is like 5000 products from one supplier.",
            "Nothing special, but I had to create 26 new contracts with data from an Excel list. It would have taken me several hours, so I created a Word template, read the data from Excel, and in seconds, 26 PDFs were generated :) I\u2019m not a good programmer, so these are small successes for me \ud83d\ude03",
            "I saw this post a bit late but I did few python projects recently and wanted to share.\nI wrote a command line tool with click called github-stalker. It is using Github GraphQl API and you can search a user, repo etc. Just for fun and for learning GraphQl a bit.\n\nI made another project for pcb designers. It is command line tool but also can be used with GitHub Actions with creating an issue on the repo. I named this project pcb-fabrication-manager. It is converting your csv input to requested csv output to send pcb assemblers. \n\nNow I am working on another projects for device initialization. But basically the project is listening the usb devices according to the operating system and it is running some commands with subprocess. I wanted to learn asyncio and subprocess. \nI saw many good ideas and will check them! Thanks for the post :)",
            "I write software to automate the slicing of brains Into thin wafers, automatically applying chemistry (think dyes and traces) ans finally the assembly line imaging of these wafers into a 3d model.\u00a0\u00a0\n\n\nI also automate shooting frickin' laser beams at brains to see what they are up to when a mouse watches TV.\n\n\nFor real.\n\n\nhttps://portal.brain-map.org/?gad_source=1&gclid=CjwKCAiAq4KuBhA6EiwArMAw1KO1NLPJ-JVdcpjh7SBLg74v2yuJMSx1SHbSM-qTmL0QkP3aoxJA8BoCtpkQAvD_BwE",
            "I follow a lot of art x.com accounts and would like to download the tweet and corresponding image. Would that require an API?\u00a0",
            "[deleted]",
            "I made a tool called [makejinja](https://github.com/mirkolenz/makejinja) that lets you automate the generation of files and folders using Jinja templates. This is the same syntax that Home Assistant and Ansible use for templating. You can even define custom makejinja plugins to fine-tune (almost) every aspect of the tool.\n\nOne cool use case for makejinja is the generation of Homa Assistant dashboards: Just declare the entities you want to show, define the lovelace layout once, and generate views for each room in your house. This has made maintaining custom views so mich easier for me personally! For those interested I added a test case with such a dashboard generation as a test file together with some instructions: [makejinja tests](https://github.com/mirkolenz/makejinja/tree/main/tests/data)",
            "I don't really know any that others made but I made one myself. It's not necessarily AI, but It's close enough as an automation project. Right? It's on [replit.com/AnonymousHakr/Acorn](https://replit.com/AnonymousHakr/Acorn)",
            "I work for a university and I automated attaching digitized acceptance letters to student accounts. Admittedly, I'm not going about in the best way: our IDs are 3 letters and 3 numbers like PDQ123 and I'm using computer vision (Tesseract) to screenshot the letters, RegEx to detect the pattern, and then automating a macro button press. In reality, I need to use something like py2pdf to \"flip\" through the PDF file of acceptance letters, use my RegEx that way, and use PyAutoGUI for input instead of the macro. My CV method is only about 95% accurate.",
            "Used py to integrate matlab report generation license with some docx libraries",
            "The one that I'm kinda proud of is being connected to a flowmeter over modbus, register data of fuel loads to an influxdb instance, then generate some charts with matplotlib with said data, fill up a xlsx template with data from the load and said charts and store the output file\n\nThen I also did a wonky looking but functional pyqt5 gui with a calendar view to navigate the output  folders with a preview of the documents and either manually edit some fields (which are preset from a file when filling the template) using a form or print the document.",
            "I have a script for\n- Confusing reddit activity like comments, posts.\n- Tansfer the subscribed subreddits to a new account. In case the user wants to close an account but resubscribe the same subreddits to the new\n\nhttps://github.com/tsaklidis/subreddits",
            "This but combined with LLM and writing a funny message based on their profile / photo would be cool \ud83d\ude0e",
            "Yes, something we could build ourselves, for inspiration.",
            "Hi, I'm Al Sweigart, creator of PyAutoGUI and author of Automate the Boring Stuff with Python.\n\nFirst, I will do the usual I'm-sorry-I've-been-neglecting-this-project apologies. PyAutoGUI is nice in that it's simple and straightforward to use, but it is rather brittle; if you tell it to click at X, Y then it will click at X, Y, but there's no guarantee the button you want to click will be at X, Y, or maybe that button is disabled and the click has no effect, or maybe the screen resolution has changed so the button is no longer at X, Y, or a software update has moved the button in the app, or you changed the window theme and the button is slightly smaller, or any number of things could happen.\n\nCurrently, my plan is:\n\n* Get the type hints, docstrings, and documentation squared away.\n* Organize a team of folks who can regularly contribute, as well as write up onboarding documentation for new contributors.\n* Read up and research on how to manage open source projects.\n* Read up and research on the Windows API, Cocoa API, and X11/Wayland windowing stuff.\n* Write some scripts that check when people mention PyAutoGUI on reddit and stack overflow so I can respond to them in a timely manner.\n* Research OpenCV an PyTesseract more to get better about finding stuff on the screen.\n* Research the source code and feature set of other automation tools like AutoHotkey and MS Automate and UIPath.\n* Triage the PRs and issue tracker and come up with well documented releases. You know, like an actual software project has instead of just some hobby thing I made.\n\nAnd then we can start on new features. This is mainly stuff that makes PyAutoGUI more aware about windows and what it's clicking on, as well as detecting errors or unknown situations. I also want to add better logging and screenshots so you can audit what the script did, as well as pause/resume functionality.",
            "\\+1 on that, My interest towards python increased when i started focussing on automation, When I used to do video editing and photoshop, i created a script using pyAutoGUI and automate the process of Repetitive stuff like importing files, placing them on timeline, filters etc, pretty cool stuff",
            "Pyautogui is also an extremely easy way to keep your status active on teams by just typing out the time every few minutes",
            "I have a friend super into wizard101, where there is a whole ingame shop that you can buy and sell materials on. Since it\u2019s an old game and the everything in the shop is bought and sold by players, a lot of people use bots. He showed me how he would refresh and try to buy things as fast as any human could and it would already be gone.\n\nUsing pyautogui, I made a bot for him the searches the screen for the item he wanted, and instantly bought it as fast as the game would register. We only used it like twice because it was contributing to the cheating, but it was one of my favorite Python projects to date (I\u2019m fairly new).",
            "There is too much coolness about this, I wouldn't know where to start describing it in a reddit post.",
            "Python knowledge is optional with this one. YAML, MQTT, SSH, and Jinja on the other hand..",
            "What do you do with the bankruptcy data after you have it?",
            "> Working on another one that screenshots pages and if they change (sale or pricedrops) they warn me through email\n\nMight wanna check changedetector.io project. It has a self host option.",
            "What tools do you use to run this every day?",
            "Where are you getting bankruptcy rss data from",
            "Could use that for my OSHA 30 hahaha",
            "That personal automation project probably taught you more than the other classes did.",
            "We use airflow extensively at work.\nAny business automation process, provisioning, Rollups, all in airflow.\n\nWe run airflow on our k8s stacks, works well!",
            "Unrelated advice move away from nbs for anything other than research/ exploration. Thank me later",
            "Was wondering if anyone called it out before I was going to. That book fueled my passion for programming. Previously, my coding was homework related, calculating circle diameters or creating library catalogs, apps I didn't see daily application for in my life.",
            "I'd love to see this code",
            "Friends did the same kind of thing for booking public badminton courts that become available at random times in the middle of the night.",
            "Hands down one of the most powerful and valuable devops tools used in the industry. Completely free, open source and in my opinion showcases the power of python in this space: its amazing for IO bound automation beyond a simple shell script.",
            "Hello World!",
            "typo, automation of course, there is no edit option for the title",
            "Playwright for Python is also a good alternative developed by Microsoft. I had been running into driver version issues with Selenium and have started to move my scripts over to this. \n\nhttps://playwright.dev/python/",
            "I also like splinter https://splinter.readthedocs.io/en/stable/",
            "damn thats cool af would love to see some more",
            "Code plx \ud83e\udd2b",
            "Id also love to see this! +1",
            "Can you share the code?",
            "Photo might be a bit much - especially in 2009 when posting happy birthdays on wall with \"ai images\" would freak people out.\n\nBut otherwise don't see why you're being down voted - good hypothetical idea",
            "Why do I get the feeling that this message was automated with\u2026 PyAutoGUI?",
            "Question for both of you then. The times I've used pyautogui have mostly been for clicking an online game. I rarely use it and, because of that, found it easiest to just grab the screen coordinates, pop them in a variable, and run it forever.  \nDo you use any sort of image/icon/etc. recognition while running yours or use the specific coordinates?  \nThe only times I have problems with mine is that the game will occasionally pop up an extra screen. I got around that by refreshing my browser every random amount of seconds/minutes and taking a screenshot that was saved in Google Drive so I could log in from my phone if it was stuck at a more challenging prompt.  \nI've just always had issues with it finding a specific image on the screen and clicking that to the point where it's easier to just say \"hey it's usually right here\" and fix it when it doesn't work.",
            "There's also projects like [Pymiere](https://github.com/qmasingarbe/pymiere) for Premiere automation, and [Photoshop API for Windows](https://github.com/loonghao/photoshop-python-api) (a comtypes wrapper)\n\nYou might be interested in projects like [appscript](https://appscript.sourceforge.io/) if you're on Mac.\n\nThese let you automate lots of Adobe software using their built in COM or Apple Event automation interfaces.",
            "If somebody has some cool examples of how to use python in home assistant that would be nice. I'm using it to scrape dates of the next garbage collection from the local website and update a template sensor for example",
            "[deleted]",
            "That would be a great idea, but in some places like NYC, they require you to answer an automated phone call and/or be on camera the entire time \ud83d\ude43",
            "What\u2019s nbs?",
            "[deleted]",
            "The language of the gods",
            "Why of course? Cellular Automaton are a very common coding project and there is a lot of cool variations you can do with them.",
            "I\u2019m seeing more and more people recommend this over Selenium. I might have to give it a try.",
            "> I had been running into driver version issues with Selenium\n\nIssues with Selenium's management of the drivers in recent versions? \n\nI know Google changed up their system around chrome driver in the summer. It took us a bit to adapt [chromedriver-autoinstaller](https://github.com/yeongbin-jo/python-chromedriver-autoinstaller) to the changes. \n\nHowever, I use selenium daily, and find Selenium is now great at getting me the right drivers without 3rd party help.",
            "Codegen on that is sooo good",
            "Haha yeah the idea wasn't to actually post an ai photo on their wall\n\nBut rather, look at their profile photo, get the sentiment of the photo and then relate the birthday message to their pfp\n\ni.e if they're holding cola in the picture then the birthday message could be related to cola \"Happy Birthday! Drink lots of cola today \ud83d\ude1c\" something like that.\n\nOr even if it was a photo, a literal snapshot of their pfp but with a party hat and balloons edited onto it could be fun.",
            "Have you tried the [locateOnScreen function](https://pyautogui.readthedocs.io/en/latest/screenshot.html)? It has a \u2018confidence\u2019 argument that uses OpenCV.",
            "I used to do my tasks with specific screen coordinates, things similar to popup do happen but rarely for me, I had to do a little bit manual intervention here and there when that happens. It was a pretty simple script no complexities were there.",
            "Recently I used the photoshop API and it's handy, first time hearing about pymiere, need to check it out.  Thanks!",
            "Curious where you see the advantage in using these 3rd party products vs using built-in adobe automation options (extend script, UXP)?\n\n\nI have python projects that read/manipulate Word documents, and create audio files. I then want to bring the text/audio into After Effects. I can see how it'd be convenient in some ways to do it all from Python. Once upon a time, I'd run imports, placement, and timing of assets on the timeline across dozens of Adobe Flash files with a single click. In my current context, I figure it'd give the creative people more freedom and control over things to give them a UI in AE.",
            "You can easily do that in Home Assistant without touching Python",
            "Cool! And then just run it on a raspberry pi that is always on?",
            "I think they wanted to say notebooks but didn't type the whole word out. Don't worry - it frustrated me too. Thank you for asking.",
            "....of deployments?",
            "I've been using webdriver-manager to get the Edge Driver but had a few cases where it wasn't pulling the most recent driver after an update.",
            "i heard that MSS is better. anyone know more about that",
            "I have tried it. What I've done is try to get the browser to the exact same size, take a screenshot, crop it to make it have less to identify and then set it. I've just never had much luck--perhaps I just need to give it another shot.  \nAt one point I wondered if my second screen was causing issues.",
            "IMO the benefits of using Python in this context are the same for most projects; Python has super readable & customisable syntax, and has an incredibly powerful standard library that ExtendScript and UXP simply does not provide.\n\nFor work we have lots of Photoshop & Illustrator tools that are parts of bigger workflows, with lots of predictable and automatable processes across apps. Technically you could still use ExtendScript/UXP for them, but we like to be able to make droplets and proper interfaces for our tools. \n\nWe previously used AppleScript for lots of this cross-app automation, since you can have make simple UI elements like dialogue and alerts but I am much preferring Python + appscript + pyobjc.",
            "Very helpful input",
            "Got any links?",
            "[deleted]",
            "Have a look at RESTful Sensor\n\nhttps://www.home-assistant.io/integrations/sensor.rest/",
            "I am not in love with using ansible for that but...\n\n[https://ansible.ninja/building-reports-with-ansible/](https://ansible.ninja/building-reports-with-ansible/)",
            "Thanks for the reference! Will try it out :)"
        ]
    },
    "Granian 1.0 is out": {
        "title": "Granian 1.0 is out",
        "score": 144,
        "url": "https://www.reddit.com/r/Python/comments/19cs4qx/granian_10_is_out/",
        "content": "Granian (the [Rust HTTP server](https://github.com/emmett-framework/granian) for Python applications) [reached 1.0](https://github.com/emmett-framework/granian/releases/tag/v1.0.0).\n\nThe release's highlights include:\n- Support for ASGI lifespan state (some frameworks like Starlette and FastAPI rely on this)\n- Support for [ASGI pathsend](https://asgi.readthedocs.io/en/latest/extensions.html#path-send)\n- Improvements in workers processes management",
        "num_comments": 29,
        "comments": [
            "We are already using Granian in production.\n\nReplace Gunicorn / Uvicorn / Hypercorn / Daphne with Granian\r  \n\r  \nFrom:\r  \n\r  \ngunicorn project.wsgi:application --bind :8000\r  \nSame for uvicorn, hypercorn, daphne...\r  \n\r  \nTo:\r  \n\r  \nWSGI\r  \ngranian --interface wsgi project.wsgi:application --port 8000\r  \n\r  \nASGI\r  \ngranian --interface asgi project.asgi:application --port 8000\r  \n\r  \nBenchmarks\r  \nhttps://github.com/emmett-framework/granian/blob/master/benchmarks/README.md",
            "Congratulations. A super project that will keep an eye one for my future needs.\n\nedit: I wanted to give it a try but this issue is a blocker for me https://github.com/emmett-framework/granian/issues/35 I'll circle back someday.",
            "Love Granian :) We even have a plug-in to work with Granian instead of uvicorn if desired.",
            "love this. py4web will adopt it immediately.",
            "Is there any comparison to the well-known alternatives (uWSGI, gunicorn, Apache with mod\\_wsgi, Daphne, Hypercorn Uvicorn)?",
            "skirt disagreeable prick bow many soup yam attempt materialistic aspiring\n\n *This post was mass deleted and anonymized with [Redact](https://redact.dev)*",
            "Any thoughts about making an example server like  [docker-flask-example](https://github.com/nickjj/docker-flask-example) or \n[uvicorn-gunicorn-docker](https://github.com/tiangolo/uvicorn-gunicorn-docker) to make it quick to try?",
            "Does it support gevent?",
            "congrats!",
            "Thank you for the fastest/usable asgi (and maybe wsgi) for python.",
            "I was here",
            "Can anyone post, performance summary comparison with uvicorn? Thanks!",
            "Hi, thanks for the heads up.\nHere's the benchmarks against Uvicorn and Hypercorn \n\nhttps://github.com/emmett-framework/granian/blob/master/benchmarks/README.md",
            "Want to try it out, does it support app factories?",
            "Congrats!",
            "Thank god theres now competition for uvicorn, CoreAPI will def rely on this.",
            "Hello, please explain, I has traefik - apache mod\\_wsgi docker container with django app.\r  \nThe apache configuration served both the wsgi application and static files.\r  \n\r  \nAs far as I understand, granian only serves wsgi/asgi applications, does that mean that a separate server is needed for static files? Same apache/nginx?",
            "Yeah, that issue is hard.\n\nGiven the only way to _circumvent_ the GIL is to run multiple processes (and thus using the `multiprocessing` library), it is very complicated to have `pickle` working correctly with objects and functions.\n\nAFAIK no server out there with a number of workers greater than 1 lets you pass an application object as target.\n\nAnd frankly having different logic and two different management policies for processes depending on the number of workers seems to me \u2013 at least for now \u2013 quite a waste of time and resources to implement.",
            "It really depends on what you mean by comparison.\n\nI'm not aware of any particular in-depth comparison, there's some [proprietary benchmarks](https://github.com/emmett-framework/granian/blob/master/benchmarks/README.md) and some [3rd party ones](https://www.techempower.com/benchmarks).",
            "Yes it does, both with ASGI and WSGI interfaces.\n\nTime of writing I'm not aware of any particular pitfalls in comparison with Gunicorn, Daphne or Uvicorn.\n\nIf you experience any of them, please open up an issue or a discussion in the Github repo :)",
            "Wondering the same thing",
            "I'm not a big fan of pre-built docker images for applications, given the amount of customisation a single project might need (system libraries, dependency manager, supervisors, etc).\n\nAlso, given the fact the difference between other servers is to add the dependency in your project and switch the entrypoint to launch Granian, I can't see any real valuable point in doing this.\n\nProbably some documentation will work better.",
            "Nope. And it won't, as the network I/O is handled directly with a Rust async runtime, which behaves like gevent.",
            "Here are the ones I'm aware of:\n- [Project benchmarks](https://github.com/emmett-framework/granian/blob/master/benchmarks/README.md#async)\n- [TechEmpower benchmarks](https://www.techempower.com/benchmarks/#hw=ph&test=plaintext&section=data-r22&l=zijzen-cn3&f=zik0zj-zik0zj-zik0zj-zik0zj-zik0zj-zik0zj-zik0zj-zik0zj-zik0zj-yelngf-zik0zj-zik0zj-zik0xr-zik0zj-1ekf)",
            "Currently not. But if you have a factory you can always add another file, eg:\n\n```python\nfrom mymodule import my_factory\n\napp = my_factory()\n```\n\nand point Granian to such instance.",
            "Not sure if this is any help whatsoever but IDLE pickles function objects. It extends the pickle table with a handler for the code type, which in turn uses the marshal module. To this day I'm not even sure what all this effort is for, given that the frontend process shouldn't run user code in the first place.\n\nhttps://github.com/python/cpython/blob/595f9ccb0c059f2fb5bf13643bfc0cdd5b55a422/Lib/idlelib/rpc.py#L45-L67",
            "No worries. I certainly wasn't complaining. I'll also look if I can repurpose my initialization approach to work with granian.",
            "Makes sense, thanks",
            "Thank you for the hint, I'll take a look at it."
        ]
    },
    "Why are python dataclasses not JSON serializable?": {
        "title": "Why are python dataclasses not JSON serializable?",
        "score": 212,
        "url": "https://www.reddit.com/r/Python/comments/193lp4s/why_are_python_dataclasses_not_json_serializable/",
        "content": "I simply added a \u2018to_dict\u2019 class method which calls \u2018dataclasses.asdict(self)\u2019 to handle this. Regardless of workarounds, shouldn\u2019t dataclasses in python be JSON serializable out of the box given their purpose as a data object?\n\nAm I misunderstanding something here? What would be other ways of doing this?",
        "num_comments": 168,
        "comments": [
            "Perhaps the problem is that people might be surprised to find that the deserializing does not create the data classes again properly.",
            "dataclasses-json gives you a decorator for dataclasses to make them ser/de with json. Can limit the types and composition, but if json-compatible types are enough for you, it should be what you need.",
            "I feel like pydantic would be how I'd solve this problem.",
            "Unfortunately, you're misunderstanding what JSON is and how it's supported in Python.\n\nPython can serialize its primitive types into json and deserialize json into **a subset** of its primitive types (no support for set, frozen set, tuple, etc). This can be done at the user's direction and proceeds without any evaluation or validation besides the key or value being read/written.\n\nObjects are NOT json serializable in python. To serialize and deserialize more complex types, you require a \"protocol\", a set of rules and conventions capable of describing more complex types.\n\ntl;dr JSON's not a serialization protocol, it's just a data format in Python",
            "Many people are answering with how they\u2019d handle the solution to the problem instead of why this isn\u2019t a core part of data classes. I\u2019m curious about the why too, especially since getting data into and out of the type is important.\n\nMy research suggest this is because they wanted them to be agnostic. You could support JSON out of the box and lots of people would love it since that is a big use case outside of web work too. \n\nThe problem is that it picks a winner and it can start to make it harder for other types of serialization as people optimize for JSON. This becomes unintentional drift over time and then JSON ends up better supported. \n\nOver the life of the standard library they\u2019ve been burdened with stuff like pickle. That has taught them to be wary of including serialization formats. More than that, it contributed to the thinking about thinning the standard lib and raising the barrier to new stuff.\n\nIt\u2019s also a decision that can be put off. For the reasons above, it felt safe to punt on it. If that turned out to be a major mistake then they could add it in. It seems the community is happy with the balance.",
            "I think serializability should be reversible. If you go from dataclass->json you lose all the methods. You cant take a json and deserialize it to the same dataclass you serialized it from. \n\nMaybe just do this instead of adding a new method. \n\n`json.dumps(dataclasses.asdict(mydataclass))`",
            "Not necessarily. Data classes can hold attributes which are not JSON-serializable. It may even describe generic types or protocol types that can be dumped or loaded multiple ways. If your class happens to only hold serializable attributes, then dumping asdict is easy enough.\n\nIt might also be surprising if `json.loads(json.dumps(instance)) != instance` which would be hard to achieve cleanly. \n\nSo it makes sense to me that data classes do not involve themselves with serialization. Though, who knows what the future may hold.",
            "My 2 cents: since the standard library's `json` module doesn't encode `dataclass` instances by default, many users have added in support using the `default` kwarg to `json.dumps`. If the `json` suddenly started supporting `dataclass` instances out-of-the-box, then that would break existing code. \n\nAlso, supporting encoding/decoding of dataclasses opens the doors to lots of additional feature requests. What about field aliases? Optional fields? Type validation? etc... They have to draw the line somewhere to avoid bloating the stdlib. Since external libraries like [msgspec](https://github.com/jcrist/msgspec) or `pydantic` already handle these cases (and do so performantly), I suspect python maintainers don't see the need to make it builtin.\n\n---\n\nFor completeness, here's a quick demo of JSON encoding/decoding dataclasses out-of-the-box with [msgspec](https://github.com/jcrist/msgspec):\n\n```\nIn [1]: import msgspec, dataclasses\n\nIn [2]: @dataclasses.dataclass\n   ...: class User:\n   ...:     name: str\n   ...:     email: str\n   ...:     is_admin: bool = False\n   ...: \n\nIn [3]: msg = User(\"alice\", \"alice@munro.com\")\n\nIn [4]: msgspec.json.encode(msg)  # encode a dataclass\nOut[4]: b'{\"name\":\"alice\",\"email\":\"alice@munro.com\",\"is_admin\":false}'\n\nIn [5]: msgspec.json.decode(_, type=User)  # decode back into a dataclass\nOut[5]: User(name='alice', email='alice@munro.com', is_admin=False)\n```\n\nFor more info, see our [docs on dataclasses support](https://jcristharif.com/msgspec/supported-types.html#dataclasses).\n\nIt even can encode alternative dataclass implementations like [edgedb.Object](https://jcristharif.com/msgspec/examples/edgedb.html#json-encoding-query-results) or `pydantic.dataclasses` (in this case faster than pydantic can do it itself):\n\n```\nIn [6]: import pydantic\n\nIn [7]: @pydantic.dataclasses.dataclass\n   ...: class PydanticUser:\n   ...:     name: str\n   ...:     email: str\n   ...:     is_admin: bool = False\n   ...: \n\nIn [8]: msg = PydanticUser(\"toni\", \"toni@morrison.com\")\n\nIn [9]: %timeit msgspec.json.encode(msg)  # bench msgspec encoding pydantic dataclasses\n214 ns \u00b1 0.597 ns per loop (mean \u00b1 std. dev. of 7 runs, 1,000,000 loops each)\n\nIn [10]: ta = pydantic.TypeAdapter(PydanticUser)\n\nIn [11]: %timeit ta.dump_json(msg)  # bench pydantic encoding pydantic dataclasses\n904 ns \u00b1 0.715 ns per loop (mean \u00b1 std. dev. of 7 runs, 1,000,000 loops each)\n```",
            "To me this comes down to \"it's better to be explicit than implicit\". Others detailed a lot of ambiguities about how to go about serializing or, even more, deserializing a dataclass, so having an implementation in the standard library would mean the language has an implicit opinion about how to do all of that.\n\n\nMuch better to leave it to 3rd party libraries to provide their opinionated and tunable versions, or have you add methods to your class.",
            "Suppose you have a member variable that's a tuple. How would you serialize/deserialize that to json? Same question for the set type.",
            "Python was invented long before JSON, and has never really specialized the standard library around the web to begin with.\n\nAnd aside from that, you have to watch out for the foot gun that is not all python types are serializable, and deserializing into python objects can be tricky. So even if it existed in the standard library it would never be as powerful as pydantic.",
            "Because it's difficult to handle all the use-cases.  There are classes that are difficult to serialize and they don't want to support all of those edge cases. One such case that comes to mind are nested classes, [which are possible in Python](https://stackoverflow.com/questions/61000501/json-serialization-of-nested-dataclasses). \n\nThat's what third party libraries are for: to solve edge cases in an opinionated way. These may not be appropriate for all cases and doesn't belong in the standard library.",
            "> shouldn\u2019t dataclasses in python be JSON serializable out of the box given their purpose as a data object?\n\nI would argue that it makes sense not to. The keys are serializable to JSON strings, but the values can obviously be of types that are not JSON-serializable. Remember that JSON scalar values can only be strings, arbitrary-precision decimal-encoded real numbers, booleans, and null. Even serializing a python `float` into JSON is fraught with peril, as non-real values like +/-infinity or NaN are not going to be serializable. Thus, the standard library does not attempt to provide any sane default serialization logic for every possible python type, leaving that up to the user.",
            "My guess is that it's because there's no canonical way to store the class of your dataclass instance. You need some way to store the class in the JSON output so that json.load knows what class to use for deserialization. I guess that specifying a format for that was not the purpose of the `json` lib.\n\n`jsonpickle` should do the trick, but the resulting JSON will be polluted by extra information encoded by the library.",
            "You'll need an accompanying from\\_dict() classmethod to deserialize the dict back to a dataclass instance - and this is much harder than just converting a dataclass to a dictionary. What if the dict has keys that don't match up to any field in the dataclass? What if the dict is missing keys that map to required fields in the dataclass instance?\n\nThus, I presume the Python devs decided to leave serialization out of the Dataclass object specification and rather created helper functions that can be used to partially support this.",
            "Not a direct answer to your question - but - use Pydantic! It\u2019s everything data classes should\u2019ve been.\n\nIt\u2019s fully serializable to and from JSON, it performs automatic schema validation and has great error messages for mismatches, it plays nicely with type checkers, and has simple concise syntax.",
            "If you stick to serializable attributes, you can simply chain dataclasses.asdict and json.dumps, which is as convenient as it could be without adding unnecessary garbage into the namespace of your custom dataclass. If that\u2019s enough for you, look into dacite for recursively inflating dataclasses from nested json dicts.",
            "What if one of the attributes of a data class is not json serializable?",
            "there is no trivial and canonical.1:1 mapping between data classes and text formats like json (or XML or yaml or whathaveyou)\n\nfor example how do you express circular references in the serialization?\nor how do you handle enums?  how do you map json structs to python dataclass names?  how do you express data model versions?\n\nthat's why there are several different python json libraries, most of which \"support dataclasses\"\n\ntl;dr it's non-trivial once you run into details.",
            "> Why are python dataclasses not JSON serializable?\n\nBecause \"works with all Python datatypes\" and \"JSON serializable\" are mutually exclusive features. You can't have both. Anything in the standard library will pick the first option.\n\nIt's trivial to fix this yourself, and multiple packages exist that solve this as well, so it's not a major issue.",
            "Because JSON = JavaScript Object Notation\n\nIt was literally created for another language. \n\nAnd No, data classes shouldn\u2019t be limited to json serialized things\u2026.it should be allowed to do stuff pythonically.",
            "The main reason is that dataclass was developed with a minimal approach. It was not intended to have full blown feature parity with attrs or pydantic. Just a minimal, easily maintainable solution light weight enough to live in the standard library.",
            "I do this all the time - build a domain model out of data classes and serialize to/from JSON for the API server. \n\nIt depends on what your member types are. If you only have text, int, float, bool, none, then it\u2019s fine. I run into this with other types such as timestamps. \n\nI create type adapters that my to_json/from_json methods call. The JSON representation has to be valid JSON.",
            "[deleted]",
            "Data classes aren\u2019t really meant for validation, i feel they serve their purpose as a way to handle state related data  between python programs without a lot of boilerplate, especially that comes with validation needed for a JSON protocol",
            "They are very much serializable; if they contain valid data for a json.  json has its own rules and allowed datatypes.  A numpy integer is not one of them.  If you ensure the data is json sanitary, you can dump it to json.",
            "[deleted]",
            "I know your question is on the ''why'. But if anyone here stumbles on this thread looking for the 'how' this might help:\n https://stackoverflow.com/questions/72604922/how-to-convert-python-dataclass-to-dictionary-of-string-literal",
            "I think I read somewhere that in a future version they will be?",
            "One idea is actually to not put any methods on the class at all so there is no chance of a method name colliding with an attribute.",
            "&r,",
            "They are if you pickel them",
            "There's no real and value reason that you will like, it just is because its tough to cover all edge cases, feel free to create a pull request/issue or email the python dev team to promote the change\n\nThe only thing that you might accept is that because the purpose of dataclasses are to store a temporary state, like a cookie or session in web development, so they probably didnt think of a need to perform serialization",
            "Don't forget the Single responsibility principle: dataclasses aren't for serde ops",
            "use desert with dataclass. or like the other dude said - ditch it and use pydantic",
            "You could try with typedload perhaps?",
            "It is serializable. It's just not a method. \n\nMaybe there's something I'm not getting. Could you post your code now, and what your ideal code would be?",
            "I use this for that \n\nhttps://github.com/coqui-ai/coqpit",
            "I'll shamelessly use this opportunity to advertise for my databind.json (https://pypi.org/project/databind.json/) package. \ud83d\ude04",
            "Use Pydantic for a data transfer object that you need JSON serialization on:\n\nhttps://docs.pydantic.dev/latest/\n\nIt\u2019s a great library. The models support both validation and methods like .json() to dump it",
            "I just gave up with dataclasses and use pydantic",
            "Why did you add a to\\_dict class method to call the existing asdict class method?\n\nYou could also probably use the built-in \\_\\_dict\\_\\_() which is [significantly faster](https://stackoverflow.com/questions/52229521/why-is-dataclasses-asdictobj-10x-slower-than-obj-dict)",
            "This is EXACTLY why. The extra step required creates symmetry in the deserialization.\n\nNotably, raw json IS NOT a full cycle serialization solution. It's just a data format.",
            "This can happen due to different versions of things.  I do it with pickle and it works fine, but I know its a hack.",
            "Right which is where dacite, a third party library comes in. It does exactly this, although I\u2019ve never attempted with sets or tuples. I feel this should be a built in functionality. If it\u2019s JSON serializable I should be able to serialize the object to JSON and likewise deserialize from JSON. Just like \u2018dict\u2019 but more organized and clean",
            "dataclasses-json is also unmaintained. As a dataclasses-json user I cannot recommend using this library anymore.\n\nFastAPI or some more established library might be a better with for JSON serialisation of dataclasses.",
            "This is awesome and I will likely use it, but I am expressing that I feel this should be a built in functionality",
            "typedload.dump() can do that, without needing to decorate anything. If you use non-dataclass stuff you can write your own serializer function.",
            "Or attrs",
            "Someone else mentioned this I think. I\u2019ve only ever used dacite, but either way I feel the functionality should be built in",
            "Came to comment just this.\n\nTo bring it back to Jason in particular, although pretty much everything can be encoded to JSON (which is part of the reason it's a popular format), it is much harder to decode JSON into /anything/.\n\n**JSON encoding is LOSSY**.\n\nThe simplest use case I come back to is: how do I know if `\"2024-01-11 3:47:23\u201d` is a string or a datetime?\n\nAt the point you start looking at type annotations you've come to why libraries like Pydantic were created.",
            "Thank you for your response. This make a lot of sense to me",
            "This is such a good response, and although it took me a moment has massive implications for how to consider serialisation.\n\nI feel like we're mostly used to serialising into some byte or unicode string (pickle, JSON).\n\nBut consider that a number of ORMs support dataclasses for their models aka are serialising from/to SQL. Should dataclasses support this use case? What about all the DB specific dialects? What about nosql data stores. (Rhetorical).",
            "> The problem is that it picks a winner and it can start to make it harder for other types of serialization as people optimize for JSON. This becomes unintentional drift over time and then JSON ends up better supported.\n\nWell, given that there's no native support for Avro, Protobuf, Yaml, (until python 3.11) TOML, messagepack, the only 2 object notations supported by python standard library are really just XML and JSON. And since nobody is wacked in the head to deal with XML today, JSON is clearly the winner that was picked. So that ship has absolutely and definitely sailed. So it's not it.",
            "JSON is the de facto standard and it has been for a decade. This is just not a very sound argument. Nobody likes pickle because it\u2019s binary and needs to be versioned. This is not true for JSON. The resulting JSON serialization code is also arguably simpler.",
            "But that's not what serialization and deserialization are for. You don't serialize a class, you serialize an object of a given class. The methods are declared and implemented in the class, not the object.\n\nWhen you want to serialize an object (e.g. to save its state between executions of the program), you serialize the state of THAT particular object, i.e. its properties.\n\nWhen you deserialize, you want to populate the properties of an instance of the same class (probably the same named object) with the data you saved. So you instantiate a blank object of the class and use its deserialization method to copy the properties from JSON to the appropriate properties, or you design a constructor with an optional argument that tells if you want it to construct the object with data from a JSON file.\n\nWhat you describe (saving and restoring a serialized CLASS's methods) is madness basically. You can't (and wouldn't want) to get an object of some arbitrary class with all its methods and deserialize it in your program. You'd either end up with a whole class that you can't reuse except if you deserialize multiple instance objects (but you can't create new ones from scratch), or with an incompatible replacement for importing modules and classes. \n\nThe class needs to be declared and implemented in the program or in a module that you import. So the methods themselves are already there, you don't need to deserialize them. What you need is only the saved properties.",
            "[deleted]",
            "So you presumably also think that NamedTuples should not be serializable?",
            "This is effectively what I did. There are third party libraries that can deserialize so I don\u2019t see why that couldn\u2019t be a built in functionality",
            "I don't think they will do it\u2026 not everything can be dumped to json. For example if a field points to an open file descriptor (the descriptor itself, not the content of the file), that is impossible to serialize, so in general not everything is serializable.",
            "anything that\u2019s a subclass of https://docs.python.org/3/library/collections.abc.html#collections.abc.Collection and *isn\u2019t* a string or a mapping would be an array in JSON\n\nthat includes both tuple and set\n\n(not trying to prove/disprove anything, that\u2019s just how it\u2019s typically handled)",
            "You could ask the same questions of lists. \"What if a list had a member that is a tuple or a set? How would you serialize/deserialize that. Therefore lists should not be serializable.\"",
            "This is a great consideration I hadn\u2019t thought of. I just tried \u2018print(json.dumps({\u201cset\u201d: {1, 2, 3}})\u2019 which threw the same TypeError. I guess my expectation is that this behavior would be the same for dataclasses but it is not. \n\nI feel the dataclasses.asdict(obj) function should be called automatically when trying to JSON serialize a dataclass. Then the same exception would be thrown in the cases of sets and tuples which I would think would make more sense than handling the way it currently is",
            "Aren't tuples just arrays in js? So presumably you would serialize tuple -> array. Deserializing idk because python has lists as well, and I'm assuming you'd need to do that logic in your calling function when you go to deserialize because there won't be anything in the json to tel you list vs tuple.",
            "Pydantic uses json schema, which is at least portable. These aren't \"pollution\", they are conventions for reading and writing complex structure from a lower level data format.\n\nIf jsonpickle and json schema are pollution of json, then protocol buffers are pollution of binary. At that point, everything is pollution of binary. Even the raw binary structure from memory is a pollution.",
            "Yeah I wrote typedload to do that, and the loading part is much harder than the dumping part.\n\nBasically you need good exception handling to find in which field the errors happened, and use typing information at runtime to reconstruct the original data\u2026 otherwise, casting a set to a list and then getting an actual list would break a lot of things.\n\nWithout type annotation I don't think it's possible at all. And in python type annotation is not mandatory, so I don't think there could exist a method that requires it.",
            "Pydantic is amazing",
            "I only have ints and floats and received a TypeError when I tried \u2018json.dump(MyClass, output_file)\u2019",
            "This is exactly what I did",
            "How does that answer the question?\n\nThe question is why the JSON serializer does not handle dataclasses.",
            "This returns all the data as strings. If using only JSON serializable data (string, integer, float, array of supported types) then just asdict would be sufficient and can be deserialized accurately by dacite or converted to a dict by json load or loads",
            "It's pretty obvious to me what they are asking about:\n\n    import json\n    from dataclasses import dataclass\n    \n    \n    @dataclass\n    class Position:\n        x: float\n        y: float\n        z: float\n    \n    \n    # Create an instance of the Position class\n    position = Position(1.0, 2.0, 3.0)\n    \n    # Serialize the position object to JSON\n    json_data = json.dumps(position)\n    \n    # Print the JSON data\n    print(json_data)\n\nLeads to:\n\n    TypeError: Object of type Position is not JSON serializable\n\nThey expect:\n\n    {\"x\": 1.0, \"y\": 2.0, \"z\": 3.0}",
            "I cannot post my code but I can provide an example. I feel I should be able to write \u2018json.dump(DataclassClass, fp)\u2019 but when I tried this I received a \u2018TypeError\u2019 that my \u2018DataclassClass\u2019 was not JSON serializable",
            "OP wants dataclass to magically support a serialization/deserialization protocol that *targets* json. They are conflating json the format with a protocol.",
            "json has no way to represent dates, Path, tuples.\n\nIn typedload for example it will convert a Path to a string, and then back to a Path, but because it knows the types. If you just have a json and no type information you can't really automatically convert anything.",
            "Why are so many people upset about using pickle to serialize/deserialize data? I like the fact that upon deserialization, pickling restores the original object automatically, which doesn\u2019t happen with json. And yes, I\u2019ve heard the argument about security issues but there has to be a way to mitigate that threat and use pickling safely.",
            "Dacite is a lot of code, and complex, and competitive with Pydantic.\n\nSo no...I don't necessarily agree it should be part of the standard library.\n\nMaybe after a decade or so of stabilization, Pydantic itself should become part of the StdLib. But it just underwent a major overhaul, so it's probably still too early.\n\nOr maybe there is some subset that should be part of the stdlib for simple cases.",
            "> I feel this should be a built in functionality.\n\nThere should be less of that. There is a Python proverb that says that the standard library is where libraries go to die. Once they are there, they can no longer evolve because it would break everyone\u2019s code.\n\nI prefer the concept of blessed libraries from Rust. There is a set of core library which serve as a kind of de facto standard library while the actual standard library stays small. So if you you are using lib X at version 1.0 and they release 2.0, you are fine, you can stay on the 1.0 version as long as you want.\n\nAlso, if we find out we actually don\u2019t like serializing dataclasses as json, we won\u2019t have that technical debt to carry around in future versions.",
            "I use pydantic for data structures that require JSON ser/de. Can even derive a json schema from class definitions which is awesome for documentation.",
            "https://github.com/jsonpickle/jsonpickle",
            "It\u2019s just not what Python\u2019s dataclasses were intended for. JSON serialization is great, but dataclasses would be very different if they were forced to maintain compatibility with it.",
            "[deleted]",
            "Python isnt Javascript, so I'm not following why you think JSON should be a native data structure.",
            "Dataclasses aren't only for primitive types. A field can be of any type. How would you automatically serialize that? How would you know which fields to serialize and deserialize? Only the trivial case is simple where a dataclass only contains primitive types and other dataclasses which fit this constraint recursively.\n\nA typical \"universal\" serializer that can serialize an arbitrary object must do so in a way that the same application (or language) can restore the serialized object to the exact same state (deserialization) from the serializer's output. Basically obj == deserializer(serializer(obj))\n\nFor feeding it into a frontend this is often completely unnecessary.\n\n&#x200B;\n\nThis is why it is not included in Python. So you either write a custom serializer to only serialize what you need or generate a simple object like a dict that can be serialized easily, becuase for example json.dumps does serialize simple objects (lists, dicts, primitive types) that can be directly mapped to JSON.\n\nAlso keep in mind that Python has built-in large integer handling, but JSON numbers are recommended to fit within a range for interoptability reasons. E.g. Javascript only knows IEEE 754 doubles (JIT compiler tracing optimizations notwithstanding which is an implementation detail). See RFC 8259 Numbers section for details regarding the number representation in JSON.\n\nSo all in all it is far simpler to not include an automatic serialization for dataclasses and instead delegate it to the user who knows exactly what their dataclasses actually store and how their hierarchy looks like.\n\nVarious libraries that solve this problem in various ways exist, but there is not one universal method.\n\n&#x200B;\n\nEdit: typos, clarity and some more thoughts",
            "School of Guido Van R,  do one thing and do it correctly.",
            "I feel like I rarely ever hear from the \u201cpython should be slower and do more stuff crowd\u201d",
            "> The simplest use case I come back to is: how do I know if `\"2024-01-11 3:47:23\u201d` is a string or a datetime?\n\nif your dataclass attribute specifies that it's a datetime, then it should attempt to interpret it as a datetime, which should probably fail since it's not in ISO format.\n\nPython standard library makes it a habit to include everything that's necessary everywhere. JSON operations are ubiquitous today, same as CSV. So we have `csv` module, and we have `json` module, but why would it be limited to dicts and not objects of dataclasses? I get it if you wanted to serialize something with private attributes that are assigned in some complex inner method logic during runtime, but a dataclass? Aside from a few notes like \"do not stick your tongue in it\" (like don't try to serialize dataclasses that are not really just dataclasses, and expect it to work predictably), object serialization and deserialization should be no different from dict serialization and deserialization.",
            "What does any of that have to do with providing functionality to deserialize JSON content into a dataclass? Nothing.",
            "JSON being popular also isn\u2019t a sound argument. It can be usurped by the next shiny thing very quickly.",
            "The problem is that you can redefine a binding at runtime.\n\n    class A:\n        def p(self):\n            print(1)\n\n    def q():\n        print(2)\n\n    a = A()\n    a.p()\n    a.p = q\n    a.p()\n\nHow do you serialize `a` in this case?",
            "Because you can\u2019t tell what types you should be inflating. Say you have type annotation A on an attribute, which is a dataclass and you have a dataclass B that inherits from A with the same dataclass fields. The JSON does not tell you whether to translate the dict into an A or B.\n\nThe standard library could arbitrarily resolve this, which would lead to people shooting themselves in the foot constantly. The wise choice for library builders is to not offer semantically ambiguous functionality like that to keep the core library simple.",
            "By that argument anything that a third party library does should be built-in",
            "I agree with you it should be possible, but /u/Flack1 is right, to be serializeable it should also be deserializable, which is not possible without specifying the dataclass you want to deserialize into.\n\nWhich is, mind you, how basically every other language handles JSON deserialization and how other Python libraries for this use case (e.g. pydantic) handle this. It\u2019s arguably a design flaw that `json.loads` doesn\u2019t accept a type parameter.\n\nThere are solutions though. You *can* convert from/to dicts and dicts are serializable, if you only add serializable fields to your dataclasses. Or you use a serialization library like dataclasses-json to handle this. You could also write your own utility as an exercise. It\u2019s not much work to parse the dataclass typehints and support the few most common types. Fully supporting aliases, unions and generics is what makes it complex.",
            "Take a look at attrs & cattrs, it is a superset of dataclasses and has the serialization that you may be looking for in cattrs",
            "If you serialise set, list and tuple as a json array you'll have difficulty deserializing to the correct type again.",
            ">What if a list had a member that is a tuple or a set?\n\nIll go a step further (because I have built many dataclass implementations that actually do this) what if you have a member field that is a list of other dataclass objects? How would you ser/de that?",
            "I'm not saying those are bad, just that they are not pure JSON and that none of those conventions is canonical. I can't find the rationale for how they designed the `json` library but it seems reasonable to me that they would be prudent about choosing an encoding convention for inclusion in the standard library when none is official or clearly dominant.",
            "Ah, ah. You can\u2019t directly pass the class. I guess that was your complaint. \n\nIt\u2019s strait forward to turn the instance into a dict first and then pass that to the json method.",
            "Ints and floats should be numbers in js?",
            "Thanks for understanding the question!",
            "That's only for the first comment. Further down are other solutions. Got to admit I didn't try them myself yet. The decarator & mixin approaches look promising. Still doesn't answer your question though. Got to admit that it's still weird dataclasses aren't json serializable. I guess it's due to what the top commenter said, when returning back to dataclasses things might get funky.",
            "but you can use asdict from the dataclasses module, no?\n\n    json_data = json.dumps(asdict(position))\n\nit's one extra call and makes it clear you're discarding the class information.",
            "Wow you\u2019re really on top of this! Maybe my opinion is shared?",
            "The json module only supports some of the built in datatypes out the box. It's two lines of code to do what you want, including the import. Just call `asdict` before passing it in. If you want to handle dataclasses and other types at the same time, make a customer encoder.\n\n    from dataclasses import dataclass, asdict\n    import json\n    \n    \n    class DataclassJSONEncoder(json.JSONEncoder):\n        def default(self, o):\n            try:\n                return asdict(o)\n            except TypeError:\n                return super().default(o)\n    \n    \n    @dataclass\n    class X:\n        x: int = 0\n    \n    print(json.dumps(asdict(X()))\n    print(json.dumps(X(), cls=DataclassJSONEncoder))\n\nYou can also check out `pickle`.",
            "> json has no way to represent dates, Path, tuples.\n\nbut if your dataclass says that something is a date, Path, tuple, then it should be clear how something should be deserialized. As long as some type implements some form of a stable serialization/deserialization method couple, this shouldn't be a problem. It's not a problem for libraries like `msgspec`, so why would it be a problem for the standard library?",
            "You could encrypt the pickle..  Idk, security is something to be delt with.  There are other ways, and mainly if you are passing data between two different programs then you might have issues with different versions of things that are hard to track down.  But its a tool.  It's there.  People maintain it.  It is useful for getting things up and running quickly which is all anybody seems to be able to afford these days.",
            "Pydantic is a great library, but it does have bloat, and it is pretty slow at serializing / deserializing because of the overhead. I don't think it should be part of the stdlib, even if the python release cycle has picked up in pace, such a library needs to be updated independantly.",
            "All I\u2019m saying is that I feel that dataclasses should be serializable the same way and dictionaries, and deserializable (provided the class) just as easily. This assumes that all attributes are json compatible but this is already true with dicts. It just feels to me like the functionality is already there if bridged with \u2018asdict,\u2019 I just feel it should be built in",
            "Not including proper json serialization in the standard lib for these reasons is just stubborn.",
            "Thank you. When I said FastAPI I really meant Pydantic!",
            "Does jsonpickle use Python 3 type hinting, or is it just manual serialisation only?",
            "And to further your point, web frameworks like FastAPI and Litestar have first-class support for de/ser to dataclasses and Pydantic models. Litestar supports MessagePack declarations, but I haven't played with that.\n\nFor older frameworks, you'll have to roll your own support. I have a large Pyramid project that we had to write a similar object model flow for, it's \"easy enough\" to get that working. I assume Flask would be similar.",
            "While we appreciate the history lesson about its origins and name, JSON is a standard now. \n\nMay I remind you that the json package *is* a built-in in python. The only thing that isn't is the ability to serialize dataclasses directly, which makes sense but not for the reasons you outlined.\n\nEdit: just to be clear, I am not implying that dataclasses should be json serializable.",
            "Technically that is the Unix Philosophy: [https://en.wikipedia.org/wiki/Unix\\_philosophy](https://en.wikipedia.org/wiki/Unix_philosophy) \n\nBut Guido is a proponent of that and does it well.",
            "No it's https://en.wikipedia.org/wiki/Batteries_Included",
            "Well I use the cgi module they're removing. Suffice to say I'm not excited.",
            "You're not getting it. How would a pure json object know which class to deserialize into?\n\nIt won't. You need to either carefully control how it's dumped and loaded, i.e. manually dumping and loading it from a carefully chosen function OR encoding additional metadata into the json dump and then loading it through an entrypoint that is aware of that additional metadata. Either of these strategies is defining and using a protocol for serialization (one is just more self-descriptive).\n\nLook into the actual internals of the pickle protocol or pydantic json serialization. You'll see how they are different from a json data representation of the object being serialized  - they are structured containers for the data of the object AND metadata to deserialize it.",
            "AFAIAA In its current state dataclasses do not require type annotations (in fact outside of type checkers, I'm not sure it even respects them). To enable supporting deserialisation would require breaking changes to the API.\n\nNow I'm not suggesting that it can't be done, breaking changes to the standard library does happen during minor releases, but it is something to consider.\n\nAnother thing to consider is how subclassing works as when deserialising it may be difficult to know if I should be creating the parent, or a descendant, or which specific descendant. It's not impossible, but it's a frequent enough scenario in my experience of Pydantic that it would be desirable to solve here.\n\nYou'll likely still end up in some kind of \"this other object type isn't supported\" hell, but it would make dataclasses much easier to use for common use cases.\n\n\nThinking out loud, perhaps a better solution would be the introduction of some new interface:\n\n```python\nPrim: int | str | float | bool | None | dict | list\n\nclass Serializable(typing.proto):\n    __toprimatives___(self) -> Prim: ...\n    @classmethod\n    __fromprimatives___(cls, data: Prim) --> self: ...\n```\n\nWhich would let classes define how to deconstruct and reconstruct themselves and fits into the suggestion of \"can JSON just use an object's dict method\" and let other modules tap into it (reading a CSV could now load complex types if given  the type of each column, yaml and ini could now do their thing etc)",
            "Sure it's kinda tangential and philosophical, but it also applies as \"what serialisation technologies /should/ the standard library support\".\n\nIt's all well and good to say \"this tech is popular so it should be supported\" but designing a standard library and the decision process around what should be included is much more than what's currently popular.\n\nTo suggest that the standard library should support a particular serialisation also raises the questions of:\n\n- why that serialisation method?\n- why not other serialisation methods?\n\nTo bring back the ORM example, one could argue that dataclasses should not support serialisation to JSON themselves and instead the standard library JSON should support serialising them (along with NamedTuple and other data structures).",
            "It is very sound for a language that calls itself batteries included *and does indeed provide a json module*. It\u2018s just so simple that it\u2019s almost useless on its own.",
            "[deleted]",
            "The wise choice is to offer a type parameter that specifies what class to instantiate.",
            "> Because you can\u2019t tell what types you should be inflating. Say you have type annotation A on an attribute, which is a dataclass and you have a dataclass B that inherits from A with the same dataclass fields. The JSON does not tell you whether to translate the dict into an A or B.\n\nMost people don't deserialize json into an unknown class, and expect it to self-identify. You're usually making the determination of what class something is, and deserializing into that.",
            "In case of serialization, yes. That\u2019s standard behavior. We have pickle, which works for arbitrary objects. The same should be available for json.",
            "I mean yeah, you\u2019re mapping many types (3) to 1. Obviously you can\u2019t just reverse a many-to-one, that\u2019s programming 101 \ud83d\ude1b\n\nBut if it\u2019s a named field with an annotation for the specific type, you can just call wrap the iterable with that type and it\u2019ll coerce it to the intended value",
            "Maybe don't have 3x types for the same field?",
            "I guess you follow the rules described by asdict. You asdict the child list which will asdict the child data class instances. And so forth.",
            "Okay, now do this example:\n\n\n    positions = [\n        Position(1.0, 2.0, 3.0),\n        Position(1.0, 2.0, 3.0),\n        Position(1.0, 2.0, 3.0)\n     ]\n\n    directions = [\n        Direction(1.0, 2.0, 3.0),\n        Direction(1.0, 2.0, 3.0),\n        Direction(1.0, 2.0, 3.0)\n    ]\n\n    objects = {\"positions\": positions, \"directions\": directions}\n\n    bigger_data_structure = {\"objects\": objects, \"other\": \"stuff\"}\n\n    # Serialize the position object to JSON\n    json_data = json.dumps(bigger_data_structure)\n\nAnd imagine that the data structure was nested five layers deeper.",
            "I suppose that my opinion is that the serializer should have a flag to enable serialization of objects that cannot be automatically deserialized.\n\nIf you enable that flag then you are making clear that you take responsibility for the mess that will result when you attempt to deserialize (assuming that's even necessary in your use-case).",
            "My post states that I ended up using asdict so it not laziness or lack of knowledge as much as curiosity as to why this isn\u2019t the case. As stated before, I just feel that it should function the same as using json.dumps with a dictionary",
            "Is it?\n\nA date can become an epoch, a string, a list of year,day,month, a list of day,month,year.\n\nThose libraries, including the one I wrote, just pick a way to serialize, but it isn't universal at all how to do it. Why prefer an epoch over an ISO string? It all depends on what you have to interoperate with, there is no single answer, which is why in typedload you can override the default serialization of a certain type.",
            ">All I\u2019m saying is that I feel that dataclasses should be serializable the same way and dictionaries, and deserializable (provided the class) just as easily. \n\nI don't understand how this would work.\n\nIf a JSON has: `{\"x\": 1.0, \"y\": 2.0, \"z\": 3.0}`, how do I know whether to deserialize it as a dictionary or a Position dataclass?\n\nSerialization loses the type information needed by deserialization.",
            "You have to write your own, because dataclass attributes aren't inherently JSON serializable.\n\nA lot of my dataclass implementations contain a `to_json()` and `from_json()` function.",
            "It's not true of dicts. Lots of things you can put as a value in a dictionary that aren't directly json serializable...after all, can be a reference to literally any python object including functions and modules.",
            "The json module seems proper to me.",
            "if something for python were as good as serde it would probably get a similar status",
            "I wrote typedload. It focuses more on using standard python types and mypy, while pydantic is more focused on using their own classes and IMHO their mypy plugin isn't that good at detecting issues.",
            "Not sure, but it does add metadata to the JSON as to what class it was to help deserialize it",
            "+1 to Litestar",
            "JSON is a standard for data serialization, but YAML and TOML is also a thing now, it is not the only thing just because you deemed it to be\n\nJson paxkage is built-in, but guess what, so is yaml in the form of pyyaml\n\nWhile we appreciate the enthusiasm, please understand that YOUR understanding is not the only understanding, assuming toml becomes standardized instead, what do you propose python to do - convert ALL json to yaml?",
            ">While we appreciate the history lesson about its origins and name, JSON is a standard now.\n\nI think you might be interpreting them a bit literally. I don't think they were saying \"The J stands for Javascript and therefore Python should stay away.\" I think it was more that converting data into strings isn't a sufficiently all-encompassing requirement of Python in a way it might be for a web-first language whose main way of shuffling data around is via strings. \n\n&#x200B;\n\nThere are a number of pretty simple ways to achieve what OP wants without sacrificing the flexibility afforded by also supporting non-serialisable data types. In a web-first language, this might not be much of a sacrifice and therefore the small extra convenience might be worth it (I'm not a web dev so I don't know!)",
            "you couldn't just leave it at...its a python sub.  Larry Wall does not agree, in fact believes the opposite, and Perl grew up on Unix.  \n\nNuances aside...",
            "> You're not getting it. How would a pure json object know which class to deserialize into?\n\nYou tell it. With the code. \"Please deserialize this JSON object into this dataclass\". Please, take it easy with statements like \"you don't get it\". I eat this for breakfast, lunch, and dinner, but I keep hearing from people who obviously don't work with this, that it couldn't work. I might get offended by this even. We obviously didn't hit it on the very first step, but please at least try to understand what I'm trying to tell you, before going into completely the opposite direction.\n\nProtocols like pickle preserve Schema AND Data. If your code offers the schema, the data will fit right in, as long as it's compatible. Since JSON is most often used as a data exchange format, this should be no problem. This is an insanely well beaten path. This is literally talked about by everyone who has ever touched giants like [Rust](https://docs.rs/serde_json/latest/serde_json/).\n\nWhen someone tells you that you **can** do something, don't start explaining that they don't understand why they can't - it looks bad. Instead, ask \"how\". I promise you, you will find a lot of treasure troves.",
            "> AFAIAA In its current state dataclasses do not require type annotations (in fact outside of type checkers, I'm not sure it even respects them). To enable supporting deserialisation would require breaking changes to the API.\n\nOk, .... weird but ok... Having dataclasses with no type annotations? Ummm... weeeiiiiird.\n\nBut fine, a runtime error could be raised if a dataclass without type annotations is used with serialization. Static checkers like mypy or pyright could even react to this issue before the code is run, as is already the case in my projects, where even VS.Code reacts accordingly when I screwed up something in the same area.\n\n> Another thing to consider is how subclassing works as when deserialising it may be difficult to know if I should be creating the parent, or a descendant, or which specific descendant. It's not impossible, but it's a frequent enough scenario in my experience of Pydantic that it would be desirable to solve here.\n\nUsually, you either have to specify in the `deserialize()` call what type you're expecting, or to have some schema information like `msgspec`'s Tagged Union feature. Just taking any JSON and asking \"please deserialize and guess the type\" is obviously not gonna work. You have to give it some information.\n\n> You'll likely still end up in some kind of \"this other object type isn't supported\" hell, but it would make dataclasses much easier to use for common use cases.\n\nThis is my everyday job. But I use `msgspec` for that. It's really close to what `dataclass` offers. Yet there is serialization, and deserialization features (that's the main goal of the module). It's really not that big of a deal. It works well, and everybody would win if something like this was available in the standard library. There's no hell, and I am able to easily model and deserialize even complex stuff like all of the `kubectl` pod list in JSON format, as well as actual data that I work with, that has tons of optional nested structures of unions of types. Once I define the classes, one call deserializes the whole lot, and another one serializes it back. So if one guy could do it in his library, why would something similar not be part of the Python standard library?",
            "Any design that allows full configurability is going to be pretty complex. (Think through the requirement here). Defaults mean people are going to shoot themselves in the foot. Best to leave for an external library.",
            "isn't it the same?  asdict is recursive according to the docs.  https://docs.python.org/3/library/dataclasses.html#dataclasses.asdict",
            "> If you enable that flag then you are making clear that you take responsibility for the mess that will result \n\nAh, yes.  Brings back fond memories of the `DontBlameSendmail` option.",
            "I'll be a bit more explicit.\n\nThe encoding is done by a class in `json`, `JSONEncoder`. Having dataclasses serializable by default wouldn't be a matter of doing something to the `dataclasses` module, but to the unrelated `json` module. \n\nThere's no easy answer here for optimal design. If you have everything go in the serializer code, then this simple json parsing lib ends up tracking N projects. If you have it look for a `__json__` method or something, you end up with large classes (this is generally how Python rolls). If you have the serialization done explicitly, it ends up more verbose.\n\nThis is essentially the [Expression Problem](https://en.wikipedia.org/wiki/Expression_problem).\n\nI wasn't there when this design was chosen, but it looks like it works pretty well over the alternatives. Of course, code that does exactly what you want at that moment is going to look like the better, obvious, simple, easy choice. You have to stretch your mind a bit and think of how saving a function call may not end up being worth it.",
            "> Is it?\n> A date can become an epoch, a string, a list of year,day,month, a list of day,month,year.\n\noh god.\n\nliterally everybody on all platforms, from MSSQL, PostgreSQL, JS, APIs everywhere, agree that the textual representation of a date is ISO 8601, or at least RFC 3339, which is almost the same thing.\n\nDon't be dramatic. The decision is easy. Support ISO. If anyone has anything else - it's their problem to deserialize it into an intermediary format (ex. int or float).\n\nISO date formats are a standardized format that express dates up to nanoseconds or more, and has many standardized ways to express timezone information, which works for the vast majority of the weirdest of use cases, even if the majority of uses in programming are with UTC.\n\nLiterally nobody is encoding or decoding tuples for this. And if you're part of that \"literally nobody\", I am very sorry, and why do you do this? There's a beautiful world out there where you don't serialize/deserialize dates as tuples. Don't let it consume you. What next? Question why Python doesn't mandate encoding and always assumes UTF-8 unless otherwise specified?",
            ">You have to write your own, because dataclass attributes aren't inherently JSON serializable.\n\nNo. That's not the reason.\n\nIf that were the reason then we'd have to say that it is equally impossible to serialize dicts and lists, because they \"might not have JSON serializable types\".\n\nThe real reason is that DE-serialization of these objects could be quite complex because there is no type information in JSON.",
            "I think you read my comment wrong! \n\nI wasn't implying that it should be better supported.\n\nI was telling the other guy that saying things like \"but json is JavaScript and you're in Python\" is a silly thing to say / is history. The point is that it's a standard regardless of your language. But that doesn't mean that dataclasses must support that standard. That's OP's fight and I don't share the \"enthusiasm\" as you say \ud83d\ude09 \n\nSpecifically about your comment, if you've been in the k8s world a bit you already know how YAML can be a PITA sometimes and how parsers differ. About TOML, it's a nice format indeed! But even then, there's no need to make dataclasses TOML serializable by default either. I don't know why OP is complaining.",
            "> it is not the only thing just because you deemed it to be\n\nDid they say that?\n\n>  please understand that YOUR understanding is not the only understanding,\n\nDid they say that?\n\n> assuming toml becomes standardized instead, what do you propose python to do - convert ALL json to yaml?\n\nDid they say that?\n\nYou seem to have read them saying \"JSON is a standard\" as \"JSON is **the** standard\".",
            "By the way, pyyaml follows the old yaml specs. Personally, I have a lot less issues with the v2 specs. For this, there's \"ruamel.yaml\". I can't stand pyyaml anymore.",
            "I wasn't implying that python had to make json serialization a first class citizen. It's already really good at providing json de/serialization over its native types and there's tons of 3rd party libraries that bridge the gap from dataclasses anyway.\n\nPython de/serialization is something I've been routinely implementing for the past 10+ years \ud83e\udd37\u200d\u2642\ufe0f I'm not a web dev either but consuming 3rd party APIs is what I do every day.",
            "Yeah but perl is also hot trash",
            "[deleted]",
            "Okay, my mistake. Maybe that's good enough.",
            "The problem of type hinting becoming compulsory remains\u2026 and all this discussion was just about ONE type. There's literally thousands of them in the stdlib!",
            "You do have to write your own JSON serialization method, it's the `default=` parameter, or `JSONEncoder.default` if you use `cls=`.\n\nhttps://docs.python.org/3/library/json.html#json.JSONEncoder.default",
            "60hz ac electricity is a standard in the US.  50hz ac electricity is a standard in eu.  The nice thing about standards is that everyone has one.  Python != javascript",
            "When someone is saying something is a standard, you typically get it in the form of \"is the standard\" for said scenario, you're being pedantic and being an ass with the whole \"Did they say that?\" \n\nOBVIOUSLY they meant that, its english mate, I know somethings are not black and white but its not that difficult to tell thats exactly what they meant",
            "Yes, I know about ruamel, but thats not relevant to the topic",
            "Also not the point, i agree, but not the point",
            "You could've started with the fact that you had no interest in a discussion and just wanted to wave your tiny dick around. Would've saved me time instead of trying to talk sense into an arrogant idiot.",
            "... yet despite the problems you're quoting, there's `dict` serialization to json, and nobody bats an eye.\n\nThe only difference is that one of them is an \"object\" with \"attributes\" that have \"name\" and \"value\", and the other one is a \"dict\" with \"pairs\" of \"keys\" and \"values\".\n\nIf the code provides type hints, they can be used. If not - treat them as you would treat a regular `json.loads()`. What is the problem?!\n\nAccording to you, not even `json.loads()` should exist because it literally has all the problems that you listed. It's not constructive, and looks really bad. Think about what you're trying to achieve here.",
            "I never said python is JavaScript. You're hallucinating.",
            "> but its not that difficult to tell thats exactly what they meant\n\nWell naturally, except they clarified that you've messed it up. Come on, it's not that difficult!",
            "So what? \ud83d\ude02 You mentioned it in the first place, this is complementary information.\n\nAre you mad/pissed or something? Did I offend you? \ud83e\udd37\u200d\u2642\ufe0f You're not being reasonable.",
            "Due, this is getting boring. Go here and pitch your idea: https://discuss.python.org\n\nI guarantee it will not be accepted.\n\nDo not reply until you've actually pitched your idea please.\n\nedit: this very mature user blocked me, but didn't go and pitch his idea to the python developers, because he knows fully well that it'd be rejected.",
            "You're right.  You didnt say that.  I just clarified it for you, since you dont seem to understand that point.  Just because Json is a \"standard\" in some languages, doesnt mean its a \"standard\" in python.",
            "You're being unnecessarily rude, obtuse and thick-skulled. This is a forum for discussions. Don't like it - go troll some other place, that's more accepting of your juvenile behavior.",
            "I didn't say it was a standard in Python either. You're again interpretating my comments to fit your narrative.\n\nTelling people they don't understand when you have no idea of their background and experience is a pretty silly thing to do. You're embarrassing yourself."
        ]
    },
    "did someone hit pycharm with a brick?": {
        "title": "did someone hit pycharm with a brick?",
        "score": 186,
        "url": "https://www.reddit.com/r/Python/comments/1917rxi/did_someone_hit_pycharm_with_a_brick/",
        "content": "i keep finding stupid little bugs like false-positives in code-inspection, auto-import failing to find symbols in eg a sister module, all kinds of minor irritata (should be a word so i made it so) that i'm sure were not there before...  \n\n\nits possible im writing more complex code and so making more obscure errors than i used to, but it feels like they're moving too quickly and missing stuff.  \n\n\nelephant in the post is i suppose most of their dev work is currently on the ai assistant which i paid for and uninstalled after a week. it's terrible. copilot-which i also pay for -also has major issues, like chat keeps crashing the ide,...i get way better help by copy-pasting to gpt4 in browser.  \n\n\ni feel everyone is releasing minimum viable product in the mad ai goldrush, and basic shit is going to hell.  \n\n\nrant ends",
        "num_comments": 91,
        "comments": [
            "AI assistant is some kind of a joke for a paid product. Did the same. Paid and uninstalled. \n\nRecently, PyCharm is not loading changes from disk, or it lasts way too long, so I have to manually enforce it. \n\nI am seriously considering switching to VSCode.",
            "I was having some problems with pycharm last week\n\nI reinstalled the latest version and it seems to have fixed it\n\nThanks for the comment about their AI. I suspect it will be better in 6 months",
            "I paid for their AI assistant to play around with at home and was a bit disappointed in it.\n\nIt felt like a hinderance more than anything.",
            "I'd say Jetbrains always had a wee bit of an issue with introducing inconvenient bugs and then taking years to fix them, but the war certainly had a huge impact on making things worse. After all, most of Jetbrain's developers were located in Russia.",
            "I cannot open the git folder. Idk, Pycharm didn't recognise it. But there are files like precommit that I have to open manually by searching these files in file explorer or total commander.",
            "Same experience here. And unanswered support tickets. JB product and service quality has fallen massively.  Btw another person that paid for JB AI 1 year upfront only to remove it. More fool me for buying on the companies reputation than their current performance.",
            "They have spent their limited time on their New UI, which is an attempt to be like VSCode, without realising that it's a huge FU to the users who use PyCharm because it is NOT VSCode.  This means they are placing less importance on fixing bugs in the current product.  Had they been focussing on the actual thing people are using today, they might have fixed this at some point during the past three years.  [https://youtrack.jetbrains.com/issue/PY-44858](https://youtrack.jetbrains.com/issue/PY-44858)\n\nLately, the AI plugin (which you cannot uninstall) seems to be   \n to be causing editor and terminal windows to stop responding to keystrokes [https://youtrack.jetbrains.com/issue/PY-65643](https://youtrack.jetbrains.com/issue/PY-65643)\n\nThese two were as nothing in comparison to how **appallingly** slow all the JB products were becoming on Linux until the release of JDK17, although, we had to wait until JB released their own version to have a stock (unadulterated) installation.\n\nI hope they turn it around, but the product strategy seems to be one of attempting to please all the people all of the time, which never works.",
            "I had to rollback to the last version.  I several stability issues out of the most recent.",
            "I'd say the last 6 months or so the bug count has been been climbing. Code inspection/linting is now a joke honestly, it's just so bad. And the bugs and IDE slow-downs using docker compose are getting worse and worse.",
            "Yessss the last couple of years have been rough, but specially, the most recent release I hit a bunch of weird bugs that I couldn\u2019t reproduce (which made my support tickets tricky to explain). \n\nI really feel like the quality of the product has been going down.",
            "No issues here while working on a code base with around 50k locs",
            "A lot of problems. \n\nOne thing that bother me is, you can't code in .devcontainer. They have one in beta, but it's called \"Remote coding\" ? And I have to download > 800MB every time I open it and it lags a lot.\n\nI'm using VSCode, but my god. I can't stand VSCode as well and there is no alternative as well.",
            "Inspections are a complex feature. Especially for complex code. It's ok that PyCharm can't understand logic flow on each case. Still helps a lot.\n\nI'm using EAP so I get confronted with bugs early. I'm mostly annoyed of IDE exceptions. Often multiple one on simple text operations. But I always report them and currently it's silent.\n\nFor those who prefer VS Code: Open a typical project which is made without PC now in PC. Even when CI/CD with several precommit hooks is enabled on their git repository.\nYou'll probably see many code quality issues. I've checked moviepy recently for example. Horrible!\n\nMy recommendation is creating high quality bug reports. They'll addressed if they're a priority issue.\n\nAnd disable plugins you don't need. Reduces IDE problems and resources.\nI've enabled IDE settings sync and some or new ones get reenabled some times.",
            "We are a small startup and live coding. My business partner uses Pycharm and I use VSCode and our experience is that both have their quirks and drawbacks and probably the more you use eacg the more quirks you'll uncover. I personally dislike how much pycharm does \"under the covers\" so that your code works great in the IDE then you try running it standalone and have to fix stuff. One thing I don't like about VSCode is the File Explorer not having the size and date columns and not being able to sort on those.",
            "PyCharm was reeally damn good in like 2017 but it just hasn't kept up at all.",
            ">irritata (should be a word so i made it so)\n\n'Irritants' is already a word, you don't need to invent faux latin.",
            "Someone thought en Passant is NOT forced so PyCharm got their pipi bricked.",
            "Just curious, are there any reasons why people use PyCharm over VSCode? Over the last years VSCode has evolved into much more than just an editor. I see no reason why not to use it. I keep hearing so many problems regarding PyCharm as well.",
            "There's a free plugin called [CodeGPT](https://plugins.jetbrains.com/plugin/21056-codegpt) that will let you use OpenAI or other (even local) tooling instead. So at least you could avoid the context-switch when copypasta.",
            "You are absolutely right. Uninstalled PyCharm and started to use vscode. Also whatsup with their themes?",
            "pycharm is the only tool I ever paid for, and mainly using it for python and nodejs. No clue what kind of issues you have and why.",
            "Wish I could upvote twice",
            "I had a paid subscription for about 4 years, then I switched to VSCode (mostly because of ssh remote development), and uninstalled pycharm.   \nUsing VSCode about for 3 years,  and I'm so happy with it.",
            "This is exactly the reason why I switched to VSCode last month. \nI regret not doing so earlier.",
            "Just use NeoVim",
            "You guys need to join their AI service now so I could use their service too. /s",
            "Lol, PyCharm is a POS. VS Code master race.",
            "errata?",
            "In the last week I'm finding the AI assistant quite useful. In fact, I have cancelled my co-pilot subscription, although I was only monthly on that and I'm not sure that decision will stick, it is a deliberate experiment. I think that it makes recommendations better tuned to the actual project I have open. This is  very subjective. And I have an openai api subscription and a client (chatbox) open nearly all the time so I still have chatgpt 4 on tap. If I do end up using the JetBrains AI plugin more, it will only be because it really is better. Time will tell.\n\nAs to the other complaints, I don't notice those problems. I am using it on linux (actually in a linux VM mostly, and on the VM I use a docker compose dev setup).\n\nI use vscode for specific niche projects, smaller ones, to increase my familiarity with it. It's a good editor and is innovating fast and building a strong ecosytem, but it's not yet a pycharm replacement for complex work. Pycharm Pro only has to save two hours a year to pay for itself (compared with what vscode offers). I think it easily has this advantage.\n\nThis biggest cloud on the horizon for me was the seemingly distant move to native wayland support but this effort is moving more quickly than I expected, once it finally got started. It's still years too late but it looks like it will be ready in the next 12 months.",
            "I have somewhat similar experience",
            "I've been using Phind for Rust and its been pretty solid as a companion junior dev to remove boilder plate generation",
            "PyCharm's is bad at utilizing type-hints. They really need to get their act together or they'll lose all users which use type-hints to VSCode or similar.",
            "I have both, I have VS Code all set up for specific work and pycharm is my all other python IDE.",
            "Already made the switch.  Vscode has its own issues, but I can't say I miss pycharm. My coworkers are getting increasingly annoyed with pycharm as well.",
            "I made the switch last week after 4 years of use. It got really bad in the past year. Now even autosaving has issues, it's insane.",
            "Same. Pycharm's container support has been a disaster for me lately, and now it's freezing when trying to load a 2.8 GB csv file which...I'm sorry, in 2024 that's not very big, and I have dealt with larger, IN PYCHARM, in the past. They have the resources, I just think they have a disconnect with their user-base on what they should be working on.",
            "Lol do it you'll wonder why you ever used Meek ass pycharm",
            "you know ctrl alt y for force refresh?",
            "I didn't know that.",
            "i guess itll improve.... maybe even in under a year ![gif](emote|free_emotes_pack|laughing)",
            "I don't like vs code the things I use PyCharm for but consider the new UI to be one of the best improvements over the last couple years. It removes a lot of wasted space and lets me see a lot more code at once. It doesn't really have any negatives in my opinion.\n\nI haven't felt that the Linux versions were slow, but I have pretty powerful hardware, so I expect it is a real issue for people with less resources.\n\nThe AI is about what I think we can expect from this type of thing at the moment. My company uses LLMs for cybersecurity work and I have some grad work in the area. It can be helpful, but there are limits that will need significant breakthroughs to surpass. Since you can do a trial, I find it pretty fair. It's not like they're making money on this. I'm guessing they break even or make a loss with that price. It's pretty expensive.",
            "Why can't you stand vscode",
            "> there is no alternative as well\n\nDepends on your use cases. Vim is enough for almost anything and you don't depend on some company decisions.",
            "Did you try Fleet?",
            "Remote coding over ssh is also incredibly janky, a lost connection takes several minutes to reset while vscode does it in a couple of seconds.",
            "yeah i submitted my first issue over the holidays, was able to make a decent mre and they were relatively quick to reproduce and escalate. i mean, they haven't fixed it, but still...\n\nhttps://youtrack.jetbrains.com/issue/PY-65385/inspection-false-positives-when-import-asynccontextmanager",
            ">Inspections are a complex feature. Especially for complex code. It's **ok** that PyCharm can't understand logic flow on each case\n\nIt' ok for code which is not properly type-hinted. It is not ok for properly type-hinted code. Which pycharm fail at in various ways **all the time.**",
            "[deleted]",
            "It's a pun on errata.  As a frequent user of hardware data sheets, I found it funny.",
            "It's playful and signifies \"minor irritants\" vs \"irritants\" so it does add more context. Lighten up.",
            "thanks, duly noted, i'll keep my linguistic levity to myself if i see you at a party.",
            "PyCharm was the only game in town for a long time, did lots of things that others could not because it was python specific.  So people (like me) got used to it.   \n\nIt just works out of the box for what I need it to do for python.  It understands python to a degree that even VSCode now does not.  It understands the python ecosystem better.   A tool designed and built to do a specific thing works better than a general purpose one with plugins to fill in the gaps.  \n\nThat said, VSCode has been getting much much better.  I do my c++ coding in it, so I have been learning it much better, so the difference between pycharm and vscode for python has been narrowing.",
            "I can't stand VSC for the same reason I hate excel: universal tools suck at most of what they do.",
            "tried vscode, but vim plugin sucks.",
            ">d PyCharm and started to use vscod\n\nIs there a free AI service available to use with CodeGPT?",
            "my jetbraons ai very rarely notices what i have open, i have to repeatedly tell it where to look, even using specific symbol names in the prompt,,,, with copilot i can just copy paste an error and it refers to specific source code in its response.",
            "I know I should just Google, and I will, but what's phind? Is it relevant to python? I've got rust on my one day list, along with umm, I forgot, the new superset of python that's supposed to be better but isn't really actually built yet.\n\nEdit... Mojo",
            "https://blog.jetbrains.com/blog/2022/12/06/update-on-jetbrains-statement-on-ukraine/",
            "I'm not sure if that's a fair characterization or not. I know R&D was in Russia before the war, and that was maybe half of their 1.8k employees. That might mean dev was there too but it's unclear to me. The three founders are Russian, but the company is Czech, and the founders are in Prague. Now the Russians are no longer using Russia.",
            "this thread is not about the utility of features, so much as it is the quality of the existing system *at the expense of* adding new features.\n\nno need to brag about your hardware.",
            "[deleted]",
            "My biggest reason is extension hell. I hate using incoherent tooling and depending on an extension marketplace where different developers can have different philosophies on how to solve problems is very jarring. Using it always just feels like a patch work mess. That's my biggest issue with it. I have 1000 more, but the lack of a centralized and opinionated vision of how to code is what bugs me most.",
            "The same reason I can't stand one-size-fits-all cloths.",
            "I had no idea this existed. Will take a look. Thank you!",
            "vscode + pylance feels like the only good option.",
            "Pycharm has native support for virtual environments right out of the box, and that's the big plus over vscode for me.",
            "[deleted]",
            "I don't know of any free ones that aren't ones people are running on hardware they own or cloud servers. I recall openai gives some free credits for signups.\n\nMy comment was really for OP because they're using gpt-4 so I inferred they have a paid account. Apparently it's an unpopular thing to bring up a plugin I have experience with that works on my terms!\n\n[Ollama](https://ollama.ai/) and [text-generation-webui](https://github.com/oobabooga/text-generation-webui) provide local OpenAI interfaces and selections of models, some folks run text-generation-webui on gpu-enabled cloud instances to lower their cost, but it's all very... not simple. If you want to know more, /r/LocalLLaMA has a lot of great state-of-the-art info.\n\nI use CodeGPT (usually from my laptop) with text-generation-webui running on my gaming computer, for inference. There's limits to my hardware, but my code isn't sent off to OpenAI or some other vendor for evaluation and I like that.",
            "Wow. I mean obviously any statement from a company is going to make them look good, but if jetbrains have paid to relocate 800 families, and reorganised their entire physical company integrating staff into presumably already used buildings etc, is pretty awesome. \n\nNot sure many governments have done as much for their people.",
            "Not to get into a meta loop, but splitting hairs between 'half' and 'most' is probably unnecessary... I didn't know there was a Russia link at all, and thank u/voneiden for the knowledge...\n\nIt seems prima face obvious that this would cause them issues atm... If anything it makes me more understanding - I can't imagine what they've had to deal with to keep their awesome product on track given the situation.",
            "Talking about the hardware is giving a caveat that even though I have only noticed improvements by moving to the new UI, I understand that someone with poor hardware could experience something different. If that made you feel bad, that wasn't my intent. The only quality issues I've seen are with the AI features, but they are in line with roughly what I think is possible. That's also a new plugin, and when they had a free trial, so certainly not a quality issue with an existing system. There was also an issue or two with 2023. 3.2 while I used 3.12, but moving to .3 seemed to fix that pretty quickly for me. New releases are allowed to have issues. \ud83e\udd37\u200d\u2642\ufe0f It happens",
            "this. a year ago i found pycharm absurdly useful, especially with all the pro trimmings like django and fastapi integrations, database tooling, and the click through linking between all kinds of stuff, im sure people can make vscode or even neovim do all this but i want to write python not spend a week making an rc or working out 20 plugins not to collide.\n\n&#x200B;\n\ni might just roll back to last year",
            "Same reason I prefer Django to Flask for anything greater than a super small project.",
            "Darn, if only VS Code wasn't size \"OSFA\" at Target. So... what's your problem with VS Code? It can do many things relatively well, and the extensions for major languages are well maintained. Do you not like >!Electron!<?",
            "[deleted]",
            "That's also the case for vscode now too! I guess it's not oob since you have to install the official python extension but you'd need it anyways!",
            "Not sure about data injection, but for typing it's very good. It has pyright and fully understands it. Pyright is basically the core of the python extension, so depending on the \"level\" you set it at, it will do all of that you said. You can also control specific cases that you want it to highlight, warn about or mark as an error (or not).You can also add in line typing \"hints\" that are basically an overlay that add inferred types even when the type hints aren't there",
            "thanks dude i appreciate the tip. \n\nif i give codegpt my openai creds, is it going to rack up charges? its free in the browser... well, not free, but included in the monthly fee",
            "I don't mean to split hairs on that word. Mostly I am simply saying that how much influence Russia could have had over it is probably small. The nationality of developers isn't relevant directly after all. The more important thing is if a power hostile to Western countries has a way to influence code changes. I'm not even saying that it doesn't but that it isn't clear. Personally I have trusted the products, mostly because a lot of really large capable entities also do.",
            "[deleted]",
            "the refactoring tools are immense!!\n\nstill a big pc fan, just tired of losing an hour trying to fix an obscure bug that it turns out never existed... i mean i learn a ton each time but i'd like to get more work done",
            "Yeah I am pretty sure using the OpenAI API requires a paid account and uses a token that is generated from that account. And codegpt would use that and cost money. But since OP is already using a paid account (because they're using GPT-4) it seems like an option.",
            "No i think you misunderstand certainly my, and I think the other poster too... My point is that if a chunk of your staff live in a place that becomes - whatever Russia has become to the rest of the world - then it's going to seriously interrupt your company... No judgement needed on the morality of any party involved in conflict, but if a bunch of your staff suddenly need to move because they can't bear their government, or might be vulnerable to abuse due to their engagement with the west, then there's really no avoiding a detriment to the product",
            "I'm on latest, 2023.3.3 or maybe .2... And I first started getting properly annoyed with 2023.3.1.. Enough to turn one of the bugs into a mre and report it... But it takes time to rip out all the actual logic and make a mre and I cba to do it with all the little niggles... \n\nRecomend you stay on 2023.2.x for time being.... I mean the new ui is pretty, but I kinda prefer getting stuff done to an attractive image... \n\nhttps://youtrack.jetbrains.com/issue/PY-65385/inspection-false-positives-when-import-asynccontextmanager",
            "Didn't see the delete .idea point, will try that! Thanks\n\nI've done invalidate caches and reset ide process a bunch of times to no avail.\n\nTruth is I'm an advanced beginner or early intermediate, and I'm often dabbling in stuff I don't totally understand, which is much of the problem - my humble nature means I forget to consider that the obscure ide warning might be bollox, often losing 20 minutes trying to solve it before just running the code and seeing its fine. The bug report I linked above is one such example -  importing a context manager makes it say nonexistent params are missing, and fail to inform when actual params are actually missing...",
            "I am op \ud83e\udd23 and I have an openai subscription hence using Gpt4 as you correctly sumise...\n\nIf I use Gpt4 in browser I am not charged anything on top of the subscription, I'm asking if using Gpt4 via codegpt will rack up further costs?\n\nMaybe I misunderstand their pricing system, but I've avoided using api keys to connect it to anything because I thought accessing other than via browser incurs further charges - can you confirm either way?",
            "Right, /u/PaluMacil may also underestimate the amount of employees they had in Russian R&D offices, but there is no hard data available so it's a guessing game. Jetbrains themselves wrote that they managed to relocate \"the majority of their workers out of Russia\" with the number of relocated was \"well over 800\".\n\nMajority could be 75%, or 60% or 51%, who knows. I'm sure many opted to stay in Russia. It's never an easy decision to relocate.\n\n [Some other folks estimated there was office space for 1500-1600 workers in Russia](https://news.ycombinator.com/item?id=30639907).",
            "Oh! I'm sorry, I rely on the highlighting to note who OP is but I must have replied directly from my inbox. \n\nI think you're correct, you will incur charges when using the api key. I just reviewed things again and I was combining the \"ChatGPT Plus\" subscription and the OpenAI API access.\n\nSo, API access is usage-based, and 100% independent of the monthly ChatGPT Plus subscription. That sucks, and sorry to mislead with my mis-remembering their billing structure. \n\nThe API access isn't very expensive, but I obviously chose to go the local route - partly because of their billing, partly because I was super irritated by all the damn disclaimers and limits, and partly because I wanted a better understanding of how all this is put together.",
            "There might have been space for that many, but I thought I remembered hearing that the company had about 1800 people total globally. I also thought I remembered being a pretty small number let go when they left Russia--over 100 but under 200. That puts it maybe at half or maybe a bit more Russian. But again, my point isn't the exact number but that I'm not sure we know that the company had a risk of Russian government control or other things we should care about. The nationality of the developers shouldn't matter. Potentially having influence from a country hostile to western countries is a concern to some people, but I just don't know that's the case. A lot of big companies trust their products.\n\nIt's totally possible I am remembering random numbers, but I thought I remembered these numbers mentioned on Reddit, so perhaps looking through comments from some of the known employees here would shed light, but probably not worth the time.",
            "So what- you're running lama on a gpu at home or something?",
            "Many of the developers working at EU offices were also of Russian background pre-war AFAIK. After all they can simply have a work permit or a dual citizenship. You can get a glimpse via [glassdoor reviews](https://www.glassdoor.com/Reviews/JetBrains-russian-Reviews-EI_IE222299.0,9_KH10,17.htm).\n\n> risk of Russian government control \n\nI've not made this kind of point, but I do agree with you. I maintain the point that they lost significant developer resources (even if it is only 100-200) due to the war and it most definitely had an effect on productivity for at least some period of time. How well they have recovered by now I don't know, but 2022 most certainly was not a good year for the company. And catching up takes time.",
            "Yeah via https://github.com/oobabooga/text-generation-webui with llama.cpp and models from huggingface. /r/LocalLLaMA is a good resource. llama.cpp will also allow loading partially on-gpu and partially in system memory, but it's quite a bit slower in system memory.\n\nSome psychopath (/s) got a tiny model running on their samsung watch: https://www.reddit.com/r/LocalLLaMA/comments/18v3l4a/llama2c_running_on_galixy_watch_4_tiny_44m_model/",
            "I guess it's burried in the comment forest now, but wish could make this top comment - thanks!",
            "I've been putting off ml for what feels like too long but this has me salivating....\n\nSorry to keep asking things I should just Google, but I have a amd 5700xt...soon after I got it - when it was pretty fresh and impressive - i was told its pretty crap for ml because drivers, and libraries... Do you know if that's still broadly accurate?"
        ]
    },
    "Fastest Way to Read Excel in Python": {
        "title": "Fastest Way to Read Excel in Python",
        "score": 114,
        "url": "https://hakibenita.com/fast-excel-python",
        "content": "",
        "num_comments": 29,
        "comments": [
            "Polars don't support excel yet? (I have no Idea, that's why I ask)",
            "I really appreciate this!! I worked on something about two years ago that involved loading rather large excel files using Python and I wish I had it then :)",
            "This is really interesting and well written. You have clearly put a lot of time into the research. \n\nTo your first paragraph, I don\u2019t have data on this either, but I am quite certain that relational dbs and/or flat files are still the most common way to store data.\n\nI\u2019m curious to know what inspired you to research this. I used to work with python and excel a lot, but speed was pretty much an afterthought. Were you reading in hundreds of large excel files a day or something?",
            "Nice analysis OP. Sometimes I have wondered what is the quickest way to either grab sheet names or column headers without loading the whole workbook.\n\nWill give some of those options you have suggested a go \ud83d\udc4d",
            "I just switched to `python-calamine` for a script that reads some metadata sent to us via a large Excel sheet, previously I was using `openpyxl`.\n\nIt improved reading the Excel file from ~30 seconds to ~1 second, which was the significant majority of the task times so they now all complete in ~5 to ~15 seconds.\n\nI would say that `python-calamine` is not very mature yet, so if you're looking to do anything other than basic extraction of tabular data it won't be any good for you. But if you are opening large Excels and just doing that it's great. Looking forward to them adding performant iterable support: https://github.com/dimastbk/python-calamine/pull/43\n\n> The only red dot here is because our integer was interpreted as float - not entirely unreasonable\n\nI also had this same issue, I've not yet gone through the github issues to see if it's something the project has made a decision on. It was very quick to just do something like:\n `(int(val) if val.is_integer() else val) if isinstance(val, float) else val`",
            "OP I just ran a couple of benchmarks on a gnarly Excel file I had with 50 worksheet but not huge in size < 2 MB. All I wanted to do was grab the sheet names.\n\nThe performance difference between pandas read\\_excel and a calamine was stark! Based on 1,000 runs pandas completed the operation in 61 seconds and calamine did it in less than 0.8 seconds!! **Pretty amazing speed up of x80!**\n\nThanks for sharing that calamine package I will keep it in mind for next time working with largish Excel files.",
            "This is awesome, and exactly the kind of in-depth comparison I've been looking for to speed up our ETLs. Subscribed.",
            "Thanks for sharing! Calamine is supported with pandas.read_excel in soon to be released pandas 2.2 (see https://pandas.pydata.org/docs/dev/whatsnew/v2.2.0.html). Would be cool to see an update in the article after that!",
            "I thinks the best is Pandas: [https://camkode.com/posts/simplifying-excel-file-handling-in-python-with-pandas](https://camkode.com/posts/simplifying-excel-file-handling-in-python-with-pandas)",
            "Pandas (as well as Polars) supports use of calamine as an engine.",
            "Any ideas to combime this camline engine and parallel read excel files will be much faster even 2x 4x ... limit by your cpu cores \ud83d\ude02 ?",
            "Curious that the benchmark doesn't include xlwt which was the standard way of reading/writing Excel files in Python for years (and which I still use today).",
            "[deleted]",
            "I actually looked at polars for this. It uses xlsx2csv or openpyxl under the hood. Openpyxl is already included on the article, so I benchmarked xlsx2csv on the large file and it was ~36s (longer than pandas even). I ended up leaving it out. \n\nhttps://docs.pola.rs/py-polars/html/reference/api/polars.read_excel.html",
            "The opening paragraph is mostly for color ;) \n\nThe motivation was a large Excel file from an external agency we needed to load into our system on daily basis for a period of several months. The loading process was a manual multi-step from a web interface so I wanted it to be fast so it won't hold-up workers.",
            ">Were you reading in hundreds of large excel files a day or something?\n\nYes! My current use case (and why I searched and found this) is bringing in hundreds of excel files being used as a form for industrial engineers, processing all the data and uploading to a database. A HUGE amount (98%) of my current runtime is due to Pandas read\\_excel() function. Will definitely be looking into refactoring with Calamine.",
            "There's probably an even faster way to get that info. Probably by opening one or more of the XMLs that make up the Excel file and grabbing only the first row (for the headers). \n\nThat said, I don't know of an *easy* way to do that, so following this article will almost certainly save you time in the long run.",
            "That's awesome! Thanks for sharing",
            "That's amazing. I did not benchmark just getting the sheet names. Given your results, I suspect pandas is doing a lot of unecessary work to get the sheet names. You can check that by trying to read the sheet itself next. If my suspicion is correct, is should be instantaneous. \n\nThanks for sharing!",
            "Thanks, that's good news!",
            "Isn't xlwt used for old format Excel files, xls?\n\nBenchmark uses the newer format xlsx.",
            "I don't know of a way to query Excel files on SQLite.",
            "I see. Thanks for the work, though!",
            "Polars has support for different excel engines as described in the link you posted. ;)",
            "You should leave the comparison in. There's no reason to hide Polars poor performance.",
            "Hhaha, but you are right, it\u2019s definitely the most widely understood way to store and process data :)\n\nWow what an interesting use case! Thank you for introducing me to a lot of libraries that I hadn\u2019t heard of. I wish I had seen your work during my old role. Making tools to automate excel reports was fun. End users also appreciate it so much. The data science community always kinda poopoos excel, so I\u2019m glad ppl like you are giving it more attention!",
            "[deleted]",
            "Right. The article is focused on xlsx (not the old format xls).",
            "I don't think it's polars problem. It's the underlying engine. You can say the same about pandas.",
            "That will be slower than every benchmark in his article. First of all it\u2019s an extra step. Also dumping a big file into SQLite can be relatively slow. And even if it wasn\u2019t, excel files generally aren\u2019t normalized. So it just defeats the purpose imo.",
            "If the testing shows that they are both equally slow then the post should show both of them with that result."
        ]
    },
    "The Python Mega Course is still free on Udemy": {
        "title": "The Python Mega Course is still free on Udemy",
        "score": 1026,
        "url": "https://www.reddit.com/r/Python/comments/18tn8y0/the_python_mega_course_is_still_free_on_udemy/",
        "content": "As some of you may know, \"**The Python Mega Course: Build 10 Real World Applications**\" is one of the top Python courses on Udemy. Last year, I made that version of the course available for free to the Reddit community, and I am doing the same today. \n\n In 2023, the course attracted 20,000+ students and collected 900+ reviews, achieving an exceptionally high average rating of 4.8/5 on Udemy. This makes the course exceptionally highly rated on Udemy.\n\n**How can you get the course for free today?**\n\nThree simple steps:\n\n1. Login to Udemy.\n2. Go to the course page: [https://udemy.com/course/former-python-mega-course-build-10-real-world-applications/](https://udemy.com/course/former-python-mega-course-build-10-real-world-applications/)\n3. Enter the password **mega\\_course** to get the course for free.\n\nThanks and have a relaxing end of the year!",
        "num_comments": 166,
        "comments": [
            "Already purchased this over a year ago; it's a great course and I highly urge anyone on the fence to go grab it while available.  Ardit does a great job of pacing things, and breaking the learning out in to guided and unguided practice.",
            "Thank you. I have signed up. \nI have read the reviews all good except for a few that don't even care to explain the low rating. One does mention not understanding 'concepts'. I'm like, dude it's 2023 there's chat gpt,bard, WhatsApp ai amongst other free resources to understand something better. Just lazy!\nAll in all thanks for this, will start in the new year",
            "Claimed; I'm intending to expand on my VBA-based programming knowledge using Python, and this will be invaluable!\n\nThank you, and Happy New Year!",
            "I was in bed, mindlessly scrolling Reddit when I saw your post. I can't explain how fast I got up and went to boot up my pc ! Thank you so much for providing this type of amazing material.",
            "Thanks man! \n\nHow long will access to this last?",
            "Very kind of you /u/Ardit-Sulce! \n\nAs /u/Atomaholic I am expanding VBA to Python and have a data Science Course lined up, this one will be great to start!",
            "What are the 10 Real World Applications?",
            "This looks lovely! Now to figure out how to consistently work on a course with adhd",
            ">Thanks and have a relaxing end of the year!\n\nWell my college decided to keep endsem on 1st jan but thanks for the course. Enrolled!",
            "Thank you! This is very generous:)",
            "Thank you so much! Happy new year everyone let\u2019s make it our best year 2024!",
            "Thank you!",
            "Thank you",
            "Thank you so much for this. God bless you Sir !",
            "Hi, I recommend you to check out the FREE Python course on [crookshanksacademy.com](http://crookshanksacademy.com) by the god of python himself. The course is short and you also get to do a hands on internship after your course completion. Although that internship is unpaid, it is a good and fun learning experience that makes you industry ready. The FREE PYTHON BOOTCAMP is available on: [https://www.crookhsanksacademy.com/python](https://www.crookhsanksacademy.com/python) . Do check it out.",
            "Thank you",
            "Many thanks !",
            "\ud83e\udee1",
            "Thanks!",
            "thanks mate",
            "Thanks, been learning Python for Maya using chatgpt and your course should definitely help fill in the gaps that I don't understand. \u2764\ufe0f",
            "Course outline looks amazing! Thank you Ardit.",
            "This is amazing! Thank you so much.",
            "Thank you!",
            "Nice thanks",
            "thank you so much!",
            "Enrolled, thank you! I\u2019m familiar with python but always love to learn :)",
            "Claimed!",
            "Thank you so much",
            "we going to the moon with this one",
            "Thanks, very generous!",
            "Thank you!",
            "Thanks alot",
            "It ain't coming could anyone help?",
            "Thank you",
            "Thanks!",
            "Many thanks brother",
            "Thank you! Ardit![gif](emote|free_emotes_pack|thumbs_up)",
            "thank you!  bro",
            "Thank you!",
            "Thanks!!",
            "Thank you!",
            "You\u2019re a hero!",
            "Thank you",
            "Thank you \ud83d\ude0a",
            "thanks OP!",
            "Is there a Java or c++ equivalent",
            "How do you get support for these kind of courses like when you get stuck on something and the videos just don\u2019t clarify?",
            "Thank you very much.",
            "Darn! I was too slow the coupon says inactive or expired.",
            "Thank you",
            "Thank you I grabbed it",
            "Thank you!",
            "Enrolled.. thank you \ud83d\ude0a",
            "Thank you!",
            "Buy an ad",
            "Thank you!",
            "thanks",
            "Thank you so much! \ud83d\ude4f",
            "Thanks, you are a star!",
            "I am getting a \u201ccourse is private\u201d screen. Did it just end?",
            "[deleted]",
            "An excellent course, take advantage if you have not. Ardit, thank you again!",
            "Thanks for sharing this. I'm looking to break out of Helpdesk Support roles and aiming to work more in the Cloud and maybe DevOps space. I will be sure to feedback how the course goes!",
            "Thank you Ardit, very generous of you. Wishing you the best for next year. I\u2019ve informed my brother who already worked in IT about this.",
            "Thanks, I entered the course and will finish it once my NLP course (NLP - Natural Language Processing with Python) is done :)",
            "That's very nice of you. I'm enrolled and happy holidays!",
            "Thanks for your generosity",
            "Thanks for this, I\u2019m sure it\u2019ll help a lot. \n\nWas just wondering which section do you cover APIs and also if there is one, which project uses an API?",
            "\ud83e\udee1",
            "Thanks for sharing this deal.",
            "Very kind gesture u/Ardit-Sulce.",
            "\ud83d\udc10 thanks so much!",
            "thank YOU!",
            "Thank you!",
            "Thank you very much",
            "Just when I needed this. Thanks man",
            "Claimed, thanks a lot!",
            "Thanks so much for this",
            "Thank you very much. I will prepare for the fresh start of the new year <3",
            "Thanks!",
            "Tnx, though just to mention he has a updated course with over 50 hours of content and 20 applications now.",
            "Not related to the topic, if anyone knows of a free mobile development course (iOS, Android), please reply.",
            "Thanks buddy, I was just killing some time on Reddit and found this gem, being meaning to iron out my Python and learn the tooling to build complete applications. This is a huge happy accident, thanks!",
            "Love this! TY",
            "Thanks",
            "Just started teaching myself Python, thanks so much for this!",
            "Thank you!!!",
            "Thank you! I'm doing the \"100 days of code\" course now and would love some real-world follow-up. I subscribed and will be doing it after this one.\n\n&#x200B;\n\nThanks again!",
            "Thank you so much!!!!!!!!!",
            "Thank you",
            "Very nice of you. \n\nHappy New Year !",
            "Thank you and happy new year to everyone! Best of 2024 ;) ![gif](emote|free_emotes_pack|snoo)",
            "Cheers, just enrolled, the course looks great, will start on it as soon as I finish 100days of coding!",
            "Many thanks !",
            "hahah hilarious im using your learn python in 60 days and you suggested this page now i get another awesome course thanks!!",
            "Thank you \ud83d\ude0a",
            "Thank you friend, what a wonderful gesture. Looks like a top notch course. Excited to get stuck in :)",
            "Thank you boss",
            "Thanks man",
            "I have an account, and it doesn\u2019t seem to appear on the app when I search for it.",
            "Thanks!",
            "Thank you.",
            "I enrolled, thanks a lot.\nRight after the introduction video, it says this is old course and provides link to new course which is not free . Is it supposed to be this way or did I land on wrong page ?",
            "Thank you very much I really appreciate your donation to the community and I would sure love to watch it! I looked at the lessons title its looking very promising!!\nIf I enrolled now would I have that forever or is it free for a certain amount of time? I'm currently learning js but was thinking about learn python after.",
            "You have to go exactly to this link BTW. You cannot search this on the udemy website since it's a private. Then it will ask for a pass word.",
            "Thanks for this. I did a few hours yesterday and it's great so far. As someone who hasn't done any programming since Fortran and MATLAB 15 years ago, I'm enjoying it a lot. It's something I've been meaning to do for years",
            "thank you! happy new year",
            "This is good for Data analyst?",
            "I am not able to access the code. Does it still work?",
            "u/Ardit-Sulce how does the non-free (oudated) course compare to the newer (paid) course ? What has been updated, so I can better make a decision to buy the new course or not.",
            "![gif](emote|free_emotes_pack|joy)",
            "I know this is already a huge free-bie , is there any other courses anyone knows about like this? i love collecting knowledge for when i have a friend in need",
            "Thank you so much!! \ud83d\udc4d\ud83d\udc4d",
            "Really really appreciated",
            "Thank you!! This is my first time giving it a try. It's basically coding right. Am getting flashbacks to web design classes.",
            "Thank you very much.",
            "Thank you so much!!!",
            "Awesome, thank you for sharing!!",
            "Thanks so much for this. Just starting some videos and some of them have a clear white-grey bar in the buffer bar which seems to skip a small part of the video. Does anyone else have the same problem?",
            "Thank you very much!!",
            "Can you share any more private courses? Preferably cybersecurity related",
            "Thank you!!",
            "Thanks for sharing. You da mvp.",
            "Will I get a certificate for completing it?",
            "Can I DM you? I want to know a few things about this course.",
            "There\u2019s a WhatsApp AI??",
            "Moving from VBA to python is a very smart career move",
            "I did the same rn lol",
            "Once you enroll, it's forever, as long as your account lasts. So enroll now.",
            "You really have to click on the link and then Course Content, you will see the projects and what else is included too.",
            "Well, then, Happy New Year!",
            "Same to you",
            "Ask for help on the many Python subreddits, or ask a chat bot like Chat GPT, or Google it. You many many options!",
            "Worked fine for me. Try a different browser",
            "Did you type in the password?",
            "I just got it this moment via the link in the post.",
            "I cannot publish a course for free on Udemy if it is more than 2 hours long and this course is 32 hours long. \n\nSource: https://teach.udemy.com/changes-free-courses/",
            "Yes, it has data analysis projects inside.",
            "You may run into some issues with some of the library versions in the older course. The newer courses use newer versions of the libraries. The newer course also has a new set of 20 applications. The older one has 10 applications.",
            "Hi, the OP/Instructor here. Can you please point to one video that has that issue? I will have a look.",
            "Yes",
            "Surely",
            "Ya?   \nYou thought those \"friends\" you're chatting with are real people?",
            "Yes there is a WhatsApp ai. Pretty handy, I hardly Google anymore. Just ask the AI, and when the answer is not clear I ask for it to elaborate. Pretty neat",
            "whatsapp ai what? they making huge money selling out data",
            "VBA is going to be the COBOL of the 2030's. All those worksheets and access databases...",
            "Requires an account and I don't know if I want to make one yet",
            "Is there a time limit for how long the material will be available ?",
            "Really? I logged into Udemy using Chrome and then typed in the code in the coupon area and it gave me that error. I suppose I\u2019ll try on safari",
            "You can distribute coupons that will make the courses free if you want.",
            "Great!\n\nThanks  a lot!",
            "Hi Ardit, I definitely found it on the course intro video and perhaps the intro to section 1 also. Next time I\u2019m on I will retest to see if it still the case",
            "Replying again - I\u2019ve noted that it\u2019s the videos of you rather than the voiceovers where I\u2019m having the issues.",
            "Even though it\u2019s technically free ?",
            "Everyone's a bot except you?",
            "LMFAO",
            "That\u2019s what we have LLMs for :)",
            "Web Mapping (create an interactive map)\n\nControl Webcam and Detecting Objects\n\nData Analysis\n\nWeb Development with Flask\n\nGUI App and SQL\n\nMobile App Development\n\nFlast and PostGreSQL - Data Collector Web App\n\nDjango and Bootstral - Blog and Translator App\n\nGeography Webb App with Panda and Flask\n\n&#x200B;\n\nI would suggest to make an account, Udemy is great!",
            "Forever x Infinity!!",
            "I just signed up a few mins ago, it still works.  Make sure you have the \\_ in the code.",
            "I've just done it on my phone. Signed up for udemy, but couldn't get it to work so came back here in used the link, now it works.\n\nI checked in a new browser that I could still access it directly via udemy and its in my courses, so backed the reddit tab back here again.\n\nAll good now.",
            "I have recreated it again on the course introduction video where there are at least 2 buffer points. It doesn't seem to happen on any of the actual content videos however.",
            "How you acquire a course, on Udemy, has no bearing on whether or not you get a cert.  That's defined by the course, and as long as you complete it you get the cert.",
            "Thank you I guess it\u2019s because I didn\u2019t use the link I just went through my own account. But I got it!",
            "Thank you so much!"
        ]
    }
}